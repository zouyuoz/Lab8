{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dceedafe-2782-41a1-8119-50ee3d6c21fd",
   "metadata": {},
   "source": [
    "# 2025 DL Lab8: RL Assignment_Super Mario World"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fa555a-e61c-4fb3-b5d0-289b66570139",
   "metadata": {},
   "source": [
    "**Your Answer:**    \n",
    "Hi I'm XXX, XXXXXXXXXX."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5b0974-9605-488a-9fd5-00816e7832cc",
   "metadata": {},
   "source": [
    "## Overview\n",
    "This project implements a **Deep Reinforcement Learning** pipeline to train an autonomous agent for Super Mario World. Leveraging the **Proximal Policy Optimization (PPO)** algorithm, the system interacts with the **stable-retro** environment to master the YoshiIsland1 level. Key components include a custom Vision Backbone for extracting features from raw pixel data and a suite of Environment Wrappers that handle frame preprocessing, action discretization, and reward shaping to facilitate efficient learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02696447",
   "metadata": {},
   "source": [
    "Reward function implement  \n",
    "should do something in the beginning (monster attack)  \n",
    "Custom PPO implement  \n",
    "pre train weight 差不多，主要是 reward function  \n",
    "model weight capacity 1GB  \n",
    "class name 不要動 (可以新增，但是原本有的不要動)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8a0ab9-f86d-4038-833d-761ec81fc4f2",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00b10def-362c-4910-9ed0-f3d0904343ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/m314834001/Lab8/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import retro\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, SubprocVecEnv\n",
    "from stable_baselines3.common.vec_env import VecNormalize\n",
    "\n",
    "from eval import evaluate_policy, record_video\n",
    "from custom_policy import VisionBackbonePolicy, CustomPPO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10361fd-f291-4d93-b50d-cc749a3af588",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4f6a25-738c-49dd-8e66-ae164b74a45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Game Settings\n",
    "GAME = \"SuperMarioWorld-Snes\"\n",
    "STATE = \"YoshiIsland1\"\n",
    "\n",
    "# Training Settings\n",
    "BASE_CHUNK  = 8192\n",
    "TRAIN_CHUNK = BASE_CHUNK * 32\n",
    "TOTAL_STEPS = TRAIN_CHUNK * 160\n",
    "N_ENVS = 16\n",
    "\n",
    "# Evaluation & Recording Settingsc\n",
    "EVAL_EPISODES = 3\n",
    "EVAL_MAX_STEPS = 18000\n",
    "RECORD_STEPS = 1200\n",
    "\n",
    "# Directories\n",
    "LOG_DIR = \"./runs_smw\"\n",
    "VIDEO_DIR       = os.path.join(LOG_DIR, \"videos\")\n",
    "CKPT_DIR        = os.path.join(LOG_DIR, \"checkpoints\")\n",
    "TENSORBOARD_LOG = os.path.join(LOG_DIR, \"tb\")\n",
    "\n",
    "os.makedirs(LOG_DIR,   exist_ok=True)\n",
    "os.makedirs(CKPT_DIR,  exist_ok=True)\n",
    "os.makedirs(VIDEO_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a34b783-0273-4835-ad2e-f9186064f76f",
   "metadata": {},
   "source": [
    "## Environment Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c34213d-2c7c-42b8-922d-bafa285d1ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wrappers import make_base_env\n",
    "def _make_env_thunk(game: str, state: str):\n",
    "    \"\"\"Return a function that creates an environment (for multiprocessing).\"\"\"\n",
    "    def _thunk():\n",
    "        return make_base_env(game, state)\n",
    "    return _thunk\n",
    "\n",
    "def make_vec_env(game: str, state: str, n_envs: int, use_subproc: bool = True):\n",
    "    \"\"\"Create a vectorized environment (multiple envs running in parallel).\"\"\"\n",
    "    env_fns = [_make_env_thunk(game, state) for _ in range(n_envs)]\n",
    "    \n",
    "    if use_subproc and n_envs > 1:\n",
    "        vec_env = SubprocVecEnv(env_fns)\n",
    "    else:\n",
    "        vec_env = DummyVecEnv(env_fns)\n",
    "\n",
    "    return vec_env"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71dff476-ea2e-4262-8780-afb32ef1b233",
   "metadata": {},
   "source": [
    "## Initialize Env & Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8c7c5fe-6421-4dbc-9bd8-822d61769c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment created: SuperMarioWorld-Snes - YoshiIsland1 with 16 parallel envs.\n",
      "[Sucess] Loaded model from runs_smw/checkpoints/Run_41.zip\n",
      "trained: 11010048, round_index: 42\n"
     ]
    }
   ],
   "source": [
    "# 1. Create Training Environment\n",
    "train_env = make_vec_env(GAME, STATE, n_envs=N_ENVS)\n",
    "# train_env = VecNormalize(train_env, norm_obs=True, norm_reward=True, clip_obs=10., clip_reward=10.)\n",
    "print(f\"Environment created: {GAME} - {STATE} with {N_ENVS} parallel envs.\")\n",
    "\n",
    "checkpoint_path = \"None\"\n",
    "checkpoint_path = \"runs_smw/checkpoints/Run_41.zip\"\n",
    "\n",
    "best_mean = -1e18\n",
    "trained = 0\n",
    "round_idx = 0\n",
    "\n",
    "# 2. Initialize Model\n",
    "if os.path.exists(checkpoint_path):\n",
    "    # 讀取現有模型\n",
    "    model = CustomPPO.load(\n",
    "        checkpoint_path, \n",
    "        env=train_env,\n",
    "        device=\"cuda:0\" # 確保使用 GPU\n",
    "    )\n",
    "    trained = model.num_timesteps\n",
    "    round_idx = int(trained / TRAIN_CHUNK)\n",
    "    print(f\"[Sucess] Loaded model from {checkpoint_path}\")\n",
    "    print(f\"trained: {trained}, round_index: {round_idx}\")\n",
    "else:\n",
    "    print(f\"[Fail] Can't load {checkpoint_path}. Will use new model\")\n",
    "    model = CustomPPO(\n",
    "        VisionBackbonePolicy,\n",
    "        train_env,\n",
    "        policy_kwargs   = dict(normalize_images=False),\n",
    "        n_epochs        = 4,\n",
    "        n_steps         = 512,\n",
    "        batch_size      = 512,\n",
    "        learning_rate   = 1e-4,\n",
    "        verbose         = 1,\n",
    "        gamma           = 0.96875,\n",
    "        kl_coef         = 1,\n",
    "        clip_range      = 0.125,\n",
    "        ent_coef        = 0.0375,\n",
    "        tensorboard_log = TENSORBOARD_LOG,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb7a896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from custom_policy import CustomPPO\n",
    "# from wrappers import make_base_env  # [新增] 必須引入這行來建立環境\n",
    "\n",
    "# # ================= 設定區 =================\n",
    "# # 請確保這些變數有被定義 (這裡沿用你原本的變數名稱)\n",
    "# # GAME = \"SuperMarioWorld-Snes\"\n",
    "# # STATE = \"Level1\" \n",
    "# # CKPT_DIR = \"./\"\n",
    "# # RECORD_STEPS = 2000\n",
    "# PSVD_DIR = \"./runs_smw/preserved/\"\n",
    "\n",
    "# target_numbers = list(range(70, 128))\n",
    "# # target_numbers = [124, 137, 147, 151, 179]\n",
    "\n",
    "# # ================= 執行迴圈 =================\n",
    "# for num in target_numbers:\n",
    "#     model_path = os.path.join(CKPT_DIR, f\"S2K_{num}.zip\")\n",
    "    \n",
    "#     if not os.path.exists(model_path):\n",
    "#         # print(f\"⚠️ 找不到檔案: {model_path}，跳過。\")\n",
    "#         continue\n",
    "    \n",
    "#     # print(f\"\\n[{num}] 正在載入模型: {model_path} ...\")\n",
    "    \n",
    "#     env = None\n",
    "#     try:\n",
    "#         model = CustomPPO.load(model_path, device=\"auto\")\n",
    "#         env = make_base_env(game=GAME, state=STATE)\n",
    "        \n",
    "#         obs, info = env.reset()\n",
    "#         final_score = 0\n",
    "#         final_coins = 0 # [新增] 初始化金幣紀錄\n",
    "        \n",
    "#         for step in range(RECORD_STEPS):\n",
    "#             action, _ = model.predict(obs, deterministic=True)\n",
    "#             obs, reward, terminated, truncated, info = env.step(action)\n",
    "            \n",
    "#             # 從 info 中讀取當前數值 \n",
    "#             final_score = info.get(\"score\", final_score)\n",
    "#             final_coins = info.get(\"coins\", final_coins)\n",
    "            \n",
    "#             if terminated or truncated:\n",
    "#                 break\n",
    "        \n",
    "#         # 修改後的印出格式\n",
    "#         print(f\"[{num}] coins: {final_coins} | score: {final_score}\")\n",
    "        \n",
    "#     except Exception as e:\n",
    "#         print(f\"❌ 發生錯誤 (Model: {num}): {e}\")\n",
    "#     finally:\n",
    "#         if env is not None:\n",
    "#             env.close()\n",
    "\n",
    "# print(\"\\n所有測試結束。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdfff83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import glob\n",
    "# from custom_policy import CustomPPO\n",
    "# from eval import record_video  # 確保 eval.py 在同一目錄下\n",
    "# PSVD_DIR = \"./runs_smw/preserved/\"\n",
    "# CKPT_DIR\n",
    "# # ================= 設定區 =================\n",
    "# # target_numbers = list(range(38, 40))\n",
    "# target_numbers = [126]\n",
    "\n",
    "# # ================= 執行迴圈 =================\n",
    "# print(f\"準備測試以下 Checkpoints: {target_numbers}\")\n",
    "\n",
    "# for num in target_numbers:\n",
    "#     model_path = os.path.join(PSVD_DIR, f\"S2K_{num}.zip\")\n",
    "    \n",
    "#     # 檢查檔案是否存在\n",
    "#     if not os.path.exists(model_path):\n",
    "#         print(f\"⚠️ 找不到檔案: {model_path}，跳過。\")\n",
    "#         continue\n",
    "    \n",
    "#     print(f\"\\n[{num}] 正在載入模型: {model_path} ...\")\n",
    "    \n",
    "#     try:\n",
    "#         # 1. 載入模型 (不需要 env 參數也能載入權重)\n",
    "#         # 如果你有改過 CustomPPO 的參數，load 會自動讀取 zip 裡的設定\n",
    "#         model = CustomPPO.load(model_path, device=\"auto\") # device=\"auto\" 會自動用 GPU\n",
    "        \n",
    "#         # 2. 錄製影片\n",
    "#         prefix_name = f\"test_{num}\"\n",
    "#         print(f\"[{num}] 正在錄影 (長度 {RECORD_STEPS} steps)...\")\n",
    "        \n",
    "#         record_video(\n",
    "#             model=model,\n",
    "#             game=GAME,\n",
    "#             state=STATE,\n",
    "#             out_dir=VIDEO_DIR,\n",
    "#             video_len=RECORD_STEPS,\n",
    "#             prefix=prefix_name\n",
    "#         )\n",
    "#         print(f\"✅ 完成！影片已儲存為 {prefix_name}.mp4\")\n",
    "        \n",
    "#     except Exception as e:\n",
    "#         print(f\"❌ 發生錯誤 (Model: {num}): {e}\")\n",
    "\n",
    "# print(\"\\n所有測試結束。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f594e443-843f-42c1-9fc6-3fbc82962021",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3af4932-c531-4113-a33a-defc6fb5858e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Round 43 | Learn 262144 steps (Total trained: 11010048) ===\n",
      "Logging to ./runs_smw/tb/Run_0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/m314834001/Lab8/.venv/lib/python3.12/site-packages/rich/live.py:256: UserWarning: install \"ipywidgets\" for \n",
       "Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/m314834001/Lab8/.venv/lib/python3.12/site-packages/rich/live.py:256: UserWarning: install \"ipywidgets\" for \n",
       "Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1043     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 11018240 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 878         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 11026432    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01558065  |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.894       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0654      |\n",
      "|    mean_step_reward   | 0.068051636 |\n",
      "|    n_updates          | 3.12 %      |\n",
      "|    policyGradLoss     | -0.0105     |\n",
      "|    value_loss         | 0.497       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 829         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 29          |\n",
      "|    total_timesteps    | 11034624    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01996505  |\n",
      "|    entropy_loss       | -2.04       |\n",
      "|    explained_variance | 0.936       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0293     |\n",
      "|    mean_step_reward   | 0.055073954 |\n",
      "|    n_updates          | 6.25 %      |\n",
      "|    policyGradLoss     | -0.017      |\n",
      "|    value_loss         | 0.254       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 811         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 40          |\n",
      "|    total_timesteps    | 11042816    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019037109 |\n",
      "|    entropy_loss       | -2.01       |\n",
      "|    explained_variance | 0.932       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0152      |\n",
      "|    mean_step_reward   | 0.054494385 |\n",
      "|    n_updates          | 9.38 %      |\n",
      "|    policyGradLoss     | -0.0157     |\n",
      "|    value_loss         | 0.304       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 799         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 51          |\n",
      "|    total_timesteps    | 11051008    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018613447 |\n",
      "|    entropy_loss       | -2          |\n",
      "|    explained_variance | 0.936       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00933    |\n",
      "|    mean_step_reward   | 0.054255933 |\n",
      "|    n_updates          | 12.50 %     |\n",
      "|    policyGradLoss     | -0.0224     |\n",
      "|    value_loss         | 0.246       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 792         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 62          |\n",
      "|    total_timesteps    | 11059200    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014373497 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.922       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0331      |\n",
      "|    mean_step_reward   | 0.052077897 |\n",
      "|    n_updates          | 15.62 %     |\n",
      "|    policyGradLoss     | -0.0122     |\n",
      "|    value_loss         | 0.484       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 72          |\n",
      "|    total_timesteps    | 11067392    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019109149 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.945       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0216     |\n",
      "|    mean_step_reward   | 0.0666112   |\n",
      "|    n_updates          | 18.75 %     |\n",
      "|    policyGradLoss     | -0.0166     |\n",
      "|    value_loss         | 0.295       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 83          |\n",
      "|    total_timesteps    | 11075584    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020785809 |\n",
      "|    entropy_loss       | -1.97       |\n",
      "|    explained_variance | 0.941       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0309      |\n",
      "|    mean_step_reward   | 0.071486905 |\n",
      "|    n_updates          | 21.88 %     |\n",
      "|    policyGradLoss     | -0.016      |\n",
      "|    value_loss         | 0.337       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 93          |\n",
      "|    total_timesteps    | 11083776    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01765269  |\n",
      "|    entropy_loss       | -1.99       |\n",
      "|    explained_variance | 0.922       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0166      |\n",
      "|    mean_step_reward   | 0.055655595 |\n",
      "|    n_updates          | 25.00 %     |\n",
      "|    policyGradLoss     | -0.0186     |\n",
      "|    value_loss         | 0.376       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 783        |\n",
      "|    iterations         | 10         |\n",
      "|    time_elapsed       | 104        |\n",
      "|    total_timesteps    | 11091968   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01798756 |\n",
      "|    entropy_loss       | -1.97      |\n",
      "|    explained_variance | 0.912      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0381    |\n",
      "|    mean_step_reward   | 0.05325123 |\n",
      "|    n_updates          | 28.12 %    |\n",
      "|    policyGradLoss     | -0.0144    |\n",
      "|    value_loss         | 0.312      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 115         |\n",
      "|    total_timesteps    | 11100160    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018978933 |\n",
      "|    entropy_loss       | -1.98       |\n",
      "|    explained_variance | 0.925       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0245     |\n",
      "|    mean_step_reward   | 0.068422444 |\n",
      "|    n_updates          | 31.25 %     |\n",
      "|    policyGradLoss     | -0.0129     |\n",
      "|    value_loss         | 0.33        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 126         |\n",
      "|    total_timesteps    | 11108352    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018420251 |\n",
      "|    entropy_loss       | -2          |\n",
      "|    explained_variance | 0.926       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0971      |\n",
      "|    mean_step_reward   | 0.0594896   |\n",
      "|    n_updates          | 34.38 %     |\n",
      "|    policyGradLoss     | -0.0167     |\n",
      "|    value_loss         | 0.408       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 137         |\n",
      "|    total_timesteps    | 11116544    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015320822 |\n",
      "|    entropy_loss       | -1.97       |\n",
      "|    explained_variance | 0.91        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00887     |\n",
      "|    mean_step_reward   | 0.076735996 |\n",
      "|    n_updates          | 37.50 %     |\n",
      "|    policyGradLoss     | -0.0111     |\n",
      "|    value_loss         | 0.366       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 774        |\n",
      "|    iterations         | 14         |\n",
      "|    time_elapsed       | 148        |\n",
      "|    total_timesteps    | 11124736   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01738219 |\n",
      "|    entropy_loss       | -1.98      |\n",
      "|    explained_variance | 0.881      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.00246   |\n",
      "|    mean_step_reward   | 0.05903866 |\n",
      "|    n_updates          | 40.62 %    |\n",
      "|    policyGradLoss     | -0.0165    |\n",
      "|    value_loss         | 0.382      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 158         |\n",
      "|    total_timesteps    | 11132928    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016317617 |\n",
      "|    entropy_loss       | -1.99       |\n",
      "|    explained_variance | 0.908       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00688    |\n",
      "|    mean_step_reward   | 0.079300895 |\n",
      "|    n_updates          | 43.75 %     |\n",
      "|    policyGradLoss     | -0.015      |\n",
      "|    value_loss         | 0.323       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 169         |\n",
      "|    total_timesteps    | 11141120    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018611636 |\n",
      "|    entropy_loss       | -2.01       |\n",
      "|    explained_variance | 0.907       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0183      |\n",
      "|    mean_step_reward   | 0.07384749  |\n",
      "|    n_updates          | 46.88 %     |\n",
      "|    policyGradLoss     | -0.0148     |\n",
      "|    value_loss         | 0.274       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 180         |\n",
      "|    total_timesteps    | 11149312    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019230401 |\n",
      "|    entropy_loss       | -1.99       |\n",
      "|    explained_variance | 0.927       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0134     |\n",
      "|    mean_step_reward   | 0.075535804 |\n",
      "|    n_updates          | 50.00 %     |\n",
      "|    policyGradLoss     | -0.0168     |\n",
      "|    value_loss         | 0.283       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 190         |\n",
      "|    total_timesteps    | 11157504    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024371255 |\n",
      "|    entropy_loss       | -1.98       |\n",
      "|    explained_variance | 0.913       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00834     |\n",
      "|    mean_step_reward   | 0.05569055  |\n",
      "|    n_updates          | 53.12 %     |\n",
      "|    policyGradLoss     | -0.0197     |\n",
      "|    value_loss         | 0.276       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 772        |\n",
      "|    iterations         | 19         |\n",
      "|    time_elapsed       | 201        |\n",
      "|    total_timesteps    | 11165696   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02063562 |\n",
      "|    entropy_loss       | -2.03      |\n",
      "|    explained_variance | 0.912      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.00719    |\n",
      "|    mean_step_reward   | 0.07095322 |\n",
      "|    n_updates          | 56.25 %    |\n",
      "|    policyGradLoss     | -0.0121    |\n",
      "|    value_loss         | 0.391      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 212         |\n",
      "|    total_timesteps    | 11173888    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016031422 |\n",
      "|    entropy_loss       | -1.99       |\n",
      "|    explained_variance | 0.9         |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0526      |\n",
      "|    mean_step_reward   | 0.07488747  |\n",
      "|    n_updates          | 59.38 %     |\n",
      "|    policyGradLoss     | -0.012      |\n",
      "|    value_loss         | 0.334       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 222         |\n",
      "|    total_timesteps    | 11182080    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018339112 |\n",
      "|    entropy_loss       | -2.03       |\n",
      "|    explained_variance | 0.928       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00534    |\n",
      "|    mean_step_reward   | 0.055899974 |\n",
      "|    n_updates          | 62.50 %     |\n",
      "|    policyGradLoss     | -0.0211     |\n",
      "|    value_loss         | 0.256       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 233         |\n",
      "|    total_timesteps    | 11190272    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015824178 |\n",
      "|    entropy_loss       | -2.03       |\n",
      "|    explained_variance | 0.903       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0158     |\n",
      "|    mean_step_reward   | 0.06742863  |\n",
      "|    n_updates          | 65.62 %     |\n",
      "|    policyGradLoss     | -0.0161     |\n",
      "|    value_loss         | 0.34        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 244         |\n",
      "|    total_timesteps    | 11198464    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016172841 |\n",
      "|    entropy_loss       | -2.02       |\n",
      "|    explained_variance | 0.914       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00197    |\n",
      "|    mean_step_reward   | 0.06213875  |\n",
      "|    n_updates          | 68.75 %     |\n",
      "|    policyGradLoss     | -0.0146     |\n",
      "|    value_loss         | 0.391       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 255         |\n",
      "|    total_timesteps    | 11206656    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013861375 |\n",
      "|    entropy_loss       | -2.03       |\n",
      "|    explained_variance | 0.947       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0342     |\n",
      "|    mean_step_reward   | 0.08102159  |\n",
      "|    n_updates          | 71.88 %     |\n",
      "|    policyGradLoss     | -0.0117     |\n",
      "|    value_loss         | 0.318       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 266         |\n",
      "|    total_timesteps    | 11214848    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013701215 |\n",
      "|    entropy_loss       | -2.04       |\n",
      "|    explained_variance | 0.883       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.038       |\n",
      "|    mean_step_reward   | 0.060437184 |\n",
      "|    n_updates          | 75.00 %     |\n",
      "|    policyGradLoss     | -0.0135     |\n",
      "|    value_loss         | 0.379       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 276         |\n",
      "|    total_timesteps    | 11223040    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013180193 |\n",
      "|    entropy_loss       | -2.03       |\n",
      "|    explained_variance | 0.926       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0223      |\n",
      "|    mean_step_reward   | 0.054372482 |\n",
      "|    n_updates          | 78.12 %     |\n",
      "|    policyGradLoss     | -0.0147     |\n",
      "|    value_loss         | 0.357       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 287         |\n",
      "|    total_timesteps    | 11231232    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016633369 |\n",
      "|    entropy_loss       | -2.03       |\n",
      "|    explained_variance | 0.927       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0578      |\n",
      "|    mean_step_reward   | 0.06561513  |\n",
      "|    n_updates          | 81.25 %     |\n",
      "|    policyGradLoss     | -0.018      |\n",
      "|    value_loss         | 0.365       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 298         |\n",
      "|    total_timesteps    | 11239424    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01689888  |\n",
      "|    entropy_loss       | -2.03       |\n",
      "|    explained_variance | 0.931       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00311     |\n",
      "|    mean_step_reward   | 0.052121587 |\n",
      "|    n_updates          | 84.38 %     |\n",
      "|    policyGradLoss     | -0.0171     |\n",
      "|    value_loss         | 0.321       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 309         |\n",
      "|    total_timesteps    | 11247616    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016658694 |\n",
      "|    entropy_loss       | -2.04       |\n",
      "|    explained_variance | 0.892       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0684      |\n",
      "|    mean_step_reward   | 0.051513683 |\n",
      "|    n_updates          | 87.50 %     |\n",
      "|    policyGradLoss     | -0.0166     |\n",
      "|    value_loss         | 0.31        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 320         |\n",
      "|    total_timesteps    | 11255808    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019143358 |\n",
      "|    entropy_loss       | -2.03       |\n",
      "|    explained_variance | 0.92        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0358      |\n",
      "|    mean_step_reward   | 0.046305444 |\n",
      "|    n_updates          | 90.62 %     |\n",
      "|    policyGradLoss     | -0.017      |\n",
      "|    value_loss         | 0.424       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 331         |\n",
      "|    total_timesteps    | 11264000    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015019603 |\n",
      "|    entropy_loss       | -2.03       |\n",
      "|    explained_variance | 0.928       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00692     |\n",
      "|    mean_step_reward   | 0.06527822  |\n",
      "|    n_updates          | 93.75 %     |\n",
      "|    policyGradLoss     | -0.015      |\n",
      "|    value_loss         | 0.339       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 341         |\n",
      "|    total_timesteps    | 11272192    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020688634 |\n",
      "|    entropy_loss       | -1.99       |\n",
      "|    explained_variance | 0.929       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0248      |\n",
      "|    mean_step_reward   | 0.055929393 |\n",
      "|    n_updates          | 96.88 %     |\n",
      "|    policyGradLoss     | -0.0171     |\n",
      "|    value_loss         | 0.306       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Run_42.zip\n",
      "[EVAL] Mean Return: 18.363, Best Return: 19.696\n",
      "Saved video to ./runs_smw/videos/Run/Run_42_18.36.mp4\n",
      "\n",
      "=== Round 44 | Learn 262144 steps (Total trained: 11272192) ===\n",
      "Logging to ./runs_smw/tb/Run_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1143     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 11280384 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 912         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 11288576    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021025116 |\n",
      "|    entropy_loss       | -2.01       |\n",
      "|    explained_variance | 0.901       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0317      |\n",
      "|    mean_step_reward   | 0.06252679  |\n",
      "|    n_updates          | 3.12 %      |\n",
      "|    policyGradLoss     | -0.0181     |\n",
      "|    value_loss         | 0.288       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 855         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 11296768    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014575517 |\n",
      "|    entropy_loss       | -2          |\n",
      "|    explained_variance | 0.923       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0502      |\n",
      "|    mean_step_reward   | 0.06595749  |\n",
      "|    n_updates          | 6.25 %      |\n",
      "|    policyGradLoss     | -0.0161     |\n",
      "|    value_loss         | 0.403       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 824         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 11304960    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019193226 |\n",
      "|    entropy_loss       | -1.99       |\n",
      "|    explained_variance | 0.942       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0178      |\n",
      "|    mean_step_reward   | 0.06836192  |\n",
      "|    n_updates          | 9.38 %      |\n",
      "|    policyGradLoss     | -0.0189     |\n",
      "|    value_loss         | 0.361       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 813         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 50          |\n",
      "|    total_timesteps    | 11313152    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020272158 |\n",
      "|    entropy_loss       | -2.01       |\n",
      "|    explained_variance | 0.934       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0589     |\n",
      "|    mean_step_reward   | 0.060992368 |\n",
      "|    n_updates          | 12.50 %     |\n",
      "|    policyGradLoss     | -0.0187     |\n",
      "|    value_loss         | 0.195       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 803         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 61          |\n",
      "|    total_timesteps    | 11321344    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018360822 |\n",
      "|    entropy_loss       | -2          |\n",
      "|    explained_variance | 0.909       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0405     |\n",
      "|    mean_step_reward   | 0.0725367   |\n",
      "|    n_updates          | 15.62 %     |\n",
      "|    policyGradLoss     | -0.0152     |\n",
      "|    value_loss         | 0.238       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 797         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 71          |\n",
      "|    total_timesteps    | 11329536    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019685654 |\n",
      "|    entropy_loss       | -2.01       |\n",
      "|    explained_variance | 0.912       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00946     |\n",
      "|    mean_step_reward   | 0.058757536 |\n",
      "|    n_updates          | 18.75 %     |\n",
      "|    policyGradLoss     | -0.0161     |\n",
      "|    value_loss         | 0.318       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 793         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 82          |\n",
      "|    total_timesteps    | 11337728    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017983336 |\n",
      "|    entropy_loss       | -2.01       |\n",
      "|    explained_variance | 0.94        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0465     |\n",
      "|    mean_step_reward   | 0.07437824  |\n",
      "|    n_updates          | 21.88 %     |\n",
      "|    policyGradLoss     | -0.0189     |\n",
      "|    value_loss         | 0.249       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 789         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 93          |\n",
      "|    total_timesteps    | 11345920    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025047645 |\n",
      "|    entropy_loss       | -1.99       |\n",
      "|    explained_variance | 0.934       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0054     |\n",
      "|    mean_step_reward   | 0.06006563  |\n",
      "|    n_updates          | 25.00 %     |\n",
      "|    policyGradLoss     | -0.0232     |\n",
      "|    value_loss         | 0.316       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 104         |\n",
      "|    total_timesteps    | 11354112    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016408423 |\n",
      "|    entropy_loss       | -1.99       |\n",
      "|    explained_variance | 0.936       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0254      |\n",
      "|    mean_step_reward   | 0.07265079  |\n",
      "|    n_updates          | 28.12 %     |\n",
      "|    policyGradLoss     | -0.0144     |\n",
      "|    value_loss         | 0.37        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 114         |\n",
      "|    total_timesteps    | 11362304    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019755475 |\n",
      "|    entropy_loss       | -1.98       |\n",
      "|    explained_variance | 0.891       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0373      |\n",
      "|    mean_step_reward   | 0.049036425 |\n",
      "|    n_updates          | 31.25 %     |\n",
      "|    policyGradLoss     | -0.0151     |\n",
      "|    value_loss         | 0.444       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 125         |\n",
      "|    total_timesteps    | 11370496    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017815517 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.931       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0384     |\n",
      "|    mean_step_reward   | 0.08320738  |\n",
      "|    n_updates          | 34.38 %     |\n",
      "|    policyGradLoss     | -0.0131     |\n",
      "|    value_loss         | 0.347       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 136         |\n",
      "|    total_timesteps    | 11378688    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015283186 |\n",
      "|    entropy_loss       | -1.99       |\n",
      "|    explained_variance | 0.918       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0176     |\n",
      "|    mean_step_reward   | 0.055048514 |\n",
      "|    n_updates          | 37.50 %     |\n",
      "|    policyGradLoss     | -0.0139     |\n",
      "|    value_loss         | 0.38        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 147         |\n",
      "|    total_timesteps    | 11386880    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017273325 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.942       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.085       |\n",
      "|    mean_step_reward   | 0.068274185 |\n",
      "|    n_updates          | 40.62 %     |\n",
      "|    policyGradLoss     | -0.0154     |\n",
      "|    value_loss         | 0.465       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 158         |\n",
      "|    total_timesteps    | 11395072    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018730119 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.928       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0396      |\n",
      "|    mean_step_reward   | 0.055454433 |\n",
      "|    n_updates          | 43.75 %     |\n",
      "|    policyGradLoss     | -0.0183     |\n",
      "|    value_loss         | 0.331       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 168         |\n",
      "|    total_timesteps    | 11403264    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020722888 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.943       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.023      |\n",
      "|    mean_step_reward   | 0.06642844  |\n",
      "|    n_updates          | 46.88 %     |\n",
      "|    policyGradLoss     | -0.0188     |\n",
      "|    value_loss         | 0.281       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 179         |\n",
      "|    total_timesteps    | 11411456    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022426844 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.942       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0661     |\n",
      "|    mean_step_reward   | 0.07127322  |\n",
      "|    n_updates          | 50.00 %     |\n",
      "|    policyGradLoss     | -0.0195     |\n",
      "|    value_loss         | 0.244       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 190         |\n",
      "|    total_timesteps    | 11419648    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016690526 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.917       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0391      |\n",
      "|    mean_step_reward   | 0.06342939  |\n",
      "|    n_updates          | 53.12 %     |\n",
      "|    policyGradLoss     | -0.0138     |\n",
      "|    value_loss         | 0.4         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 200         |\n",
      "|    total_timesteps    | 11427840    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019751407 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.922       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0134      |\n",
      "|    mean_step_reward   | 0.0767294   |\n",
      "|    n_updates          | 56.25 %     |\n",
      "|    policyGradLoss     | -0.0151     |\n",
      "|    value_loss         | 0.337       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 211         |\n",
      "|    total_timesteps    | 11436032    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029041518 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.944       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0382     |\n",
      "|    mean_step_reward   | 0.070063934 |\n",
      "|    n_updates          | 59.38 %     |\n",
      "|    policyGradLoss     | -0.0224     |\n",
      "|    value_loss         | 0.213       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 222         |\n",
      "|    total_timesteps    | 11444224    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015090534 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.915       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0288      |\n",
      "|    mean_step_reward   | 0.06039238  |\n",
      "|    n_updates          | 62.50 %     |\n",
      "|    policyGradLoss     | -0.016      |\n",
      "|    value_loss         | 0.385       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 233         |\n",
      "|    total_timesteps    | 11452416    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021622434 |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.935       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0185     |\n",
      "|    mean_step_reward   | 0.060863722 |\n",
      "|    n_updates          | 65.62 %     |\n",
      "|    policyGradLoss     | -0.0176     |\n",
      "|    value_loss         | 0.378       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 242         |\n",
      "|    total_timesteps    | 11460608    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01757878  |\n",
      "|    entropy_loss       | -1.97       |\n",
      "|    explained_variance | 0.911       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0103      |\n",
      "|    mean_step_reward   | 0.068808675 |\n",
      "|    n_updates          | 68.75 %     |\n",
      "|    policyGradLoss     | -0.0141     |\n",
      "|    value_loss         | 0.307       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 253         |\n",
      "|    total_timesteps    | 11468800    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016953424 |\n",
      "|    entropy_loss       | -1.98       |\n",
      "|    explained_variance | 0.921       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0421      |\n",
      "|    mean_step_reward   | 0.086637266 |\n",
      "|    n_updates          | 71.88 %     |\n",
      "|    policyGradLoss     | -0.0159     |\n",
      "|    value_loss         | 0.348       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 264         |\n",
      "|    total_timesteps    | 11476992    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021436173 |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.945       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0185      |\n",
      "|    mean_step_reward   | 0.06498179  |\n",
      "|    n_updates          | 75.00 %     |\n",
      "|    policyGradLoss     | -0.0178     |\n",
      "|    value_loss         | 0.276       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 275         |\n",
      "|    total_timesteps    | 11485184    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020540424 |\n",
      "|    entropy_loss       | -1.97       |\n",
      "|    explained_variance | 0.942       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0301     |\n",
      "|    mean_step_reward   | 0.064129785 |\n",
      "|    n_updates          | 78.12 %     |\n",
      "|    policyGradLoss     | -0.0193     |\n",
      "|    value_loss         | 0.269       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 285         |\n",
      "|    total_timesteps    | 11493376    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014581764 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.94        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00376     |\n",
      "|    mean_step_reward   | 0.076424025 |\n",
      "|    n_updates          | 81.25 %     |\n",
      "|    policyGradLoss     | -0.0171     |\n",
      "|    value_loss         | 0.319       |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 773       |\n",
      "|    iterations         | 28        |\n",
      "|    time_elapsed       | 296       |\n",
      "|    total_timesteps    | 11501568  |\n",
      "| train/                |           |\n",
      "|    approx_kl          | 0.0188366 |\n",
      "|    entropy_loss       | -1.95     |\n",
      "|    explained_variance | 0.936     |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    loss               | 0.00757   |\n",
      "|    mean_step_reward   | 0.0793835 |\n",
      "|    n_updates          | 84.38 %   |\n",
      "|    policyGradLoss     | -0.0156   |\n",
      "|    value_loss         | 0.325     |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 307         |\n",
      "|    total_timesteps    | 11509760    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015560025 |\n",
      "|    entropy_loss       | -2          |\n",
      "|    explained_variance | 0.925       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0137     |\n",
      "|    mean_step_reward   | 0.060475677 |\n",
      "|    n_updates          | 87.50 %     |\n",
      "|    policyGradLoss     | -0.0149     |\n",
      "|    value_loss         | 0.375       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 317         |\n",
      "|    total_timesteps    | 11517952    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020871803 |\n",
      "|    entropy_loss       | -1.99       |\n",
      "|    explained_variance | 0.943       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.014      |\n",
      "|    mean_step_reward   | 0.073911615 |\n",
      "|    n_updates          | 90.62 %     |\n",
      "|    policyGradLoss     | -0.0191     |\n",
      "|    value_loss         | 0.23        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 328         |\n",
      "|    total_timesteps    | 11526144    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015895126 |\n",
      "|    entropy_loss       | -1.98       |\n",
      "|    explained_variance | 0.943       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0497      |\n",
      "|    mean_step_reward   | 0.066187605 |\n",
      "|    n_updates          | 93.75 %     |\n",
      "|    policyGradLoss     | -0.0166     |\n",
      "|    value_loss         | 0.409       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 339         |\n",
      "|    total_timesteps    | 11534336    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013674609 |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.916       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00416    |\n",
      "|    mean_step_reward   | 0.06728897  |\n",
      "|    n_updates          | 96.88 %     |\n",
      "|    policyGradLoss     | -0.0163     |\n",
      "|    value_loss         | 0.376       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Run_43.zip\n",
      "[EVAL] Mean Return: 93.320, Best Return: 97.320\n",
      "Saved video to ./runs_smw/videos/Run/Run_43_93.32.mp4\n",
      "\n",
      "=== Round 45 | Learn 262144 steps (Total trained: 11534336) ===\n",
      "Logging to ./runs_smw/tb/Run_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1147     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 11542528 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 923         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 11550720    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015474277 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.904       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0301      |\n",
      "|    mean_step_reward   | 0.062937394 |\n",
      "|    n_updates          | 3.12 %      |\n",
      "|    policyGradLoss     | -0.0136     |\n",
      "|    value_loss         | 0.403       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 869         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 11558912    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016489465 |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.939       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0274      |\n",
      "|    mean_step_reward   | 0.074454315 |\n",
      "|    n_updates          | 6.25 %      |\n",
      "|    policyGradLoss     | -0.0141     |\n",
      "|    value_loss         | 0.355       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 844         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 38          |\n",
      "|    total_timesteps    | 11567104    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021417186 |\n",
      "|    entropy_loss       | -1.97       |\n",
      "|    explained_variance | 0.927       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.036      |\n",
      "|    mean_step_reward   | 0.054190096 |\n",
      "|    n_updates          | 9.38 %      |\n",
      "|    policyGradLoss     | -0.0221     |\n",
      "|    value_loss         | 0.276       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 822         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 49          |\n",
      "|    total_timesteps    | 11575296    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015696056 |\n",
      "|    entropy_loss       | -1.98       |\n",
      "|    explained_variance | 0.934       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0182     |\n",
      "|    mean_step_reward   | 0.08108586  |\n",
      "|    n_updates          | 12.50 %     |\n",
      "|    policyGradLoss     | -0.0134     |\n",
      "|    value_loss         | 0.276       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 807         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 60          |\n",
      "|    total_timesteps    | 11583488    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017865203 |\n",
      "|    entropy_loss       | -2.01       |\n",
      "|    explained_variance | 0.917       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00625     |\n",
      "|    mean_step_reward   | 0.046866335 |\n",
      "|    n_updates          | 15.62 %     |\n",
      "|    policyGradLoss     | -0.0149     |\n",
      "|    value_loss         | 0.287       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 800         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 71          |\n",
      "|    total_timesteps    | 11591680    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013937838 |\n",
      "|    entropy_loss       | -1.99       |\n",
      "|    explained_variance | 0.919       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0187      |\n",
      "|    mean_step_reward   | 0.06248136  |\n",
      "|    n_updates          | 18.75 %     |\n",
      "|    policyGradLoss     | -0.0144     |\n",
      "|    value_loss         | 0.328       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 796         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 82          |\n",
      "|    total_timesteps    | 11599872    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018340422 |\n",
      "|    entropy_loss       | -1.97       |\n",
      "|    explained_variance | 0.927       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00611     |\n",
      "|    mean_step_reward   | 0.07171728  |\n",
      "|    n_updates          | 21.88 %     |\n",
      "|    policyGradLoss     | -0.0163     |\n",
      "|    value_loss         | 0.372       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 792          |\n",
      "|    iterations         | 9            |\n",
      "|    time_elapsed       | 93           |\n",
      "|    total_timesteps    | 11608064     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0149383545 |\n",
      "|    entropy_loss       | -1.95        |\n",
      "|    explained_variance | 0.935        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.031       |\n",
      "|    mean_step_reward   | 0.06653555   |\n",
      "|    n_updates          | 25.00 %      |\n",
      "|    policyGradLoss     | -0.0175      |\n",
      "|    value_loss         | 0.343        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 789         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 103         |\n",
      "|    total_timesteps    | 11616256    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015971253 |\n",
      "|    entropy_loss       | -1.97       |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0133     |\n",
      "|    mean_step_reward   | 0.07209951  |\n",
      "|    n_updates          | 28.12 %     |\n",
      "|    policyGradLoss     | -0.0201     |\n",
      "|    value_loss         | 0.258       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 114         |\n",
      "|    total_timesteps    | 11624448    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018191608 |\n",
      "|    entropy_loss       | -1.99       |\n",
      "|    explained_variance | 0.948       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00288    |\n",
      "|    mean_step_reward   | 0.07323773  |\n",
      "|    n_updates          | 31.25 %     |\n",
      "|    policyGradLoss     | -0.0186     |\n",
      "|    value_loss         | 0.229       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 125         |\n",
      "|    total_timesteps    | 11632640    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019154094 |\n",
      "|    entropy_loss       | -1.97       |\n",
      "|    explained_variance | 0.936       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00737    |\n",
      "|    mean_step_reward   | 0.076290965 |\n",
      "|    n_updates          | 34.38 %     |\n",
      "|    policyGradLoss     | -0.0163     |\n",
      "|    value_loss         | 0.319       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 136         |\n",
      "|    total_timesteps    | 11640832    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016068405 |\n",
      "|    entropy_loss       | -1.97       |\n",
      "|    explained_variance | 0.926       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00291    |\n",
      "|    mean_step_reward   | 0.05899011  |\n",
      "|    n_updates          | 37.50 %     |\n",
      "|    policyGradLoss     | -0.0159     |\n",
      "|    value_loss         | 0.301       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 146         |\n",
      "|    total_timesteps    | 11649024    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023424562 |\n",
      "|    entropy_loss       | -1.97       |\n",
      "|    explained_variance | 0.95        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0208     |\n",
      "|    mean_step_reward   | 0.07448216  |\n",
      "|    n_updates          | 40.62 %     |\n",
      "|    policyGradLoss     | -0.0178     |\n",
      "|    value_loss         | 0.186       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 157         |\n",
      "|    total_timesteps    | 11657216    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018666748 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.936       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0166      |\n",
      "|    mean_step_reward   | 0.076856375 |\n",
      "|    n_updates          | 43.75 %     |\n",
      "|    policyGradLoss     | -0.0114     |\n",
      "|    value_loss         | 0.274       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 168         |\n",
      "|    total_timesteps    | 11665408    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016772205 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.957       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00311    |\n",
      "|    mean_step_reward   | 0.08426181  |\n",
      "|    n_updates          | 46.88 %     |\n",
      "|    policyGradLoss     | -0.0167     |\n",
      "|    value_loss         | 0.266       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 179         |\n",
      "|    total_timesteps    | 11673600    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025652051 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0446     |\n",
      "|    mean_step_reward   | 0.092151895 |\n",
      "|    n_updates          | 50.00 %     |\n",
      "|    policyGradLoss     | -0.0203     |\n",
      "|    value_loss         | 0.204       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 189         |\n",
      "|    total_timesteps    | 11681792    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027122427 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.957       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0432     |\n",
      "|    mean_step_reward   | 0.08339289  |\n",
      "|    n_updates          | 53.12 %     |\n",
      "|    policyGradLoss     | -0.0203     |\n",
      "|    value_loss         | 0.185       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 200         |\n",
      "|    total_timesteps    | 11689984    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021936059 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.948       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0291      |\n",
      "|    mean_step_reward   | 0.06494414  |\n",
      "|    n_updates          | 56.25 %     |\n",
      "|    policyGradLoss     | -0.0151     |\n",
      "|    value_loss         | 0.315       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 211         |\n",
      "|    total_timesteps    | 11698176    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020210426 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.957       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0309     |\n",
      "|    mean_step_reward   | 0.08926209  |\n",
      "|    n_updates          | 59.38 %     |\n",
      "|    policyGradLoss     | -0.0182     |\n",
      "|    value_loss         | 0.255       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 221         |\n",
      "|    total_timesteps    | 11706368    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016644355 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.87        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0249      |\n",
      "|    mean_step_reward   | 0.0725003   |\n",
      "|    n_updates          | 62.50 %     |\n",
      "|    policyGradLoss     | -0.0105     |\n",
      "|    value_loss         | 0.37        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 232         |\n",
      "|    total_timesteps    | 11714560    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018726524 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.939       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0306     |\n",
      "|    mean_step_reward   | 0.06918886  |\n",
      "|    n_updates          | 65.62 %     |\n",
      "|    policyGradLoss     | -0.0182     |\n",
      "|    value_loss         | 0.254       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 243         |\n",
      "|    total_timesteps    | 11722752    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020299619 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.948       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0166     |\n",
      "|    mean_step_reward   | 0.07903391  |\n",
      "|    n_updates          | 68.75 %     |\n",
      "|    policyGradLoss     | -0.0162     |\n",
      "|    value_loss         | 0.287       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 254         |\n",
      "|    total_timesteps    | 11730944    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02335208  |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.922       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0248     |\n",
      "|    mean_step_reward   | 0.059992936 |\n",
      "|    n_updates          | 71.88 %     |\n",
      "|    policyGradLoss     | -0.0179     |\n",
      "|    value_loss         | 0.251       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 264         |\n",
      "|    total_timesteps    | 11739136    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018648982 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.908       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0118      |\n",
      "|    mean_step_reward   | 0.06903258  |\n",
      "|    n_updates          | 75.00 %     |\n",
      "|    policyGradLoss     | -0.0161     |\n",
      "|    value_loss         | 0.363       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 275         |\n",
      "|    total_timesteps    | 11747328    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019459944 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.951       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0245     |\n",
      "|    mean_step_reward   | 0.08500673  |\n",
      "|    n_updates          | 78.12 %     |\n",
      "|    policyGradLoss     | -0.0191     |\n",
      "|    value_loss         | 0.226       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 286         |\n",
      "|    total_timesteps    | 11755520    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020428771 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.95        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0215     |\n",
      "|    mean_step_reward   | 0.07527143  |\n",
      "|    n_updates          | 81.25 %     |\n",
      "|    policyGradLoss     | -0.0184     |\n",
      "|    value_loss         | 0.249       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 297         |\n",
      "|    total_timesteps    | 11763712    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020433959 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.921       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -7.37e-05   |\n",
      "|    mean_step_reward   | 0.05757405  |\n",
      "|    n_updates          | 84.38 %     |\n",
      "|    policyGradLoss     | -0.0189     |\n",
      "|    value_loss         | 0.231       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 308         |\n",
      "|    total_timesteps    | 11771904    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019758765 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0449     |\n",
      "|    mean_step_reward   | 0.07866019  |\n",
      "|    n_updates          | 87.50 %     |\n",
      "|    policyGradLoss     | -0.018      |\n",
      "|    value_loss         | 0.166       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 319         |\n",
      "|    total_timesteps    | 11780096    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019628497 |\n",
      "|    entropy_loss       | -1.97       |\n",
      "|    explained_variance | 0.931       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00575    |\n",
      "|    mean_step_reward   | 0.07569827  |\n",
      "|    n_updates          | 90.62 %     |\n",
      "|    policyGradLoss     | -0.0145     |\n",
      "|    value_loss         | 0.282       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 329         |\n",
      "|    total_timesteps    | 11788288    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016450264 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.951       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0365     |\n",
      "|    mean_step_reward   | 0.08608335  |\n",
      "|    n_updates          | 93.75 %     |\n",
      "|    policyGradLoss     | -0.0128     |\n",
      "|    value_loss         | 0.227       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 340         |\n",
      "|    total_timesteps    | 11796480    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017504724 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.941       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.116       |\n",
      "|    mean_step_reward   | 0.06949338  |\n",
      "|    n_updates          | 96.88 %     |\n",
      "|    policyGradLoss     | -0.0173     |\n",
      "|    value_loss         | 0.375       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Run_44.zip\n",
      "[EVAL] Mean Return: 125.770, Best Return: 132.270\n",
      "Saved video to ./runs_smw/videos/Run/Run_44_125.77.mp4\n",
      "\n",
      "=== Round 46 | Learn 262144 steps (Total trained: 11796480) ===\n",
      "Logging to ./runs_smw/tb/Run_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1146     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 11804672 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 915         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 11812864    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019280529 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.945       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0302     |\n",
      "|    mean_step_reward   | 0.09221714  |\n",
      "|    n_updates          | 3.12 %      |\n",
      "|    policyGradLoss     | -0.0154     |\n",
      "|    value_loss         | 0.278       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 869         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 11821056    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021427322 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.941       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0415     |\n",
      "|    mean_step_reward   | 0.06749055  |\n",
      "|    n_updates          | 6.25 %      |\n",
      "|    policyGradLoss     | -0.0184     |\n",
      "|    value_loss         | 0.289       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 840         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 38          |\n",
      "|    total_timesteps    | 11829248    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018850302 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.948       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0114      |\n",
      "|    mean_step_reward   | 0.082584396 |\n",
      "|    n_updates          | 9.38 %      |\n",
      "|    policyGradLoss     | -0.0175     |\n",
      "|    value_loss         | 0.33        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 832        |\n",
      "|    iterations         | 5          |\n",
      "|    time_elapsed       | 49         |\n",
      "|    total_timesteps    | 11837440   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01858474 |\n",
      "|    entropy_loss       | -1.95      |\n",
      "|    explained_variance | 0.95       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.0107     |\n",
      "|    mean_step_reward   | 0.08281669 |\n",
      "|    n_updates          | 12.50 %    |\n",
      "|    policyGradLoss     | -0.0186    |\n",
      "|    value_loss         | 0.294      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 828         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 59          |\n",
      "|    total_timesteps    | 11845632    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018871896 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.938       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0414      |\n",
      "|    mean_step_reward   | 0.059466187 |\n",
      "|    n_updates          | 15.62 %     |\n",
      "|    policyGradLoss     | -0.0165     |\n",
      "|    value_loss         | 0.421       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 819        |\n",
      "|    iterations         | 7          |\n",
      "|    time_elapsed       | 69         |\n",
      "|    total_timesteps    | 11853824   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02030569 |\n",
      "|    entropy_loss       | -1.93      |\n",
      "|    explained_variance | 0.951      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0595    |\n",
      "|    mean_step_reward   | 0.07619351 |\n",
      "|    n_updates          | 18.75 %    |\n",
      "|    policyGradLoss     | -0.0178    |\n",
      "|    value_loss         | 0.23       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 817         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 80          |\n",
      "|    total_timesteps    | 11862016    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022729462 |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.938       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0109     |\n",
      "|    mean_step_reward   | 0.06315073  |\n",
      "|    n_updates          | 21.88 %     |\n",
      "|    policyGradLoss     | -0.0194     |\n",
      "|    value_loss         | 0.244       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 810         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 90          |\n",
      "|    total_timesteps    | 11870208    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017178752 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00461     |\n",
      "|    mean_step_reward   | 0.09268271  |\n",
      "|    n_updates          | 25.00 %     |\n",
      "|    policyGradLoss     | -0.0175     |\n",
      "|    value_loss         | 0.265       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 806         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 101         |\n",
      "|    total_timesteps    | 11878400    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021936217 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.933       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0498     |\n",
      "|    mean_step_reward   | 0.07109286  |\n",
      "|    n_updates          | 28.12 %     |\n",
      "|    policyGradLoss     | -0.0212     |\n",
      "|    value_loss         | 0.253       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 804         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 112         |\n",
      "|    total_timesteps    | 11886592    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018097425 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.905       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0124     |\n",
      "|    mean_step_reward   | 0.062259845 |\n",
      "|    n_updates          | 31.25 %     |\n",
      "|    policyGradLoss     | -0.014      |\n",
      "|    value_loss         | 0.351       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 800         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 122         |\n",
      "|    total_timesteps    | 11894784    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014907392 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.926       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0106      |\n",
      "|    mean_step_reward   | 0.08001669  |\n",
      "|    n_updates          | 34.38 %     |\n",
      "|    policyGradLoss     | -0.0136     |\n",
      "|    value_loss         | 0.372       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 797         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 133         |\n",
      "|    total_timesteps    | 11902976    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025081977 |\n",
      "|    entropy_loss       | -1.97       |\n",
      "|    explained_variance | 0.936       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0716     |\n",
      "|    mean_step_reward   | 0.06616042  |\n",
      "|    n_updates          | 37.50 %     |\n",
      "|    policyGradLoss     | -0.0227     |\n",
      "|    value_loss         | 0.204       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 796        |\n",
      "|    iterations         | 14         |\n",
      "|    time_elapsed       | 144        |\n",
      "|    total_timesteps    | 11911168   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01959489 |\n",
      "|    entropy_loss       | -1.94      |\n",
      "|    explained_variance | 0.942      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.0054     |\n",
      "|    mean_step_reward   | 0.07418922 |\n",
      "|    n_updates          | 40.62 %    |\n",
      "|    policyGradLoss     | -0.0161    |\n",
      "|    value_loss         | 0.391      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 794         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 154         |\n",
      "|    total_timesteps    | 11919360    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017686106 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.944       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0275     |\n",
      "|    mean_step_reward   | 0.08333921  |\n",
      "|    n_updates          | 43.75 %     |\n",
      "|    policyGradLoss     | -0.0163     |\n",
      "|    value_loss         | 0.26        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 793         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 165         |\n",
      "|    total_timesteps    | 11927552    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020695258 |\n",
      "|    entropy_loss       | -2          |\n",
      "|    explained_variance | 0.916       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0547     |\n",
      "|    mean_step_reward   | 0.05236031  |\n",
      "|    n_updates          | 46.88 %     |\n",
      "|    policyGradLoss     | -0.0221     |\n",
      "|    value_loss         | 0.242       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 791         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 175         |\n",
      "|    total_timesteps    | 11935744    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016703773 |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.921       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0201      |\n",
      "|    mean_step_reward   | 0.063686244 |\n",
      "|    n_updates          | 50.00 %     |\n",
      "|    policyGradLoss     | -0.0175     |\n",
      "|    value_loss         | 0.409       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 789         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 186         |\n",
      "|    total_timesteps    | 11943936    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017341614 |\n",
      "|    entropy_loss       | -1.97       |\n",
      "|    explained_variance | 0.927       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0665      |\n",
      "|    mean_step_reward   | 0.06071351  |\n",
      "|    n_updates          | 53.12 %     |\n",
      "|    policyGradLoss     | -0.0155     |\n",
      "|    value_loss         | 0.311       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 788         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 197         |\n",
      "|    total_timesteps    | 11952128    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014978064 |\n",
      "|    entropy_loss       | -1.99       |\n",
      "|    explained_variance | 0.942       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.000104   |\n",
      "|    mean_step_reward   | 0.08416405  |\n",
      "|    n_updates          | 56.25 %     |\n",
      "|    policyGradLoss     | -0.0173     |\n",
      "|    value_loss         | 0.301       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 788         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 207         |\n",
      "|    total_timesteps    | 11960320    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014959842 |\n",
      "|    entropy_loss       | -1.97       |\n",
      "|    explained_variance | 0.902       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0252      |\n",
      "|    mean_step_reward   | 0.06427865  |\n",
      "|    n_updates          | 59.38 %     |\n",
      "|    policyGradLoss     | -0.0127     |\n",
      "|    value_loss         | 0.424       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 218         |\n",
      "|    total_timesteps    | 11968512    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016862663 |\n",
      "|    entropy_loss       | -1.98       |\n",
      "|    explained_variance | 0.944       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0301     |\n",
      "|    mean_step_reward   | 0.07065747  |\n",
      "|    n_updates          | 62.50 %     |\n",
      "|    policyGradLoss     | -0.0178     |\n",
      "|    value_loss         | 0.226       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 229         |\n",
      "|    total_timesteps    | 11976704    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020298097 |\n",
      "|    entropy_loss       | -1.98       |\n",
      "|    explained_variance | 0.937       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0115     |\n",
      "|    mean_step_reward   | 0.061296992 |\n",
      "|    n_updates          | 65.62 %     |\n",
      "|    policyGradLoss     | -0.0195     |\n",
      "|    value_loss         | 0.276       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 240         |\n",
      "|    total_timesteps    | 11984896    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014960606 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.879       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0816      |\n",
      "|    mean_step_reward   | 0.07893527  |\n",
      "|    n_updates          | 68.75 %     |\n",
      "|    policyGradLoss     | -0.0136     |\n",
      "|    value_loss         | 0.454       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 784        |\n",
      "|    iterations         | 24         |\n",
      "|    time_elapsed       | 250        |\n",
      "|    total_timesteps    | 11993088   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02025158 |\n",
      "|    entropy_loss       | -1.92      |\n",
      "|    explained_variance | 0.926      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.0402     |\n",
      "|    mean_step_reward   | 0.07543512 |\n",
      "|    n_updates          | 71.88 %    |\n",
      "|    policyGradLoss     | -0.0136    |\n",
      "|    value_loss         | 0.426      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 261         |\n",
      "|    total_timesteps    | 12001280    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016181123 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.93        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0672      |\n",
      "|    mean_step_reward   | 0.079044014 |\n",
      "|    n_updates          | 75.00 %     |\n",
      "|    policyGradLoss     | -0.0133     |\n",
      "|    value_loss         | 0.401       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 271         |\n",
      "|    total_timesteps    | 12009472    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019691676 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.929       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0071      |\n",
      "|    mean_step_reward   | 0.07061592  |\n",
      "|    n_updates          | 78.12 %     |\n",
      "|    policyGradLoss     | -0.018      |\n",
      "|    value_loss         | 0.327       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 282         |\n",
      "|    total_timesteps    | 12017664    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022128932 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.932       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0381     |\n",
      "|    mean_step_reward   | 0.070743665 |\n",
      "|    n_updates          | 81.25 %     |\n",
      "|    policyGradLoss     | -0.0176     |\n",
      "|    value_loss         | 0.287       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 292         |\n",
      "|    total_timesteps    | 12025856    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017447952 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.94        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0311     |\n",
      "|    mean_step_reward   | 0.06675058  |\n",
      "|    n_updates          | 84.38 %     |\n",
      "|    policyGradLoss     | -0.0187     |\n",
      "|    value_loss         | 0.254       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 303         |\n",
      "|    total_timesteps    | 12034048    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021158827 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.941       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00373     |\n",
      "|    mean_step_reward   | 0.07471755  |\n",
      "|    n_updates          | 87.50 %     |\n",
      "|    policyGradLoss     | -0.0191     |\n",
      "|    value_loss         | 0.283       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 313         |\n",
      "|    total_timesteps    | 12042240    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018762644 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.945       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0281      |\n",
      "|    mean_step_reward   | 0.07496016  |\n",
      "|    n_updates          | 90.62 %     |\n",
      "|    policyGradLoss     | -0.0172     |\n",
      "|    value_loss         | 0.397       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 783        |\n",
      "|    iterations         | 31         |\n",
      "|    time_elapsed       | 324        |\n",
      "|    total_timesteps    | 12050432   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02249078 |\n",
      "|    entropy_loss       | -1.92      |\n",
      "|    explained_variance | 0.939      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0124    |\n",
      "|    mean_step_reward   | 0.07536826 |\n",
      "|    n_updates          | 93.75 %    |\n",
      "|    policyGradLoss     | -0.0185    |\n",
      "|    value_loss         | 0.265      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 334         |\n",
      "|    total_timesteps    | 12058624    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021414794 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.914       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0133      |\n",
      "|    mean_step_reward   | 0.06757094  |\n",
      "|    n_updates          | 96.88 %     |\n",
      "|    policyGradLoss     | -0.0166     |\n",
      "|    value_loss         | 0.294       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Run_45.zip\n",
      "[EVAL] Mean Return: 39.753, Best Return: 41.753\n",
      "Saved video to ./runs_smw/videos/Run/Run_45_39.75.mp4\n",
      "\n",
      "=== Round 47 | Learn 262144 steps (Total trained: 12058624) ===\n",
      "Logging to ./runs_smw/tb/Run_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1118     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 12066816 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 899         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 12075008    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021754365 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.941       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0139     |\n",
      "|    mean_step_reward   | 0.067624226 |\n",
      "|    n_updates          | 3.12 %      |\n",
      "|    policyGradLoss     | -0.022      |\n",
      "|    value_loss         | 0.262       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 856         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 12083200    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021296155 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.932       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.052       |\n",
      "|    mean_step_reward   | 0.07794665  |\n",
      "|    n_updates          | 6.25 %      |\n",
      "|    policyGradLoss     | -0.0146     |\n",
      "|    value_loss         | 0.396       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 831         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 12091392    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020414766 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.95        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00147     |\n",
      "|    mean_step_reward   | 0.07258555  |\n",
      "|    n_updates          | 9.38 %      |\n",
      "|    policyGradLoss     | -0.0203     |\n",
      "|    value_loss         | 0.269       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 818         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 50          |\n",
      "|    total_timesteps    | 12099584    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01461451  |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.948       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00674     |\n",
      "|    mean_step_reward   | 0.082718804 |\n",
      "|    n_updates          | 12.50 %     |\n",
      "|    policyGradLoss     | -0.0145     |\n",
      "|    value_loss         | 0.363       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 807        |\n",
      "|    iterations         | 6          |\n",
      "|    time_elapsed       | 60         |\n",
      "|    total_timesteps    | 12107776   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01817811 |\n",
      "|    entropy_loss       | -1.9       |\n",
      "|    explained_variance | 0.946      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.00648    |\n",
      "|    mean_step_reward   | 0.07446002 |\n",
      "|    n_updates          | 15.62 %    |\n",
      "|    policyGradLoss     | -0.017     |\n",
      "|    value_loss         | 0.292      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 798         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 71          |\n",
      "|    total_timesteps    | 12115968    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019535094 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.939       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00267     |\n",
      "|    mean_step_reward   | 0.07220456  |\n",
      "|    n_updates          | 18.75 %     |\n",
      "|    policyGradLoss     | -0.0188     |\n",
      "|    value_loss         | 0.273       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 796         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 82          |\n",
      "|    total_timesteps    | 12124160    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01933556  |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.941       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0574      |\n",
      "|    mean_step_reward   | 0.080134824 |\n",
      "|    n_updates          | 21.88 %     |\n",
      "|    policyGradLoss     | -0.0171     |\n",
      "|    value_loss         | 0.322       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 791         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 93          |\n",
      "|    total_timesteps    | 12132352    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016244316 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.931       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0718      |\n",
      "|    mean_step_reward   | 0.06722645  |\n",
      "|    n_updates          | 25.00 %     |\n",
      "|    policyGradLoss     | -0.0142     |\n",
      "|    value_loss         | 0.318       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 793         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 103         |\n",
      "|    total_timesteps    | 12140544    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021485034 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.942       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00175    |\n",
      "|    mean_step_reward   | 0.075912245 |\n",
      "|    n_updates          | 28.12 %     |\n",
      "|    policyGradLoss     | -0.0187     |\n",
      "|    value_loss         | 0.242       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 791         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 113         |\n",
      "|    total_timesteps    | 12148736    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016538352 |\n",
      "|    entropy_loss       | -1.97       |\n",
      "|    explained_variance | 0.905       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0158      |\n",
      "|    mean_step_reward   | 0.08352831  |\n",
      "|    n_updates          | 31.25 %     |\n",
      "|    policyGradLoss     | -0.0121     |\n",
      "|    value_loss         | 0.33        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 788         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 124         |\n",
      "|    total_timesteps    | 12156928    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017085675 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.933       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00226     |\n",
      "|    mean_step_reward   | 0.072032824 |\n",
      "|    n_updates          | 34.38 %     |\n",
      "|    policyGradLoss     | -0.0154     |\n",
      "|    value_loss         | 0.36        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 135         |\n",
      "|    total_timesteps    | 12165120    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015182275 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.926       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00341     |\n",
      "|    mean_step_reward   | 0.07797601  |\n",
      "|    n_updates          | 37.50 %     |\n",
      "|    policyGradLoss     | -0.013      |\n",
      "|    value_loss         | 0.316       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 145         |\n",
      "|    total_timesteps    | 12173312    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021066818 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.944       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00617     |\n",
      "|    mean_step_reward   | 0.07699767  |\n",
      "|    n_updates          | 40.62 %     |\n",
      "|    policyGradLoss     | -0.0167     |\n",
      "|    value_loss         | 0.361       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 784          |\n",
      "|    iterations         | 15           |\n",
      "|    time_elapsed       | 156          |\n",
      "|    total_timesteps    | 12181504     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0144635625 |\n",
      "|    entropy_loss       | -1.9         |\n",
      "|    explained_variance | 0.952        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0523       |\n",
      "|    mean_step_reward   | 0.10057277   |\n",
      "|    n_updates          | 43.75 %      |\n",
      "|    policyGradLoss     | -0.016       |\n",
      "|    value_loss         | 0.319        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 167         |\n",
      "|    total_timesteps    | 12189696    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023596302 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.925       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00985     |\n",
      "|    mean_step_reward   | 0.05928722  |\n",
      "|    n_updates          | 46.88 %     |\n",
      "|    policyGradLoss     | -0.0163     |\n",
      "|    value_loss         | 0.353       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 177         |\n",
      "|    total_timesteps    | 12197888    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019030953 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.954       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0433      |\n",
      "|    mean_step_reward   | 0.09856109  |\n",
      "|    n_updates          | 50.00 %     |\n",
      "|    policyGradLoss     | -0.0157     |\n",
      "|    value_loss         | 0.305       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 188         |\n",
      "|    total_timesteps    | 12206080    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021160867 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.927       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00761    |\n",
      "|    mean_step_reward   | 0.06429748  |\n",
      "|    n_updates          | 53.12 %     |\n",
      "|    policyGradLoss     | -0.0185     |\n",
      "|    value_loss         | 0.35        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 785        |\n",
      "|    iterations         | 19         |\n",
      "|    time_elapsed       | 198        |\n",
      "|    total_timesteps    | 12214272   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01925682 |\n",
      "|    entropy_loss       | -1.91      |\n",
      "|    explained_variance | 0.951      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.0257     |\n",
      "|    mean_step_reward   | 0.08361699 |\n",
      "|    n_updates          | 56.25 %    |\n",
      "|    policyGradLoss     | -0.0176    |\n",
      "|    value_loss         | 0.292      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 208         |\n",
      "|    total_timesteps    | 12222464    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018716661 |\n",
      "|    entropy_loss       | -2          |\n",
      "|    explained_variance | 0.905       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0487     |\n",
      "|    mean_step_reward   | 0.06628178  |\n",
      "|    n_updates          | 59.38 %     |\n",
      "|    policyGradLoss     | -0.0171     |\n",
      "|    value_loss         | 0.215       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 218         |\n",
      "|    total_timesteps    | 12230656    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020198654 |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.934       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0168     |\n",
      "|    mean_step_reward   | 0.07189472  |\n",
      "|    n_updates          | 62.50 %     |\n",
      "|    policyGradLoss     | -0.0163     |\n",
      "|    value_loss         | 0.298       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 228         |\n",
      "|    total_timesteps    | 12238848    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023974976 |\n",
      "|    entropy_loss       | -1.97       |\n",
      "|    explained_variance | 0.922       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0265     |\n",
      "|    mean_step_reward   | 0.062839285 |\n",
      "|    n_updates          | 65.62 %     |\n",
      "|    policyGradLoss     | -0.017      |\n",
      "|    value_loss         | 0.198       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 240         |\n",
      "|    total_timesteps    | 12247040    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021896876 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.913       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0465     |\n",
      "|    mean_step_reward   | 0.060142685 |\n",
      "|    n_updates          | 68.75 %     |\n",
      "|    policyGradLoss     | -0.0165     |\n",
      "|    value_loss         | 0.242       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 251         |\n",
      "|    total_timesteps    | 12255232    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016932305 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.943       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0171     |\n",
      "|    mean_step_reward   | 0.08380704  |\n",
      "|    n_updates          | 71.88 %     |\n",
      "|    policyGradLoss     | -0.0148     |\n",
      "|    value_loss         | 0.258       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 263         |\n",
      "|    total_timesteps    | 12263424    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019717883 |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.941       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0168     |\n",
      "|    mean_step_reward   | 0.09027382  |\n",
      "|    n_updates          | 75.00 %     |\n",
      "|    policyGradLoss     | -0.0179     |\n",
      "|    value_loss         | 0.253       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 274         |\n",
      "|    total_timesteps    | 12271616    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018395763 |\n",
      "|    entropy_loss       | -1.98       |\n",
      "|    explained_variance | 0.921       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0599      |\n",
      "|    mean_step_reward   | 0.059466943 |\n",
      "|    n_updates          | 78.12 %     |\n",
      "|    policyGradLoss     | -0.0184     |\n",
      "|    value_loss         | 0.445       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 285         |\n",
      "|    total_timesteps    | 12279808    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013906515 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.913       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.083       |\n",
      "|    mean_step_reward   | 0.08119999  |\n",
      "|    n_updates          | 81.25 %     |\n",
      "|    policyGradLoss     | -0.0118     |\n",
      "|    value_loss         | 0.556       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 296         |\n",
      "|    total_timesteps    | 12288000    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017557602 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.941       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0237      |\n",
      "|    mean_step_reward   | 0.07606045  |\n",
      "|    n_updates          | 84.38 %     |\n",
      "|    policyGradLoss     | -0.0183     |\n",
      "|    value_loss         | 0.324       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 307         |\n",
      "|    total_timesteps    | 12296192    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019885894 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.947       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0314     |\n",
      "|    mean_step_reward   | 0.07101704  |\n",
      "|    n_updates          | 87.50 %     |\n",
      "|    policyGradLoss     | -0.0203     |\n",
      "|    value_loss         | 0.298       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 318         |\n",
      "|    total_timesteps    | 12304384    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018517572 |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.945       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0326     |\n",
      "|    mean_step_reward   | 0.07404533  |\n",
      "|    n_updates          | 90.62 %     |\n",
      "|    policyGradLoss     | -0.0193     |\n",
      "|    value_loss         | 0.26        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 330         |\n",
      "|    total_timesteps    | 12312576    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017028134 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.955       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0216     |\n",
      "|    mean_step_reward   | 0.082444154 |\n",
      "|    n_updates          | 93.75 %     |\n",
      "|    policyGradLoss     | -0.0184     |\n",
      "|    value_loss         | 0.287       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 341         |\n",
      "|    total_timesteps    | 12320768    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015217726 |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.92        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0654      |\n",
      "|    mean_step_reward   | 0.0675347   |\n",
      "|    n_updates          | 96.88 %     |\n",
      "|    policyGradLoss     | -0.0179     |\n",
      "|    value_loss         | 0.379       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Run_46.zip\n",
      "[EVAL] Mean Return: 37.008, Best Return: 39.008\n",
      "Saved video to ./runs_smw/videos/Run/Run_46_37.01.mp4\n",
      "\n",
      "=== Round 48 | Learn 262144 steps (Total trained: 12320768) ===\n",
      "Logging to ./runs_smw/tb/Run_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1151     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 12328960 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 883         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 12337152    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016809124 |\n",
      "|    entropy_loss       | -1.97       |\n",
      "|    explained_variance | 0.942       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0243     |\n",
      "|    mean_step_reward   | 0.08118439  |\n",
      "|    n_updates          | 3.12 %      |\n",
      "|    policyGradLoss     | -0.0168     |\n",
      "|    value_loss         | 0.319       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 814         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 30          |\n",
      "|    total_timesteps    | 12345344    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015093552 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.931       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0335      |\n",
      "|    mean_step_reward   | 0.06603536  |\n",
      "|    n_updates          | 6.25 %      |\n",
      "|    policyGradLoss     | -0.0171     |\n",
      "|    value_loss         | 0.423       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 788         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 41          |\n",
      "|    total_timesteps    | 12353536    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013386088 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.937       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00911     |\n",
      "|    mean_step_reward   | 0.087099984 |\n",
      "|    n_updates          | 9.38 %      |\n",
      "|    policyGradLoss     | -0.0146     |\n",
      "|    value_loss         | 0.355       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 52          |\n",
      "|    total_timesteps    | 12361728    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015427964 |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.927       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00779     |\n",
      "|    mean_step_reward   | 0.08444481  |\n",
      "|    n_updates          | 12.50 %     |\n",
      "|    policyGradLoss     | -0.0147     |\n",
      "|    value_loss         | 0.356       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 63          |\n",
      "|    total_timesteps    | 12369920    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021018703 |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.929       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0177     |\n",
      "|    mean_step_reward   | 0.05802113  |\n",
      "|    n_updates          | 15.62 %     |\n",
      "|    policyGradLoss     | -0.0211     |\n",
      "|    value_loss         | 0.277       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 74          |\n",
      "|    total_timesteps    | 12378112    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016739663 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.938       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00838    |\n",
      "|    mean_step_reward   | 0.08771823  |\n",
      "|    n_updates          | 18.75 %     |\n",
      "|    policyGradLoss     | -0.0143     |\n",
      "|    value_loss         | 0.32        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 762         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 85          |\n",
      "|    total_timesteps    | 12386304    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015636459 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.929       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.035       |\n",
      "|    mean_step_reward   | 0.07791151  |\n",
      "|    n_updates          | 21.88 %     |\n",
      "|    policyGradLoss     | -0.0118     |\n",
      "|    value_loss         | 0.36        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 757         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 97          |\n",
      "|    total_timesteps    | 12394496    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022798996 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.014       |\n",
      "|    mean_step_reward   | 0.09122877  |\n",
      "|    n_updates          | 25.00 %     |\n",
      "|    policyGradLoss     | -0.0163     |\n",
      "|    value_loss         | 0.265       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 751         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 109         |\n",
      "|    total_timesteps    | 12402688    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018992309 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00309    |\n",
      "|    mean_step_reward   | 0.093851894 |\n",
      "|    n_updates          | 28.12 %     |\n",
      "|    policyGradLoss     | -0.0184     |\n",
      "|    value_loss         | 0.271       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 748         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 120         |\n",
      "|    total_timesteps    | 12410880    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023070479 |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.917       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0494     |\n",
      "|    mean_step_reward   | 0.06849027  |\n",
      "|    n_updates          | 31.25 %     |\n",
      "|    policyGradLoss     | -0.0192     |\n",
      "|    value_loss         | 0.288       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 747         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 131         |\n",
      "|    total_timesteps    | 12419072    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021057075 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.95        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0372     |\n",
      "|    mean_step_reward   | 0.08733302  |\n",
      "|    n_updates          | 34.38 %     |\n",
      "|    policyGradLoss     | -0.0189     |\n",
      "|    value_loss         | 0.214       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 747         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 142         |\n",
      "|    total_timesteps    | 12427264    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021515563 |\n",
      "|    entropy_loss       | -1.99       |\n",
      "|    explained_variance | 0.829       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0271      |\n",
      "|    mean_step_reward   | 0.051820077 |\n",
      "|    n_updates          | 37.50 %     |\n",
      "|    policyGradLoss     | -0.0133     |\n",
      "|    value_loss         | 0.399       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 746        |\n",
      "|    iterations         | 14         |\n",
      "|    time_elapsed       | 153        |\n",
      "|    total_timesteps    | 12435456   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01897625 |\n",
      "|    entropy_loss       | -1.98      |\n",
      "|    explained_variance | 0.874      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0236    |\n",
      "|    mean_step_reward   | 0.07340183 |\n",
      "|    n_updates          | 40.62 %    |\n",
      "|    policyGradLoss     | -0.0145    |\n",
      "|    value_loss         | 0.339      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 746         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 164         |\n",
      "|    total_timesteps    | 12443648    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016966306 |\n",
      "|    entropy_loss       | -1.98       |\n",
      "|    explained_variance | 0.939       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.000198    |\n",
      "|    mean_step_reward   | 0.09020702  |\n",
      "|    n_updates          | 43.75 %     |\n",
      "|    policyGradLoss     | -0.018      |\n",
      "|    value_loss         | 0.302       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 752         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 174         |\n",
      "|    total_timesteps    | 12451840    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016631106 |\n",
      "|    entropy_loss       | -2          |\n",
      "|    explained_variance | 0.912       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.017      |\n",
      "|    mean_step_reward   | 0.06676184  |\n",
      "|    n_updates          | 46.88 %     |\n",
      "|    policyGradLoss     | -0.016      |\n",
      "|    value_loss         | 0.3         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 758         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 183         |\n",
      "|    total_timesteps    | 12460032    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017137313 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.942       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0215     |\n",
      "|    mean_step_reward   | 0.07944448  |\n",
      "|    n_updates          | 50.00 %     |\n",
      "|    policyGradLoss     | -0.0185     |\n",
      "|    value_loss         | 0.322       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 764         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 192         |\n",
      "|    total_timesteps    | 12468224    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021638293 |\n",
      "|    entropy_loss       | -1.98       |\n",
      "|    explained_variance | 0.939       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0169     |\n",
      "|    mean_step_reward   | 0.07719684  |\n",
      "|    n_updates          | 53.12 %     |\n",
      "|    policyGradLoss     | -0.0216     |\n",
      "|    value_loss         | 0.249       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 764         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 203         |\n",
      "|    total_timesteps    | 12476416    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023362072 |\n",
      "|    entropy_loss       | -1.97       |\n",
      "|    explained_variance | 0.94        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0216     |\n",
      "|    mean_step_reward   | 0.08707154  |\n",
      "|    n_updates          | 56.25 %     |\n",
      "|    policyGradLoss     | -0.0125     |\n",
      "|    value_loss         | 0.332       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 761        |\n",
      "|    iterations         | 20         |\n",
      "|    time_elapsed       | 215        |\n",
      "|    total_timesteps    | 12484608   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02301193 |\n",
      "|    entropy_loss       | -1.96      |\n",
      "|    explained_variance | 0.951      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0211    |\n",
      "|    mean_step_reward   | 0.0654874  |\n",
      "|    n_updates          | 59.38 %    |\n",
      "|    policyGradLoss     | -0.0163    |\n",
      "|    value_loss         | 0.246      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 759        |\n",
      "|    iterations         | 21         |\n",
      "|    time_elapsed       | 226        |\n",
      "|    total_timesteps    | 12492800   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02122932 |\n",
      "|    entropy_loss       | -1.94      |\n",
      "|    explained_variance | 0.958      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0331    |\n",
      "|    mean_step_reward   | 0.08786902 |\n",
      "|    n_updates          | 62.50 %    |\n",
      "|    policyGradLoss     | -0.019     |\n",
      "|    value_loss         | 0.267      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 759         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 237         |\n",
      "|    total_timesteps    | 12500992    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020774767 |\n",
      "|    entropy_loss       | -1.99       |\n",
      "|    explained_variance | 0.944       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0382     |\n",
      "|    mean_step_reward   | 0.0723106   |\n",
      "|    n_updates          | 65.62 %     |\n",
      "|    policyGradLoss     | -0.017      |\n",
      "|    value_loss         | 0.228       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 758         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 248         |\n",
      "|    total_timesteps    | 12509184    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020892527 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.945       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0533     |\n",
      "|    mean_step_reward   | 0.085901745 |\n",
      "|    n_updates          | 68.75 %     |\n",
      "|    policyGradLoss     | -0.0183     |\n",
      "|    value_loss         | 0.213       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 758         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 259         |\n",
      "|    total_timesteps    | 12517376    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01725252  |\n",
      "|    entropy_loss       | -1.97       |\n",
      "|    explained_variance | 0.924       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0823      |\n",
      "|    mean_step_reward   | 0.070924446 |\n",
      "|    n_updates          | 71.88 %     |\n",
      "|    policyGradLoss     | -0.0134     |\n",
      "|    value_loss         | 0.3         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 756         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 270         |\n",
      "|    total_timesteps    | 12525568    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018788146 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.948       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0432     |\n",
      "|    mean_step_reward   | 0.08752225  |\n",
      "|    n_updates          | 75.00 %     |\n",
      "|    policyGradLoss     | -0.019      |\n",
      "|    value_loss         | 0.301       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 754         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 282         |\n",
      "|    total_timesteps    | 12533760    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02452134  |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.937       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00493    |\n",
      "|    mean_step_reward   | 0.066882685 |\n",
      "|    n_updates          | 78.12 %     |\n",
      "|    policyGradLoss     | -0.0212     |\n",
      "|    value_loss         | 0.236       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 752         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 293         |\n",
      "|    total_timesteps    | 12541952    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018667514 |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.948       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0515     |\n",
      "|    mean_step_reward   | 0.07789754  |\n",
      "|    n_updates          | 81.25 %     |\n",
      "|    policyGradLoss     | -0.019      |\n",
      "|    value_loss         | 0.259       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 751         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 305         |\n",
      "|    total_timesteps    | 12550144    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.0215148   |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.949       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00371    |\n",
      "|    mean_step_reward   | 0.072888486 |\n",
      "|    n_updates          | 84.38 %     |\n",
      "|    policyGradLoss     | -0.0198     |\n",
      "|    value_loss         | 0.307       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 750         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 316         |\n",
      "|    total_timesteps    | 12558336    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020663194 |\n",
      "|    entropy_loss       | -1.97       |\n",
      "|    explained_variance | 0.943       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0344      |\n",
      "|    mean_step_reward   | 0.0677463   |\n",
      "|    n_updates          | 87.50 %     |\n",
      "|    policyGradLoss     | -0.0147     |\n",
      "|    value_loss         | 0.305       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 750         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 327         |\n",
      "|    total_timesteps    | 12566528    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019252446 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.917       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0274     |\n",
      "|    mean_step_reward   | 0.07387127  |\n",
      "|    n_updates          | 90.62 %     |\n",
      "|    policyGradLoss     | -0.0151     |\n",
      "|    value_loss         | 0.355       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 750         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 338         |\n",
      "|    total_timesteps    | 12574720    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018956974 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.946       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00893     |\n",
      "|    mean_step_reward   | 0.08951743  |\n",
      "|    n_updates          | 93.75 %     |\n",
      "|    policyGradLoss     | -0.0153     |\n",
      "|    value_loss         | 0.329       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 749         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 349         |\n",
      "|    total_timesteps    | 12582912    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022442479 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.947       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0405     |\n",
      "|    mean_step_reward   | 0.08732504  |\n",
      "|    n_updates          | 96.88 %     |\n",
      "|    policyGradLoss     | -0.0181     |\n",
      "|    value_loss         | 0.224       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Run_47.zip\n",
      "[EVAL] Mean Return: 73.633, Best Return: 80.466\n",
      "Saved video to ./runs_smw/videos/Run/Run_47_73.63.mp4\n",
      "\n",
      "=== Round 49 | Learn 262144 steps (Total trained: 12582912) ===\n",
      "Logging to ./runs_smw/tb/Run_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1187     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 12591104 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 900         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 12599296    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018929526 |\n",
      "|    entropy_loss       | -1.99       |\n",
      "|    explained_variance | 0.925       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00349    |\n",
      "|    mean_step_reward   | 0.065100916 |\n",
      "|    n_updates          | 3.12 %      |\n",
      "|    policyGradLoss     | -0.0183     |\n",
      "|    value_loss         | 0.252       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 825         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 29          |\n",
      "|    total_timesteps    | 12607488    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015196081 |\n",
      "|    entropy_loss       | -1.97       |\n",
      "|    explained_variance | 0.905       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0292     |\n",
      "|    mean_step_reward   | 0.07000712  |\n",
      "|    n_updates          | 6.25 %      |\n",
      "|    policyGradLoss     | -0.0129     |\n",
      "|    value_loss         | 0.334       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 791         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 41          |\n",
      "|    total_timesteps    | 12615680    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016139036 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.947       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00323    |\n",
      "|    mean_step_reward   | 0.06377278  |\n",
      "|    n_updates          | 9.38 %      |\n",
      "|    policyGradLoss     | -0.0181     |\n",
      "|    value_loss         | 0.268       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 52          |\n",
      "|    total_timesteps    | 12623872    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021269962 |\n",
      "|    entropy_loss       | -1.97       |\n",
      "|    explained_variance | 0.93        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0187     |\n",
      "|    mean_step_reward   | 0.065109216 |\n",
      "|    n_updates          | 12.50 %     |\n",
      "|    policyGradLoss     | -0.0174     |\n",
      "|    value_loss         | 0.304       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 771        |\n",
      "|    iterations         | 6          |\n",
      "|    time_elapsed       | 63         |\n",
      "|    total_timesteps    | 12632064   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01681317 |\n",
      "|    entropy_loss       | -1.94      |\n",
      "|    explained_variance | 0.926      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.006     |\n",
      "|    mean_step_reward   | 0.07018075 |\n",
      "|    n_updates          | 15.62 %    |\n",
      "|    policyGradLoss     | -0.0171    |\n",
      "|    value_loss         | 0.303      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 74          |\n",
      "|    total_timesteps    | 12640256    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020326518 |\n",
      "|    entropy_loss       | -1.99       |\n",
      "|    explained_variance | 0.93        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00627    |\n",
      "|    mean_step_reward   | 0.056949623 |\n",
      "|    n_updates          | 18.75 %     |\n",
      "|    policyGradLoss     | -0.0168     |\n",
      "|    value_loss         | 0.243       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 761         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 86          |\n",
      "|    total_timesteps    | 12648448    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013568018 |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.914       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0161      |\n",
      "|    mean_step_reward   | 0.08786586  |\n",
      "|    n_updates          | 21.88 %     |\n",
      "|    policyGradLoss     | -0.0118     |\n",
      "|    value_loss         | 0.331       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 756         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 97          |\n",
      "|    total_timesteps    | 12656640    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021687623 |\n",
      "|    entropy_loss       | -1.99       |\n",
      "|    explained_variance | 0.941       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0129     |\n",
      "|    mean_step_reward   | 0.0529432   |\n",
      "|    n_updates          | 25.00 %     |\n",
      "|    policyGradLoss     | -0.0179     |\n",
      "|    value_loss         | 0.34        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 751         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 109         |\n",
      "|    total_timesteps    | 12664832    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017790768 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.942       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0352      |\n",
      "|    mean_step_reward   | 0.093853325 |\n",
      "|    n_updates          | 28.12 %     |\n",
      "|    policyGradLoss     | -0.0137     |\n",
      "|    value_loss         | 0.355       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 746         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 120         |\n",
      "|    total_timesteps    | 12673024    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022118822 |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.924       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0341     |\n",
      "|    mean_step_reward   | 0.048940998 |\n",
      "|    n_updates          | 31.25 %     |\n",
      "|    policyGradLoss     | -0.0203     |\n",
      "|    value_loss         | 0.266       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 744         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 132         |\n",
      "|    total_timesteps    | 12681216    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020509928 |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.944       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00182    |\n",
      "|    mean_step_reward   | 0.08762759  |\n",
      "|    n_updates          | 34.38 %     |\n",
      "|    policyGradLoss     | -0.0122     |\n",
      "|    value_loss         | 0.335       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 754         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 141         |\n",
      "|    total_timesteps    | 12689408    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017720006 |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.918       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00384    |\n",
      "|    mean_step_reward   | 0.06415076  |\n",
      "|    n_updates          | 37.50 %     |\n",
      "|    policyGradLoss     | -0.0153     |\n",
      "|    value_loss         | 0.339       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 762         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 150         |\n",
      "|    total_timesteps    | 12697600    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020852137 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.94        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0697      |\n",
      "|    mean_step_reward   | 0.094006956 |\n",
      "|    n_updates          | 40.62 %     |\n",
      "|    policyGradLoss     | -0.0152     |\n",
      "|    value_loss         | 0.361       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 159         |\n",
      "|    total_timesteps    | 12705792    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021731913 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.934       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0259      |\n",
      "|    mean_step_reward   | 0.07011984  |\n",
      "|    n_updates          | 43.75 %     |\n",
      "|    policyGradLoss     | -0.0189     |\n",
      "|    value_loss         | 0.282       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 170         |\n",
      "|    total_timesteps    | 12713984    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013731237 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.938       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0757      |\n",
      "|    mean_step_reward   | 0.07746599  |\n",
      "|    n_updates          | 46.88 %     |\n",
      "|    policyGradLoss     | -0.015      |\n",
      "|    value_loss         | 0.428       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 181         |\n",
      "|    total_timesteps    | 12722176    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019665753 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.946       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00379     |\n",
      "|    mean_step_reward   | 0.07008885  |\n",
      "|    n_updates          | 50.00 %     |\n",
      "|    policyGradLoss     | -0.0181     |\n",
      "|    value_loss         | 0.306       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 765         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 192         |\n",
      "|    total_timesteps    | 12730368    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020398669 |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.928       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0301     |\n",
      "|    mean_step_reward   | 0.074363135 |\n",
      "|    n_updates          | 53.12 %     |\n",
      "|    policyGradLoss     | -0.0151     |\n",
      "|    value_loss         | 0.29        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 761         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 204         |\n",
      "|    total_timesteps    | 12738560    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020748554 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.908       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0218     |\n",
      "|    mean_step_reward   | 0.058520325 |\n",
      "|    n_updates          | 56.25 %     |\n",
      "|    policyGradLoss     | -0.0202     |\n",
      "|    value_loss         | 0.254       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 759         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 215         |\n",
      "|    total_timesteps    | 12746752    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017831596 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.946       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0117     |\n",
      "|    mean_step_reward   | 0.07839954  |\n",
      "|    n_updates          | 59.38 %     |\n",
      "|    policyGradLoss     | -0.0141     |\n",
      "|    value_loss         | 0.207       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 757         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 227         |\n",
      "|    total_timesteps    | 12754944    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022216953 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.947       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0512     |\n",
      "|    mean_step_reward   | 0.075627334 |\n",
      "|    n_updates          | 62.50 %     |\n",
      "|    policyGradLoss     | -0.0215     |\n",
      "|    value_loss         | 0.216       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 756         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 238         |\n",
      "|    total_timesteps    | 12763136    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018980218 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.923       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0366      |\n",
      "|    mean_step_reward   | 0.067417815 |\n",
      "|    n_updates          | 65.62 %     |\n",
      "|    policyGradLoss     | -0.00828    |\n",
      "|    value_loss         | 0.419       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 755         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 249         |\n",
      "|    total_timesteps    | 12771328    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018447433 |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.933       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.05       |\n",
      "|    mean_step_reward   | 0.08347368  |\n",
      "|    n_updates          | 68.75 %     |\n",
      "|    policyGradLoss     | -0.02       |\n",
      "|    value_loss         | 0.223       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 754         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 260         |\n",
      "|    total_timesteps    | 12779520    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018109329 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.917       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0389      |\n",
      "|    mean_step_reward   | 0.07473335  |\n",
      "|    n_updates          | 71.88 %     |\n",
      "|    policyGradLoss     | -0.0129     |\n",
      "|    value_loss         | 0.376       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 752         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 272         |\n",
      "|    total_timesteps    | 12787712    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020786207 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.94        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0469      |\n",
      "|    mean_step_reward   | 0.09202122  |\n",
      "|    n_updates          | 75.00 %     |\n",
      "|    policyGradLoss     | -0.0144     |\n",
      "|    value_loss         | 0.337       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 750         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 283         |\n",
      "|    total_timesteps    | 12795904    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026767302 |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.94        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0521     |\n",
      "|    mean_step_reward   | 0.06562899  |\n",
      "|    n_updates          | 78.12 %     |\n",
      "|    policyGradLoss     | -0.0226     |\n",
      "|    value_loss         | 0.168       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 749         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 295         |\n",
      "|    total_timesteps    | 12804096    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017253995 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.94        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0305      |\n",
      "|    mean_step_reward   | 0.0897053   |\n",
      "|    n_updates          | 81.25 %     |\n",
      "|    policyGradLoss     | -0.0158     |\n",
      "|    value_loss         | 0.363       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 748         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 306         |\n",
      "|    total_timesteps    | 12812288    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019572875 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.942       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0271     |\n",
      "|    mean_step_reward   | 0.06731858  |\n",
      "|    n_updates          | 84.38 %     |\n",
      "|    policyGradLoss     | -0.0187     |\n",
      "|    value_loss         | 0.292       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 748         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 317         |\n",
      "|    total_timesteps    | 12820480    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021930292 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.938       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0373     |\n",
      "|    mean_step_reward   | 0.07964161  |\n",
      "|    n_updates          | 87.50 %     |\n",
      "|    policyGradLoss     | -0.014      |\n",
      "|    value_loss         | 0.286       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 748        |\n",
      "|    iterations         | 30         |\n",
      "|    time_elapsed       | 328        |\n",
      "|    total_timesteps    | 12828672   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01327092 |\n",
      "|    entropy_loss       | -1.91      |\n",
      "|    explained_variance | 0.946      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0018    |\n",
      "|    mean_step_reward   | 0.10338029 |\n",
      "|    n_updates          | 90.62 %    |\n",
      "|    policyGradLoss     | -0.0113    |\n",
      "|    value_loss         | 0.317      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 747         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 339         |\n",
      "|    total_timesteps    | 12836864    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020490829 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.951       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0265      |\n",
      "|    mean_step_reward   | 0.07793771  |\n",
      "|    n_updates          | 93.75 %     |\n",
      "|    policyGradLoss     | -0.0173     |\n",
      "|    value_loss         | 0.283       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 745         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 351         |\n",
      "|    total_timesteps    | 12845056    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018566769 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.951       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00844     |\n",
      "|    mean_step_reward   | 0.10472943  |\n",
      "|    n_updates          | 96.88 %     |\n",
      "|    policyGradLoss     | -0.0166     |\n",
      "|    value_loss         | 0.31        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Run_48.zip\n",
      "[EVAL] Mean Return: 123.777, Best Return: 129.444\n",
      "Saved video to ./runs_smw/videos/Run/Run_48_123.78.mp4\n",
      "\n",
      "=== Round 50 | Learn 262144 steps (Total trained: 12845056) ===\n",
      "Logging to ./runs_smw/tb/Run_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1132     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 12853248 |\n",
      "---------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 895        |\n",
      "|    iterations         | 2          |\n",
      "|    time_elapsed       | 18         |\n",
      "|    total_timesteps    | 12861440   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01586888 |\n",
      "|    entropy_loss       | -1.92      |\n",
      "|    explained_variance | 0.935      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.044     |\n",
      "|    mean_step_reward   | 0.09457708 |\n",
      "|    n_updates          | 3.12 %     |\n",
      "|    policyGradLoss     | -0.0153    |\n",
      "|    value_loss         | 0.266      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 839         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 29          |\n",
      "|    total_timesteps    | 12869632    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013079044 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.883       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0433      |\n",
      "|    mean_step_reward   | 0.06582375  |\n",
      "|    n_updates          | 6.25 %      |\n",
      "|    policyGradLoss     | -0.0101     |\n",
      "|    value_loss         | 0.381       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 818         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 40          |\n",
      "|    total_timesteps    | 12877824    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016516108 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.937       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00525    |\n",
      "|    mean_step_reward   | 0.09611053  |\n",
      "|    n_updates          | 9.38 %      |\n",
      "|    policyGradLoss     | -0.0128     |\n",
      "|    value_loss         | 0.325       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 799         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 51          |\n",
      "|    total_timesteps    | 12886016    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020859402 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.939       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0409     |\n",
      "|    mean_step_reward   | 0.09346011  |\n",
      "|    n_updates          | 12.50 %     |\n",
      "|    policyGradLoss     | -0.0159     |\n",
      "|    value_loss         | 0.264       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 62          |\n",
      "|    total_timesteps    | 12894208    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01935691  |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.958       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00583    |\n",
      "|    mean_step_reward   | 0.074643895 |\n",
      "|    n_updates          | 15.62 %     |\n",
      "|    policyGradLoss     | -0.0166     |\n",
      "|    value_loss         | 0.284       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 74          |\n",
      "|    total_timesteps    | 12902400    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018558405 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.948       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0284      |\n",
      "|    mean_step_reward   | 0.08052901  |\n",
      "|    n_updates          | 18.75 %     |\n",
      "|    policyGradLoss     | -0.0147     |\n",
      "|    value_loss         | 0.334       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 763        |\n",
      "|    iterations         | 8          |\n",
      "|    time_elapsed       | 85         |\n",
      "|    total_timesteps    | 12910592   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02706039 |\n",
      "|    entropy_loss       | -1.93      |\n",
      "|    explained_variance | 0.932      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.055     |\n",
      "|    mean_step_reward   | 0.07514782 |\n",
      "|    n_updates          | 21.88 %    |\n",
      "|    policyGradLoss     | -0.0168    |\n",
      "|    value_loss         | 0.212      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 764         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 96          |\n",
      "|    total_timesteps    | 12918784    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027741296 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.945       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0353     |\n",
      "|    mean_step_reward   | 0.07662273  |\n",
      "|    n_updates          | 25.00 %     |\n",
      "|    policyGradLoss     | -0.0178     |\n",
      "|    value_loss         | 0.245       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 105         |\n",
      "|    total_timesteps    | 12926976    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023815809 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0451     |\n",
      "|    mean_step_reward   | 0.08526321  |\n",
      "|    n_updates          | 28.12 %     |\n",
      "|    policyGradLoss     | -0.0197     |\n",
      "|    value_loss         | 0.214       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 115         |\n",
      "|    total_timesteps    | 12935168    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019424278 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.9         |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0204     |\n",
      "|    mean_step_reward   | 0.0858264   |\n",
      "|    n_updates          | 31.25 %     |\n",
      "|    policyGradLoss     | -0.0114     |\n",
      "|    value_loss         | 0.345       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 125         |\n",
      "|    total_timesteps    | 12943360    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021442631 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.03       |\n",
      "|    mean_step_reward   | 0.09441727  |\n",
      "|    n_updates          | 34.38 %     |\n",
      "|    policyGradLoss     | -0.022      |\n",
      "|    value_loss         | 0.227       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 137         |\n",
      "|    total_timesteps    | 12951552    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019583924 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.925       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0169     |\n",
      "|    mean_step_reward   | 0.06671269  |\n",
      "|    n_updates          | 37.50 %     |\n",
      "|    policyGradLoss     | -0.0152     |\n",
      "|    value_loss         | 0.301       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 148         |\n",
      "|    total_timesteps    | 12959744    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022219632 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.957       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0513     |\n",
      "|    mean_step_reward   | 0.08686438  |\n",
      "|    n_updates          | 40.62 %     |\n",
      "|    policyGradLoss     | -0.0198     |\n",
      "|    value_loss         | 0.216       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 159         |\n",
      "|    total_timesteps    | 12967936    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023208898 |\n",
      "|    entropy_loss       | -2          |\n",
      "|    explained_variance | 0.943       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0367     |\n",
      "|    mean_step_reward   | 0.058057547 |\n",
      "|    n_updates          | 43.75 %     |\n",
      "|    policyGradLoss     | -0.018      |\n",
      "|    value_loss         | 0.276       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 170         |\n",
      "|    total_timesteps    | 12976128    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022846382 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.924       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0127     |\n",
      "|    mean_step_reward   | 0.0717805   |\n",
      "|    n_updates          | 46.88 %     |\n",
      "|    policyGradLoss     | -0.0172     |\n",
      "|    value_loss         | 0.281       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 181         |\n",
      "|    total_timesteps    | 12984320    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017921254 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.951       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.012      |\n",
      "|    mean_step_reward   | 0.07338656  |\n",
      "|    n_updates          | 50.00 %     |\n",
      "|    policyGradLoss     | -0.0176     |\n",
      "|    value_loss         | 0.302       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 765         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 192         |\n",
      "|    total_timesteps    | 12992512    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018155595 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.94        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.124       |\n",
      "|    mean_step_reward   | 0.081961185 |\n",
      "|    n_updates          | 53.12 %     |\n",
      "|    policyGradLoss     | -0.0154     |\n",
      "|    value_loss         | 0.323       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 762        |\n",
      "|    iterations         | 19         |\n",
      "|    time_elapsed       | 204        |\n",
      "|    total_timesteps    | 13000704   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02442984 |\n",
      "|    entropy_loss       | -1.94      |\n",
      "|    explained_variance | 0.958      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0307    |\n",
      "|    mean_step_reward   | 0.08015014 |\n",
      "|    n_updates          | 56.25 %    |\n",
      "|    policyGradLoss     | -0.0214    |\n",
      "|    value_loss         | 0.219      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 760        |\n",
      "|    iterations         | 20         |\n",
      "|    time_elapsed       | 215        |\n",
      "|    total_timesteps    | 13008896   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01975907 |\n",
      "|    entropy_loss       | -1.93      |\n",
      "|    explained_variance | 0.922      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.0316     |\n",
      "|    mean_step_reward   | 0.06697151 |\n",
      "|    n_updates          | 59.38 %    |\n",
      "|    policyGradLoss     | -0.0153    |\n",
      "|    value_loss         | 0.322      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 758         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 226         |\n",
      "|    total_timesteps    | 13017088    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018490685 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.948       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.105       |\n",
      "|    mean_step_reward   | 0.09098674  |\n",
      "|    n_updates          | 62.50 %     |\n",
      "|    policyGradLoss     | -0.0164     |\n",
      "|    value_loss         | 0.299       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 758         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 237         |\n",
      "|    total_timesteps    | 13025280    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021117594 |\n",
      "|    entropy_loss       | -1.98       |\n",
      "|    explained_variance | 0.919       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0186     |\n",
      "|    mean_step_reward   | 0.06792296  |\n",
      "|    n_updates          | 65.62 %     |\n",
      "|    policyGradLoss     | -0.0171     |\n",
      "|    value_loss         | 0.31        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 757         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 248         |\n",
      "|    total_timesteps    | 13033472    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017525587 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.936       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.105       |\n",
      "|    mean_step_reward   | 0.08599593  |\n",
      "|    n_updates          | 68.75 %     |\n",
      "|    policyGradLoss     | -0.0155     |\n",
      "|    value_loss         | 0.427       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 756         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 259         |\n",
      "|    total_timesteps    | 13041664    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021057535 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0377     |\n",
      "|    mean_step_reward   | 0.07644173  |\n",
      "|    n_updates          | 71.88 %     |\n",
      "|    policyGradLoss     | -0.0182     |\n",
      "|    value_loss         | 0.23        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 755         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 271         |\n",
      "|    total_timesteps    | 13049856    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01983622  |\n",
      "|    entropy_loss       | -1.99       |\n",
      "|    explained_variance | 0.928       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0147     |\n",
      "|    mean_step_reward   | 0.076305196 |\n",
      "|    n_updates          | 75.00 %     |\n",
      "|    policyGradLoss     | -0.0139     |\n",
      "|    value_loss         | 0.271       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 752        |\n",
      "|    iterations         | 26         |\n",
      "|    time_elapsed       | 282        |\n",
      "|    total_timesteps    | 13058048   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01805463 |\n",
      "|    entropy_loss       | -1.98      |\n",
      "|    explained_variance | 0.907      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0354    |\n",
      "|    mean_step_reward   | 0.07155605 |\n",
      "|    n_updates          | 78.12 %    |\n",
      "|    policyGradLoss     | -0.0147    |\n",
      "|    value_loss         | 0.297      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 751         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 294         |\n",
      "|    total_timesteps    | 13066240    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014090795 |\n",
      "|    entropy_loss       | -1.99       |\n",
      "|    explained_variance | 0.93        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0298     |\n",
      "|    mean_step_reward   | 0.056801766 |\n",
      "|    n_updates          | 81.25 %     |\n",
      "|    policyGradLoss     | -0.017      |\n",
      "|    value_loss         | 0.329       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 750         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 305         |\n",
      "|    total_timesteps    | 13074432    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017720386 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.933       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00813     |\n",
      "|    mean_step_reward   | 0.084352545 |\n",
      "|    n_updates          | 84.38 %     |\n",
      "|    policyGradLoss     | -0.0132     |\n",
      "|    value_loss         | 0.419       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 750         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 316         |\n",
      "|    total_timesteps    | 13082624    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016456107 |\n",
      "|    entropy_loss       | -1.98       |\n",
      "|    explained_variance | 0.921       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0734      |\n",
      "|    mean_step_reward   | 0.071372345 |\n",
      "|    n_updates          | 87.50 %     |\n",
      "|    policyGradLoss     | -0.0152     |\n",
      "|    value_loss         | 0.417       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 750         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 327         |\n",
      "|    total_timesteps    | 13090816    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018361147 |\n",
      "|    entropy_loss       | -2          |\n",
      "|    explained_variance | 0.904       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00163    |\n",
      "|    mean_step_reward   | 0.062656075 |\n",
      "|    n_updates          | 90.62 %     |\n",
      "|    policyGradLoss     | -0.0169     |\n",
      "|    value_loss         | 0.269       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 749         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 338         |\n",
      "|    total_timesteps    | 13099008    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01597664  |\n",
      "|    entropy_loss       | -2          |\n",
      "|    explained_variance | 0.923       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00356     |\n",
      "|    mean_step_reward   | 0.056503814 |\n",
      "|    n_updates          | 93.75 %     |\n",
      "|    policyGradLoss     | -0.0182     |\n",
      "|    value_loss         | 0.261       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 748         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 350         |\n",
      "|    total_timesteps    | 13107200    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017666914 |\n",
      "|    entropy_loss       | -1.99       |\n",
      "|    explained_variance | 0.899       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00342     |\n",
      "|    mean_step_reward   | 0.07137564  |\n",
      "|    n_updates          | 96.88 %     |\n",
      "|    policyGradLoss     | -0.0158     |\n",
      "|    value_loss         | 0.438       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Run_49.zip\n",
      "[EVAL] Mean Return: 136.725, Best Return: 143.725\n",
      "Saved video to ./runs_smw/videos/Run/Run_49_136.73.mp4\n",
      "\n",
      "=== Round 51 | Learn 262144 steps (Total trained: 13107200) ===\n",
      "Logging to ./runs_smw/tb/Run_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1075     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 13115392 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 854         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 19          |\n",
      "|    total_timesteps    | 13123584    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015643349 |\n",
      "|    entropy_loss       | -1.99       |\n",
      "|    explained_variance | 0.947       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0562      |\n",
      "|    mean_step_reward   | 0.07368001  |\n",
      "|    n_updates          | 3.12 %      |\n",
      "|    policyGradLoss     | -0.0201     |\n",
      "|    value_loss         | 0.292       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 30          |\n",
      "|    total_timesteps    | 13131776    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014793037 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.93        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0419     |\n",
      "|    mean_step_reward   | 0.09323719  |\n",
      "|    n_updates          | 6.25 %      |\n",
      "|    policyGradLoss     | -0.0147     |\n",
      "|    value_loss         | 0.345       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 790         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 41          |\n",
      "|    total_timesteps    | 13139968    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018186431 |\n",
      "|    entropy_loss       | -1.97       |\n",
      "|    explained_variance | 0.91        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0446     |\n",
      "|    mean_step_reward   | 0.074121356 |\n",
      "|    n_updates          | 9.38 %      |\n",
      "|    policyGradLoss     | -0.0171     |\n",
      "|    value_loss         | 0.259       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 806         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 50          |\n",
      "|    total_timesteps    | 13148160    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017741654 |\n",
      "|    entropy_loss       | -1.97       |\n",
      "|    explained_variance | 0.955       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0314     |\n",
      "|    mean_step_reward   | 0.0894032   |\n",
      "|    n_updates          | 12.50 %     |\n",
      "|    policyGradLoss     | -0.0202     |\n",
      "|    value_loss         | 0.199       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 819         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 59          |\n",
      "|    total_timesteps    | 13156352    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021614876 |\n",
      "|    entropy_loss       | -2          |\n",
      "|    explained_variance | 0.936       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0631     |\n",
      "|    mean_step_reward   | 0.08106069  |\n",
      "|    n_updates          | 15.62 %     |\n",
      "|    policyGradLoss     | -0.0215     |\n",
      "|    value_loss         | 0.185       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 825         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 69          |\n",
      "|    total_timesteps    | 13164544    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017633228 |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.917       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0575      |\n",
      "|    mean_step_reward   | 0.083696574 |\n",
      "|    n_updates          | 18.75 %     |\n",
      "|    policyGradLoss     | -0.0146     |\n",
      "|    value_loss         | 0.338       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 822         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 79          |\n",
      "|    total_timesteps    | 13172736    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019541604 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.951       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0552     |\n",
      "|    mean_step_reward   | 0.08653796  |\n",
      "|    n_updates          | 21.88 %     |\n",
      "|    policyGradLoss     | -0.019      |\n",
      "|    value_loss         | 0.241       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 806         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 91          |\n",
      "|    total_timesteps    | 13180928    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016257124 |\n",
      "|    entropy_loss       | -1.97       |\n",
      "|    explained_variance | 0.923       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0267     |\n",
      "|    mean_step_reward   | 0.07420674  |\n",
      "|    n_updates          | 25.00 %     |\n",
      "|    policyGradLoss     | -0.016      |\n",
      "|    value_loss         | 0.292       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 796         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 102         |\n",
      "|    total_timesteps    | 13189120    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015026158 |\n",
      "|    entropy_loss       | -1.97       |\n",
      "|    explained_variance | 0.936       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0268     |\n",
      "|    mean_step_reward   | 0.09579546  |\n",
      "|    n_updates          | 28.12 %     |\n",
      "|    policyGradLoss     | -0.0151     |\n",
      "|    value_loss         | 0.325       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 790         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 114         |\n",
      "|    total_timesteps    | 13197312    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018095396 |\n",
      "|    entropy_loss       | -1.99       |\n",
      "|    explained_variance | 0.954       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0359     |\n",
      "|    mean_step_reward   | 0.081151046 |\n",
      "|    n_updates          | 31.25 %     |\n",
      "|    policyGradLoss     | -0.0172     |\n",
      "|    value_loss         | 0.242       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 125         |\n",
      "|    total_timesteps    | 13205504    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017435431 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.923       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0336      |\n",
      "|    mean_step_reward   | 0.08428784  |\n",
      "|    n_updates          | 34.38 %     |\n",
      "|    policyGradLoss     | -0.0124     |\n",
      "|    value_loss         | 0.4         |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 780        |\n",
      "|    iterations         | 13         |\n",
      "|    time_elapsed       | 136        |\n",
      "|    total_timesteps    | 13213696   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02338092 |\n",
      "|    entropy_loss       | -1.95      |\n",
      "|    explained_variance | 0.916      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.032     |\n",
      "|    mean_step_reward   | 0.07306491 |\n",
      "|    n_updates          | 37.50 %    |\n",
      "|    policyGradLoss     | -0.0178    |\n",
      "|    value_loss         | 0.279      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 147         |\n",
      "|    total_timesteps    | 13221888    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018409155 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.942       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0608      |\n",
      "|    mean_step_reward   | 0.075000405 |\n",
      "|    n_updates          | 40.62 %     |\n",
      "|    policyGradLoss     | -0.0168     |\n",
      "|    value_loss         | 0.361       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 159         |\n",
      "|    total_timesteps    | 13230080    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016231414 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.939       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0295     |\n",
      "|    mean_step_reward   | 0.09612024  |\n",
      "|    n_updates          | 43.75 %     |\n",
      "|    policyGradLoss     | -0.0132     |\n",
      "|    value_loss         | 0.306       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 170         |\n",
      "|    total_timesteps    | 13238272    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015965287 |\n",
      "|    entropy_loss       | -1.98       |\n",
      "|    explained_variance | 0.894       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0358      |\n",
      "|    mean_step_reward   | 0.052551806 |\n",
      "|    n_updates          | 46.88 %     |\n",
      "|    policyGradLoss     | -0.0142     |\n",
      "|    value_loss         | 0.503       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 764         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 182         |\n",
      "|    total_timesteps    | 13246464    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017064452 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.934       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0706      |\n",
      "|    mean_step_reward   | 0.107525714 |\n",
      "|    n_updates          | 50.00 %     |\n",
      "|    policyGradLoss     | -0.0149     |\n",
      "|    value_loss         | 0.404       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 762         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 193         |\n",
      "|    total_timesteps    | 13254656    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020135172 |\n",
      "|    entropy_loss       | -1.99       |\n",
      "|    explained_variance | 0.943       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0444     |\n",
      "|    mean_step_reward   | 0.06931397  |\n",
      "|    n_updates          | 53.12 %     |\n",
      "|    policyGradLoss     | -0.0176     |\n",
      "|    value_loss         | 0.263       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 761         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 204         |\n",
      "|    total_timesteps    | 13262848    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020427983 |\n",
      "|    entropy_loss       | -1.97       |\n",
      "|    explained_variance | 0.928       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0102      |\n",
      "|    mean_step_reward   | 0.0613791   |\n",
      "|    n_updates          | 56.25 %     |\n",
      "|    policyGradLoss     | -0.0187     |\n",
      "|    value_loss         | 0.3         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 760         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 215         |\n",
      "|    total_timesteps    | 13271040    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016839754 |\n",
      "|    entropy_loss       | -2          |\n",
      "|    explained_variance | 0.946       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00824     |\n",
      "|    mean_step_reward   | 0.082166575 |\n",
      "|    n_updates          | 59.38 %     |\n",
      "|    policyGradLoss     | -0.0146     |\n",
      "|    value_loss         | 0.296       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 758         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 226         |\n",
      "|    total_timesteps    | 13279232    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022066463 |\n",
      "|    entropy_loss       | -2.06       |\n",
      "|    explained_variance | 0.926       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0517     |\n",
      "|    mean_step_reward   | 0.050958693 |\n",
      "|    n_updates          | 62.50 %     |\n",
      "|    policyGradLoss     | -0.0185     |\n",
      "|    value_loss         | 0.223       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 756         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 238         |\n",
      "|    total_timesteps    | 13287424    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014251284 |\n",
      "|    entropy_loss       | -2.05       |\n",
      "|    explained_variance | 0.917       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0152     |\n",
      "|    mean_step_reward   | 0.061124094 |\n",
      "|    n_updates          | 65.62 %     |\n",
      "|    policyGradLoss     | -0.0111     |\n",
      "|    value_loss         | 0.328       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 753         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 250         |\n",
      "|    total_timesteps    | 13295616    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02229089  |\n",
      "|    entropy_loss       | -2.07       |\n",
      "|    explained_variance | 0.923       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0531     |\n",
      "|    mean_step_reward   | 0.051189937 |\n",
      "|    n_updates          | 68.75 %     |\n",
      "|    policyGradLoss     | -0.02       |\n",
      "|    value_loss         | 0.21        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 752         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 261         |\n",
      "|    total_timesteps    | 13303808    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013936738 |\n",
      "|    entropy_loss       | -2.04       |\n",
      "|    explained_variance | 0.931       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.035      |\n",
      "|    mean_step_reward   | 0.07362126  |\n",
      "|    n_updates          | 71.88 %     |\n",
      "|    policyGradLoss     | -0.0121     |\n",
      "|    value_loss         | 0.305       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 750         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 272         |\n",
      "|    total_timesteps    | 13312000    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017498687 |\n",
      "|    entropy_loss       | -2          |\n",
      "|    explained_variance | 0.932       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.000847   |\n",
      "|    mean_step_reward   | 0.078580916 |\n",
      "|    n_updates          | 75.00 %     |\n",
      "|    policyGradLoss     | -0.0155     |\n",
      "|    value_loss         | 0.292       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 750         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 283         |\n",
      "|    total_timesteps    | 13320192    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020418532 |\n",
      "|    entropy_loss       | -2.01       |\n",
      "|    explained_variance | 0.931       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0153      |\n",
      "|    mean_step_reward   | 0.054262742 |\n",
      "|    n_updates          | 78.12 %     |\n",
      "|    policyGradLoss     | -0.0194     |\n",
      "|    value_loss         | 0.299       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 750        |\n",
      "|    iterations         | 27         |\n",
      "|    time_elapsed       | 294        |\n",
      "|    total_timesteps    | 13328384   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01773789 |\n",
      "|    entropy_loss       | -1.98      |\n",
      "|    explained_variance | 0.961      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0142    |\n",
      "|    mean_step_reward   | 0.09546996 |\n",
      "|    n_updates          | 81.25 %    |\n",
      "|    policyGradLoss     | -0.018     |\n",
      "|    value_loss         | 0.246      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 749         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 306         |\n",
      "|    total_timesteps    | 13336576    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015968155 |\n",
      "|    entropy_loss       | -1.97       |\n",
      "|    explained_variance | 0.954       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0107     |\n",
      "|    mean_step_reward   | 0.08890834  |\n",
      "|    n_updates          | 84.38 %     |\n",
      "|    policyGradLoss     | -0.0183     |\n",
      "|    value_loss         | 0.281       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 747         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 317         |\n",
      "|    total_timesteps    | 13344768    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023376174 |\n",
      "|    entropy_loss       | -1.99       |\n",
      "|    explained_variance | 0.943       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.000291    |\n",
      "|    mean_step_reward   | 0.07618949  |\n",
      "|    n_updates          | 87.50 %     |\n",
      "|    policyGradLoss     | -0.02       |\n",
      "|    value_loss         | 0.225       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 745         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 329         |\n",
      "|    total_timesteps    | 13352960    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018334718 |\n",
      "|    entropy_loss       | -1.98       |\n",
      "|    explained_variance | 0.931       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0169     |\n",
      "|    mean_step_reward   | 0.07648645  |\n",
      "|    n_updates          | 90.62 %     |\n",
      "|    policyGradLoss     | -0.0159     |\n",
      "|    value_loss         | 0.298       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 744         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 341         |\n",
      "|    total_timesteps    | 13361152    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014232851 |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.952       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0324     |\n",
      "|    mean_step_reward   | 0.09279643  |\n",
      "|    n_updates          | 93.75 %     |\n",
      "|    policyGradLoss     | -0.0166     |\n",
      "|    value_loss         | 0.267       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 744         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 352         |\n",
      "|    total_timesteps    | 13369344    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014281085 |\n",
      "|    entropy_loss       | -1.98       |\n",
      "|    explained_variance | 0.937       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00445    |\n",
      "|    mean_step_reward   | 0.0833054   |\n",
      "|    n_updates          | 96.88 %     |\n",
      "|    policyGradLoss     | -0.0143     |\n",
      "|    value_loss         | 0.343       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Run_50.zip\n",
      "[EVAL] Mean Return: 17.825, Best Return: 19.158\n",
      "Saved video to ./runs_smw/videos/Run/Run_50_17.82.mp4\n",
      "\n",
      "=== Round 52 | Learn 262144 steps (Total trained: 13369344) ===\n",
      "Logging to ./runs_smw/tb/Run_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1177     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 13377536 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 918         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 13385728    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015201175 |\n",
      "|    entropy_loss       | -1.98       |\n",
      "|    explained_variance | 0.9         |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.117       |\n",
      "|    mean_step_reward   | 0.07170919  |\n",
      "|    n_updates          | 3.12 %      |\n",
      "|    policyGradLoss     | -0.014      |\n",
      "|    value_loss         | 0.525       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 914        |\n",
      "|    iterations         | 3          |\n",
      "|    time_elapsed       | 26         |\n",
      "|    total_timesteps    | 13393920   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02232939 |\n",
      "|    entropy_loss       | -1.98      |\n",
      "|    explained_variance | 0.932      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0175    |\n",
      "|    mean_step_reward   | 0.06960188 |\n",
      "|    n_updates          | 6.25 %     |\n",
      "|    policyGradLoss     | -0.0191    |\n",
      "|    value_loss         | 0.244      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 904         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 36          |\n",
      "|    total_timesteps    | 13402112    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018796675 |\n",
      "|    entropy_loss       | -2          |\n",
      "|    explained_variance | 0.943       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.048      |\n",
      "|    mean_step_reward   | 0.07455571  |\n",
      "|    n_updates          | 9.38 %      |\n",
      "|    policyGradLoss     | -0.0183     |\n",
      "|    value_loss         | 0.261       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 897         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 45          |\n",
      "|    total_timesteps    | 13410304    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018456077 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.94        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0428     |\n",
      "|    mean_step_reward   | 0.084287666 |\n",
      "|    n_updates          | 12.50 %     |\n",
      "|    policyGradLoss     | -0.0181     |\n",
      "|    value_loss         | 0.247       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 867         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 56          |\n",
      "|    total_timesteps    | 13418496    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019578528 |\n",
      "|    entropy_loss       | -1.97       |\n",
      "|    explained_variance | 0.94        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.04       |\n",
      "|    mean_step_reward   | 0.07547097  |\n",
      "|    n_updates          | 15.62 %     |\n",
      "|    policyGradLoss     | -0.0201     |\n",
      "|    value_loss         | 0.273       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 839         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 68          |\n",
      "|    total_timesteps    | 13426688    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.0169601   |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.949       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.02       |\n",
      "|    mean_step_reward   | 0.081661865 |\n",
      "|    n_updates          | 18.75 %     |\n",
      "|    policyGradLoss     | -0.0179     |\n",
      "|    value_loss         | 0.276       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 822         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 79          |\n",
      "|    total_timesteps    | 13434880    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020856064 |\n",
      "|    entropy_loss       | -1.98       |\n",
      "|    explained_variance | 0.93        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0174     |\n",
      "|    mean_step_reward   | 0.08381551  |\n",
      "|    n_updates          | 21.88 %     |\n",
      "|    policyGradLoss     | -0.0201     |\n",
      "|    value_loss         | 0.264       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 811        |\n",
      "|    iterations         | 9          |\n",
      "|    time_elapsed       | 90         |\n",
      "|    total_timesteps    | 13443072   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.0229139  |\n",
      "|    entropy_loss       | -1.94      |\n",
      "|    explained_variance | 0.948      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.00221    |\n",
      "|    mean_step_reward   | 0.08744447 |\n",
      "|    n_updates          | 25.00 %    |\n",
      "|    policyGradLoss     | -0.0188    |\n",
      "|    value_loss         | 0.261      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 804         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 101         |\n",
      "|    total_timesteps    | 13451264    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021853048 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.951       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0274      |\n",
      "|    mean_step_reward   | 0.09606697  |\n",
      "|    n_updates          | 28.12 %     |\n",
      "|    policyGradLoss     | -0.0214     |\n",
      "|    value_loss         | 0.276       |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 798       |\n",
      "|    iterations         | 11        |\n",
      "|    time_elapsed       | 112       |\n",
      "|    total_timesteps    | 13459456  |\n",
      "| train/                |           |\n",
      "|    approx_kl          | 0.0164282 |\n",
      "|    entropy_loss       | -2.02     |\n",
      "|    explained_variance | 0.919     |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    loss               | -0.0299   |\n",
      "|    mean_step_reward   | 0.0680466 |\n",
      "|    n_updates          | 31.25 %   |\n",
      "|    policyGradLoss     | -0.0142   |\n",
      "|    value_loss         | 0.233     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 792        |\n",
      "|    iterations         | 12         |\n",
      "|    time_elapsed       | 124        |\n",
      "|    total_timesteps    | 13467648   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02224617 |\n",
      "|    entropy_loss       | -1.94      |\n",
      "|    explained_variance | 0.963      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0504    |\n",
      "|    mean_step_reward   | 0.09708429 |\n",
      "|    n_updates          | 34.38 %    |\n",
      "|    policyGradLoss     | -0.0176    |\n",
      "|    value_loss         | 0.194      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 135         |\n",
      "|    total_timesteps    | 13475840    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023248056 |\n",
      "|    entropy_loss       | -1.97       |\n",
      "|    explained_variance | 0.913       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00798    |\n",
      "|    mean_step_reward   | 0.073562615 |\n",
      "|    n_updates          | 37.50 %     |\n",
      "|    policyGradLoss     | -0.0151     |\n",
      "|    value_loss         | 0.349       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 147         |\n",
      "|    total_timesteps    | 13484032    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021461222 |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.942       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0541     |\n",
      "|    mean_step_reward   | 0.0839356   |\n",
      "|    n_updates          | 40.62 %     |\n",
      "|    policyGradLoss     | -0.0212     |\n",
      "|    value_loss         | 0.239       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 158         |\n",
      "|    total_timesteps    | 13492224    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020675177 |\n",
      "|    entropy_loss       | -1.97       |\n",
      "|    explained_variance | 0.93        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0267     |\n",
      "|    mean_step_reward   | 0.08254619  |\n",
      "|    n_updates          | 43.75 %     |\n",
      "|    policyGradLoss     | -0.0134     |\n",
      "|    value_loss         | 0.277       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 170         |\n",
      "|    total_timesteps    | 13500416    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018760316 |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.931       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0441     |\n",
      "|    mean_step_reward   | 0.076361865 |\n",
      "|    n_updates          | 46.88 %     |\n",
      "|    policyGradLoss     | -0.018      |\n",
      "|    value_loss         | 0.252       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 181         |\n",
      "|    total_timesteps    | 13508608    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019687757 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.935       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0323     |\n",
      "|    mean_step_reward   | 0.09865484  |\n",
      "|    n_updates          | 50.00 %     |\n",
      "|    policyGradLoss     | -0.0205     |\n",
      "|    value_loss         | 0.265       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 766        |\n",
      "|    iterations         | 18         |\n",
      "|    time_elapsed       | 192        |\n",
      "|    total_timesteps    | 13516800   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02072815 |\n",
      "|    entropy_loss       | -1.98      |\n",
      "|    explained_variance | 0.925      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.00279    |\n",
      "|    mean_step_reward   | 0.06881119 |\n",
      "|    n_updates          | 53.12 %    |\n",
      "|    policyGradLoss     | -0.0195    |\n",
      "|    value_loss         | 0.285      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 764         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 203         |\n",
      "|    total_timesteps    | 13524992    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018397715 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.936       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0585      |\n",
      "|    mean_step_reward   | 0.087299794 |\n",
      "|    n_updates          | 56.25 %     |\n",
      "|    policyGradLoss     | -0.0145     |\n",
      "|    value_loss         | 0.389       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 761         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 215         |\n",
      "|    total_timesteps    | 13533184    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018377881 |\n",
      "|    entropy_loss       | -1.98       |\n",
      "|    explained_variance | 0.936       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0116     |\n",
      "|    mean_step_reward   | 0.07421974  |\n",
      "|    n_updates          | 59.38 %     |\n",
      "|    policyGradLoss     | -0.0183     |\n",
      "|    value_loss         | 0.269       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 757         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 227         |\n",
      "|    total_timesteps    | 13541376    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016084075 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.924       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0474      |\n",
      "|    mean_step_reward   | 0.09513563  |\n",
      "|    n_updates          | 62.50 %     |\n",
      "|    policyGradLoss     | -0.0134     |\n",
      "|    value_loss         | 0.325       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 755         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 238         |\n",
      "|    total_timesteps    | 13549568    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021190925 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.912       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0144     |\n",
      "|    mean_step_reward   | 0.07629356  |\n",
      "|    n_updates          | 65.62 %     |\n",
      "|    policyGradLoss     | -0.0171     |\n",
      "|    value_loss         | 0.401       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 754         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 249         |\n",
      "|    total_timesteps    | 13557760    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019157365 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.93        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00913    |\n",
      "|    mean_step_reward   | 0.08852802  |\n",
      "|    n_updates          | 68.75 %     |\n",
      "|    policyGradLoss     | -0.0158     |\n",
      "|    value_loss         | 0.268       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 754        |\n",
      "|    iterations         | 24         |\n",
      "|    time_elapsed       | 260        |\n",
      "|    total_timesteps    | 13565952   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02134734 |\n",
      "|    entropy_loss       | -1.91      |\n",
      "|    explained_variance | 0.948      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0149    |\n",
      "|    mean_step_reward   | 0.08366938 |\n",
      "|    n_updates          | 71.88 %    |\n",
      "|    policyGradLoss     | -0.0175    |\n",
      "|    value_loss         | 0.286      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 753        |\n",
      "|    iterations         | 25         |\n",
      "|    time_elapsed       | 271        |\n",
      "|    total_timesteps    | 13574144   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02223302 |\n",
      "|    entropy_loss       | -1.91      |\n",
      "|    explained_variance | 0.949      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.00272    |\n",
      "|    mean_step_reward   | 0.08994868 |\n",
      "|    n_updates          | 75.00 %    |\n",
      "|    policyGradLoss     | -0.0176    |\n",
      "|    value_loss         | 0.304      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 752         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 283         |\n",
      "|    total_timesteps    | 13582336    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017724814 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.939       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0175     |\n",
      "|    mean_step_reward   | 0.09760361  |\n",
      "|    n_updates          | 78.12 %     |\n",
      "|    policyGradLoss     | -0.0143     |\n",
      "|    value_loss         | 0.355       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 750         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 294         |\n",
      "|    total_timesteps    | 13590528    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016690522 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.929       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0125      |\n",
      "|    mean_step_reward   | 0.07738905  |\n",
      "|    n_updates          | 81.25 %     |\n",
      "|    policyGradLoss     | -0.0151     |\n",
      "|    value_loss         | 0.363       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 748         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 306         |\n",
      "|    total_timesteps    | 13598720    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017671373 |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.933       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00209    |\n",
      "|    mean_step_reward   | 0.08781937  |\n",
      "|    n_updates          | 84.38 %     |\n",
      "|    policyGradLoss     | -0.0149     |\n",
      "|    value_loss         | 0.354       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 747        |\n",
      "|    iterations         | 29         |\n",
      "|    time_elapsed       | 317        |\n",
      "|    total_timesteps    | 13606912   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.0204694  |\n",
      "|    entropy_loss       | -1.97      |\n",
      "|    explained_variance | 0.958      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0263    |\n",
      "|    mean_step_reward   | 0.09041108 |\n",
      "|    n_updates          | 87.50 %    |\n",
      "|    policyGradLoss     | -0.0209    |\n",
      "|    value_loss         | 0.226      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 747         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 328         |\n",
      "|    total_timesteps    | 13615104    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017603125 |\n",
      "|    entropy_loss       | -1.98       |\n",
      "|    explained_variance | 0.928       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0091      |\n",
      "|    mean_step_reward   | 0.06986847  |\n",
      "|    n_updates          | 90.62 %     |\n",
      "|    policyGradLoss     | -0.0157     |\n",
      "|    value_loss         | 0.359       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 746         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 339         |\n",
      "|    total_timesteps    | 13623296    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021224413 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.945       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0222      |\n",
      "|    mean_step_reward   | 0.068755    |\n",
      "|    n_updates          | 93.75 %     |\n",
      "|    policyGradLoss     | -0.0172     |\n",
      "|    value_loss         | 0.277       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 746        |\n",
      "|    iterations         | 32         |\n",
      "|    time_elapsed       | 350        |\n",
      "|    total_timesteps    | 13631488   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02184086 |\n",
      "|    entropy_loss       | -1.97      |\n",
      "|    explained_variance | 0.948      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.00655   |\n",
      "|    mean_step_reward   | 0.09414761 |\n",
      "|    n_updates          | 96.88 %    |\n",
      "|    policyGradLoss     | -0.0121    |\n",
      "|    value_loss         | 0.26       |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Run_51.zip\n",
      "[EVAL] Mean Return: 21.089, Best Return: 21.756\n",
      "Saved video to ./runs_smw/videos/Run/Run_51_21.09.mp4\n",
      "\n",
      "=== Round 53 | Learn 262144 steps (Total trained: 13631488) ===\n",
      "Logging to ./runs_smw/tb/Run_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1429     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 13639680 |\n",
      "---------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 1089       |\n",
      "|    iterations         | 2          |\n",
      "|    time_elapsed       | 15         |\n",
      "|    total_timesteps    | 13647872   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01611774 |\n",
      "|    entropy_loss       | -1.94      |\n",
      "|    explained_variance | 0.935      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.0552     |\n",
      "|    mean_step_reward   | 0.08250463 |\n",
      "|    n_updates          | 3.12 %     |\n",
      "|    policyGradLoss     | -0.0144    |\n",
      "|    value_loss         | 0.37       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 953         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 25          |\n",
      "|    total_timesteps    | 13656064    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018326228 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.958       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0251     |\n",
      "|    mean_step_reward   | 0.09382142  |\n",
      "|    n_updates          | 6.25 %      |\n",
      "|    policyGradLoss     | -0.0186     |\n",
      "|    value_loss         | 0.198       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 878         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 37          |\n",
      "|    total_timesteps    | 13664256    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019220619 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0211     |\n",
      "|    mean_step_reward   | 0.09719984  |\n",
      "|    n_updates          | 9.38 %      |\n",
      "|    policyGradLoss     | -0.017      |\n",
      "|    value_loss         | 0.235       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 835         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 49          |\n",
      "|    total_timesteps    | 13672448    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022790805 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0385     |\n",
      "|    mean_step_reward   | 0.10169219  |\n",
      "|    n_updates          | 12.50 %     |\n",
      "|    policyGradLoss     | -0.019      |\n",
      "|    value_loss         | 0.217       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 814         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 60          |\n",
      "|    total_timesteps    | 13680640    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019289866 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.948       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0556      |\n",
      "|    mean_step_reward   | 0.07658078  |\n",
      "|    n_updates          | 15.62 %     |\n",
      "|    policyGradLoss     | -0.0179     |\n",
      "|    value_loss         | 0.322       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 803        |\n",
      "|    iterations         | 7          |\n",
      "|    time_elapsed       | 71         |\n",
      "|    total_timesteps    | 13688832   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02470412 |\n",
      "|    entropy_loss       | -1.88      |\n",
      "|    explained_variance | 0.966      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0333    |\n",
      "|    mean_step_reward   | 0.09193022 |\n",
      "|    n_updates          | 18.75 %    |\n",
      "|    policyGradLoss     | -0.0208    |\n",
      "|    value_loss         | 0.203      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 795         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 82          |\n",
      "|    total_timesteps    | 13697024    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017890811 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.947       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0662      |\n",
      "|    mean_step_reward   | 0.092486635 |\n",
      "|    n_updates          | 21.88 %     |\n",
      "|    policyGradLoss     | -0.0148     |\n",
      "|    value_loss         | 0.346       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 93          |\n",
      "|    total_timesteps    | 13705216    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023925908 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00588    |\n",
      "|    mean_step_reward   | 0.09597125  |\n",
      "|    n_updates          | 25.00 %     |\n",
      "|    policyGradLoss     | -0.0175     |\n",
      "|    value_loss         | 0.212       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 104         |\n",
      "|    total_timesteps    | 13713408    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02485548  |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.955       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0427     |\n",
      "|    mean_step_reward   | 0.092593834 |\n",
      "|    n_updates          | 28.12 %     |\n",
      "|    policyGradLoss     | -0.0185     |\n",
      "|    value_loss         | 0.216       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 116         |\n",
      "|    total_timesteps    | 13721600    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022798147 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.922       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0267     |\n",
      "|    mean_step_reward   | 0.083692364 |\n",
      "|    n_updates          | 31.25 %     |\n",
      "|    policyGradLoss     | -0.0159     |\n",
      "|    value_loss         | 0.352       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 127         |\n",
      "|    total_timesteps    | 13729792    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019087728 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.943       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0462      |\n",
      "|    mean_step_reward   | 0.08843602  |\n",
      "|    n_updates          | 34.38 %     |\n",
      "|    policyGradLoss     | -0.0176     |\n",
      "|    value_loss         | 0.312       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 139         |\n",
      "|    total_timesteps    | 13737984    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018926585 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.935       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0338      |\n",
      "|    mean_step_reward   | 0.08960606  |\n",
      "|    n_updates          | 37.50 %     |\n",
      "|    policyGradLoss     | -0.0153     |\n",
      "|    value_loss         | 0.325       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 764         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 149         |\n",
      "|    total_timesteps    | 13746176    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020467915 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.929       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0255      |\n",
      "|    mean_step_reward   | 0.09187792  |\n",
      "|    n_updates          | 40.62 %     |\n",
      "|    policyGradLoss     | -0.0164     |\n",
      "|    value_loss         | 0.354       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 762         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 161         |\n",
      "|    total_timesteps    | 13754368    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023525916 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0533     |\n",
      "|    mean_step_reward   | 0.10582158  |\n",
      "|    n_updates          | 43.75 %     |\n",
      "|    policyGradLoss     | -0.0213     |\n",
      "|    value_loss         | 0.244       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 760        |\n",
      "|    iterations         | 16         |\n",
      "|    time_elapsed       | 172        |\n",
      "|    total_timesteps    | 13762560   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01996197 |\n",
      "|    entropy_loss       | -1.92      |\n",
      "|    explained_variance | 0.944      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0298    |\n",
      "|    mean_step_reward   | 0.08485147 |\n",
      "|    n_updates          | 46.88 %    |\n",
      "|    policyGradLoss     | -0.0194    |\n",
      "|    value_loss         | 0.245      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 758         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 183         |\n",
      "|    total_timesteps    | 13770752    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019449905 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0202     |\n",
      "|    mean_step_reward   | 0.10499282  |\n",
      "|    n_updates          | 50.00 %     |\n",
      "|    policyGradLoss     | -0.0161     |\n",
      "|    value_loss         | 0.23        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 755         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 195         |\n",
      "|    total_timesteps    | 13778944    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015238354 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.883       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0629      |\n",
      "|    mean_step_reward   | 0.08193123  |\n",
      "|    n_updates          | 53.12 %     |\n",
      "|    policyGradLoss     | -0.00792    |\n",
      "|    value_loss         | 0.524       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 752         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 206         |\n",
      "|    total_timesteps    | 13787136    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018025424 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.95        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0135      |\n",
      "|    mean_step_reward   | 0.08017264  |\n",
      "|    n_updates          | 56.25 %     |\n",
      "|    policyGradLoss     | -0.0173     |\n",
      "|    value_loss         | 0.272       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 750         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 218         |\n",
      "|    total_timesteps    | 13795328    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015501027 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.92        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0404     |\n",
      "|    mean_step_reward   | 0.09875651  |\n",
      "|    n_updates          | 59.38 %     |\n",
      "|    policyGradLoss     | -0.0165     |\n",
      "|    value_loss         | 0.298       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 749         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 229         |\n",
      "|    total_timesteps    | 13803520    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018757876 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.93        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0495      |\n",
      "|    mean_step_reward   | 0.10020475  |\n",
      "|    n_updates          | 62.50 %     |\n",
      "|    policyGradLoss     | -0.0124     |\n",
      "|    value_loss         | 0.385       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 749         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 240         |\n",
      "|    total_timesteps    | 13811712    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017409563 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.943       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0197     |\n",
      "|    mean_step_reward   | 0.092478275 |\n",
      "|    n_updates          | 65.62 %     |\n",
      "|    policyGradLoss     | -0.014      |\n",
      "|    value_loss         | 0.32        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 749         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 251         |\n",
      "|    total_timesteps    | 13819904    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016498502 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.934       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0575      |\n",
      "|    mean_step_reward   | 0.103835344 |\n",
      "|    n_updates          | 68.75 %     |\n",
      "|    policyGradLoss     | -0.0154     |\n",
      "|    value_loss         | 0.385       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 747         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 262         |\n",
      "|    total_timesteps    | 13828096    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016905649 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.949       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0341     |\n",
      "|    mean_step_reward   | 0.091708735 |\n",
      "|    n_updates          | 71.88 %     |\n",
      "|    policyGradLoss     | -0.0161     |\n",
      "|    value_loss         | 0.319       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 746         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 274         |\n",
      "|    total_timesteps    | 13836288    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019839393 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.957       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.026      |\n",
      "|    mean_step_reward   | 0.096874006 |\n",
      "|    n_updates          | 75.00 %     |\n",
      "|    policyGradLoss     | -0.0189     |\n",
      "|    value_loss         | 0.225       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 744         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 286         |\n",
      "|    total_timesteps    | 13844480    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019070704 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.954       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0048      |\n",
      "|    mean_step_reward   | 0.09224412  |\n",
      "|    n_updates          | 78.12 %     |\n",
      "|    policyGradLoss     | -0.0176     |\n",
      "|    value_loss         | 0.325       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 743         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 297         |\n",
      "|    total_timesteps    | 13852672    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025021816 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.945       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0356     |\n",
      "|    mean_step_reward   | 0.08559868  |\n",
      "|    n_updates          | 81.25 %     |\n",
      "|    policyGradLoss     | -0.0194     |\n",
      "|    value_loss         | 0.224       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 743         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 308         |\n",
      "|    total_timesteps    | 13860864    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018153746 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.949       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0223      |\n",
      "|    mean_step_reward   | 0.099758446 |\n",
      "|    n_updates          | 84.38 %     |\n",
      "|    policyGradLoss     | -0.0155     |\n",
      "|    value_loss         | 0.294       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 743         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 319         |\n",
      "|    total_timesteps    | 13869056    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020450924 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.939       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0645      |\n",
      "|    mean_step_reward   | 0.07230902  |\n",
      "|    n_updates          | 87.50 %     |\n",
      "|    policyGradLoss     | -0.0196     |\n",
      "|    value_loss         | 0.359       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 743         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 330         |\n",
      "|    total_timesteps    | 13877248    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023147078 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.954       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.046       |\n",
      "|    mean_step_reward   | 0.10255154  |\n",
      "|    n_updates          | 90.62 %     |\n",
      "|    policyGradLoss     | -0.0203     |\n",
      "|    value_loss         | 0.239       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 744         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 341         |\n",
      "|    total_timesteps    | 13885440    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.0216171   |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.946       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0098     |\n",
      "|    mean_step_reward   | 0.085874304 |\n",
      "|    n_updates          | 93.75 %     |\n",
      "|    policyGradLoss     | -0.0204     |\n",
      "|    value_loss         | 0.245       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 749         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 349         |\n",
      "|    total_timesteps    | 13893632    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017131427 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.942       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0191     |\n",
      "|    mean_step_reward   | 0.08897083  |\n",
      "|    n_updates          | 96.88 %     |\n",
      "|    policyGradLoss     | -0.018      |\n",
      "|    value_loss         | 0.209       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Run_52.zip\n",
      "[EVAL] Mean Return: 67.517, Best Return: 71.350\n",
      "Saved video to ./runs_smw/videos/Run/Run_52_67.52.mp4\n",
      "\n",
      "=== Round 54 | Learn 262144 steps (Total trained: 13893632) ===\n",
      "Logging to ./runs_smw/tb/Run_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1092     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 13901824 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 857         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 19          |\n",
      "|    total_timesteps    | 13910016    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024414096 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.957       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0553     |\n",
      "|    mean_step_reward   | 0.09135009  |\n",
      "|    n_updates          | 3.12 %      |\n",
      "|    policyGradLoss     | -0.0208     |\n",
      "|    value_loss         | 0.165       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 804         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 30          |\n",
      "|    total_timesteps    | 13918208    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018458918 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.949       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0469     |\n",
      "|    mean_step_reward   | 0.11101189  |\n",
      "|    n_updates          | 6.25 %      |\n",
      "|    policyGradLoss     | -0.0186     |\n",
      "|    value_loss         | 0.245       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 789         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 41          |\n",
      "|    total_timesteps    | 13926400    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020271726 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.943       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0613     |\n",
      "|    mean_step_reward   | 0.096337795 |\n",
      "|    n_updates          | 9.38 %      |\n",
      "|    policyGradLoss     | -0.0186     |\n",
      "|    value_loss         | 0.246       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 52          |\n",
      "|    total_timesteps    | 13934592    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017791659 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.927       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0042      |\n",
      "|    mean_step_reward   | 0.08200313  |\n",
      "|    n_updates          | 12.50 %     |\n",
      "|    policyGradLoss     | -0.0177     |\n",
      "|    value_loss         | 0.373       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 63          |\n",
      "|    total_timesteps    | 13942784    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019181833 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.934       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.003       |\n",
      "|    mean_step_reward   | 0.1008881   |\n",
      "|    n_updates          | 15.62 %     |\n",
      "|    policyGradLoss     | -0.0181     |\n",
      "|    value_loss         | 0.4         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 764         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 74          |\n",
      "|    total_timesteps    | 13950976    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019117907 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.942       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0116     |\n",
      "|    mean_step_reward   | 0.08217549  |\n",
      "|    n_updates          | 18.75 %     |\n",
      "|    policyGradLoss     | -0.0191     |\n",
      "|    value_loss         | 0.293       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 756         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 86          |\n",
      "|    total_timesteps    | 13959168    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019479793 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.943       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00349     |\n",
      "|    mean_step_reward   | 0.090307325 |\n",
      "|    n_updates          | 21.88 %     |\n",
      "|    policyGradLoss     | -0.0164     |\n",
      "|    value_loss         | 0.378       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 750         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 98          |\n",
      "|    total_timesteps    | 13967360    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018595537 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0139      |\n",
      "|    mean_step_reward   | 0.09814695  |\n",
      "|    n_updates          | 25.00 %     |\n",
      "|    policyGradLoss     | -0.0155     |\n",
      "|    value_loss         | 0.253       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 747         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 109         |\n",
      "|    total_timesteps    | 13975552    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020005982 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.937       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0277      |\n",
      "|    mean_step_reward   | 0.08447686  |\n",
      "|    n_updates          | 28.12 %     |\n",
      "|    policyGradLoss     | -0.0167     |\n",
      "|    value_loss         | 0.282       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 748         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 120         |\n",
      "|    total_timesteps    | 13983744    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015887372 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.928       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00836    |\n",
      "|    mean_step_reward   | 0.08721225  |\n",
      "|    n_updates          | 31.25 %     |\n",
      "|    policyGradLoss     | -0.0137     |\n",
      "|    value_loss         | 0.367       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 748         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 131         |\n",
      "|    total_timesteps    | 13991936    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023375094 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0533     |\n",
      "|    mean_step_reward   | 0.09047066  |\n",
      "|    n_updates          | 34.38 %     |\n",
      "|    policyGradLoss     | -0.0217     |\n",
      "|    value_loss         | 0.179       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 747         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 142         |\n",
      "|    total_timesteps    | 14000128    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015417682 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.941       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0277      |\n",
      "|    mean_step_reward   | 0.105787456 |\n",
      "|    n_updates          | 37.50 %     |\n",
      "|    policyGradLoss     | -0.0139     |\n",
      "|    value_loss         | 0.296       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 746        |\n",
      "|    iterations         | 14         |\n",
      "|    time_elapsed       | 153        |\n",
      "|    total_timesteps    | 14008320   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02200891 |\n",
      "|    entropy_loss       | -1.94      |\n",
      "|    explained_variance | 0.932      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0441    |\n",
      "|    mean_step_reward   | 0.09332455 |\n",
      "|    n_updates          | 40.62 %    |\n",
      "|    policyGradLoss     | -0.0198    |\n",
      "|    value_loss         | 0.289      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 743         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 165         |\n",
      "|    total_timesteps    | 14016512    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015601591 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.916       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0847      |\n",
      "|    mean_step_reward   | 0.07137421  |\n",
      "|    n_updates          | 43.75 %     |\n",
      "|    policyGradLoss     | -0.0128     |\n",
      "|    value_loss         | 0.408       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 741         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 176         |\n",
      "|    total_timesteps    | 14024704    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021622812 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.949       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0144      |\n",
      "|    mean_step_reward   | 0.08325945  |\n",
      "|    n_updates          | 46.88 %     |\n",
      "|    policyGradLoss     | -0.0184     |\n",
      "|    value_loss         | 0.355       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 740        |\n",
      "|    iterations         | 17         |\n",
      "|    time_elapsed       | 188        |\n",
      "|    total_timesteps    | 14032896   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01701114 |\n",
      "|    entropy_loss       | -1.93      |\n",
      "|    explained_variance | 0.915      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0237    |\n",
      "|    mean_step_reward   | 0.09603304 |\n",
      "|    n_updates          | 50.00 %    |\n",
      "|    policyGradLoss     | -0.0122    |\n",
      "|    value_loss         | 0.359      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 740         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 199         |\n",
      "|    total_timesteps    | 14041088    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019386921 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.912       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0193      |\n",
      "|    mean_step_reward   | 0.070582256 |\n",
      "|    n_updates          | 53.12 %     |\n",
      "|    policyGradLoss     | -0.014      |\n",
      "|    value_loss         | 0.382       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 740        |\n",
      "|    iterations         | 19         |\n",
      "|    time_elapsed       | 210        |\n",
      "|    total_timesteps    | 14049280   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02090264 |\n",
      "|    entropy_loss       | -1.94      |\n",
      "|    explained_variance | 0.905      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.0303     |\n",
      "|    mean_step_reward   | 0.07537126 |\n",
      "|    n_updates          | 56.25 %    |\n",
      "|    policyGradLoss     | -0.0177    |\n",
      "|    value_loss         | 0.289      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 741         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 221         |\n",
      "|    total_timesteps    | 14057472    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017283477 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.955       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.042      |\n",
      "|    mean_step_reward   | 0.109427795 |\n",
      "|    n_updates          | 59.38 %     |\n",
      "|    policyGradLoss     | -0.0165     |\n",
      "|    value_loss         | 0.217       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 740         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 232         |\n",
      "|    total_timesteps    | 14065664    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02341196  |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.949       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0486      |\n",
      "|    mean_step_reward   | 0.092086434 |\n",
      "|    n_updates          | 62.50 %     |\n",
      "|    policyGradLoss     | -0.0197     |\n",
      "|    value_loss         | 0.26        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 738         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 243         |\n",
      "|    total_timesteps    | 14073856    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015983984 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.941       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0537      |\n",
      "|    mean_step_reward   | 0.10578422  |\n",
      "|    n_updates          | 65.62 %     |\n",
      "|    policyGradLoss     | -0.0147     |\n",
      "|    value_loss         | 0.312       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 737         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 255         |\n",
      "|    total_timesteps    | 14082048    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017123006 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.914       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0323     |\n",
      "|    mean_step_reward   | 0.08560887  |\n",
      "|    n_updates          | 68.75 %     |\n",
      "|    policyGradLoss     | -0.0156     |\n",
      "|    value_loss         | 0.338       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 736         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 266         |\n",
      "|    total_timesteps    | 14090240    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014407508 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.938       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00134     |\n",
      "|    mean_step_reward   | 0.08617989  |\n",
      "|    n_updates          | 71.88 %     |\n",
      "|    policyGradLoss     | -0.0142     |\n",
      "|    value_loss         | 0.426       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 737         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 277         |\n",
      "|    total_timesteps    | 14098432    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017975956 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.923       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0326      |\n",
      "|    mean_step_reward   | 0.08983448  |\n",
      "|    n_updates          | 75.00 %     |\n",
      "|    policyGradLoss     | -0.0165     |\n",
      "|    value_loss         | 0.345       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 737         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 288         |\n",
      "|    total_timesteps    | 14106624    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01680463  |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.949       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00476    |\n",
      "|    mean_step_reward   | 0.086604856 |\n",
      "|    n_updates          | 78.12 %     |\n",
      "|    policyGradLoss     | -0.0131     |\n",
      "|    value_loss         | 0.259       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 737        |\n",
      "|    iterations         | 27         |\n",
      "|    time_elapsed       | 299        |\n",
      "|    total_timesteps    | 14114816   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02003565 |\n",
      "|    entropy_loss       | -1.88      |\n",
      "|    explained_variance | 0.956      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0166    |\n",
      "|    mean_step_reward   | 0.09977868 |\n",
      "|    n_updates          | 81.25 %    |\n",
      "|    policyGradLoss     | -0.0179    |\n",
      "|    value_loss         | 0.263      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 736         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 311         |\n",
      "|    total_timesteps    | 14123008    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023829326 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.947       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0494     |\n",
      "|    mean_step_reward   | 0.08843696  |\n",
      "|    n_updates          | 84.38 %     |\n",
      "|    policyGradLoss     | -0.0165     |\n",
      "|    value_loss         | 0.243       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 740         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 320         |\n",
      "|    total_timesteps    | 14131200    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018604197 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.944       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0408     |\n",
      "|    mean_step_reward   | 0.107139856 |\n",
      "|    n_updates          | 87.50 %     |\n",
      "|    policyGradLoss     | -0.0161     |\n",
      "|    value_loss         | 0.307       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 744         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 330         |\n",
      "|    total_timesteps    | 14139392    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020361498 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.955       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0657     |\n",
      "|    mean_step_reward   | 0.10550072  |\n",
      "|    n_updates          | 90.62 %     |\n",
      "|    policyGradLoss     | -0.0175     |\n",
      "|    value_loss         | 0.213       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 747         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 339         |\n",
      "|    total_timesteps    | 14147584    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018156264 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.941       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0248      |\n",
      "|    mean_step_reward   | 0.10809323  |\n",
      "|    n_updates          | 93.75 %     |\n",
      "|    policyGradLoss     | -0.0129     |\n",
      "|    value_loss         | 0.407       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 748         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 350         |\n",
      "|    total_timesteps    | 14155776    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022444788 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.927       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0673      |\n",
      "|    mean_step_reward   | 0.09168756  |\n",
      "|    n_updates          | 96.88 %     |\n",
      "|    policyGradLoss     | -0.0169     |\n",
      "|    value_loss         | 0.366       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Run_53.zip\n",
      "[EVAL] Mean Return: 68.776, Best Return: 73.276\n",
      "Saved video to ./runs_smw/videos/Run/Run_53_68.78.mp4\n",
      "\n",
      "=== Round 55 | Learn 262144 steps (Total trained: 14155776) ===\n",
      "Logging to ./runs_smw/tb/Run_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1084     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 14163968 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 861         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 19          |\n",
      "|    total_timesteps    | 14172160    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020663043 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00526    |\n",
      "|    mean_step_reward   | 0.10482323  |\n",
      "|    n_updates          | 3.12 %      |\n",
      "|    policyGradLoss     | -0.017      |\n",
      "|    value_loss         | 0.28        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 30          |\n",
      "|    total_timesteps    | 14180352    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.0200883   |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.949       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0048      |\n",
      "|    mean_step_reward   | 0.109993786 |\n",
      "|    n_updates          | 6.25 %      |\n",
      "|    policyGradLoss     | -0.0187     |\n",
      "|    value_loss         | 0.283       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 795         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 41          |\n",
      "|    total_timesteps    | 14188544    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027960531 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.954       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0173     |\n",
      "|    mean_step_reward   | 0.09028311  |\n",
      "|    n_updates          | 9.38 %      |\n",
      "|    policyGradLoss     | -0.0184     |\n",
      "|    value_loss         | 0.283       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 52          |\n",
      "|    total_timesteps    | 14196736    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016591802 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0805      |\n",
      "|    mean_step_reward   | 0.095195554 |\n",
      "|    n_updates          | 12.50 %     |\n",
      "|    policyGradLoss     | -0.0148     |\n",
      "|    value_loss         | 0.339       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 63          |\n",
      "|    total_timesteps    | 14204928    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022219697 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.95        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0368     |\n",
      "|    mean_step_reward   | 0.10900432  |\n",
      "|    n_updates          | 15.62 %     |\n",
      "|    policyGradLoss     | -0.0196     |\n",
      "|    value_loss         | 0.283       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 74          |\n",
      "|    total_timesteps    | 14213120    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023290709 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.938       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00797     |\n",
      "|    mean_step_reward   | 0.08593057  |\n",
      "|    n_updates          | 18.75 %     |\n",
      "|    policyGradLoss     | -0.0166     |\n",
      "|    value_loss         | 0.386       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 760         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 86          |\n",
      "|    total_timesteps    | 14221312    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020157188 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.948       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0275     |\n",
      "|    mean_step_reward   | 0.09275253  |\n",
      "|    n_updates          | 21.88 %     |\n",
      "|    policyGradLoss     | -0.0215     |\n",
      "|    value_loss         | 0.249       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 754        |\n",
      "|    iterations         | 9          |\n",
      "|    time_elapsed       | 97         |\n",
      "|    total_timesteps    | 14229504   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02012817 |\n",
      "|    entropy_loss       | -1.91      |\n",
      "|    explained_variance | 0.937      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0434    |\n",
      "|    mean_step_reward   | 0.09089105 |\n",
      "|    n_updates          | 25.00 %    |\n",
      "|    policyGradLoss     | -0.0198    |\n",
      "|    value_loss         | 0.278      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 750         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 109         |\n",
      "|    total_timesteps    | 14237696    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02138109  |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.019      |\n",
      "|    mean_step_reward   | 0.105462894 |\n",
      "|    n_updates          | 28.12 %     |\n",
      "|    policyGradLoss     | -0.0195     |\n",
      "|    value_loss         | 0.236       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 748         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 120         |\n",
      "|    total_timesteps    | 14245888    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019068122 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.933       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00504    |\n",
      "|    mean_step_reward   | 0.09960751  |\n",
      "|    n_updates          | 31.25 %     |\n",
      "|    policyGradLoss     | -0.0194     |\n",
      "|    value_loss         | 0.369       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 747         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 131         |\n",
      "|    total_timesteps    | 14254080    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016959034 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.924       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0201      |\n",
      "|    mean_step_reward   | 0.09292272  |\n",
      "|    n_updates          | 34.38 %     |\n",
      "|    policyGradLoss     | -0.0157     |\n",
      "|    value_loss         | 0.311       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 747         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 142         |\n",
      "|    total_timesteps    | 14262272    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016293146 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.925       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0166     |\n",
      "|    mean_step_reward   | 0.10049644  |\n",
      "|    n_updates          | 37.50 %     |\n",
      "|    policyGradLoss     | -0.0126     |\n",
      "|    value_loss         | 0.377       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 745         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 153         |\n",
      "|    total_timesteps    | 14270464    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021334162 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.941       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00641     |\n",
      "|    mean_step_reward   | 0.099289805 |\n",
      "|    n_updates          | 40.62 %     |\n",
      "|    policyGradLoss     | -0.0155     |\n",
      "|    value_loss         | 0.364       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 742         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 165         |\n",
      "|    total_timesteps    | 14278656    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022039466 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.928       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0304     |\n",
      "|    mean_step_reward   | 0.112153485 |\n",
      "|    n_updates          | 43.75 %     |\n",
      "|    policyGradLoss     | -0.018      |\n",
      "|    value_loss         | 0.289       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 740         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 177         |\n",
      "|    total_timesteps    | 14286848    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020535968 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.947       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0345     |\n",
      "|    mean_step_reward   | 0.093428776 |\n",
      "|    n_updates          | 46.88 %     |\n",
      "|    policyGradLoss     | -0.0149     |\n",
      "|    value_loss         | 0.3         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 739         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 188         |\n",
      "|    total_timesteps    | 14295040    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017285008 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.943       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0526      |\n",
      "|    mean_step_reward   | 0.1153615   |\n",
      "|    n_updates          | 50.00 %     |\n",
      "|    policyGradLoss     | -0.0134     |\n",
      "|    value_loss         | 0.357       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 740         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 199         |\n",
      "|    total_timesteps    | 14303232    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016972572 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.942       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0681      |\n",
      "|    mean_step_reward   | 0.07903732  |\n",
      "|    n_updates          | 53.12 %     |\n",
      "|    policyGradLoss     | -0.0162     |\n",
      "|    value_loss         | 0.38        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 740         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 210         |\n",
      "|    total_timesteps    | 14311424    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017319053 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.926       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0433      |\n",
      "|    mean_step_reward   | 0.09802605  |\n",
      "|    n_updates          | 56.25 %     |\n",
      "|    policyGradLoss     | -0.0158     |\n",
      "|    value_loss         | 0.45        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 739         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 221         |\n",
      "|    total_timesteps    | 14319616    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023644414 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.944       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0208      |\n",
      "|    mean_step_reward   | 0.086028725 |\n",
      "|    n_updates          | 59.38 %     |\n",
      "|    policyGradLoss     | -0.0179     |\n",
      "|    value_loss         | 0.241       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 739         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 232         |\n",
      "|    total_timesteps    | 14327808    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023387207 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.943       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0348     |\n",
      "|    mean_step_reward   | 0.088234484 |\n",
      "|    n_updates          | 62.50 %     |\n",
      "|    policyGradLoss     | -0.0173     |\n",
      "|    value_loss         | 0.234       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 738         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 244         |\n",
      "|    total_timesteps    | 14336000    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023544835 |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.945       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0674     |\n",
      "|    mean_step_reward   | 0.07820259  |\n",
      "|    n_updates          | 65.62 %     |\n",
      "|    policyGradLoss     | -0.0215     |\n",
      "|    value_loss         | 0.185       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 736         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 255         |\n",
      "|    total_timesteps    | 14344192    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019213859 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.952       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0591      |\n",
      "|    mean_step_reward   | 0.09918549  |\n",
      "|    n_updates          | 68.75 %     |\n",
      "|    policyGradLoss     | -0.0168     |\n",
      "|    value_loss         | 0.297       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 735        |\n",
      "|    iterations         | 24         |\n",
      "|    time_elapsed       | 267        |\n",
      "|    total_timesteps    | 14352384   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02100937 |\n",
      "|    entropy_loss       | -1.91      |\n",
      "|    explained_variance | 0.947      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0262    |\n",
      "|    mean_step_reward   | 0.10418992 |\n",
      "|    n_updates          | 71.88 %    |\n",
      "|    policyGradLoss     | -0.018     |\n",
      "|    value_loss         | 0.259      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 736         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 278         |\n",
      "|    total_timesteps    | 14360576    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020052187 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.921       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0168      |\n",
      "|    mean_step_reward   | 0.09117237  |\n",
      "|    n_updates          | 75.00 %     |\n",
      "|    policyGradLoss     | -0.0151     |\n",
      "|    value_loss         | 0.371       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 741         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 287         |\n",
      "|    total_timesteps    | 14368768    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019286335 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0465      |\n",
      "|    mean_step_reward   | 0.11424014  |\n",
      "|    n_updates          | 78.12 %     |\n",
      "|    policyGradLoss     | -0.0192     |\n",
      "|    value_loss         | 0.226       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 745        |\n",
      "|    iterations         | 27         |\n",
      "|    time_elapsed       | 296        |\n",
      "|    total_timesteps    | 14376960   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02500496 |\n",
      "|    entropy_loss       | -1.93      |\n",
      "|    explained_variance | 0.921      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0683    |\n",
      "|    mean_step_reward   | 0.08137256 |\n",
      "|    n_updates          | 81.25 %    |\n",
      "|    policyGradLoss     | -0.0232    |\n",
      "|    value_loss         | 0.184      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 749         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 306         |\n",
      "|    total_timesteps    | 14385152    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018386686 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.93        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00279     |\n",
      "|    mean_step_reward   | 0.09089723  |\n",
      "|    n_updates          | 84.38 %     |\n",
      "|    policyGradLoss     | -0.0105     |\n",
      "|    value_loss         | 0.327       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 750         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 316         |\n",
      "|    total_timesteps    | 14393344    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020364095 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.919       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0406      |\n",
      "|    mean_step_reward   | 0.09673607  |\n",
      "|    n_updates          | 87.50 %     |\n",
      "|    policyGradLoss     | -0.0175     |\n",
      "|    value_loss         | 0.387       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 749         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 327         |\n",
      "|    total_timesteps    | 14401536    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021083727 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.932       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0457     |\n",
      "|    mean_step_reward   | 0.103490494 |\n",
      "|    n_updates          | 90.62 %     |\n",
      "|    policyGradLoss     | -0.0174     |\n",
      "|    value_loss         | 0.302       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 747         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 339         |\n",
      "|    total_timesteps    | 14409728    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019319942 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.933       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0234     |\n",
      "|    mean_step_reward   | 0.102809206 |\n",
      "|    n_updates          | 93.75 %     |\n",
      "|    policyGradLoss     | -0.0137     |\n",
      "|    value_loss         | 0.307       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 746         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 351         |\n",
      "|    total_timesteps    | 14417920    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024742404 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.938       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0137      |\n",
      "|    mean_step_reward   | 0.08244834  |\n",
      "|    n_updates          | 96.88 %     |\n",
      "|    policyGradLoss     | -0.0202     |\n",
      "|    value_loss         | 0.321       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Run_54.zip\n",
      "[EVAL] Mean Return: 135.513, Best Return: 143.013\n",
      "Saved video to ./runs_smw/videos/Run/Run_54_135.51.mp4\n",
      "\n",
      "=== Round 56 | Learn 262144 steps (Total trained: 14417920) ===\n",
      "Logging to ./runs_smw/tb/Run_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1179     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 14426112 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 908         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 14434304    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017235681 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.915       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0118      |\n",
      "|    mean_step_reward   | 0.09889056  |\n",
      "|    n_updates          | 3.12 %      |\n",
      "|    policyGradLoss     | -0.0154     |\n",
      "|    value_loss         | 0.361       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 841         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 29          |\n",
      "|    total_timesteps    | 14442496    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017948616 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.92        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0945      |\n",
      "|    mean_step_reward   | 0.11238384  |\n",
      "|    n_updates          | 6.25 %      |\n",
      "|    policyGradLoss     | -0.0123     |\n",
      "|    value_loss         | 0.503       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 803         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 40          |\n",
      "|    total_timesteps    | 14450688    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018880116 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.93        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.000142    |\n",
      "|    mean_step_reward   | 0.0761763   |\n",
      "|    n_updates          | 9.38 %      |\n",
      "|    policyGradLoss     | -0.0171     |\n",
      "|    value_loss         | 0.281       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 52          |\n",
      "|    total_timesteps    | 14458880    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02168537  |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.935       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0369     |\n",
      "|    mean_step_reward   | 0.104331754 |\n",
      "|    n_updates          | 12.50 %     |\n",
      "|    policyGradLoss     | -0.016      |\n",
      "|    value_loss         | 0.289       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 63          |\n",
      "|    total_timesteps    | 14467072    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019044224 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.924       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00977    |\n",
      "|    mean_step_reward   | 0.09393489  |\n",
      "|    n_updates          | 15.62 %     |\n",
      "|    policyGradLoss     | -0.0191     |\n",
      "|    value_loss         | 0.295       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 762         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 75          |\n",
      "|    total_timesteps    | 14475264    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018913627 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.925       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00263    |\n",
      "|    mean_step_reward   | 0.097858205 |\n",
      "|    n_updates          | 18.75 %     |\n",
      "|    policyGradLoss     | -0.0191     |\n",
      "|    value_loss         | 0.358       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 761         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 86          |\n",
      "|    total_timesteps    | 14483456    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021321392 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.944       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0295     |\n",
      "|    mean_step_reward   | 0.09698294  |\n",
      "|    n_updates          | 21.88 %     |\n",
      "|    policyGradLoss     | -0.0187     |\n",
      "|    value_loss         | 0.304       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 758         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 97          |\n",
      "|    total_timesteps    | 14491648    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024082901 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.949       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00851    |\n",
      "|    mean_step_reward   | 0.08790966  |\n",
      "|    n_updates          | 25.00 %     |\n",
      "|    policyGradLoss     | -0.0215     |\n",
      "|    value_loss         | 0.283       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 755         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 108         |\n",
      "|    total_timesteps    | 14499840    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020548308 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.936       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0207     |\n",
      "|    mean_step_reward   | 0.08618806  |\n",
      "|    n_updates          | 28.12 %     |\n",
      "|    policyGradLoss     | -0.0171     |\n",
      "|    value_loss         | 0.337       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 751        |\n",
      "|    iterations         | 11         |\n",
      "|    time_elapsed       | 119        |\n",
      "|    total_timesteps    | 14508032   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02114506 |\n",
      "|    entropy_loss       | -1.9       |\n",
      "|    explained_variance | 0.942      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0141    |\n",
      "|    mean_step_reward   | 0.10235737 |\n",
      "|    n_updates          | 31.25 %    |\n",
      "|    policyGradLoss     | -0.0168    |\n",
      "|    value_loss         | 0.339      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 747         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 131         |\n",
      "|    total_timesteps    | 14516224    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02260879  |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.895       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00149    |\n",
      "|    mean_step_reward   | 0.072134525 |\n",
      "|    n_updates          | 34.38 %     |\n",
      "|    policyGradLoss     | -0.0156     |\n",
      "|    value_loss         | 0.399       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 745         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 142         |\n",
      "|    total_timesteps    | 14524416    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023777263 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.943       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0047      |\n",
      "|    mean_step_reward   | 0.0996034   |\n",
      "|    n_updates          | 37.50 %     |\n",
      "|    policyGradLoss     | -0.0166     |\n",
      "|    value_loss         | 0.389       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 743         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 154         |\n",
      "|    total_timesteps    | 14532608    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017889567 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.931       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00577     |\n",
      "|    mean_step_reward   | 0.09156741  |\n",
      "|    n_updates          | 40.62 %     |\n",
      "|    policyGradLoss     | -0.018      |\n",
      "|    value_loss         | 0.376       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 743         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 165         |\n",
      "|    total_timesteps    | 14540800    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019332763 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.949       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.012      |\n",
      "|    mean_step_reward   | 0.1089142   |\n",
      "|    n_updates          | 43.75 %     |\n",
      "|    policyGradLoss     | -0.0185     |\n",
      "|    value_loss         | 0.257       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 744         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 176         |\n",
      "|    total_timesteps    | 14548992    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023594152 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.945       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0367     |\n",
      "|    mean_step_reward   | 0.10111209  |\n",
      "|    n_updates          | 46.88 %     |\n",
      "|    policyGradLoss     | -0.0192     |\n",
      "|    value_loss         | 0.242       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 743         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 187         |\n",
      "|    total_timesteps    | 14557184    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019960139 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.939       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0237      |\n",
      "|    mean_step_reward   | 0.093130425 |\n",
      "|    n_updates          | 50.00 %     |\n",
      "|    policyGradLoss     | -0.0175     |\n",
      "|    value_loss         | 0.43        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 741         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 198         |\n",
      "|    total_timesteps    | 14565376    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019978376 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.945       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0155     |\n",
      "|    mean_step_reward   | 0.086902395 |\n",
      "|    n_updates          | 53.12 %     |\n",
      "|    policyGradLoss     | -0.0199     |\n",
      "|    value_loss         | 0.275       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 739         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 210         |\n",
      "|    total_timesteps    | 14573568    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024929866 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.044      |\n",
      "|    mean_step_reward   | 0.11216852  |\n",
      "|    n_updates          | 56.25 %     |\n",
      "|    policyGradLoss     | -0.0207     |\n",
      "|    value_loss         | 0.212       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 738         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 221         |\n",
      "|    total_timesteps    | 14581760    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021825086 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.947       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0232     |\n",
      "|    mean_step_reward   | 0.09448849  |\n",
      "|    n_updates          | 59.38 %     |\n",
      "|    policyGradLoss     | -0.0175     |\n",
      "|    value_loss         | 0.251       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 738         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 233         |\n",
      "|    total_timesteps    | 14589952    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020179031 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.94        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0503     |\n",
      "|    mean_step_reward   | 0.10227125  |\n",
      "|    n_updates          | 62.50 %     |\n",
      "|    policyGradLoss     | -0.0183     |\n",
      "|    value_loss         | 0.321       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 739         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 243         |\n",
      "|    total_timesteps    | 14598144    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018816758 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.919       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0248     |\n",
      "|    mean_step_reward   | 0.09950222  |\n",
      "|    n_updates          | 65.62 %     |\n",
      "|    policyGradLoss     | -0.0135     |\n",
      "|    value_loss         | 0.381       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 746        |\n",
      "|    iterations         | 23         |\n",
      "|    time_elapsed       | 252        |\n",
      "|    total_timesteps    | 14606336   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02011485 |\n",
      "|    entropy_loss       | -1.92      |\n",
      "|    explained_variance | 0.947      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0597    |\n",
      "|    mean_step_reward   | 0.10241963 |\n",
      "|    n_updates          | 68.75 %    |\n",
      "|    policyGradLoss     | -0.0198    |\n",
      "|    value_loss         | 0.261      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 750         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 261         |\n",
      "|    total_timesteps    | 14614528    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017532565 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.913       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0231     |\n",
      "|    mean_step_reward   | 0.09565372  |\n",
      "|    n_updates          | 71.88 %     |\n",
      "|    policyGradLoss     | -0.0171     |\n",
      "|    value_loss         | 0.397       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 755         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 271         |\n",
      "|    total_timesteps    | 14622720    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022999428 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.958       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0225     |\n",
      "|    mean_step_reward   | 0.11168574  |\n",
      "|    n_updates          | 75.00 %     |\n",
      "|    policyGradLoss     | -0.0177     |\n",
      "|    value_loss         | 0.261       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 754         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 282         |\n",
      "|    total_timesteps    | 14630912    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018095117 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.95        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0527      |\n",
      "|    mean_step_reward   | 0.1058177   |\n",
      "|    n_updates          | 78.12 %     |\n",
      "|    policyGradLoss     | -0.0183     |\n",
      "|    value_loss         | 0.349       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 752         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 293         |\n",
      "|    total_timesteps    | 14639104    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015144901 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.904       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0328      |\n",
      "|    mean_step_reward   | 0.08314951  |\n",
      "|    n_updates          | 81.25 %     |\n",
      "|    policyGradLoss     | -0.0165     |\n",
      "|    value_loss         | 0.436       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 751         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 305         |\n",
      "|    total_timesteps    | 14647296    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029126422 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0415     |\n",
      "|    mean_step_reward   | 0.10305226  |\n",
      "|    n_updates          | 84.38 %     |\n",
      "|    policyGradLoss     | -0.0174     |\n",
      "|    value_loss         | 0.213       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 750         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 316         |\n",
      "|    total_timesteps    | 14655488    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019224599 |\n",
      "|    entropy_loss       | -1.98       |\n",
      "|    explained_variance | 0.916       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00811    |\n",
      "|    mean_step_reward   | 0.0761576   |\n",
      "|    n_updates          | 87.50 %     |\n",
      "|    policyGradLoss     | -0.0147     |\n",
      "|    value_loss         | 0.322       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 749         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 327         |\n",
      "|    total_timesteps    | 14663680    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023106351 |\n",
      "|    entropy_loss       | -1.98       |\n",
      "|    explained_variance | 0.934       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0177     |\n",
      "|    mean_step_reward   | 0.07540196  |\n",
      "|    n_updates          | 90.62 %     |\n",
      "|    policyGradLoss     | -0.0187     |\n",
      "|    value_loss         | 0.261       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 749         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 338         |\n",
      "|    total_timesteps    | 14671872    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021669012 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.941       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0166     |\n",
      "|    mean_step_reward   | 0.09624799  |\n",
      "|    n_updates          | 93.75 %     |\n",
      "|    policyGradLoss     | -0.0183     |\n",
      "|    value_loss         | 0.332       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 749         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 349         |\n",
      "|    total_timesteps    | 14680064    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019301537 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.919       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0203      |\n",
      "|    mean_step_reward   | 0.07040023  |\n",
      "|    n_updates          | 96.88 %     |\n",
      "|    policyGradLoss     | -0.0183     |\n",
      "|    value_loss         | 0.387       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Run_55.zip\n",
      "[EVAL] Mean Return: 71.794, Best Return: 74.461\n",
      "Saved video to ./runs_smw/videos/Run/Run_55_71.79.mp4\n",
      "\n",
      "=== Round 57 | Learn 262144 steps (Total trained: 14680064) ===\n",
      "Logging to ./runs_smw/tb/Run_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1089     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 14688256 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 864         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 14696448    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020974278 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.938       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0118      |\n",
      "|    mean_step_reward   | 0.092587754 |\n",
      "|    n_updates          | 3.12 %      |\n",
      "|    policyGradLoss     | -0.0192     |\n",
      "|    value_loss         | 0.279       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 816         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 30          |\n",
      "|    total_timesteps    | 14704640    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021023814 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.923       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0354      |\n",
      "|    mean_step_reward   | 0.08749608  |\n",
      "|    n_updates          | 6.25 %      |\n",
      "|    policyGradLoss     | -0.0168     |\n",
      "|    value_loss         | 0.335       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 798         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 41          |\n",
      "|    total_timesteps    | 14712832    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01991322  |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.946       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0353     |\n",
      "|    mean_step_reward   | 0.100337155 |\n",
      "|    n_updates          | 9.38 %      |\n",
      "|    policyGradLoss     | -0.018      |\n",
      "|    value_loss         | 0.285       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 52          |\n",
      "|    total_timesteps    | 14721024    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017784916 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.938       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0339     |\n",
      "|    mean_step_reward   | 0.09370066  |\n",
      "|    n_updates          | 12.50 %     |\n",
      "|    policyGradLoss     | -0.0162     |\n",
      "|    value_loss         | 0.316       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 63          |\n",
      "|    total_timesteps    | 14729216    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017382484 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.943       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00803     |\n",
      "|    mean_step_reward   | 0.10082725  |\n",
      "|    n_updates          | 15.62 %     |\n",
      "|    policyGradLoss     | -0.0174     |\n",
      "|    value_loss         | 0.323       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 765         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 74          |\n",
      "|    total_timesteps    | 14737408    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019605946 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.93        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0183      |\n",
      "|    mean_step_reward   | 0.10324604  |\n",
      "|    n_updates          | 18.75 %     |\n",
      "|    policyGradLoss     | -0.0146     |\n",
      "|    value_loss         | 0.331       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 758         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 86          |\n",
      "|    total_timesteps    | 14745600    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016929511 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.938       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0421      |\n",
      "|    mean_step_reward   | 0.07951616  |\n",
      "|    n_updates          | 21.88 %     |\n",
      "|    policyGradLoss     | -0.018      |\n",
      "|    value_loss         | 0.341       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 754         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 97          |\n",
      "|    total_timesteps    | 14753792    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01913911  |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.949       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.018      |\n",
      "|    mean_step_reward   | 0.099153005 |\n",
      "|    n_updates          | 25.00 %     |\n",
      "|    policyGradLoss     | -0.0194     |\n",
      "|    value_loss         | 0.316       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 751         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 108         |\n",
      "|    total_timesteps    | 14761984    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018815214 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.95        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0202     |\n",
      "|    mean_step_reward   | 0.11184691  |\n",
      "|    n_updates          | 28.12 %     |\n",
      "|    policyGradLoss     | -0.0183     |\n",
      "|    value_loss         | 0.312       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 750         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 120         |\n",
      "|    total_timesteps    | 14770176    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020367526 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.93        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0367      |\n",
      "|    mean_step_reward   | 0.08554381  |\n",
      "|    n_updates          | 31.25 %     |\n",
      "|    policyGradLoss     | -0.0172     |\n",
      "|    value_loss         | 0.314       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 750         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 131         |\n",
      "|    total_timesteps    | 14778368    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017136168 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.949       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0173     |\n",
      "|    mean_step_reward   | 0.10547486  |\n",
      "|    n_updates          | 34.38 %     |\n",
      "|    policyGradLoss     | -0.0151     |\n",
      "|    value_loss         | 0.301       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 748         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 142         |\n",
      "|    total_timesteps    | 14786560    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01795753  |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.943       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0171      |\n",
      "|    mean_step_reward   | 0.107136205 |\n",
      "|    n_updates          | 37.50 %     |\n",
      "|    policyGradLoss     | -0.0157     |\n",
      "|    value_loss         | 0.305       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 745         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 153         |\n",
      "|    total_timesteps    | 14794752    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022324901 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.942       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.000663   |\n",
      "|    mean_step_reward   | 0.09224959  |\n",
      "|    n_updates          | 40.62 %     |\n",
      "|    policyGradLoss     | -0.0199     |\n",
      "|    value_loss         | 0.311       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 742        |\n",
      "|    iterations         | 15         |\n",
      "|    time_elapsed       | 165        |\n",
      "|    total_timesteps    | 14802944   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01947051 |\n",
      "|    entropy_loss       | -1.89      |\n",
      "|    explained_variance | 0.924      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0166    |\n",
      "|    mean_step_reward   | 0.08207528 |\n",
      "|    n_updates          | 43.75 %    |\n",
      "|    policyGradLoss     | -0.0153    |\n",
      "|    value_loss         | 0.374      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 740         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 177         |\n",
      "|    total_timesteps    | 14811136    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021647362 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.952       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0804      |\n",
      "|    mean_step_reward   | 0.09591207  |\n",
      "|    n_updates          | 46.88 %     |\n",
      "|    policyGradLoss     | -0.0142     |\n",
      "|    value_loss         | 0.286       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 739         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 188         |\n",
      "|    total_timesteps    | 14819328    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017695878 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.905       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.13        |\n",
      "|    mean_step_reward   | 0.085547164 |\n",
      "|    n_updates          | 50.00 %     |\n",
      "|    policyGradLoss     | -0.0106     |\n",
      "|    value_loss         | 0.514       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 739         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 199         |\n",
      "|    total_timesteps    | 14827520    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01732127  |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.94        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0218      |\n",
      "|    mean_step_reward   | 0.096820906 |\n",
      "|    n_updates          | 53.12 %     |\n",
      "|    policyGradLoss     | -0.0181     |\n",
      "|    value_loss         | 0.323       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 746         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 208         |\n",
      "|    total_timesteps    | 14835712    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022339314 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.939       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0519     |\n",
      "|    mean_step_reward   | 0.09984511  |\n",
      "|    n_updates          | 56.25 %     |\n",
      "|    policyGradLoss     | -0.02       |\n",
      "|    value_loss         | 0.268       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 751         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 217         |\n",
      "|    total_timesteps    | 14843904    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019756049 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.948       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0101      |\n",
      "|    mean_step_reward   | 0.09894051  |\n",
      "|    n_updates          | 59.38 %     |\n",
      "|    policyGradLoss     | -0.0169     |\n",
      "|    value_loss         | 0.321       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 757         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 227         |\n",
      "|    total_timesteps    | 14852096    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022873515 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.933       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0129     |\n",
      "|    mean_step_reward   | 0.09643144  |\n",
      "|    n_updates          | 62.50 %     |\n",
      "|    policyGradLoss     | -0.0156     |\n",
      "|    value_loss         | 0.279       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 758         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 237         |\n",
      "|    total_timesteps    | 14860288    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023328297 |\n",
      "|    entropy_loss       | -1.97       |\n",
      "|    explained_variance | 0.933       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00947    |\n",
      "|    mean_step_reward   | 0.08863141  |\n",
      "|    n_updates          | 65.62 %     |\n",
      "|    policyGradLoss     | -0.0138     |\n",
      "|    value_loss         | 0.241       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 756        |\n",
      "|    iterations         | 23         |\n",
      "|    time_elapsed       | 249        |\n",
      "|    total_timesteps    | 14868480   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02375308 |\n",
      "|    entropy_loss       | -1.88      |\n",
      "|    explained_variance | 0.944      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0187    |\n",
      "|    mean_step_reward   | 0.10652652 |\n",
      "|    n_updates          | 68.75 %    |\n",
      "|    policyGradLoss     | -0.0178    |\n",
      "|    value_loss         | 0.335      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 754        |\n",
      "|    iterations         | 24         |\n",
      "|    time_elapsed       | 260        |\n",
      "|    total_timesteps    | 14876672   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01656863 |\n",
      "|    entropy_loss       | -1.96      |\n",
      "|    explained_variance | 0.944      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.00474    |\n",
      "|    mean_step_reward   | 0.08845603 |\n",
      "|    n_updates          | 71.88 %    |\n",
      "|    policyGradLoss     | -0.0152    |\n",
      "|    value_loss         | 0.284      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 752         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 272         |\n",
      "|    total_timesteps    | 14884864    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02294416  |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.909       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0126     |\n",
      "|    mean_step_reward   | 0.084711455 |\n",
      "|    n_updates          | 75.00 %     |\n",
      "|    policyGradLoss     | -0.013      |\n",
      "|    value_loss         | 0.376       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 751         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 283         |\n",
      "|    total_timesteps    | 14893056    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022747323 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.947       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0397     |\n",
      "|    mean_step_reward   | 0.10966009  |\n",
      "|    n_updates          | 78.12 %     |\n",
      "|    policyGradLoss     | -0.019      |\n",
      "|    value_loss         | 0.242       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 751         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 294         |\n",
      "|    total_timesteps    | 14901248    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021057587 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0375     |\n",
      "|    mean_step_reward   | 0.08684219  |\n",
      "|    n_updates          | 81.25 %     |\n",
      "|    policyGradLoss     | -0.0168     |\n",
      "|    value_loss         | 0.232       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 751         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 305         |\n",
      "|    total_timesteps    | 14909440    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021502038 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.942       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0135     |\n",
      "|    mean_step_reward   | 0.09908766  |\n",
      "|    n_updates          | 84.38 %     |\n",
      "|    policyGradLoss     | -0.0206     |\n",
      "|    value_loss         | 0.367       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 750         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 316         |\n",
      "|    total_timesteps    | 14917632    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018395048 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.916       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0149      |\n",
      "|    mean_step_reward   | 0.06459735  |\n",
      "|    n_updates          | 87.50 %     |\n",
      "|    policyGradLoss     | -0.0151     |\n",
      "|    value_loss         | 0.379       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 749         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 327         |\n",
      "|    total_timesteps    | 14925824    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017842717 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.943       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00427     |\n",
      "|    mean_step_reward   | 0.09697406  |\n",
      "|    n_updates          | 90.62 %     |\n",
      "|    policyGradLoss     | -0.0174     |\n",
      "|    value_loss         | 0.45        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 748         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 339         |\n",
      "|    total_timesteps    | 14934016    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020635834 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.944       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0395     |\n",
      "|    mean_step_reward   | 0.080160335 |\n",
      "|    n_updates          | 93.75 %     |\n",
      "|    policyGradLoss     | -0.0219     |\n",
      "|    value_loss         | 0.301       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 746         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 350         |\n",
      "|    total_timesteps    | 14942208    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021345802 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.931       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.000249   |\n",
      "|    mean_step_reward   | 0.087570354 |\n",
      "|    n_updates          | 96.88 %     |\n",
      "|    policyGradLoss     | -0.0182     |\n",
      "|    value_loss         | 0.305       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Run_56.zip\n",
      "[EVAL] Mean Return: 75.021, Best Return: 79.188\n",
      "Saved video to ./runs_smw/videos/Run/Run_56_75.02.mp4\n",
      "\n",
      "=== Round 58 | Learn 262144 steps (Total trained: 14942208) ===\n",
      "Logging to ./runs_smw/tb/Run_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1097     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 14950400 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 876         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 14958592    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020961206 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0384     |\n",
      "|    mean_step_reward   | 0.10603915  |\n",
      "|    n_updates          | 3.12 %      |\n",
      "|    policyGradLoss     | -0.018      |\n",
      "|    value_loss         | 0.278       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 823        |\n",
      "|    iterations         | 3          |\n",
      "|    time_elapsed       | 29         |\n",
      "|    total_timesteps    | 14966784   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01915888 |\n",
      "|    entropy_loss       | -1.93      |\n",
      "|    explained_variance | 0.94       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.00686   |\n",
      "|    mean_step_reward   | 0.06792118 |\n",
      "|    n_updates          | 6.25 %     |\n",
      "|    policyGradLoss     | -0.0188    |\n",
      "|    value_loss         | 0.363      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 804         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 40          |\n",
      "|    total_timesteps    | 14974976    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021179024 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.951       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0272     |\n",
      "|    mean_step_reward   | 0.094317645 |\n",
      "|    n_updates          | 9.38 %      |\n",
      "|    policyGradLoss     | -0.0192     |\n",
      "|    value_loss         | 0.292       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 793         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 51          |\n",
      "|    total_timesteps    | 14983168    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019917432 |\n",
      "|    entropy_loss       | -1.97       |\n",
      "|    explained_variance | 0.928       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0344     |\n",
      "|    mean_step_reward   | 0.0826635   |\n",
      "|    n_updates          | 12.50 %     |\n",
      "|    policyGradLoss     | -0.0159     |\n",
      "|    value_loss         | 0.274       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 63          |\n",
      "|    total_timesteps    | 14991360    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017828733 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.912       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0871      |\n",
      "|    mean_step_reward   | 0.08784911  |\n",
      "|    n_updates          | 15.62 %     |\n",
      "|    policyGradLoss     | -0.015      |\n",
      "|    value_loss         | 0.435       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 74          |\n",
      "|    total_timesteps    | 14999552    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018617636 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.935       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00128    |\n",
      "|    mean_step_reward   | 0.10598805  |\n",
      "|    n_updates          | 18.75 %     |\n",
      "|    policyGradLoss     | -0.0185     |\n",
      "|    value_loss         | 0.332       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 759        |\n",
      "|    iterations         | 8          |\n",
      "|    time_elapsed       | 86         |\n",
      "|    total_timesteps    | 15007744   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02100425 |\n",
      "|    entropy_loss       | -1.94      |\n",
      "|    explained_variance | 0.943      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.0335     |\n",
      "|    mean_step_reward   | 0.07825387 |\n",
      "|    n_updates          | 21.88 %    |\n",
      "|    policyGradLoss     | -0.02      |\n",
      "|    value_loss         | 0.285      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 755         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 97          |\n",
      "|    total_timesteps    | 15015936    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020058427 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.919       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0437      |\n",
      "|    mean_step_reward   | 0.108344704 |\n",
      "|    n_updates          | 25.00 %     |\n",
      "|    policyGradLoss     | -0.0171     |\n",
      "|    value_loss         | 0.423       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 754        |\n",
      "|    iterations         | 10         |\n",
      "|    time_elapsed       | 108        |\n",
      "|    total_timesteps    | 15024128   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01650534 |\n",
      "|    entropy_loss       | -1.95      |\n",
      "|    explained_variance | 0.911      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0338    |\n",
      "|    mean_step_reward   | 0.07335052 |\n",
      "|    n_updates          | 28.12 %    |\n",
      "|    policyGradLoss     | -0.0126    |\n",
      "|    value_loss         | 0.306      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 754         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 119         |\n",
      "|    total_timesteps    | 15032320    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024728173 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.958       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00011    |\n",
      "|    mean_step_reward   | 0.10071244  |\n",
      "|    n_updates          | 31.25 %     |\n",
      "|    policyGradLoss     | -0.0204     |\n",
      "|    value_loss         | 0.284       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 753        |\n",
      "|    iterations         | 12         |\n",
      "|    time_elapsed       | 130        |\n",
      "|    total_timesteps    | 15040512   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01643361 |\n",
      "|    entropy_loss       | -1.92      |\n",
      "|    explained_variance | 0.919      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.071      |\n",
      "|    mean_step_reward   | 0.06521337 |\n",
      "|    n_updates          | 34.38 %    |\n",
      "|    policyGradLoss     | -0.0179    |\n",
      "|    value_loss         | 0.476      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 751        |\n",
      "|    iterations         | 13         |\n",
      "|    time_elapsed       | 141        |\n",
      "|    total_timesteps    | 15048704   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02192961 |\n",
      "|    entropy_loss       | -1.93      |\n",
      "|    explained_variance | 0.944      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0401    |\n",
      "|    mean_step_reward   | 0.10717807 |\n",
      "|    n_updates          | 37.50 %    |\n",
      "|    policyGradLoss     | -0.0199    |\n",
      "|    value_loss         | 0.266      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 748         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 153         |\n",
      "|    total_timesteps    | 15056896    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018635452 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.92        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00428     |\n",
      "|    mean_step_reward   | 0.09442387  |\n",
      "|    n_updates          | 40.62 %     |\n",
      "|    policyGradLoss     | -0.015      |\n",
      "|    value_loss         | 0.36        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 745         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 164         |\n",
      "|    total_timesteps    | 15065088    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021806993 |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.921       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0349     |\n",
      "|    mean_step_reward   | 0.085889935 |\n",
      "|    n_updates          | 43.75 %     |\n",
      "|    policyGradLoss     | -0.0167     |\n",
      "|    value_loss         | 0.321       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 754         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 173         |\n",
      "|    total_timesteps    | 15073280    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022359619 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.935       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0208      |\n",
      "|    mean_step_reward   | 0.081103876 |\n",
      "|    n_updates          | 46.88 %     |\n",
      "|    policyGradLoss     | -0.0154     |\n",
      "|    value_loss         | 0.414       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 760         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 183         |\n",
      "|    total_timesteps    | 15081472    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020657387 |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.919       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0488     |\n",
      "|    mean_step_reward   | 0.079457246 |\n",
      "|    n_updates          | 50.00 %     |\n",
      "|    policyGradLoss     | -0.0206     |\n",
      "|    value_loss         | 0.353       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 192         |\n",
      "|    total_timesteps    | 15089664    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021646809 |\n",
      "|    entropy_loss       | -1.97       |\n",
      "|    explained_variance | 0.944       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0285     |\n",
      "|    mean_step_reward   | 0.09694607  |\n",
      "|    n_updates          | 53.12 %     |\n",
      "|    policyGradLoss     | -0.0176     |\n",
      "|    value_loss         | 0.246       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 203         |\n",
      "|    total_timesteps    | 15097856    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021538744 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.919       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.068       |\n",
      "|    mean_step_reward   | 0.068709984 |\n",
      "|    n_updates          | 56.25 %     |\n",
      "|    policyGradLoss     | -0.0167     |\n",
      "|    value_loss         | 0.421       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 765         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 214         |\n",
      "|    total_timesteps    | 15106048    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02098518  |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.919       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00392     |\n",
      "|    mean_step_reward   | 0.079851635 |\n",
      "|    n_updates          | 59.38 %     |\n",
      "|    policyGradLoss     | -0.0167     |\n",
      "|    value_loss         | 0.45        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 764         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 224         |\n",
      "|    total_timesteps    | 15114240    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018544562 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.93        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0392     |\n",
      "|    mean_step_reward   | 0.083960325 |\n",
      "|    n_updates          | 62.50 %     |\n",
      "|    policyGradLoss     | -0.0176     |\n",
      "|    value_loss         | 0.257       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 762         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 236         |\n",
      "|    total_timesteps    | 15122432    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017078528 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.929       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.000419    |\n",
      "|    mean_step_reward   | 0.096883215 |\n",
      "|    n_updates          | 65.62 %     |\n",
      "|    policyGradLoss     | -0.0174     |\n",
      "|    value_loss         | 0.367       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 760         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 247         |\n",
      "|    total_timesteps    | 15130624    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020663239 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.936       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0307     |\n",
      "|    mean_step_reward   | 0.085713334 |\n",
      "|    n_updates          | 68.75 %     |\n",
      "|    policyGradLoss     | -0.0216     |\n",
      "|    value_loss         | 0.261       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 758         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 259         |\n",
      "|    total_timesteps    | 15138816    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022144195 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0429     |\n",
      "|    mean_step_reward   | 0.10117871  |\n",
      "|    n_updates          | 71.88 %     |\n",
      "|    policyGradLoss     | -0.0198     |\n",
      "|    value_loss         | 0.232       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 756         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 270         |\n",
      "|    total_timesteps    | 15147008    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019253632 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.928       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0971      |\n",
      "|    mean_step_reward   | 0.09165018  |\n",
      "|    n_updates          | 75.00 %     |\n",
      "|    policyGradLoss     | -0.0184     |\n",
      "|    value_loss         | 0.395       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 756        |\n",
      "|    iterations         | 26         |\n",
      "|    time_elapsed       | 281        |\n",
      "|    total_timesteps    | 15155200   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01916818 |\n",
      "|    entropy_loss       | -1.94      |\n",
      "|    explained_variance | 0.949      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0113    |\n",
      "|    mean_step_reward   | 0.09175137 |\n",
      "|    n_updates          | 78.12 %    |\n",
      "|    policyGradLoss     | -0.0197    |\n",
      "|    value_loss         | 0.326      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 755         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 292         |\n",
      "|    total_timesteps    | 15163392    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019654503 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.925       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0025      |\n",
      "|    mean_step_reward   | 0.082994774 |\n",
      "|    n_updates          | 81.25 %     |\n",
      "|    policyGradLoss     | -0.0178     |\n",
      "|    value_loss         | 0.391       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 754         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 303         |\n",
      "|    total_timesteps    | 15171584    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021279166 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.935       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0402     |\n",
      "|    mean_step_reward   | 0.09182949  |\n",
      "|    n_updates          | 84.38 %     |\n",
      "|    policyGradLoss     | -0.0168     |\n",
      "|    value_loss         | 0.311       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 753        |\n",
      "|    iterations         | 29         |\n",
      "|    time_elapsed       | 315        |\n",
      "|    total_timesteps    | 15179776   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02287519 |\n",
      "|    entropy_loss       | -1.93      |\n",
      "|    explained_variance | 0.935      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.0399     |\n",
      "|    mean_step_reward   | 0.08572478 |\n",
      "|    n_updates          | 87.50 %    |\n",
      "|    policyGradLoss     | -0.0174    |\n",
      "|    value_loss         | 0.292      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 752         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 326         |\n",
      "|    total_timesteps    | 15187968    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024159249 |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.939       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0496     |\n",
      "|    mean_step_reward   | 0.09086798  |\n",
      "|    n_updates          | 90.62 %     |\n",
      "|    policyGradLoss     | -0.0197     |\n",
      "|    value_loss         | 0.255       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 750         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 338         |\n",
      "|    total_timesteps    | 15196160    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020790355 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.929       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0139     |\n",
      "|    mean_step_reward   | 0.08566463  |\n",
      "|    n_updates          | 93.75 %     |\n",
      "|    policyGradLoss     | -0.0171     |\n",
      "|    value_loss         | 0.329       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 749         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 349         |\n",
      "|    total_timesteps    | 15204352    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020487064 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.915       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0145      |\n",
      "|    mean_step_reward   | 0.07881822  |\n",
      "|    n_updates          | 96.88 %     |\n",
      "|    policyGradLoss     | -0.0204     |\n",
      "|    value_loss         | 0.412       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Run_57.zip\n",
      "[EVAL] Mean Return: 147.342, Best Return: 154.675\n",
      "Saved video to ./runs_smw/videos/Run/Run_57_147.34.mp4\n",
      "\n",
      "=== Round 59 | Learn 262144 steps (Total trained: 15204352) ===\n",
      "Logging to ./runs_smw/tb/Run_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1191     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 15212544 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 906         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 15220736    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022775905 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.933       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00594    |\n",
      "|    mean_step_reward   | 0.09609917  |\n",
      "|    n_updates          | 3.12 %      |\n",
      "|    policyGradLoss     | -0.0151     |\n",
      "|    value_loss         | 0.367       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 842        |\n",
      "|    iterations         | 3          |\n",
      "|    time_elapsed       | 29         |\n",
      "|    total_timesteps    | 15228928   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01989936 |\n",
      "|    entropy_loss       | -1.89      |\n",
      "|    explained_variance | 0.926      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.0583     |\n",
      "|    mean_step_reward   | 0.09004976 |\n",
      "|    n_updates          | 6.25 %     |\n",
      "|    policyGradLoss     | -0.0159    |\n",
      "|    value_loss         | 0.496      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 807         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 40          |\n",
      "|    total_timesteps    | 15237120    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020265978 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.944       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.034      |\n",
      "|    mean_step_reward   | 0.11219673  |\n",
      "|    n_updates          | 9.38 %      |\n",
      "|    policyGradLoss     | -0.0185     |\n",
      "|    value_loss         | 0.254       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 785        |\n",
      "|    iterations         | 5          |\n",
      "|    time_elapsed       | 52         |\n",
      "|    total_timesteps    | 15245312   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01957151 |\n",
      "|    entropy_loss       | -1.95      |\n",
      "|    explained_variance | 0.931      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.0178     |\n",
      "|    mean_step_reward   | 0.07302604 |\n",
      "|    n_updates          | 12.50 %    |\n",
      "|    policyGradLoss     | -0.0189    |\n",
      "|    value_loss         | 0.369      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 63          |\n",
      "|    total_timesteps    | 15253504    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01690282  |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.92        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0829      |\n",
      "|    mean_step_reward   | 0.097855225 |\n",
      "|    n_updates          | 15.62 %     |\n",
      "|    policyGradLoss     | -0.0145     |\n",
      "|    value_loss         | 0.518       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 74          |\n",
      "|    total_timesteps    | 15261696    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020868365 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.942       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0495      |\n",
      "|    mean_step_reward   | 0.078292795 |\n",
      "|    n_updates          | 18.75 %     |\n",
      "|    policyGradLoss     | -0.0186     |\n",
      "|    value_loss         | 0.332       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 766        |\n",
      "|    iterations         | 8          |\n",
      "|    time_elapsed       | 85         |\n",
      "|    total_timesteps    | 15269888   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01694838 |\n",
      "|    entropy_loss       | -1.92      |\n",
      "|    explained_variance | 0.933      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.00561    |\n",
      "|    mean_step_reward   | 0.10675527 |\n",
      "|    n_updates          | 21.88 %    |\n",
      "|    policyGradLoss     | -0.0143    |\n",
      "|    value_loss         | 0.353      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 762         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 96          |\n",
      "|    total_timesteps    | 15278080    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015701678 |\n",
      "|    entropy_loss       | -1.98       |\n",
      "|    explained_variance | 0.94        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.001       |\n",
      "|    mean_step_reward   | 0.09548335  |\n",
      "|    n_updates          | 25.00 %     |\n",
      "|    policyGradLoss     | -0.0159     |\n",
      "|    value_loss         | 0.297       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 760         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 107         |\n",
      "|    total_timesteps    | 15286272    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015151592 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.948       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0224      |\n",
      "|    mean_step_reward   | 0.10127902  |\n",
      "|    n_updates          | 28.12 %     |\n",
      "|    policyGradLoss     | -0.0152     |\n",
      "|    value_loss         | 0.344       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 755         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 119         |\n",
      "|    total_timesteps    | 15294464    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017866189 |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.941       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0264     |\n",
      "|    mean_step_reward   | 0.08440183  |\n",
      "|    n_updates          | 31.25 %     |\n",
      "|    policyGradLoss     | -0.0188     |\n",
      "|    value_loss         | 0.269       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 757         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 129         |\n",
      "|    total_timesteps    | 15302656    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018167702 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.939       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00954     |\n",
      "|    mean_step_reward   | 0.10291974  |\n",
      "|    n_updates          | 34.38 %     |\n",
      "|    policyGradLoss     | -0.0161     |\n",
      "|    value_loss         | 0.31        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 138         |\n",
      "|    total_timesteps    | 15310848    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016336545 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.927       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0147      |\n",
      "|    mean_step_reward   | 0.09621395  |\n",
      "|    n_updates          | 37.50 %     |\n",
      "|    policyGradLoss     | -0.014      |\n",
      "|    value_loss         | 0.454       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 774        |\n",
      "|    iterations         | 14         |\n",
      "|    time_elapsed       | 148        |\n",
      "|    total_timesteps    | 15319040   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01946057 |\n",
      "|    entropy_loss       | -1.91      |\n",
      "|    explained_variance | 0.934      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.0351     |\n",
      "|    mean_step_reward   | 0.09827557 |\n",
      "|    n_updates          | 40.62 %    |\n",
      "|    policyGradLoss     | -0.0195    |\n",
      "|    value_loss         | 0.359      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 779        |\n",
      "|    iterations         | 15         |\n",
      "|    time_elapsed       | 157        |\n",
      "|    total_timesteps    | 15327232   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02306176 |\n",
      "|    entropy_loss       | -1.96      |\n",
      "|    explained_variance | 0.928      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0165    |\n",
      "|    mean_step_reward   | 0.08996998 |\n",
      "|    n_updates          | 43.75 %    |\n",
      "|    policyGradLoss     | -0.0193    |\n",
      "|    value_loss         | 0.333      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 168         |\n",
      "|    total_timesteps    | 15335424    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019570287 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.921       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.034      |\n",
      "|    mean_step_reward   | 0.09148573  |\n",
      "|    n_updates          | 46.88 %     |\n",
      "|    policyGradLoss     | -0.0173     |\n",
      "|    value_loss         | 0.372       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 179         |\n",
      "|    total_timesteps    | 15343616    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016099297 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.918       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.1         |\n",
      "|    mean_step_reward   | 0.106141    |\n",
      "|    n_updates          | 50.00 %     |\n",
      "|    policyGradLoss     | -0.014      |\n",
      "|    value_loss         | 0.411       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 191         |\n",
      "|    total_timesteps    | 15351808    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023223164 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.941       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0435     |\n",
      "|    mean_step_reward   | 0.09457904  |\n",
      "|    n_updates          | 53.12 %     |\n",
      "|    policyGradLoss     | -0.0188     |\n",
      "|    value_loss         | 0.245       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 202         |\n",
      "|    total_timesteps    | 15360000    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019561537 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.933       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.000929    |\n",
      "|    mean_step_reward   | 0.11754943  |\n",
      "|    n_updates          | 56.25 %     |\n",
      "|    policyGradLoss     | -0.0155     |\n",
      "|    value_loss         | 0.352       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 213         |\n",
      "|    total_timesteps    | 15368192    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022845259 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.942       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.027      |\n",
      "|    mean_step_reward   | 0.09557229  |\n",
      "|    n_updates          | 59.38 %     |\n",
      "|    policyGradLoss     | -0.0176     |\n",
      "|    value_loss         | 0.311       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 765         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 224         |\n",
      "|    total_timesteps    | 15376384    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027725123 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.928       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0237      |\n",
      "|    mean_step_reward   | 0.08120755  |\n",
      "|    n_updates          | 62.50 %     |\n",
      "|    policyGradLoss     | -0.0197     |\n",
      "|    value_loss         | 0.326       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 764         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 235         |\n",
      "|    total_timesteps    | 15384576    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018279044 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.911       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00944     |\n",
      "|    mean_step_reward   | 0.100897335 |\n",
      "|    n_updates          | 65.62 %     |\n",
      "|    policyGradLoss     | -0.0111     |\n",
      "|    value_loss         | 0.407       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 762         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 247         |\n",
      "|    total_timesteps    | 15392768    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021473322 |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.945       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0408     |\n",
      "|    mean_step_reward   | 0.078508124 |\n",
      "|    n_updates          | 68.75 %     |\n",
      "|    policyGradLoss     | -0.0228     |\n",
      "|    value_loss         | 0.258       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 759         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 258         |\n",
      "|    total_timesteps    | 15400960    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021017417 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.924       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0352     |\n",
      "|    mean_step_reward   | 0.073466055 |\n",
      "|    n_updates          | 71.88 %     |\n",
      "|    policyGradLoss     | -0.0164     |\n",
      "|    value_loss         | 0.304       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 757         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 270         |\n",
      "|    total_timesteps    | 15409152    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016659267 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.926       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00685    |\n",
      "|    mean_step_reward   | 0.08631895  |\n",
      "|    n_updates          | 75.00 %     |\n",
      "|    policyGradLoss     | -0.0127     |\n",
      "|    value_loss         | 0.434       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 756         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 281         |\n",
      "|    total_timesteps    | 15417344    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019460198 |\n",
      "|    entropy_loss       | -1.97       |\n",
      "|    explained_variance | 0.947       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0524     |\n",
      "|    mean_step_reward   | 0.07834568  |\n",
      "|    n_updates          | 78.12 %     |\n",
      "|    policyGradLoss     | -0.0194     |\n",
      "|    value_loss         | 0.224       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 755         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 292         |\n",
      "|    total_timesteps    | 15425536    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018553574 |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.933       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0419     |\n",
      "|    mean_step_reward   | 0.075005256 |\n",
      "|    n_updates          | 81.25 %     |\n",
      "|    policyGradLoss     | -0.0182     |\n",
      "|    value_loss         | 0.283       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 755         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 303         |\n",
      "|    total_timesteps    | 15433728    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023511399 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.946       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00381    |\n",
      "|    mean_step_reward   | 0.086531505 |\n",
      "|    n_updates          | 84.38 %     |\n",
      "|    policyGradLoss     | -0.0164     |\n",
      "|    value_loss         | 0.316       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 754         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 314         |\n",
      "|    total_timesteps    | 15441920    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018806584 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.933       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00598    |\n",
      "|    mean_step_reward   | 0.10053027  |\n",
      "|    n_updates          | 87.50 %     |\n",
      "|    policyGradLoss     | -0.0166     |\n",
      "|    value_loss         | 0.437       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 753        |\n",
      "|    iterations         | 30         |\n",
      "|    time_elapsed       | 326        |\n",
      "|    total_timesteps    | 15450112   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01961783 |\n",
      "|    entropy_loss       | -1.96      |\n",
      "|    explained_variance | 0.945      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0384    |\n",
      "|    mean_step_reward   | 0.08788461 |\n",
      "|    n_updates          | 90.62 %    |\n",
      "|    policyGradLoss     | -0.0184    |\n",
      "|    value_loss         | 0.245      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 751        |\n",
      "|    iterations         | 31         |\n",
      "|    time_elapsed       | 337        |\n",
      "|    total_timesteps    | 15458304   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01787066 |\n",
      "|    entropy_loss       | -1.94      |\n",
      "|    explained_variance | 0.926      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.0941     |\n",
      "|    mean_step_reward   | 0.08217947 |\n",
      "|    n_updates          | 93.75 %    |\n",
      "|    policyGradLoss     | -0.0102    |\n",
      "|    value_loss         | 0.456      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 750         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 349         |\n",
      "|    total_timesteps    | 15466496    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022746846 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.949       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00109    |\n",
      "|    mean_step_reward   | 0.102610365 |\n",
      "|    n_updates          | 96.88 %     |\n",
      "|    policyGradLoss     | -0.0167     |\n",
      "|    value_loss         | 0.279       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Run_58.zip\n",
      "[EVAL] Mean Return: 136.068, Best Return: 143.401\n",
      "Saved video to ./runs_smw/videos/Run/Run_58_136.07.mp4\n",
      "\n",
      "=== Round 60 | Learn 262144 steps (Total trained: 15466496) ===\n",
      "Logging to ./runs_smw/tb/Run_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1127     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 15474688 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 900         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 15482880    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016051877 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.936       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0346     |\n",
      "|    mean_step_reward   | 0.098967254 |\n",
      "|    n_updates          | 3.12 %      |\n",
      "|    policyGradLoss     | -0.0162     |\n",
      "|    value_loss         | 0.332       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 843         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 29          |\n",
      "|    total_timesteps    | 15491072    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01650998  |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.948       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00564    |\n",
      "|    mean_step_reward   | 0.084747985 |\n",
      "|    n_updates          | 6.25 %      |\n",
      "|    policyGradLoss     | -0.0178     |\n",
      "|    value_loss         | 0.44        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 809         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 40          |\n",
      "|    total_timesteps    | 15499264    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016902748 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.939       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0186      |\n",
      "|    mean_step_reward   | 0.09786509  |\n",
      "|    n_updates          | 9.38 %      |\n",
      "|    policyGradLoss     | -0.017      |\n",
      "|    value_loss         | 0.343       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 52          |\n",
      "|    total_timesteps    | 15507456    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023113742 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.95        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0511     |\n",
      "|    mean_step_reward   | 0.085899726 |\n",
      "|    n_updates          | 12.50 %     |\n",
      "|    policyGradLoss     | -0.0222     |\n",
      "|    value_loss         | 0.233       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 63          |\n",
      "|    total_timesteps    | 15515648    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018714845 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.923       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.021       |\n",
      "|    mean_step_reward   | 0.0829047   |\n",
      "|    n_updates          | 15.62 %     |\n",
      "|    policyGradLoss     | -0.02       |\n",
      "|    value_loss         | 0.339       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 763         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 75          |\n",
      "|    total_timesteps    | 15523840    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017514136 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.937       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.011       |\n",
      "|    mean_step_reward   | 0.102258734 |\n",
      "|    n_updates          | 18.75 %     |\n",
      "|    policyGradLoss     | -0.0176     |\n",
      "|    value_loss         | 0.36        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 761         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 86          |\n",
      "|    total_timesteps    | 15532032    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016621128 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.935       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0449      |\n",
      "|    mean_step_reward   | 0.09118275  |\n",
      "|    n_updates          | 21.88 %     |\n",
      "|    policyGradLoss     | -0.0179     |\n",
      "|    value_loss         | 0.443       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 95          |\n",
      "|    total_timesteps    | 15540224    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017239703 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.925       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0154      |\n",
      "|    mean_step_reward   | 0.10695867  |\n",
      "|    n_updates          | 25.00 %     |\n",
      "|    policyGradLoss     | -0.0163     |\n",
      "|    value_loss         | 0.355       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 104         |\n",
      "|    total_timesteps    | 15548416    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015430827 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.93        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0222     |\n",
      "|    mean_step_reward   | 0.095193714 |\n",
      "|    n_updates          | 28.12 %     |\n",
      "|    policyGradLoss     | -0.0158     |\n",
      "|    value_loss         | 0.354       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 791         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 113         |\n",
      "|    total_timesteps    | 15556608    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018678144 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.932       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0567      |\n",
      "|    mean_step_reward   | 0.08861231  |\n",
      "|    n_updates          | 31.25 %     |\n",
      "|    policyGradLoss     | -0.0157     |\n",
      "|    value_loss         | 0.424       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 792         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 124         |\n",
      "|    total_timesteps    | 15564800    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017510608 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.931       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0914      |\n",
      "|    mean_step_reward   | 0.083086126 |\n",
      "|    n_updates          | 34.38 %     |\n",
      "|    policyGradLoss     | -0.018      |\n",
      "|    value_loss         | 0.398       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 135         |\n",
      "|    total_timesteps    | 15572992    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017187536 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.943       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0155     |\n",
      "|    mean_step_reward   | 0.116923586 |\n",
      "|    n_updates          | 37.50 %     |\n",
      "|    policyGradLoss     | -0.0165     |\n",
      "|    value_loss         | 0.336       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 146         |\n",
      "|    total_timesteps    | 15581184    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021231882 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.937       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00363     |\n",
      "|    mean_step_reward   | 0.08114021  |\n",
      "|    n_updates          | 40.62 %     |\n",
      "|    policyGradLoss     | -0.0179     |\n",
      "|    value_loss         | 0.327       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 158         |\n",
      "|    total_timesteps    | 15589376    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017813265 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.95        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0175     |\n",
      "|    mean_step_reward   | 0.13983946  |\n",
      "|    n_updates          | 43.75 %     |\n",
      "|    policyGradLoss     | -0.0145     |\n",
      "|    value_loss         | 0.272       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 772        |\n",
      "|    iterations         | 16         |\n",
      "|    time_elapsed       | 169        |\n",
      "|    total_timesteps    | 15597568   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01850993 |\n",
      "|    entropy_loss       | -1.95      |\n",
      "|    explained_variance | 0.92       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.0448     |\n",
      "|    mean_step_reward   | 0.07467584 |\n",
      "|    n_updates          | 46.88 %    |\n",
      "|    policyGradLoss     | -0.0157    |\n",
      "|    value_loss         | 0.372      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 180         |\n",
      "|    total_timesteps    | 15605760    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017545784 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.933       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00328     |\n",
      "|    mean_step_reward   | 0.099590465 |\n",
      "|    n_updates          | 50.00 %     |\n",
      "|    policyGradLoss     | -0.017      |\n",
      "|    value_loss         | 0.441       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 191         |\n",
      "|    total_timesteps    | 15613952    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015716828 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.921       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00925     |\n",
      "|    mean_step_reward   | 0.07630221  |\n",
      "|    n_updates          | 53.12 %     |\n",
      "|    policyGradLoss     | -0.0181     |\n",
      "|    value_loss         | 0.46        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 202         |\n",
      "|    total_timesteps    | 15622144    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016589187 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.925       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0311     |\n",
      "|    mean_step_reward   | 0.10104364  |\n",
      "|    n_updates          | 56.25 %     |\n",
      "|    policyGradLoss     | -0.0153     |\n",
      "|    value_loss         | 0.338       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 764         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 214         |\n",
      "|    total_timesteps    | 15630336    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015456388 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.918       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00841     |\n",
      "|    mean_step_reward   | 0.09404251  |\n",
      "|    n_updates          | 59.38 %     |\n",
      "|    policyGradLoss     | -0.016      |\n",
      "|    value_loss         | 0.431       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 760         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 226         |\n",
      "|    total_timesteps    | 15638528    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019053707 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.902       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0187     |\n",
      "|    mean_step_reward   | 0.07342196  |\n",
      "|    n_updates          | 62.50 %     |\n",
      "|    policyGradLoss     | -0.0162     |\n",
      "|    value_loss         | 0.407       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 758         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 237         |\n",
      "|    total_timesteps    | 15646720    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016002964 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.938       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0417     |\n",
      "|    mean_step_reward   | 0.111857675 |\n",
      "|    n_updates          | 65.62 %     |\n",
      "|    policyGradLoss     | -0.0161     |\n",
      "|    value_loss         | 0.282       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 757         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 248         |\n",
      "|    total_timesteps    | 15654912    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021668185 |\n",
      "|    entropy_loss       | -1.99       |\n",
      "|    explained_variance | 0.947       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0257     |\n",
      "|    mean_step_reward   | 0.08663626  |\n",
      "|    n_updates          | 68.75 %     |\n",
      "|    policyGradLoss     | -0.0162     |\n",
      "|    value_loss         | 0.228       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 756         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 260         |\n",
      "|    total_timesteps    | 15663104    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02019599  |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.952       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0384     |\n",
      "|    mean_step_reward   | 0.114490755 |\n",
      "|    n_updates          | 71.88 %     |\n",
      "|    policyGradLoss     | -0.0169     |\n",
      "|    value_loss         | 0.323       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 756         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 270         |\n",
      "|    total_timesteps    | 15671296    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019794509 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.943       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0302      |\n",
      "|    mean_step_reward   | 0.07581047  |\n",
      "|    n_updates          | 75.00 %     |\n",
      "|    policyGradLoss     | -0.0176     |\n",
      "|    value_loss         | 0.456       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 755         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 281         |\n",
      "|    total_timesteps    | 15679488    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021232164 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.957       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.026      |\n",
      "|    mean_step_reward   | 0.100554146 |\n",
      "|    n_updates          | 78.12 %     |\n",
      "|    policyGradLoss     | -0.0204     |\n",
      "|    value_loss         | 0.29        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 754         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 293         |\n",
      "|    total_timesteps    | 15687680    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019108888 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.938       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0607     |\n",
      "|    mean_step_reward   | 0.09009765  |\n",
      "|    n_updates          | 81.25 %     |\n",
      "|    policyGradLoss     | -0.0211     |\n",
      "|    value_loss         | 0.255       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 751        |\n",
      "|    iterations         | 28         |\n",
      "|    time_elapsed       | 305        |\n",
      "|    total_timesteps    | 15695872   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.0198858  |\n",
      "|    entropy_loss       | -1.95      |\n",
      "|    explained_variance | 0.937      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.018      |\n",
      "|    mean_step_reward   | 0.07733769 |\n",
      "|    n_updates          | 84.38 %    |\n",
      "|    policyGradLoss     | -0.019     |\n",
      "|    value_loss         | 0.357      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 750         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 316         |\n",
      "|    total_timesteps    | 15704064    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020978497 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.935       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0133      |\n",
      "|    mean_step_reward   | 0.10394843  |\n",
      "|    n_updates          | 87.50 %     |\n",
      "|    policyGradLoss     | -0.0188     |\n",
      "|    value_loss         | 0.328       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 749         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 328         |\n",
      "|    total_timesteps    | 15712256    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020686064 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.925       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00255    |\n",
      "|    mean_step_reward   | 0.09228271  |\n",
      "|    n_updates          | 90.62 %     |\n",
      "|    policyGradLoss     | -0.0183     |\n",
      "|    value_loss         | 0.332       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 748        |\n",
      "|    iterations         | 31         |\n",
      "|    time_elapsed       | 339        |\n",
      "|    total_timesteps    | 15720448   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.0184557  |\n",
      "|    entropy_loss       | -1.9       |\n",
      "|    explained_variance | 0.957      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.0306     |\n",
      "|    mean_step_reward   | 0.09238614 |\n",
      "|    n_updates          | 93.75 %    |\n",
      "|    policyGradLoss     | -0.0193    |\n",
      "|    value_loss         | 0.334      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 748         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 350         |\n",
      "|    total_timesteps    | 15728640    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019845441 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.947       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0174     |\n",
      "|    mean_step_reward   | 0.10427514  |\n",
      "|    n_updates          | 96.88 %     |\n",
      "|    policyGradLoss     | -0.0182     |\n",
      "|    value_loss         | 0.314       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Run_59.zip\n",
      "[EVAL] Mean Return: 141.007, Best Return: 147.841\n",
      "Saved video to ./runs_smw/videos/Run/Run_59_141.01.mp4\n",
      "\n",
      "=== Round 61 | Learn 262144 steps (Total trained: 15728640) ===\n",
      "Logging to ./runs_smw/tb/Run_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1156     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 15736832 |\n",
      "---------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 886        |\n",
      "|    iterations         | 2          |\n",
      "|    time_elapsed       | 18         |\n",
      "|    total_timesteps    | 15745024   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02045311 |\n",
      "|    entropy_loss       | -1.85      |\n",
      "|    explained_variance | 0.938      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0255    |\n",
      "|    mean_step_reward   | 0.11964978 |\n",
      "|    n_updates          | 3.12 %     |\n",
      "|    policyGradLoss     | -0.0137    |\n",
      "|    value_loss         | 0.431      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 814         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 30          |\n",
      "|    total_timesteps    | 15753216    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022936234 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.947       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0404     |\n",
      "|    mean_step_reward   | 0.096096754 |\n",
      "|    n_updates          | 6.25 %      |\n",
      "|    policyGradLoss     | -0.018      |\n",
      "|    value_loss         | 0.262       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 788         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 41          |\n",
      "|    total_timesteps    | 15761408    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018185735 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.95        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0553      |\n",
      "|    mean_step_reward   | 0.124697834 |\n",
      "|    n_updates          | 9.38 %      |\n",
      "|    policyGradLoss     | -0.0157     |\n",
      "|    value_loss         | 0.353       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 51          |\n",
      "|    total_timesteps    | 15769600    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019995082 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.898       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0409      |\n",
      "|    mean_step_reward   | 0.06682435  |\n",
      "|    n_updates          | 12.50 %     |\n",
      "|    policyGradLoss     | -0.0141     |\n",
      "|    value_loss         | 0.502       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 809         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 60          |\n",
      "|    total_timesteps    | 15777792    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017154953 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.942       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0274      |\n",
      "|    mean_step_reward   | 0.099688895 |\n",
      "|    n_updates          | 15.62 %     |\n",
      "|    policyGradLoss     | -0.0161     |\n",
      "|    value_loss         | 0.327       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 820         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 69          |\n",
      "|    total_timesteps    | 15785984    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022090046 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.941       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.033      |\n",
      "|    mean_step_reward   | 0.09151321  |\n",
      "|    n_updates          | 18.75 %     |\n",
      "|    policyGradLoss     | -0.0182     |\n",
      "|    value_loss         | 0.275       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 825         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 79          |\n",
      "|    total_timesteps    | 15794176    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018683258 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.899       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0257      |\n",
      "|    mean_step_reward   | 0.081225105 |\n",
      "|    n_updates          | 21.88 %     |\n",
      "|    policyGradLoss     | -0.0151     |\n",
      "|    value_loss         | 0.502       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 816         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 90          |\n",
      "|    total_timesteps    | 15802368    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.0190862   |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.931       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0324      |\n",
      "|    mean_step_reward   | 0.102928266 |\n",
      "|    n_updates          | 25.00 %     |\n",
      "|    policyGradLoss     | -0.0159     |\n",
      "|    value_loss         | 0.427       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 804         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 101         |\n",
      "|    total_timesteps    | 15810560    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021054542 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.942       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0227     |\n",
      "|    mean_step_reward   | 0.09987214  |\n",
      "|    n_updates          | 28.12 %     |\n",
      "|    policyGradLoss     | -0.018      |\n",
      "|    value_loss         | 0.316       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 795         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 113         |\n",
      "|    total_timesteps    | 15818752    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021938473 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.926       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.000975   |\n",
      "|    mean_step_reward   | 0.07763751  |\n",
      "|    n_updates          | 31.25 %     |\n",
      "|    policyGradLoss     | -0.0178     |\n",
      "|    value_loss         | 0.261       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 789         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 124         |\n",
      "|    total_timesteps    | 15826944    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024045337 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.948       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0135      |\n",
      "|    mean_step_reward   | 0.10236478  |\n",
      "|    n_updates          | 34.38 %     |\n",
      "|    policyGradLoss     | -0.0168     |\n",
      "|    value_loss         | 0.305       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 135         |\n",
      "|    total_timesteps    | 15835136    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017496169 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.923       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0172      |\n",
      "|    mean_step_reward   | 0.10295272  |\n",
      "|    n_updates          | 37.50 %     |\n",
      "|    policyGradLoss     | -0.0132     |\n",
      "|    value_loss         | 0.379       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 146         |\n",
      "|    total_timesteps    | 15843328    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022943279 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.941       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00701    |\n",
      "|    mean_step_reward   | 0.104135536 |\n",
      "|    n_updates          | 40.62 %     |\n",
      "|    policyGradLoss     | -0.0157     |\n",
      "|    value_loss         | 0.307       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 157         |\n",
      "|    total_timesteps    | 15851520    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020962998 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.939       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0302     |\n",
      "|    mean_step_reward   | 0.09490575  |\n",
      "|    n_updates          | 43.75 %     |\n",
      "|    policyGradLoss     | -0.0179     |\n",
      "|    value_loss         | 0.327       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 168         |\n",
      "|    total_timesteps    | 15859712    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017312758 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.906       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.025      |\n",
      "|    mean_step_reward   | 0.10494588  |\n",
      "|    n_updates          | 46.88 %     |\n",
      "|    policyGradLoss     | -0.0148     |\n",
      "|    value_loss         | 0.455       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 180         |\n",
      "|    total_timesteps    | 15867904    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022490129 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.945       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00783    |\n",
      "|    mean_step_reward   | 0.09921177  |\n",
      "|    n_updates          | 50.00 %     |\n",
      "|    policyGradLoss     | -0.0205     |\n",
      "|    value_loss         | 0.286       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 192         |\n",
      "|    total_timesteps    | 15876096    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015692653 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.936       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0422      |\n",
      "|    mean_step_reward   | 0.090818875 |\n",
      "|    n_updates          | 53.12 %     |\n",
      "|    policyGradLoss     | -0.0131     |\n",
      "|    value_loss         | 0.363       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 765        |\n",
      "|    iterations         | 19         |\n",
      "|    time_elapsed       | 203        |\n",
      "|    total_timesteps    | 15884288   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01979025 |\n",
      "|    entropy_loss       | -1.87      |\n",
      "|    explained_variance | 0.894      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.0595     |\n",
      "|    mean_step_reward   | 0.098597   |\n",
      "|    n_updates          | 56.25 %    |\n",
      "|    policyGradLoss     | -0.0138    |\n",
      "|    value_loss         | 0.452      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 763         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 214         |\n",
      "|    total_timesteps    | 15892480    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022385223 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.949       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0572     |\n",
      "|    mean_step_reward   | 0.09833053  |\n",
      "|    n_updates          | 59.38 %     |\n",
      "|    policyGradLoss     | -0.0181     |\n",
      "|    value_loss         | 0.217       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 762         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 225         |\n",
      "|    total_timesteps    | 15900672    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021148622 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.95        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00111     |\n",
      "|    mean_step_reward   | 0.10967499  |\n",
      "|    n_updates          | 62.50 %     |\n",
      "|    policyGradLoss     | -0.0169     |\n",
      "|    value_loss         | 0.252       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 762         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 236         |\n",
      "|    total_timesteps    | 15908864    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017339483 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.938       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00665     |\n",
      "|    mean_step_reward   | 0.09647927  |\n",
      "|    n_updates          | 65.62 %     |\n",
      "|    policyGradLoss     | -0.0151     |\n",
      "|    value_loss         | 0.336       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 760        |\n",
      "|    iterations         | 23         |\n",
      "|    time_elapsed       | 247        |\n",
      "|    total_timesteps    | 15917056   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01732701 |\n",
      "|    entropy_loss       | -1.88      |\n",
      "|    explained_variance | 0.945      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0109    |\n",
      "|    mean_step_reward   | 0.12301047 |\n",
      "|    n_updates          | 68.75 %    |\n",
      "|    policyGradLoss     | -0.0169    |\n",
      "|    value_loss         | 0.297      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 758        |\n",
      "|    iterations         | 24         |\n",
      "|    time_elapsed       | 259        |\n",
      "|    total_timesteps    | 15925248   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02293229 |\n",
      "|    entropy_loss       | -1.93      |\n",
      "|    explained_variance | 0.958      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.00299    |\n",
      "|    mean_step_reward   | 0.09702541 |\n",
      "|    n_updates          | 71.88 %    |\n",
      "|    policyGradLoss     | -0.0176    |\n",
      "|    value_loss         | 0.217      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 756         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 270         |\n",
      "|    total_timesteps    | 15933440    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021969508 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.948       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0198      |\n",
      "|    mean_step_reward   | 0.10165068  |\n",
      "|    n_updates          | 75.00 %     |\n",
      "|    policyGradLoss     | -0.0163     |\n",
      "|    value_loss         | 0.295       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 754         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 282         |\n",
      "|    total_timesteps    | 15941632    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015837245 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.939       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00129    |\n",
      "|    mean_step_reward   | 0.1162221   |\n",
      "|    n_updates          | 78.12 %     |\n",
      "|    policyGradLoss     | -0.0159     |\n",
      "|    value_loss         | 0.41        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 753         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 293         |\n",
      "|    total_timesteps    | 15949824    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020489406 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.935       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0804      |\n",
      "|    mean_step_reward   | 0.089943506 |\n",
      "|    n_updates          | 81.25 %     |\n",
      "|    policyGradLoss     | -0.0177     |\n",
      "|    value_loss         | 0.38        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 752         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 304         |\n",
      "|    total_timesteps    | 15958016    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018323593 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.921       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.146       |\n",
      "|    mean_step_reward   | 0.124737814 |\n",
      "|    n_updates          | 84.38 %     |\n",
      "|    policyGradLoss     | -0.0165     |\n",
      "|    value_loss         | 0.417       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 752         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 315         |\n",
      "|    total_timesteps    | 15966208    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018154236 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.949       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0235      |\n",
      "|    mean_step_reward   | 0.08397845  |\n",
      "|    n_updates          | 87.50 %     |\n",
      "|    policyGradLoss     | -0.0153     |\n",
      "|    value_loss         | 0.326       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 751         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 327         |\n",
      "|    total_timesteps    | 15974400    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021891993 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.94        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0137      |\n",
      "|    mean_step_reward   | 0.111366615 |\n",
      "|    n_updates          | 90.62 %     |\n",
      "|    policyGradLoss     | -0.0151     |\n",
      "|    value_loss         | 0.384       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 749         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 338         |\n",
      "|    total_timesteps    | 15982592    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022150476 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.944       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0992      |\n",
      "|    mean_step_reward   | 0.08973631  |\n",
      "|    n_updates          | 93.75 %     |\n",
      "|    policyGradLoss     | -0.018      |\n",
      "|    value_loss         | 0.338       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 748         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 350         |\n",
      "|    total_timesteps    | 15990784    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021001229 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.957       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.01       |\n",
      "|    mean_step_reward   | 0.114337854 |\n",
      "|    n_updates          | 96.88 %     |\n",
      "|    policyGradLoss     | -0.0154     |\n",
      "|    value_loss         | 0.216       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Run_60.zip\n",
      "[EVAL] Mean Return: 145.982, Best Return: 153.316\n",
      "Saved video to ./runs_smw/videos/Run/Run_60_145.98.mp4\n",
      "\n",
      "=== Round 62 | Learn 262144 steps (Total trained: 15990784) ===\n",
      "Logging to ./runs_smw/tb/Run_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1167     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 15998976 |\n",
      "---------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 1016       |\n",
      "|    iterations         | 2          |\n",
      "|    time_elapsed       | 16         |\n",
      "|    total_timesteps    | 16007168   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01771575 |\n",
      "|    entropy_loss       | -1.83      |\n",
      "|    explained_variance | 0.965      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0198    |\n",
      "|    mean_step_reward   | 0.14327188 |\n",
      "|    n_updates          | 3.12 %     |\n",
      "|    policyGradLoss     | -0.0138    |\n",
      "|    value_loss         | 0.262      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 974         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 25          |\n",
      "|    total_timesteps    | 16015360    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022759521 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.935       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0188      |\n",
      "|    mean_step_reward   | 0.081270844 |\n",
      "|    n_updates          | 6.25 %      |\n",
      "|    policyGradLoss     | -0.0174     |\n",
      "|    value_loss         | 0.339       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 943         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 34          |\n",
      "|    total_timesteps    | 16023552    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017844578 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0147      |\n",
      "|    mean_step_reward   | 0.12477587  |\n",
      "|    n_updates          | 9.38 %      |\n",
      "|    policyGradLoss     | -0.0143     |\n",
      "|    value_loss         | 0.383       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 914         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 44          |\n",
      "|    total_timesteps    | 16031744    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020138033 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.922       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0183     |\n",
      "|    mean_step_reward   | 0.085296795 |\n",
      "|    n_updates          | 12.50 %     |\n",
      "|    policyGradLoss     | -0.0162     |\n",
      "|    value_loss         | 0.287       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 874         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 56          |\n",
      "|    total_timesteps    | 16039936    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018472157 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.954       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0344      |\n",
      "|    mean_step_reward   | 0.105199575 |\n",
      "|    n_updates          | 15.62 %     |\n",
      "|    policyGradLoss     | -0.0137     |\n",
      "|    value_loss         | 0.313       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 850        |\n",
      "|    iterations         | 7          |\n",
      "|    time_elapsed       | 67         |\n",
      "|    total_timesteps    | 16048128   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02727648 |\n",
      "|    entropy_loss       | -1.84      |\n",
      "|    explained_variance | 0.959      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.00154   |\n",
      "|    mean_step_reward   | 0.10729557 |\n",
      "|    n_updates          | 18.75 %    |\n",
      "|    policyGradLoss     | -0.0182    |\n",
      "|    value_loss         | 0.234      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 832         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 78          |\n",
      "|    total_timesteps    | 16056320    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027119983 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0228     |\n",
      "|    mean_step_reward   | 0.098773316 |\n",
      "|    n_updates          | 21.88 %     |\n",
      "|    policyGradLoss     | -0.0173     |\n",
      "|    value_loss         | 0.224       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 822         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 89          |\n",
      "|    total_timesteps    | 16064512    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019434161 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.951       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0366     |\n",
      "|    mean_step_reward   | 0.1062184   |\n",
      "|    n_updates          | 25.00 %     |\n",
      "|    policyGradLoss     | -0.0123     |\n",
      "|    value_loss         | 0.292       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 814         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 100         |\n",
      "|    total_timesteps    | 16072704    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020706892 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.95        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00856     |\n",
      "|    mean_step_reward   | 0.09264107  |\n",
      "|    n_updates          | 28.12 %     |\n",
      "|    policyGradLoss     | -0.0161     |\n",
      "|    value_loss         | 0.27        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 805         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 111         |\n",
      "|    total_timesteps    | 16080896    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01952973  |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0315      |\n",
      "|    mean_step_reward   | 0.113718495 |\n",
      "|    n_updates          | 31.25 %     |\n",
      "|    policyGradLoss     | -0.0166     |\n",
      "|    value_loss         | 0.41        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 795        |\n",
      "|    iterations         | 12         |\n",
      "|    time_elapsed       | 123        |\n",
      "|    total_timesteps    | 16089088   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02291387 |\n",
      "|    entropy_loss       | -1.9       |\n",
      "|    explained_variance | 0.963      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0533    |\n",
      "|    mean_step_reward   | 0.11066584 |\n",
      "|    n_updates          | 34.38 %    |\n",
      "|    policyGradLoss     | -0.0201    |\n",
      "|    value_loss         | 0.205      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 788         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 135         |\n",
      "|    total_timesteps    | 16097280    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019546378 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.951       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0399     |\n",
      "|    mean_step_reward   | 0.12881212  |\n",
      "|    n_updates          | 37.50 %     |\n",
      "|    policyGradLoss     | -0.0116     |\n",
      "|    value_loss         | 0.206       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 146         |\n",
      "|    total_timesteps    | 16105472    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021273851 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.939       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.017      |\n",
      "|    mean_step_reward   | 0.10559976  |\n",
      "|    n_updates          | 40.62 %     |\n",
      "|    policyGradLoss     | -0.0171     |\n",
      "|    value_loss         | 0.335       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 157         |\n",
      "|    total_timesteps    | 16113664    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023796793 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.958       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0223     |\n",
      "|    mean_step_reward   | 0.110560924 |\n",
      "|    n_updates          | 43.75 %     |\n",
      "|    policyGradLoss     | -0.0179     |\n",
      "|    value_loss         | 0.237       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 168         |\n",
      "|    total_timesteps    | 16121856    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023215795 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.946       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0559     |\n",
      "|    mean_step_reward   | 0.10117188  |\n",
      "|    n_updates          | 46.88 %     |\n",
      "|    policyGradLoss     | -0.017      |\n",
      "|    value_loss         | 0.269       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 775        |\n",
      "|    iterations         | 17         |\n",
      "|    time_elapsed       | 179        |\n",
      "|    total_timesteps    | 16130048   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01790438 |\n",
      "|    entropy_loss       | -1.91      |\n",
      "|    explained_variance | 0.969      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.00594   |\n",
      "|    mean_step_reward   | 0.11157624 |\n",
      "|    n_updates          | 50.00 %    |\n",
      "|    policyGradLoss     | -0.017     |\n",
      "|    value_loss         | 0.179      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 190         |\n",
      "|    total_timesteps    | 16138240    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024391685 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0404     |\n",
      "|    mean_step_reward   | 0.11721329  |\n",
      "|    n_updates          | 53.12 %     |\n",
      "|    policyGradLoss     | -0.0186     |\n",
      "|    value_loss         | 0.226       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 202         |\n",
      "|    total_timesteps    | 16146432    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02009316  |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.954       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0345      |\n",
      "|    mean_step_reward   | 0.092869245 |\n",
      "|    n_updates          | 56.25 %     |\n",
      "|    policyGradLoss     | -0.0169     |\n",
      "|    value_loss         | 0.332       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 765        |\n",
      "|    iterations         | 20         |\n",
      "|    time_elapsed       | 214        |\n",
      "|    total_timesteps    | 16154624   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01896276 |\n",
      "|    entropy_loss       | -1.87      |\n",
      "|    explained_variance | 0.938      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.00795   |\n",
      "|    mean_step_reward   | 0.11177737 |\n",
      "|    n_updates          | 59.38 %    |\n",
      "|    policyGradLoss     | -0.0171    |\n",
      "|    value_loss         | 0.341      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 763        |\n",
      "|    iterations         | 21         |\n",
      "|    time_elapsed       | 225        |\n",
      "|    total_timesteps    | 16162816   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.0164823  |\n",
      "|    entropy_loss       | -1.93      |\n",
      "|    explained_variance | 0.94       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0235    |\n",
      "|    mean_step_reward   | 0.09590058 |\n",
      "|    n_updates          | 62.50 %    |\n",
      "|    policyGradLoss     | -0.0155    |\n",
      "|    value_loss         | 0.303      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 761         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 236         |\n",
      "|    total_timesteps    | 16171008    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023984535 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.957       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0282      |\n",
      "|    mean_step_reward   | 0.10445521  |\n",
      "|    n_updates          | 65.62 %     |\n",
      "|    policyGradLoss     | -0.018      |\n",
      "|    value_loss         | 0.295       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 761         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 247         |\n",
      "|    total_timesteps    | 16179200    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024698593 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.945       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0168      |\n",
      "|    mean_step_reward   | 0.10088062  |\n",
      "|    n_updates          | 68.75 %     |\n",
      "|    policyGradLoss     | -0.0171     |\n",
      "|    value_loss         | 0.304       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 759         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 258         |\n",
      "|    total_timesteps    | 16187392    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023912784 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0205     |\n",
      "|    mean_step_reward   | 0.10306677  |\n",
      "|    n_updates          | 71.88 %     |\n",
      "|    policyGradLoss     | -0.0168     |\n",
      "|    value_loss         | 0.274       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 757         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 270         |\n",
      "|    total_timesteps    | 16195584    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019836154 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.927       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0585      |\n",
      "|    mean_step_reward   | 0.10137563  |\n",
      "|    n_updates          | 75.00 %     |\n",
      "|    policyGradLoss     | -0.0142     |\n",
      "|    value_loss         | 0.475       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 756         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 281         |\n",
      "|    total_timesteps    | 16203776    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017658066 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.941       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0367      |\n",
      "|    mean_step_reward   | 0.07401459  |\n",
      "|    n_updates          | 78.12 %     |\n",
      "|    policyGradLoss     | -0.0175     |\n",
      "|    value_loss         | 0.349       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 754         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 293         |\n",
      "|    total_timesteps    | 16211968    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020749178 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.947       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0222      |\n",
      "|    mean_step_reward   | 0.121888615 |\n",
      "|    n_updates          | 81.25 %     |\n",
      "|    policyGradLoss     | -0.013      |\n",
      "|    value_loss         | 0.425       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 752         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 304         |\n",
      "|    total_timesteps    | 16220160    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02559102  |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0165      |\n",
      "|    mean_step_reward   | 0.104708396 |\n",
      "|    n_updates          | 84.38 %     |\n",
      "|    policyGradLoss     | -0.014      |\n",
      "|    value_loss         | 0.206       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 752         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 315         |\n",
      "|    total_timesteps    | 16228352    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026745686 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.946       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0601      |\n",
      "|    mean_step_reward   | 0.09096841  |\n",
      "|    n_updates          | 87.50 %     |\n",
      "|    policyGradLoss     | -0.0157     |\n",
      "|    value_loss         | 0.376       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 751         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 327         |\n",
      "|    total_timesteps    | 16236544    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014840268 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.944       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0421      |\n",
      "|    mean_step_reward   | 0.12375063  |\n",
      "|    n_updates          | 90.62 %     |\n",
      "|    policyGradLoss     | -0.0137     |\n",
      "|    value_loss         | 0.437       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 751         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 338         |\n",
      "|    total_timesteps    | 16244736    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023912001 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.931       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0321     |\n",
      "|    mean_step_reward   | 0.096882254 |\n",
      "|    n_updates          | 93.75 %     |\n",
      "|    policyGradLoss     | -0.0181     |\n",
      "|    value_loss         | 0.257       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 750         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 349         |\n",
      "|    total_timesteps    | 16252928    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025221076 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0016      |\n",
      "|    mean_step_reward   | 0.094862334 |\n",
      "|    n_updates          | 96.88 %     |\n",
      "|    policyGradLoss     | -0.0175     |\n",
      "|    value_loss         | 0.284       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Run_61.zip\n",
      "[EVAL] Mean Return: 153.950, Best Return: 160.783\n",
      "Saved video to ./runs_smw/videos/Run/Run_61_153.95.mp4\n",
      "\n",
      "=== Round 63 | Learn 262144 steps (Total trained: 16252928) ===\n",
      "Logging to ./runs_smw/tb/Run_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1398     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 16261120 |\n",
      "---------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 1081       |\n",
      "|    iterations         | 2          |\n",
      "|    time_elapsed       | 15         |\n",
      "|    total_timesteps    | 16269312   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01940117 |\n",
      "|    entropy_loss       | -1.87      |\n",
      "|    explained_variance | 0.903      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.0304     |\n",
      "|    mean_step_reward   | 0.09081156 |\n",
      "|    n_updates          | 3.12 %     |\n",
      "|    policyGradLoss     | -0.0144    |\n",
      "|    value_loss         | 0.517      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 938        |\n",
      "|    iterations         | 3          |\n",
      "|    time_elapsed       | 26         |\n",
      "|    total_timesteps    | 16277504   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02248002 |\n",
      "|    entropy_loss       | -1.91      |\n",
      "|    explained_variance | 0.935      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0398    |\n",
      "|    mean_step_reward   | 0.09273182 |\n",
      "|    n_updates          | 6.25 %     |\n",
      "|    policyGradLoss     | -0.0187    |\n",
      "|    value_loss         | 0.243      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 867         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 37          |\n",
      "|    total_timesteps    | 16285696    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018663352 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.932       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0117      |\n",
      "|    mean_step_reward   | 0.09046942  |\n",
      "|    n_updates          | 9.38 %      |\n",
      "|    policyGradLoss     | -0.0174     |\n",
      "|    value_loss         | 0.372       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 830         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 49          |\n",
      "|    total_timesteps    | 16293888    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023846906 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.958       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0272     |\n",
      "|    mean_step_reward   | 0.1107927   |\n",
      "|    n_updates          | 12.50 %     |\n",
      "|    policyGradLoss     | -0.0173     |\n",
      "|    value_loss         | 0.251       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 808         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 60          |\n",
      "|    total_timesteps    | 16302080    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020566769 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.955       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00639    |\n",
      "|    mean_step_reward   | 0.11588973  |\n",
      "|    n_updates          | 15.62 %     |\n",
      "|    policyGradLoss     | -0.0192     |\n",
      "|    value_loss         | 0.281       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 796         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 72          |\n",
      "|    total_timesteps    | 16310272    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022861943 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0323     |\n",
      "|    mean_step_reward   | 0.113065824 |\n",
      "|    n_updates          | 18.75 %     |\n",
      "|    policyGradLoss     | -0.0205     |\n",
      "|    value_loss         | 0.255       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 789         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 83          |\n",
      "|    total_timesteps    | 16318464    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023819998 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0632     |\n",
      "|    mean_step_reward   | 0.11126291  |\n",
      "|    n_updates          | 21.88 %     |\n",
      "|    policyGradLoss     | -0.0212     |\n",
      "|    value_loss         | 0.176       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 93          |\n",
      "|    total_timesteps    | 16326656    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020816237 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.931       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0127     |\n",
      "|    mean_step_reward   | 0.09912261  |\n",
      "|    n_updates          | 25.00 %     |\n",
      "|    policyGradLoss     | -0.0162     |\n",
      "|    value_loss         | 0.336       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 105         |\n",
      "|    total_timesteps    | 16334848    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020205442 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.945       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0145     |\n",
      "|    mean_step_reward   | 0.10918355  |\n",
      "|    n_updates          | 28.12 %     |\n",
      "|    policyGradLoss     | -0.018      |\n",
      "|    value_loss         | 0.268       |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 774       |\n",
      "|    iterations         | 11        |\n",
      "|    time_elapsed       | 116       |\n",
      "|    total_timesteps    | 16343040  |\n",
      "| train/                |           |\n",
      "|    approx_kl          | 0.0256082 |\n",
      "|    entropy_loss       | -1.86     |\n",
      "|    explained_variance | 0.958     |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    loss               | -0.0229   |\n",
      "|    mean_step_reward   | 0.1167057 |\n",
      "|    n_updates          | 31.25 %   |\n",
      "|    policyGradLoss     | -0.0177   |\n",
      "|    value_loss         | 0.232     |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 128         |\n",
      "|    total_timesteps    | 16351232    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016165309 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.915       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0334      |\n",
      "|    mean_step_reward   | 0.09944398  |\n",
      "|    n_updates          | 34.38 %     |\n",
      "|    policyGradLoss     | -0.0115     |\n",
      "|    value_loss         | 0.364       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 762        |\n",
      "|    iterations         | 13         |\n",
      "|    time_elapsed       | 139        |\n",
      "|    total_timesteps    | 16359424   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01710635 |\n",
      "|    entropy_loss       | -1.85      |\n",
      "|    explained_variance | 0.94       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.041      |\n",
      "|    mean_step_reward   | 0.10040769 |\n",
      "|    n_updates          | 37.50 %    |\n",
      "|    policyGradLoss     | -0.016     |\n",
      "|    value_loss         | 0.354      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 760        |\n",
      "|    iterations         | 14         |\n",
      "|    time_elapsed       | 150        |\n",
      "|    total_timesteps    | 16367616   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02340725 |\n",
      "|    entropy_loss       | -1.82      |\n",
      "|    explained_variance | 0.946      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.00709    |\n",
      "|    mean_step_reward   | 0.1206735  |\n",
      "|    n_updates          | 40.62 %    |\n",
      "|    policyGradLoss     | -0.016     |\n",
      "|    value_loss         | 0.33       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 758         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 161         |\n",
      "|    total_timesteps    | 16375808    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020044267 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.033      |\n",
      "|    mean_step_reward   | 0.10476343  |\n",
      "|    n_updates          | 43.75 %     |\n",
      "|    policyGradLoss     | -0.0178     |\n",
      "|    value_loss         | 0.222       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 759         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 172         |\n",
      "|    total_timesteps    | 16384000    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019423058 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.923       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0101     |\n",
      "|    mean_step_reward   | 0.113685876 |\n",
      "|    n_updates          | 46.88 %     |\n",
      "|    policyGradLoss     | -0.0165     |\n",
      "|    value_loss         | 0.447       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 757        |\n",
      "|    iterations         | 17         |\n",
      "|    time_elapsed       | 183        |\n",
      "|    total_timesteps    | 16392192   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01842692 |\n",
      "|    entropy_loss       | -1.9       |\n",
      "|    explained_variance | 0.92       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.00816   |\n",
      "|    mean_step_reward   | 0.08915742 |\n",
      "|    n_updates          | 50.00 %    |\n",
      "|    policyGradLoss     | -0.0133    |\n",
      "|    value_loss         | 0.35       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 755         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 195         |\n",
      "|    total_timesteps    | 16400384    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017732434 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.926       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.045       |\n",
      "|    mean_step_reward   | 0.10119623  |\n",
      "|    n_updates          | 53.12 %     |\n",
      "|    policyGradLoss     | -0.0137     |\n",
      "|    value_loss         | 0.444       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 752         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 206         |\n",
      "|    total_timesteps    | 16408576    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018289428 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.941       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0558     |\n",
      "|    mean_step_reward   | 0.09855089  |\n",
      "|    n_updates          | 56.25 %     |\n",
      "|    policyGradLoss     | -0.0168     |\n",
      "|    value_loss         | 0.248       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 750        |\n",
      "|    iterations         | 20         |\n",
      "|    time_elapsed       | 218        |\n",
      "|    total_timesteps    | 16416768   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01902536 |\n",
      "|    entropy_loss       | -1.86      |\n",
      "|    explained_variance | 0.941      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.0207     |\n",
      "|    mean_step_reward   | 0.09625587 |\n",
      "|    n_updates          | 59.38 %    |\n",
      "|    policyGradLoss     | -0.0145    |\n",
      "|    value_loss         | 0.419      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 749        |\n",
      "|    iterations         | 21         |\n",
      "|    time_elapsed       | 229        |\n",
      "|    total_timesteps    | 16424960   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02000976 |\n",
      "|    entropy_loss       | -1.9       |\n",
      "|    explained_variance | 0.944      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0404    |\n",
      "|    mean_step_reward   | 0.10547037 |\n",
      "|    n_updates          | 62.50 %    |\n",
      "|    policyGradLoss     | -0.0173    |\n",
      "|    value_loss         | 0.26       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 749         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 240         |\n",
      "|    total_timesteps    | 16433152    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01835221  |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.917       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0734      |\n",
      "|    mean_step_reward   | 0.086612895 |\n",
      "|    n_updates          | 65.62 %     |\n",
      "|    policyGradLoss     | -0.0182     |\n",
      "|    value_loss         | 0.369       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 749         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 251         |\n",
      "|    total_timesteps    | 16441344    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020655429 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.946       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0153      |\n",
      "|    mean_step_reward   | 0.10570853  |\n",
      "|    n_updates          | 68.75 %     |\n",
      "|    policyGradLoss     | -0.0182     |\n",
      "|    value_loss         | 0.393       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 748         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 262         |\n",
      "|    total_timesteps    | 16449536    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021519896 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0395     |\n",
      "|    mean_step_reward   | 0.1017532   |\n",
      "|    n_updates          | 71.88 %     |\n",
      "|    policyGradLoss     | -0.0215     |\n",
      "|    value_loss         | 0.184       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 746         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 274         |\n",
      "|    total_timesteps    | 16457728    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018656727 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.94        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0909      |\n",
      "|    mean_step_reward   | 0.088461325 |\n",
      "|    n_updates          | 75.00 %     |\n",
      "|    policyGradLoss     | -0.0151     |\n",
      "|    value_loss         | 0.384       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 745         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 285         |\n",
      "|    total_timesteps    | 16465920    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021473557 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.955       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.026      |\n",
      "|    mean_step_reward   | 0.13295259  |\n",
      "|    n_updates          | 78.12 %     |\n",
      "|    policyGradLoss     | -0.0182     |\n",
      "|    value_loss         | 0.267       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 744         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 297         |\n",
      "|    total_timesteps    | 16474112    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018547263 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.947       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.041      |\n",
      "|    mean_step_reward   | 0.08644846  |\n",
      "|    n_updates          | 81.25 %     |\n",
      "|    policyGradLoss     | -0.0184     |\n",
      "|    value_loss         | 0.27        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 743         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 308         |\n",
      "|    total_timesteps    | 16482304    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02128318  |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.946       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0352     |\n",
      "|    mean_step_reward   | 0.109087035 |\n",
      "|    n_updates          | 84.38 %     |\n",
      "|    policyGradLoss     | -0.0187     |\n",
      "|    value_loss         | 0.314       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 743         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 319         |\n",
      "|    total_timesteps    | 16490496    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018373324 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.9         |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0135      |\n",
      "|    mean_step_reward   | 0.09923106  |\n",
      "|    n_updates          | 87.50 %     |\n",
      "|    policyGradLoss     | -0.0169     |\n",
      "|    value_loss         | 0.358       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 743         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 330         |\n",
      "|    total_timesteps    | 16498688    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020645898 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.936       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00735    |\n",
      "|    mean_step_reward   | 0.093507975 |\n",
      "|    n_updates          | 90.62 %     |\n",
      "|    policyGradLoss     | -0.0185     |\n",
      "|    value_loss         | 0.339       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 747        |\n",
      "|    iterations         | 31         |\n",
      "|    time_elapsed       | 339        |\n",
      "|    total_timesteps    | 16506880   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03100691 |\n",
      "|    entropy_loss       | -1.9       |\n",
      "|    explained_variance | 0.938      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0116    |\n",
      "|    mean_step_reward   | 0.10658769 |\n",
      "|    n_updates          | 93.75 %    |\n",
      "|    policyGradLoss     | -0.0182    |\n",
      "|    value_loss         | 0.329      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 752         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 348         |\n",
      "|    total_timesteps    | 16515072    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018127853 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.948       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0998      |\n",
      "|    mean_step_reward   | 0.10404162  |\n",
      "|    n_updates          | 96.88 %     |\n",
      "|    policyGradLoss     | -0.018      |\n",
      "|    value_loss         | 0.359       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Run_62.zip\n",
      "[EVAL] Mean Return: 152.207, Best Return: 159.207\n",
      "Saved video to ./runs_smw/videos/Run/Run_62_152.21.mp4\n",
      "\n",
      "=== Round 64 | Learn 262144 steps (Total trained: 16515072) ===\n",
      "Logging to ./runs_smw/tb/Run_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1115     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 16523264 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 862         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 16531456    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022123989 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.946       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0488      |\n",
      "|    mean_step_reward   | 0.11975862  |\n",
      "|    n_updates          | 3.12 %      |\n",
      "|    policyGradLoss     | -0.0188     |\n",
      "|    value_loss         | 0.286       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 809         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 30          |\n",
      "|    total_timesteps    | 16539648    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018946819 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.937       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00624     |\n",
      "|    mean_step_reward   | 0.0956464   |\n",
      "|    n_updates          | 6.25 %      |\n",
      "|    policyGradLoss     | -0.0171     |\n",
      "|    value_loss         | 0.333       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 792         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 41          |\n",
      "|    total_timesteps    | 16547840    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020976447 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.928       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0151      |\n",
      "|    mean_step_reward   | 0.10056086  |\n",
      "|    n_updates          | 9.38 %      |\n",
      "|    policyGradLoss     | -0.0155     |\n",
      "|    value_loss         | 0.407       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 52          |\n",
      "|    total_timesteps    | 16556032    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021854097 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0493     |\n",
      "|    mean_step_reward   | 0.12269705  |\n",
      "|    n_updates          | 12.50 %     |\n",
      "|    policyGradLoss     | -0.016      |\n",
      "|    value_loss         | 0.225       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 779        |\n",
      "|    iterations         | 6          |\n",
      "|    time_elapsed       | 63         |\n",
      "|    total_timesteps    | 16564224   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01916698 |\n",
      "|    entropy_loss       | -1.9       |\n",
      "|    explained_variance | 0.922      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0314    |\n",
      "|    mean_step_reward   | 0.09473536 |\n",
      "|    n_updates          | 15.62 %    |\n",
      "|    policyGradLoss     | -0.0157    |\n",
      "|    value_loss         | 0.345      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 74          |\n",
      "|    total_timesteps    | 16572416    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019800724 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.926       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.006       |\n",
      "|    mean_step_reward   | 0.08968271  |\n",
      "|    n_updates          | 18.75 %     |\n",
      "|    policyGradLoss     | -0.0185     |\n",
      "|    value_loss         | 0.425       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 763         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 85          |\n",
      "|    total_timesteps    | 16580608    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020083304 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.948       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0296     |\n",
      "|    mean_step_reward   | 0.11029966  |\n",
      "|    n_updates          | 21.88 %     |\n",
      "|    policyGradLoss     | -0.0192     |\n",
      "|    value_loss         | 0.287       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 756        |\n",
      "|    iterations         | 9          |\n",
      "|    time_elapsed       | 97         |\n",
      "|    total_timesteps    | 16588800   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02121083 |\n",
      "|    entropy_loss       | -1.88      |\n",
      "|    explained_variance | 0.935      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.00256   |\n",
      "|    mean_step_reward   | 0.08784664 |\n",
      "|    n_updates          | 25.00 %    |\n",
      "|    policyGradLoss     | -0.0175    |\n",
      "|    value_loss         | 0.313      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 753         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 108         |\n",
      "|    total_timesteps    | 16596992    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019690521 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.947       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0294     |\n",
      "|    mean_step_reward   | 0.11958978  |\n",
      "|    n_updates          | 28.12 %     |\n",
      "|    policyGradLoss     | -0.0179     |\n",
      "|    value_loss         | 0.274       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 751         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 119         |\n",
      "|    total_timesteps    | 16605184    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020164412 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.939       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00976    |\n",
      "|    mean_step_reward   | 0.09725194  |\n",
      "|    n_updates          | 31.25 %     |\n",
      "|    policyGradLoss     | -0.0157     |\n",
      "|    value_loss         | 0.388       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 750         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 130         |\n",
      "|    total_timesteps    | 16613376    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019439977 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.946       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00928     |\n",
      "|    mean_step_reward   | 0.102143854 |\n",
      "|    n_updates          | 34.38 %     |\n",
      "|    policyGradLoss     | -0.0175     |\n",
      "|    value_loss         | 0.333       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 749         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 142         |\n",
      "|    total_timesteps    | 16621568    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017239895 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.941       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0312     |\n",
      "|    mean_step_reward   | 0.12522322  |\n",
      "|    n_updates          | 37.50 %     |\n",
      "|    policyGradLoss     | -0.0152     |\n",
      "|    value_loss         | 0.264       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 748         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 153         |\n",
      "|    total_timesteps    | 16629760    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019986678 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.942       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0159      |\n",
      "|    mean_step_reward   | 0.09187361  |\n",
      "|    n_updates          | 40.62 %     |\n",
      "|    policyGradLoss     | -0.0158     |\n",
      "|    value_loss         | 0.265       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 745         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 164         |\n",
      "|    total_timesteps    | 16637952    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020042159 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.948       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0315     |\n",
      "|    mean_step_reward   | 0.12326208  |\n",
      "|    n_updates          | 43.75 %     |\n",
      "|    policyGradLoss     | -0.0145     |\n",
      "|    value_loss         | 0.31        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 742         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 176         |\n",
      "|    total_timesteps    | 16646144    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021891177 |\n",
      "|    entropy_loss       | -1.98       |\n",
      "|    explained_variance | 0.939       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0299     |\n",
      "|    mean_step_reward   | 0.083231926 |\n",
      "|    n_updates          | 46.88 %     |\n",
      "|    policyGradLoss     | -0.0154     |\n",
      "|    value_loss         | 0.205       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 741         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 187         |\n",
      "|    total_timesteps    | 16654336    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021897215 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.939       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0287      |\n",
      "|    mean_step_reward   | 0.0997079   |\n",
      "|    n_updates          | 50.00 %     |\n",
      "|    policyGradLoss     | -0.0139     |\n",
      "|    value_loss         | 0.44        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 740         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 198         |\n",
      "|    total_timesteps    | 16662528    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016948946 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.928       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00278    |\n",
      "|    mean_step_reward   | 0.082402006 |\n",
      "|    n_updates          | 53.12 %     |\n",
      "|    policyGradLoss     | -0.0171     |\n",
      "|    value_loss         | 0.331       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 741         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 209         |\n",
      "|    total_timesteps    | 16670720    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019683182 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.946       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.014       |\n",
      "|    mean_step_reward   | 0.08475216  |\n",
      "|    n_updates          | 56.25 %     |\n",
      "|    policyGradLoss     | -0.0165     |\n",
      "|    value_loss         | 0.312       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 740        |\n",
      "|    iterations         | 20         |\n",
      "|    time_elapsed       | 221        |\n",
      "|    total_timesteps    | 16678912   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.0154006  |\n",
      "|    entropy_loss       | -1.92      |\n",
      "|    explained_variance | 0.916      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.00795   |\n",
      "|    mean_step_reward   | 0.09949874 |\n",
      "|    n_updates          | 59.38 %    |\n",
      "|    policyGradLoss     | -0.0147    |\n",
      "|    value_loss         | 0.442      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 740         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 232         |\n",
      "|    total_timesteps    | 16687104    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020180704 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.943       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00167     |\n",
      "|    mean_step_reward   | 0.08454205  |\n",
      "|    n_updates          | 62.50 %     |\n",
      "|    policyGradLoss     | -0.019      |\n",
      "|    value_loss         | 0.353       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 739         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 243         |\n",
      "|    total_timesteps    | 16695296    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015140423 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.924       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0661      |\n",
      "|    mean_step_reward   | 0.11141474  |\n",
      "|    n_updates          | 65.62 %     |\n",
      "|    policyGradLoss     | -0.0124     |\n",
      "|    value_loss         | 0.455       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 737         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 255         |\n",
      "|    total_timesteps    | 16703488    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018025722 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.905       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.000349    |\n",
      "|    mean_step_reward   | 0.08046338  |\n",
      "|    n_updates          | 68.75 %     |\n",
      "|    policyGradLoss     | -0.0167     |\n",
      "|    value_loss         | 0.386       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 736         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 266         |\n",
      "|    total_timesteps    | 16711680    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022510914 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.941       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0683     |\n",
      "|    mean_step_reward   | 0.088168785 |\n",
      "|    n_updates          | 71.88 %     |\n",
      "|    policyGradLoss     | -0.0206     |\n",
      "|    value_loss         | 0.206       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 736         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 277         |\n",
      "|    total_timesteps    | 16719872    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016585985 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.919       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0253      |\n",
      "|    mean_step_reward   | 0.09440184  |\n",
      "|    n_updates          | 75.00 %     |\n",
      "|    policyGradLoss     | -0.0148     |\n",
      "|    value_loss         | 0.349       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 737         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 288         |\n",
      "|    total_timesteps    | 16728064    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019833766 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.935       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.102       |\n",
      "|    mean_step_reward   | 0.10496931  |\n",
      "|    n_updates          | 78.12 %     |\n",
      "|    policyGradLoss     | -0.0177     |\n",
      "|    value_loss         | 0.432       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 737         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 299         |\n",
      "|    total_timesteps    | 16736256    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021094568 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0311     |\n",
      "|    mean_step_reward   | 0.11100677  |\n",
      "|    n_updates          | 81.25 %     |\n",
      "|    policyGradLoss     | -0.02       |\n",
      "|    value_loss         | 0.226       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 739        |\n",
      "|    iterations         | 28         |\n",
      "|    time_elapsed       | 309        |\n",
      "|    total_timesteps    | 16744448   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01631869 |\n",
      "|    entropy_loss       | -1.9       |\n",
      "|    explained_variance | 0.925      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.0297     |\n",
      "|    mean_step_reward   | 0.08499922 |\n",
      "|    n_updates          | 84.38 %    |\n",
      "|    policyGradLoss     | -0.0143    |\n",
      "|    value_loss         | 0.438      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 744         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 318         |\n",
      "|    total_timesteps    | 16752640    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015573517 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.951       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00435    |\n",
      "|    mean_step_reward   | 0.116120726 |\n",
      "|    n_updates          | 87.50 %     |\n",
      "|    policyGradLoss     | -0.0182     |\n",
      "|    value_loss         | 0.32        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 748         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 328         |\n",
      "|    total_timesteps    | 16760832    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024820946 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.944       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0295      |\n",
      "|    mean_step_reward   | 0.093790755 |\n",
      "|    n_updates          | 90.62 %     |\n",
      "|    policyGradLoss     | -0.0178     |\n",
      "|    value_loss         | 0.283       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 751         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 337         |\n",
      "|    total_timesteps    | 16769024    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020319885 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.951       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0448     |\n",
      "|    mean_step_reward   | 0.117665716 |\n",
      "|    n_updates          | 93.75 %     |\n",
      "|    policyGradLoss     | -0.0197     |\n",
      "|    value_loss         | 0.291       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 750         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 349         |\n",
      "|    total_timesteps    | 16777216    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019750189 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.944       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0502      |\n",
      "|    mean_step_reward   | 0.09887455  |\n",
      "|    n_updates          | 96.88 %     |\n",
      "|    policyGradLoss     | -0.0176     |\n",
      "|    value_loss         | 0.363       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Run_63.zip\n",
      "[EVAL] Mean Return: 140.905, Best Return: 148.405\n",
      "Saved video to ./runs_smw/videos/Run/Run_63_140.91.mp4\n",
      "\n",
      "=== Round 65 | Learn 262144 steps (Total trained: 16777216) ===\n",
      "Logging to ./runs_smw/tb/Run_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1198     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 16785408 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 919         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 16793600    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018639578 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0065      |\n",
      "|    mean_step_reward   | 0.12937407  |\n",
      "|    n_updates          | 3.12 %      |\n",
      "|    policyGradLoss     | -0.0162     |\n",
      "|    value_loss         | 0.247       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 843         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 29          |\n",
      "|    total_timesteps    | 16801792    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023464438 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.000553   |\n",
      "|    mean_step_reward   | 0.10770794  |\n",
      "|    n_updates          | 6.25 %      |\n",
      "|    policyGradLoss     | -0.018      |\n",
      "|    value_loss         | 0.247       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 806         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 40          |\n",
      "|    total_timesteps    | 16809984    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023274388 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.943       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.000108    |\n",
      "|    mean_step_reward   | 0.09914221  |\n",
      "|    n_updates          | 9.38 %      |\n",
      "|    policyGradLoss     | -0.0165     |\n",
      "|    value_loss         | 0.322       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 52          |\n",
      "|    total_timesteps    | 16818176    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027834147 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0111      |\n",
      "|    mean_step_reward   | 0.10120459  |\n",
      "|    n_updates          | 12.50 %     |\n",
      "|    policyGradLoss     | -0.0211     |\n",
      "|    value_loss         | 0.234       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 63          |\n",
      "|    total_timesteps    | 16826368    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021702569 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.948       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0226     |\n",
      "|    mean_step_reward   | 0.09607171  |\n",
      "|    n_updates          | 15.62 %     |\n",
      "|    policyGradLoss     | -0.0181     |\n",
      "|    value_loss         | 0.28        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 769        |\n",
      "|    iterations         | 7          |\n",
      "|    time_elapsed       | 74         |\n",
      "|    total_timesteps    | 16834560   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01999037 |\n",
      "|    entropy_loss       | -1.88      |\n",
      "|    explained_variance | 0.947      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.0463     |\n",
      "|    mean_step_reward   | 0.09802337 |\n",
      "|    n_updates          | 18.75 %    |\n",
      "|    policyGradLoss     | -0.0176    |\n",
      "|    value_loss         | 0.366      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 85          |\n",
      "|    total_timesteps    | 16842752    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018330455 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.941       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0146      |\n",
      "|    mean_step_reward   | 0.08463826  |\n",
      "|    n_updates          | 21.88 %     |\n",
      "|    policyGradLoss     | -0.0157     |\n",
      "|    value_loss         | 0.399       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 764         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 96          |\n",
      "|    total_timesteps    | 16850944    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017327406 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.92        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0198      |\n",
      "|    mean_step_reward   | 0.09051792  |\n",
      "|    n_updates          | 25.00 %     |\n",
      "|    policyGradLoss     | -0.011      |\n",
      "|    value_loss         | 0.371       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 759         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 107         |\n",
      "|    total_timesteps    | 16859136    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016243577 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.921       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0423      |\n",
      "|    mean_step_reward   | 0.11370017  |\n",
      "|    n_updates          | 28.12 %     |\n",
      "|    policyGradLoss     | -0.0173     |\n",
      "|    value_loss         | 0.531       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 754         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 119         |\n",
      "|    total_timesteps    | 16867328    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024237847 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.942       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0106      |\n",
      "|    mean_step_reward   | 0.110422745 |\n",
      "|    n_updates          | 31.25 %     |\n",
      "|    policyGradLoss     | -0.0181     |\n",
      "|    value_loss         | 0.341       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 749         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 131         |\n",
      "|    total_timesteps    | 16875520    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022284957 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.939       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.113       |\n",
      "|    mean_step_reward   | 0.102137715 |\n",
      "|    n_updates          | 34.38 %     |\n",
      "|    policyGradLoss     | -0.0164     |\n",
      "|    value_loss         | 0.329       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 747         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 142         |\n",
      "|    total_timesteps    | 16883712    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017501999 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0555     |\n",
      "|    mean_step_reward   | 0.1095715   |\n",
      "|    n_updates          | 37.50 %     |\n",
      "|    policyGradLoss     | -0.0176     |\n",
      "|    value_loss         | 0.267       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 747         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 153         |\n",
      "|    total_timesteps    | 16891904    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02178906  |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.946       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0154     |\n",
      "|    mean_step_reward   | 0.090094194 |\n",
      "|    n_updates          | 40.62 %     |\n",
      "|    policyGradLoss     | -0.0159     |\n",
      "|    value_loss         | 0.279       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 747         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 164         |\n",
      "|    total_timesteps    | 16900096    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023623757 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.934       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0174      |\n",
      "|    mean_step_reward   | 0.09568707  |\n",
      "|    n_updates          | 43.75 %     |\n",
      "|    policyGradLoss     | -0.0161     |\n",
      "|    value_loss         | 0.387       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 747        |\n",
      "|    iterations         | 16         |\n",
      "|    time_elapsed       | 175        |\n",
      "|    total_timesteps    | 16908288   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02403734 |\n",
      "|    entropy_loss       | -1.89      |\n",
      "|    explained_variance | 0.953      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0209    |\n",
      "|    mean_step_reward   | 0.11583686 |\n",
      "|    n_updates          | 46.88 %    |\n",
      "|    policyGradLoss     | -0.0151    |\n",
      "|    value_loss         | 0.29       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 746         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 186         |\n",
      "|    total_timesteps    | 16916480    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025028445 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.944       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0165      |\n",
      "|    mean_step_reward   | 0.106636524 |\n",
      "|    n_updates          | 50.00 %     |\n",
      "|    policyGradLoss     | -0.0185     |\n",
      "|    value_loss         | 0.346       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 744         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 198         |\n",
      "|    total_timesteps    | 16924672    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021766325 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.942       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0312      |\n",
      "|    mean_step_reward   | 0.08425263  |\n",
      "|    n_updates          | 53.12 %     |\n",
      "|    policyGradLoss     | -0.0198     |\n",
      "|    value_loss         | 0.329       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 741         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 209         |\n",
      "|    total_timesteps    | 16932864    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023925617 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.941       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0519     |\n",
      "|    mean_step_reward   | 0.093447775 |\n",
      "|    n_updates          | 56.25 %     |\n",
      "|    policyGradLoss     | -0.0208     |\n",
      "|    value_loss         | 0.306       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 740         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 221         |\n",
      "|    total_timesteps    | 16941056    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023532655 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.947       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00553     |\n",
      "|    mean_step_reward   | 0.08597897  |\n",
      "|    n_updates          | 59.38 %     |\n",
      "|    policyGradLoss     | -0.0173     |\n",
      "|    value_loss         | 0.381       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 739         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 232         |\n",
      "|    total_timesteps    | 16949248    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023386937 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.948       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.000464    |\n",
      "|    mean_step_reward   | 0.108878225 |\n",
      "|    n_updates          | 62.50 %     |\n",
      "|    policyGradLoss     | -0.0208     |\n",
      "|    value_loss         | 0.329       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 739         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 243         |\n",
      "|    total_timesteps    | 16957440    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020355128 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.93        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0214     |\n",
      "|    mean_step_reward   | 0.076636754 |\n",
      "|    n_updates          | 65.62 %     |\n",
      "|    policyGradLoss     | -0.0175     |\n",
      "|    value_loss         | 0.313       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 739         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 254         |\n",
      "|    total_timesteps    | 16965632    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023237996 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0384     |\n",
      "|    mean_step_reward   | 0.113200545 |\n",
      "|    n_updates          | 68.75 %     |\n",
      "|    policyGradLoss     | -0.0188     |\n",
      "|    value_loss         | 0.277       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 739         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 265         |\n",
      "|    total_timesteps    | 16973824    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017853772 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.934       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00786    |\n",
      "|    mean_step_reward   | 0.105931476 |\n",
      "|    n_updates          | 71.88 %     |\n",
      "|    policyGradLoss     | -0.017      |\n",
      "|    value_loss         | 0.424       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 743         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 275         |\n",
      "|    total_timesteps    | 16982016    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02159518  |\n",
      "|    entropy_loss       | -1.97       |\n",
      "|    explained_variance | 0.934       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.123       |\n",
      "|    mean_step_reward   | 0.080546565 |\n",
      "|    n_updates          | 75.00 %     |\n",
      "|    policyGradLoss     | -0.0193     |\n",
      "|    value_loss         | 0.374       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 749         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 284         |\n",
      "|    total_timesteps    | 16990208    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020841926 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.912       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0437     |\n",
      "|    mean_step_reward   | 0.09761216  |\n",
      "|    n_updates          | 78.12 %     |\n",
      "|    policyGradLoss     | -0.0148     |\n",
      "|    value_loss         | 0.398       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 753         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 293         |\n",
      "|    total_timesteps    | 16998400    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025401328 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.936       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0131      |\n",
      "|    mean_step_reward   | 0.09432622  |\n",
      "|    n_updates          | 81.25 %     |\n",
      "|    policyGradLoss     | -0.0172     |\n",
      "|    value_loss         | 0.305       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 757        |\n",
      "|    iterations         | 28         |\n",
      "|    time_elapsed       | 302        |\n",
      "|    total_timesteps    | 17006592   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02226393 |\n",
      "|    entropy_loss       | -1.89      |\n",
      "|    explained_variance | 0.954      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.00176    |\n",
      "|    mean_step_reward   | 0.1143686  |\n",
      "|    n_updates          | 84.38 %    |\n",
      "|    policyGradLoss     | -0.02      |\n",
      "|    value_loss         | 0.254      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 756         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 313         |\n",
      "|    total_timesteps    | 17014784    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019871611 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.926       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00179     |\n",
      "|    mean_step_reward   | 0.09386057  |\n",
      "|    n_updates          | 87.50 %     |\n",
      "|    policyGradLoss     | -0.0164     |\n",
      "|    value_loss         | 0.372       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 754         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 325         |\n",
      "|    total_timesteps    | 17022976    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021632772 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.929       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0895      |\n",
      "|    mean_step_reward   | 0.08067361  |\n",
      "|    n_updates          | 90.62 %     |\n",
      "|    policyGradLoss     | -0.0169     |\n",
      "|    value_loss         | 0.411       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 753         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 337         |\n",
      "|    total_timesteps    | 17031168    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021033715 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.94        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00943    |\n",
      "|    mean_step_reward   | 0.10555153  |\n",
      "|    n_updates          | 93.75 %     |\n",
      "|    policyGradLoss     | -0.0175     |\n",
      "|    value_loss         | 0.277       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 753         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 348         |\n",
      "|    total_timesteps    | 17039360    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018038947 |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.925       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00547     |\n",
      "|    mean_step_reward   | 0.079028845 |\n",
      "|    n_updates          | 96.88 %     |\n",
      "|    policyGradLoss     | -0.0169     |\n",
      "|    value_loss         | 0.303       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Run_64.zip\n",
      "[EVAL] Mean Return: 127.230, Best Return: 132.564\n",
      "Saved video to ./runs_smw/videos/Run/Run_64_127.23.mp4\n",
      "\n",
      "=== Round 66 | Learn 262144 steps (Total trained: 17039360) ===\n",
      "Logging to ./runs_smw/tb/Run_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1168     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 17047552 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 896         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 17055744    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020678706 |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.933       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0626     |\n",
      "|    mean_step_reward   | 0.08548567  |\n",
      "|    n_updates          | 3.12 %      |\n",
      "|    policyGradLoss     | -0.0206     |\n",
      "|    value_loss         | 0.279       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 825         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 29          |\n",
      "|    total_timesteps    | 17063936    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018761111 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.94        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0569     |\n",
      "|    mean_step_reward   | 0.093129754 |\n",
      "|    n_updates          | 6.25 %      |\n",
      "|    policyGradLoss     | -0.0175     |\n",
      "|    value_loss         | 0.311       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 790         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 41          |\n",
      "|    total_timesteps    | 17072128    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022753645 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.921       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0231      |\n",
      "|    mean_step_reward   | 0.087050565 |\n",
      "|    n_updates          | 9.38 %      |\n",
      "|    policyGradLoss     | -0.0179     |\n",
      "|    value_loss         | 0.348       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 52          |\n",
      "|    total_timesteps    | 17080320    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02029702  |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.933       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0138      |\n",
      "|    mean_step_reward   | 0.099571615 |\n",
      "|    n_updates          | 12.50 %     |\n",
      "|    policyGradLoss     | -0.0189     |\n",
      "|    value_loss         | 0.284       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 64          |\n",
      "|    total_timesteps    | 17088512    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022193357 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.946       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.074       |\n",
      "|    mean_step_reward   | 0.09502821  |\n",
      "|    n_updates          | 15.62 %     |\n",
      "|    policyGradLoss     | -0.0175     |\n",
      "|    value_loss         | 0.435       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 764         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 74          |\n",
      "|    total_timesteps    | 17096704    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016834576 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.942       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0414      |\n",
      "|    mean_step_reward   | 0.111278415 |\n",
      "|    n_updates          | 18.75 %     |\n",
      "|    policyGradLoss     | -0.0145     |\n",
      "|    value_loss         | 0.375       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 761         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 86          |\n",
      "|    total_timesteps    | 17104896    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020445377 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.918       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0387     |\n",
      "|    mean_step_reward   | 0.10198429  |\n",
      "|    n_updates          | 21.88 %     |\n",
      "|    policyGradLoss     | -0.0166     |\n",
      "|    value_loss         | 0.348       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 760         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 96          |\n",
      "|    total_timesteps    | 17113088    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025471345 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.95        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0351     |\n",
      "|    mean_step_reward   | 0.096603155 |\n",
      "|    n_updates          | 25.00 %     |\n",
      "|    policyGradLoss     | -0.0163     |\n",
      "|    value_loss         | 0.265       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 757         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 108         |\n",
      "|    total_timesteps    | 17121280    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024741761 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.95        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00816    |\n",
      "|    mean_step_reward   | 0.10579561  |\n",
      "|    n_updates          | 28.12 %     |\n",
      "|    policyGradLoss     | -0.0161     |\n",
      "|    value_loss         | 0.321       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 753         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 119         |\n",
      "|    total_timesteps    | 17129472    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024769127 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.938       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0332     |\n",
      "|    mean_step_reward   | 0.10223747  |\n",
      "|    n_updates          | 31.25 %     |\n",
      "|    policyGradLoss     | -0.0179     |\n",
      "|    value_loss         | 0.288       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 749         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 131         |\n",
      "|    total_timesteps    | 17137664    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020175397 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.942       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00644     |\n",
      "|    mean_step_reward   | 0.10846408  |\n",
      "|    n_updates          | 34.38 %     |\n",
      "|    policyGradLoss     | -0.0154     |\n",
      "|    value_loss         | 0.426       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 748         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 142         |\n",
      "|    total_timesteps    | 17145856    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023388572 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.949       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0394     |\n",
      "|    mean_step_reward   | 0.10895881  |\n",
      "|    n_updates          | 37.50 %     |\n",
      "|    policyGradLoss     | -0.0191     |\n",
      "|    value_loss         | 0.267       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 747        |\n",
      "|    iterations         | 14         |\n",
      "|    time_elapsed       | 153        |\n",
      "|    total_timesteps    | 17154048   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01983647 |\n",
      "|    entropy_loss       | -1.88      |\n",
      "|    explained_variance | 0.942      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.0315     |\n",
      "|    mean_step_reward   | 0.0989639  |\n",
      "|    n_updates          | 40.62 %    |\n",
      "|    policyGradLoss     | -0.0174    |\n",
      "|    value_loss         | 0.291      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 747        |\n",
      "|    iterations         | 15         |\n",
      "|    time_elapsed       | 164        |\n",
      "|    total_timesteps    | 17162240   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02600193 |\n",
      "|    entropy_loss       | -1.84      |\n",
      "|    explained_variance | 0.955      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0293    |\n",
      "|    mean_step_reward   | 0.12037069 |\n",
      "|    n_updates          | 43.75 %    |\n",
      "|    policyGradLoss     | -0.0193    |\n",
      "|    value_loss         | 0.256      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 746         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 175         |\n",
      "|    total_timesteps    | 17170432    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021645568 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.919       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0693      |\n",
      "|    mean_step_reward   | 0.07323055  |\n",
      "|    n_updates          | 46.88 %     |\n",
      "|    policyGradLoss     | -0.0177     |\n",
      "|    value_loss         | 0.529       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 745        |\n",
      "|    iterations         | 17         |\n",
      "|    time_elapsed       | 186        |\n",
      "|    total_timesteps    | 17178624   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03004055 |\n",
      "|    entropy_loss       | -1.81      |\n",
      "|    explained_variance | 0.973      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0337    |\n",
      "|    mean_step_reward   | 0.13328397 |\n",
      "|    n_updates          | 50.00 %    |\n",
      "|    policyGradLoss     | -0.0178    |\n",
      "|    value_loss         | 0.253      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 743         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 198         |\n",
      "|    total_timesteps    | 17186816    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021205766 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.934       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0106     |\n",
      "|    mean_step_reward   | 0.086995706 |\n",
      "|    n_updates          | 53.12 %     |\n",
      "|    policyGradLoss     | -0.0184     |\n",
      "|    value_loss         | 0.397       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 740         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 210         |\n",
      "|    total_timesteps    | 17195008    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019760095 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.955       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0369      |\n",
      "|    mean_step_reward   | 0.11987713  |\n",
      "|    n_updates          | 56.25 %     |\n",
      "|    policyGradLoss     | -0.0162     |\n",
      "|    value_loss         | 0.333       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 739         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 221         |\n",
      "|    total_timesteps    | 17203200    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022776145 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.952       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0454      |\n",
      "|    mean_step_reward   | 0.10597578  |\n",
      "|    n_updates          | 59.38 %     |\n",
      "|    policyGradLoss     | -0.0186     |\n",
      "|    value_loss         | 0.268       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 740        |\n",
      "|    iterations         | 21         |\n",
      "|    time_elapsed       | 232        |\n",
      "|    total_timesteps    | 17211392   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.0219461  |\n",
      "|    entropy_loss       | -1.89      |\n",
      "|    explained_variance | 0.925      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0101    |\n",
      "|    mean_step_reward   | 0.09683288 |\n",
      "|    n_updates          | 62.50 %    |\n",
      "|    policyGradLoss     | -0.0145    |\n",
      "|    value_loss         | 0.347      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 745         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 241         |\n",
      "|    total_timesteps    | 17219584    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020988975 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.935       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0334     |\n",
      "|    mean_step_reward   | 0.09974229  |\n",
      "|    n_updates          | 65.62 %     |\n",
      "|    policyGradLoss     | -0.0184     |\n",
      "|    value_loss         | 0.302       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 751        |\n",
      "|    iterations         | 23         |\n",
      "|    time_elapsed       | 250        |\n",
      "|    total_timesteps    | 17227776   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02472686 |\n",
      "|    entropy_loss       | -1.89      |\n",
      "|    explained_variance | 0.932      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0324    |\n",
      "|    mean_step_reward   | 0.0980656  |\n",
      "|    n_updates          | 68.75 %    |\n",
      "|    policyGradLoss     | -0.0195    |\n",
      "|    value_loss         | 0.349      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 755        |\n",
      "|    iterations         | 24         |\n",
      "|    time_elapsed       | 260        |\n",
      "|    total_timesteps    | 17235968   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01972602 |\n",
      "|    entropy_loss       | -1.91      |\n",
      "|    explained_variance | 0.932      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0172    |\n",
      "|    mean_step_reward   | 0.08085933 |\n",
      "|    n_updates          | 71.88 %    |\n",
      "|    policyGradLoss     | -0.0192    |\n",
      "|    value_loss         | 0.299      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 755         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 270         |\n",
      "|    total_timesteps    | 17244160    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025775686 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.93        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00752    |\n",
      "|    mean_step_reward   | 0.08950508  |\n",
      "|    n_updates          | 75.00 %     |\n",
      "|    policyGradLoss     | -0.0215     |\n",
      "|    value_loss         | 0.314       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 754        |\n",
      "|    iterations         | 26         |\n",
      "|    time_elapsed       | 282        |\n",
      "|    total_timesteps    | 17252352   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02618101 |\n",
      "|    entropy_loss       | -1.87      |\n",
      "|    explained_variance | 0.937      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.00197   |\n",
      "|    mean_step_reward   | 0.08818247 |\n",
      "|    n_updates          | 78.12 %    |\n",
      "|    policyGradLoss     | -0.0173    |\n",
      "|    value_loss         | 0.297      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 753         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 293         |\n",
      "|    total_timesteps    | 17260544    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016142886 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.937       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0936      |\n",
      "|    mean_step_reward   | 0.118040115 |\n",
      "|    n_updates          | 81.25 %     |\n",
      "|    policyGradLoss     | -0.0141     |\n",
      "|    value_loss         | 0.382       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 751         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 305         |\n",
      "|    total_timesteps    | 17268736    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021843646 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.938       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0354      |\n",
      "|    mean_step_reward   | 0.08696892  |\n",
      "|    n_updates          | 84.38 %     |\n",
      "|    policyGradLoss     | -0.0203     |\n",
      "|    value_loss         | 0.332       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 750         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 316         |\n",
      "|    total_timesteps    | 17276928    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022010084 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.949       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0594      |\n",
      "|    mean_step_reward   | 0.11756678  |\n",
      "|    n_updates          | 87.50 %     |\n",
      "|    policyGradLoss     | -0.0176     |\n",
      "|    value_loss         | 0.387       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 749         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 327         |\n",
      "|    total_timesteps    | 17285120    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023249276 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.943       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.025      |\n",
      "|    mean_step_reward   | 0.09676266  |\n",
      "|    n_updates          | 90.62 %     |\n",
      "|    policyGradLoss     | -0.0196     |\n",
      "|    value_loss         | 0.263       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 749         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 338         |\n",
      "|    total_timesteps    | 17293312    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023849852 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.936       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0134     |\n",
      "|    mean_step_reward   | 0.097772226 |\n",
      "|    n_updates          | 93.75 %     |\n",
      "|    policyGradLoss     | -0.0201     |\n",
      "|    value_loss         | 0.261       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 749         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 349         |\n",
      "|    total_timesteps    | 17301504    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024317019 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.927       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0106      |\n",
      "|    mean_step_reward   | 0.08963821  |\n",
      "|    n_updates          | 96.88 %     |\n",
      "|    policyGradLoss     | -0.0226     |\n",
      "|    value_loss         | 0.254       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Run_65.zip\n",
      "[EVAL] Mean Return: 153.134, Best Return: 160.134\n",
      "Saved video to ./runs_smw/videos/Run/Run_65_153.13.mp4\n",
      "\n",
      "=== Round 67 | Learn 262144 steps (Total trained: 17301504) ===\n",
      "Logging to ./runs_smw/tb/Run_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1147     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 17309696 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 874         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 17317888    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022051994 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.944       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0175     |\n",
      "|    mean_step_reward   | 0.10033356  |\n",
      "|    n_updates          | 3.12 %      |\n",
      "|    policyGradLoss     | -0.02       |\n",
      "|    value_loss         | 0.286       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 810         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 30          |\n",
      "|    total_timesteps    | 17326080    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026392978 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.946       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0255     |\n",
      "|    mean_step_reward   | 0.10756606  |\n",
      "|    n_updates          | 6.25 %      |\n",
      "|    policyGradLoss     | -0.0199     |\n",
      "|    value_loss         | 0.274       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 41          |\n",
      "|    total_timesteps    | 17334272    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021378051 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.947       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0129     |\n",
      "|    mean_step_reward   | 0.10090791  |\n",
      "|    n_updates          | 9.38 %      |\n",
      "|    policyGradLoss     | -0.0185     |\n",
      "|    value_loss         | 0.31        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 52          |\n",
      "|    total_timesteps    | 17342464    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023271427 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.938       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00889    |\n",
      "|    mean_step_reward   | 0.091772586 |\n",
      "|    n_updates          | 12.50 %     |\n",
      "|    policyGradLoss     | -0.0201     |\n",
      "|    value_loss         | 0.323       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 63          |\n",
      "|    total_timesteps    | 17350656    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024317745 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.955       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0152     |\n",
      "|    mean_step_reward   | 0.10521067  |\n",
      "|    n_updates          | 15.62 %     |\n",
      "|    policyGradLoss     | -0.0235     |\n",
      "|    value_loss         | 0.255       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 764         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 75          |\n",
      "|    total_timesteps    | 17358848    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022910919 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.957       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0411     |\n",
      "|    mean_step_reward   | 0.112570494 |\n",
      "|    n_updates          | 18.75 %     |\n",
      "|    policyGradLoss     | -0.0187     |\n",
      "|    value_loss         | 0.237       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 757         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 86          |\n",
      "|    total_timesteps    | 17367040    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023238324 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0372     |\n",
      "|    mean_step_reward   | 0.1046072   |\n",
      "|    n_updates          | 21.88 %     |\n",
      "|    policyGradLoss     | -0.023      |\n",
      "|    value_loss         | 0.265       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 750         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 98          |\n",
      "|    total_timesteps    | 17375232    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025569255 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.951       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0689     |\n",
      "|    mean_step_reward   | 0.10064533  |\n",
      "|    n_updates          | 25.00 %     |\n",
      "|    policyGradLoss     | -0.0205     |\n",
      "|    value_loss         | 0.21        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 745         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 109         |\n",
      "|    total_timesteps    | 17383424    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018415466 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.943       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0387      |\n",
      "|    mean_step_reward   | 0.09929873  |\n",
      "|    n_updates          | 28.12 %     |\n",
      "|    policyGradLoss     | -0.0154     |\n",
      "|    value_loss         | 0.364       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 744         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 121         |\n",
      "|    total_timesteps    | 17391616    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018642355 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.947       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0166     |\n",
      "|    mean_step_reward   | 0.11107744  |\n",
      "|    n_updates          | 31.25 %     |\n",
      "|    policyGradLoss     | -0.0181     |\n",
      "|    value_loss         | 0.396       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 743         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 132         |\n",
      "|    total_timesteps    | 17399808    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020628672 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0557     |\n",
      "|    mean_step_reward   | 0.11145797  |\n",
      "|    n_updates          | 34.38 %     |\n",
      "|    policyGradLoss     | -0.0216     |\n",
      "|    value_loss         | 0.232       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 743        |\n",
      "|    iterations         | 13         |\n",
      "|    time_elapsed       | 143        |\n",
      "|    total_timesteps    | 17408000   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01759833 |\n",
      "|    entropy_loss       | -1.91      |\n",
      "|    explained_variance | 0.946      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.032      |\n",
      "|    mean_step_reward   | 0.10769093 |\n",
      "|    n_updates          | 37.50 %    |\n",
      "|    policyGradLoss     | -0.0201    |\n",
      "|    value_loss         | 0.325      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 743        |\n",
      "|    iterations         | 14         |\n",
      "|    time_elapsed       | 154        |\n",
      "|    total_timesteps    | 17416192   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02037951 |\n",
      "|    entropy_loss       | -1.88      |\n",
      "|    explained_variance | 0.944      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.0314     |\n",
      "|    mean_step_reward   | 0.08209881 |\n",
      "|    n_updates          | 40.62 %    |\n",
      "|    policyGradLoss     | -0.0196    |\n",
      "|    value_loss         | 0.33       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 743         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 165         |\n",
      "|    total_timesteps    | 17424384    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019846987 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.936       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0377     |\n",
      "|    mean_step_reward   | 0.107698105 |\n",
      "|    n_updates          | 43.75 %     |\n",
      "|    policyGradLoss     | -0.0184     |\n",
      "|    value_loss         | 0.361       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 741         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 176         |\n",
      "|    total_timesteps    | 17432576    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021503046 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.939       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0027     |\n",
      "|    mean_step_reward   | 0.073354006 |\n",
      "|    n_updates          | 46.88 %     |\n",
      "|    policyGradLoss     | -0.0193     |\n",
      "|    value_loss         | 0.353       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 739         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 188         |\n",
      "|    total_timesteps    | 17440768    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019060375 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.94        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0053     |\n",
      "|    mean_step_reward   | 0.09886381  |\n",
      "|    n_updates          | 50.00 %     |\n",
      "|    policyGradLoss     | -0.016      |\n",
      "|    value_loss         | 0.43        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 742         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 198         |\n",
      "|    total_timesteps    | 17448960    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019095885 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.924       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0102     |\n",
      "|    mean_step_reward   | 0.11045679  |\n",
      "|    n_updates          | 53.12 %     |\n",
      "|    policyGradLoss     | -0.0179     |\n",
      "|    value_loss         | 0.444       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 749         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 207         |\n",
      "|    total_timesteps    | 17457152    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017220322 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.926       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0238      |\n",
      "|    mean_step_reward   | 0.08772023  |\n",
      "|    n_updates          | 56.25 %     |\n",
      "|    policyGradLoss     | -0.0161     |\n",
      "|    value_loss         | 0.384       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 754         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 217         |\n",
      "|    total_timesteps    | 17465344    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021703314 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.95        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0367     |\n",
      "|    mean_step_reward   | 0.090108655 |\n",
      "|    n_updates          | 59.38 %     |\n",
      "|    policyGradLoss     | -0.0203     |\n",
      "|    value_loss         | 0.26        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 756        |\n",
      "|    iterations         | 21         |\n",
      "|    time_elapsed       | 227        |\n",
      "|    total_timesteps    | 17473536   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01676615 |\n",
      "|    entropy_loss       | -1.94      |\n",
      "|    explained_variance | 0.933      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0077    |\n",
      "|    mean_step_reward   | 0.07430911 |\n",
      "|    n_updates          | 62.50 %    |\n",
      "|    policyGradLoss     | -0.0153    |\n",
      "|    value_loss         | 0.391      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 754         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 238         |\n",
      "|    total_timesteps    | 17481728    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019116692 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0153      |\n",
      "|    mean_step_reward   | 0.1188328   |\n",
      "|    n_updates          | 65.62 %     |\n",
      "|    policyGradLoss     | -0.0182     |\n",
      "|    value_loss         | 0.302       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 754        |\n",
      "|    iterations         | 23         |\n",
      "|    time_elapsed       | 249        |\n",
      "|    total_timesteps    | 17489920   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01991734 |\n",
      "|    entropy_loss       | -1.88      |\n",
      "|    explained_variance | 0.947      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.00226    |\n",
      "|    mean_step_reward   | 0.08677896 |\n",
      "|    n_updates          | 68.75 %    |\n",
      "|    policyGradLoss     | -0.0192    |\n",
      "|    value_loss         | 0.287      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 753         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 260         |\n",
      "|    total_timesteps    | 17498112    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014189042 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.952       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.000145    |\n",
      "|    mean_step_reward   | 0.11878176  |\n",
      "|    n_updates          | 71.88 %     |\n",
      "|    policyGradLoss     | -0.0158     |\n",
      "|    value_loss         | 0.345       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 752         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 272         |\n",
      "|    total_timesteps    | 17506304    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018533222 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.929       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.023      |\n",
      "|    mean_step_reward   | 0.08151366  |\n",
      "|    n_updates          | 75.00 %     |\n",
      "|    policyGradLoss     | -0.0163     |\n",
      "|    value_loss         | 0.342       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 750         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 283         |\n",
      "|    total_timesteps    | 17514496    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014046031 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.93        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0851      |\n",
      "|    mean_step_reward   | 0.11554438  |\n",
      "|    n_updates          | 78.12 %     |\n",
      "|    policyGradLoss     | -0.0134     |\n",
      "|    value_loss         | 0.473       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 748         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 295         |\n",
      "|    total_timesteps    | 17522688    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025097417 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.954       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0345      |\n",
      "|    mean_step_reward   | 0.10860692  |\n",
      "|    n_updates          | 81.25 %     |\n",
      "|    policyGradLoss     | -0.0187     |\n",
      "|    value_loss         | 0.303       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 747        |\n",
      "|    iterations         | 28         |\n",
      "|    time_elapsed       | 306        |\n",
      "|    total_timesteps    | 17530880   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02092899 |\n",
      "|    entropy_loss       | -1.89      |\n",
      "|    explained_variance | 0.952      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.00247    |\n",
      "|    mean_step_reward   | 0.09873736 |\n",
      "|    n_updates          | 84.38 %    |\n",
      "|    policyGradLoss     | -0.0166    |\n",
      "|    value_loss         | 0.351      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 747         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 317         |\n",
      "|    total_timesteps    | 17539072    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019170346 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.955       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0442     |\n",
      "|    mean_step_reward   | 0.11703494  |\n",
      "|    n_updates          | 87.50 %     |\n",
      "|    policyGradLoss     | -0.0168     |\n",
      "|    value_loss         | 0.243       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 747         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 328         |\n",
      "|    total_timesteps    | 17547264    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019919371 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.948       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0518      |\n",
      "|    mean_step_reward   | 0.087699085 |\n",
      "|    n_updates          | 90.62 %     |\n",
      "|    policyGradLoss     | -0.0171     |\n",
      "|    value_loss         | 0.455       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 747         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 339         |\n",
      "|    total_timesteps    | 17555456    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015600772 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.943       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0376      |\n",
      "|    mean_step_reward   | 0.121202216 |\n",
      "|    n_updates          | 93.75 %     |\n",
      "|    policyGradLoss     | -0.0133     |\n",
      "|    value_loss         | 0.431       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 747         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 350         |\n",
      "|    total_timesteps    | 17563648    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016570881 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.946       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.027      |\n",
      "|    mean_step_reward   | 0.09064861  |\n",
      "|    n_updates          | 96.88 %     |\n",
      "|    policyGradLoss     | -0.0169     |\n",
      "|    value_loss         | 0.341       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Run_66.zip\n",
      "[EVAL] Mean Return: 151.392, Best Return: 158.392\n",
      "Saved video to ./runs_smw/videos/Run/Run_66_151.39.mp4\n",
      "\n",
      "=== Round 68 | Learn 262144 steps (Total trained: 17563648) ===\n",
      "Logging to ./runs_smw/tb/Run_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1073     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 17571840 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 856         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 19          |\n",
      "|    total_timesteps    | 17580032    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014710287 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.934       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0482      |\n",
      "|    mean_step_reward   | 0.11649507  |\n",
      "|    n_updates          | 3.12 %      |\n",
      "|    policyGradLoss     | -0.0121     |\n",
      "|    value_loss         | 0.353       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 819         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 30          |\n",
      "|    total_timesteps    | 17588224    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018758502 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.952       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0178     |\n",
      "|    mean_step_reward   | 0.11945134  |\n",
      "|    n_updates          | 6.25 %      |\n",
      "|    policyGradLoss     | -0.0154     |\n",
      "|    value_loss         | 0.258       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 794         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 41          |\n",
      "|    total_timesteps    | 17596416    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020028837 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.943       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0504      |\n",
      "|    mean_step_reward   | 0.113439836 |\n",
      "|    n_updates          | 9.38 %      |\n",
      "|    policyGradLoss     | -0.018      |\n",
      "|    value_loss         | 0.339       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 783        |\n",
      "|    iterations         | 5          |\n",
      "|    time_elapsed       | 52         |\n",
      "|    total_timesteps    | 17604608   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01668548 |\n",
      "|    entropy_loss       | -1.87      |\n",
      "|    explained_variance | 0.943      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.0306     |\n",
      "|    mean_step_reward   | 0.09784031 |\n",
      "|    n_updates          | 12.50 %    |\n",
      "|    policyGradLoss     | -0.0165    |\n",
      "|    value_loss         | 0.336      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 63          |\n",
      "|    total_timesteps    | 17612800    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019032195 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.927       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0475      |\n",
      "|    mean_step_reward   | 0.11295076  |\n",
      "|    n_updates          | 15.62 %     |\n",
      "|    policyGradLoss     | -0.0126     |\n",
      "|    value_loss         | 0.481       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 74          |\n",
      "|    total_timesteps    | 17620992    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020704392 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.939       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0537      |\n",
      "|    mean_step_reward   | 0.087152086 |\n",
      "|    n_updates          | 18.75 %     |\n",
      "|    policyGradLoss     | -0.018      |\n",
      "|    value_loss         | 0.278       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 760         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 86          |\n",
      "|    total_timesteps    | 17629184    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019567557 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.949       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00961     |\n",
      "|    mean_step_reward   | 0.109227985 |\n",
      "|    n_updates          | 21.88 %     |\n",
      "|    policyGradLoss     | -0.0183     |\n",
      "|    value_loss         | 0.395       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 755         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 97          |\n",
      "|    total_timesteps    | 17637376    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024175312 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.958       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0335      |\n",
      "|    mean_step_reward   | 0.10359147  |\n",
      "|    n_updates          | 25.00 %     |\n",
      "|    policyGradLoss     | -0.0185     |\n",
      "|    value_loss         | 0.249       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 752         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 108         |\n",
      "|    total_timesteps    | 17645568    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020674787 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.944       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0185     |\n",
      "|    mean_step_reward   | 0.10814702  |\n",
      "|    n_updates          | 28.12 %     |\n",
      "|    policyGradLoss     | -0.0173     |\n",
      "|    value_loss         | 0.345       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 750         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 120         |\n",
      "|    total_timesteps    | 17653760    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022257786 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.957       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.027      |\n",
      "|    mean_step_reward   | 0.10552961  |\n",
      "|    n_updates          | 31.25 %     |\n",
      "|    policyGradLoss     | -0.0186     |\n",
      "|    value_loss         | 0.227       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 749         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 131         |\n",
      "|    total_timesteps    | 17661952    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021196194 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0368     |\n",
      "|    mean_step_reward   | 0.10203891  |\n",
      "|    n_updates          | 34.38 %     |\n",
      "|    policyGradLoss     | -0.0198     |\n",
      "|    value_loss         | 0.222       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 748         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 142         |\n",
      "|    total_timesteps    | 17670144    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022199761 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.939       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0113      |\n",
      "|    mean_step_reward   | 0.10118451  |\n",
      "|    n_updates          | 37.50 %     |\n",
      "|    policyGradLoss     | -0.0164     |\n",
      "|    value_loss         | 0.343       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 753         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 152         |\n",
      "|    total_timesteps    | 17678336    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020696677 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.949       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0497      |\n",
      "|    mean_step_reward   | 0.08883608  |\n",
      "|    n_updates          | 40.62 %     |\n",
      "|    policyGradLoss     | -0.0175     |\n",
      "|    value_loss         | 0.39        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 762         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 161         |\n",
      "|    total_timesteps    | 17686528    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018802041 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.944       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0171     |\n",
      "|    mean_step_reward   | 0.10553643  |\n",
      "|    n_updates          | 43.75 %     |\n",
      "|    policyGradLoss     | -0.0151     |\n",
      "|    value_loss         | 0.284       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 170         |\n",
      "|    total_timesteps    | 17694720    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020226562 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.932       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0106      |\n",
      "|    mean_step_reward   | 0.08622956  |\n",
      "|    n_updates          | 46.88 %     |\n",
      "|    policyGradLoss     | -0.0179     |\n",
      "|    value_loss         | 0.413       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 180         |\n",
      "|    total_timesteps    | 17702912    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020431107 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.946       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0329     |\n",
      "|    mean_step_reward   | 0.095886245 |\n",
      "|    n_updates          | 50.00 %     |\n",
      "|    policyGradLoss     | -0.019      |\n",
      "|    value_loss         | 0.296       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 191         |\n",
      "|    total_timesteps    | 17711104    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029946562 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0675     |\n",
      "|    mean_step_reward   | 0.115173474 |\n",
      "|    n_updates          | 53.12 %     |\n",
      "|    policyGradLoss     | -0.0242     |\n",
      "|    value_loss         | 0.161       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 203         |\n",
      "|    total_timesteps    | 17719296    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019637216 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.941       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0296      |\n",
      "|    mean_step_reward   | 0.11473659  |\n",
      "|    n_updates          | 56.25 %     |\n",
      "|    policyGradLoss     | -0.0164     |\n",
      "|    value_loss         | 0.394       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 765         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 214         |\n",
      "|    total_timesteps    | 17727488    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022138547 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0174      |\n",
      "|    mean_step_reward   | 0.101255104 |\n",
      "|    n_updates          | 59.38 %     |\n",
      "|    policyGradLoss     | -0.0195     |\n",
      "|    value_loss         | 0.196       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 764        |\n",
      "|    iterations         | 21         |\n",
      "|    time_elapsed       | 225        |\n",
      "|    total_timesteps    | 17735680   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02264899 |\n",
      "|    entropy_loss       | -1.9       |\n",
      "|    explained_variance | 0.954      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.0471     |\n",
      "|    mean_step_reward   | 0.09177532 |\n",
      "|    n_updates          | 62.50 %    |\n",
      "|    policyGradLoss     | -0.0184    |\n",
      "|    value_loss         | 0.3        |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 762         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 236         |\n",
      "|    total_timesteps    | 17743872    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021513682 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0183      |\n",
      "|    mean_step_reward   | 0.10104678  |\n",
      "|    n_updates          | 65.62 %     |\n",
      "|    policyGradLoss     | -0.0137     |\n",
      "|    value_loss         | 0.25        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 759         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 247         |\n",
      "|    total_timesteps    | 17752064    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023775436 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.947       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00718    |\n",
      "|    mean_step_reward   | 0.10177298  |\n",
      "|    n_updates          | 68.75 %     |\n",
      "|    policyGradLoss     | -0.0141     |\n",
      "|    value_loss         | 0.253       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 756         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 259         |\n",
      "|    total_timesteps    | 17760256    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019593794 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.952       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.000285   |\n",
      "|    mean_step_reward   | 0.12207861  |\n",
      "|    n_updates          | 71.88 %     |\n",
      "|    policyGradLoss     | -0.0178     |\n",
      "|    value_loss         | 0.334       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 755         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 271         |\n",
      "|    total_timesteps    | 17768448    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023788773 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.015      |\n",
      "|    mean_step_reward   | 0.10702269  |\n",
      "|    n_updates          | 75.00 %     |\n",
      "|    policyGradLoss     | -0.0205     |\n",
      "|    value_loss         | 0.259       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 754         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 282         |\n",
      "|    total_timesteps    | 17776640    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022424102 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.945       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0291     |\n",
      "|    mean_step_reward   | 0.10620382  |\n",
      "|    n_updates          | 78.12 %     |\n",
      "|    policyGradLoss     | -0.0133     |\n",
      "|    value_loss         | 0.336       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 755         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 292         |\n",
      "|    total_timesteps    | 17784832    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022458494 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.95        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.011       |\n",
      "|    mean_step_reward   | 0.089611575 |\n",
      "|    n_updates          | 81.25 %     |\n",
      "|    policyGradLoss     | -0.0173     |\n",
      "|    value_loss         | 0.316       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 755         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 303         |\n",
      "|    total_timesteps    | 17793024    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02370122  |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0244      |\n",
      "|    mean_step_reward   | 0.110175274 |\n",
      "|    n_updates          | 84.38 %     |\n",
      "|    policyGradLoss     | -0.0172     |\n",
      "|    value_loss         | 0.301       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 754        |\n",
      "|    iterations         | 29         |\n",
      "|    time_elapsed       | 314        |\n",
      "|    total_timesteps    | 17801216   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02354908 |\n",
      "|    entropy_loss       | -1.87      |\n",
      "|    explained_variance | 0.96       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0197    |\n",
      "|    mean_step_reward   | 0.09783904 |\n",
      "|    n_updates          | 87.50 %    |\n",
      "|    policyGradLoss     | -0.0198    |\n",
      "|    value_loss         | 0.277      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 753         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 326         |\n",
      "|    total_timesteps    | 17809408    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021715213 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.917       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00601     |\n",
      "|    mean_step_reward   | 0.08661245  |\n",
      "|    n_updates          | 90.62 %     |\n",
      "|    policyGradLoss     | -0.014      |\n",
      "|    value_loss         | 0.419       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 751        |\n",
      "|    iterations         | 31         |\n",
      "|    time_elapsed       | 338        |\n",
      "|    total_timesteps    | 17817600   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02340913 |\n",
      "|    entropy_loss       | -1.9       |\n",
      "|    explained_variance | 0.941      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0496    |\n",
      "|    mean_step_reward   | 0.09368795 |\n",
      "|    n_updates          | 93.75 %    |\n",
      "|    policyGradLoss     | -0.0213    |\n",
      "|    value_loss         | 0.26       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 749         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 349         |\n",
      "|    total_timesteps    | 17825792    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019198045 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.944       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0136     |\n",
      "|    mean_step_reward   | 0.11424635  |\n",
      "|    n_updates          | 96.88 %     |\n",
      "|    policyGradLoss     | -0.0155     |\n",
      "|    value_loss         | 0.314       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Run_67.zip\n",
      "[EVAL] Mean Return: 144.909, Best Return: 152.242\n",
      "Saved video to ./runs_smw/videos/Run/Run_67_144.91.mp4\n",
      "\n",
      "=== Round 69 | Learn 262144 steps (Total trained: 17825792) ===\n",
      "Logging to ./runs_smw/tb/Run_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1169     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 17833984 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 914         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 17842176    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020849967 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.949       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0268     |\n",
      "|    mean_step_reward   | 0.12332735  |\n",
      "|    n_updates          | 3.12 %      |\n",
      "|    policyGradLoss     | -0.0164     |\n",
      "|    value_loss         | 0.382       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 841         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 29          |\n",
      "|    total_timesteps    | 17850368    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023931867 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00221    |\n",
      "|    mean_step_reward   | 0.09304316  |\n",
      "|    n_updates          | 6.25 %      |\n",
      "|    policyGradLoss     | -0.0174     |\n",
      "|    value_loss         | 0.258       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 806         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 40          |\n",
      "|    total_timesteps    | 17858560    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023779295 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.952       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0243     |\n",
      "|    mean_step_reward   | 0.10840559  |\n",
      "|    n_updates          | 9.38 %      |\n",
      "|    policyGradLoss     | -0.0186     |\n",
      "|    value_loss         | 0.309       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 52          |\n",
      "|    total_timesteps    | 17866752    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018888315 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.916       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0313      |\n",
      "|    mean_step_reward   | 0.098559335 |\n",
      "|    n_updates          | 12.50 %     |\n",
      "|    policyGradLoss     | -0.0135     |\n",
      "|    value_loss         | 0.414       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 63          |\n",
      "|    total_timesteps    | 17874944    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02470188  |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.951       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0203     |\n",
      "|    mean_step_reward   | 0.107328884 |\n",
      "|    n_updates          | 15.62 %     |\n",
      "|    policyGradLoss     | -0.0201     |\n",
      "|    value_loss         | 0.279       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 764         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 75          |\n",
      "|    total_timesteps    | 17883136    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021436471 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0538     |\n",
      "|    mean_step_reward   | 0.11460602  |\n",
      "|    n_updates          | 18.75 %     |\n",
      "|    policyGradLoss     | -0.0195     |\n",
      "|    value_loss         | 0.237       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 760         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 86          |\n",
      "|    total_timesteps    | 17891328    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021883233 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0194     |\n",
      "|    mean_step_reward   | 0.10140501  |\n",
      "|    n_updates          | 21.88 %     |\n",
      "|    policyGradLoss     | -0.0169     |\n",
      "|    value_loss         | 0.218       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 758         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 97          |\n",
      "|    total_timesteps    | 17899520    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021831734 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.957       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0287     |\n",
      "|    mean_step_reward   | 0.10066022  |\n",
      "|    n_updates          | 25.00 %     |\n",
      "|    policyGradLoss     | -0.02       |\n",
      "|    value_loss         | 0.259       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 763         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 107         |\n",
      "|    total_timesteps    | 17907712    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.0189485   |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0307     |\n",
      "|    mean_step_reward   | 0.109454304 |\n",
      "|    n_updates          | 28.12 %     |\n",
      "|    policyGradLoss     | -0.0151     |\n",
      "|    value_loss         | 0.245       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 116         |\n",
      "|    total_timesteps    | 17915904    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024235684 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.947       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0543     |\n",
      "|    mean_step_reward   | 0.08920945  |\n",
      "|    n_updates          | 31.25 %     |\n",
      "|    policyGradLoss     | -0.0163     |\n",
      "|    value_loss         | 0.264       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 125         |\n",
      "|    total_timesteps    | 17924096    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022574231 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.036      |\n",
      "|    mean_step_reward   | 0.10798727  |\n",
      "|    n_updates          | 34.38 %     |\n",
      "|    policyGradLoss     | -0.0157     |\n",
      "|    value_loss         | 0.266       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 135         |\n",
      "|    total_timesteps    | 17932288    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023582736 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.957       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0162     |\n",
      "|    mean_step_reward   | 0.09305079  |\n",
      "|    n_updates          | 37.50 %     |\n",
      "|    policyGradLoss     | -0.0184     |\n",
      "|    value_loss         | 0.25        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 147         |\n",
      "|    total_timesteps    | 17940480    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024412354 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.92        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00238    |\n",
      "|    mean_step_reward   | 0.08928594  |\n",
      "|    n_updates          | 40.62 %     |\n",
      "|    policyGradLoss     | -0.016      |\n",
      "|    value_loss         | 0.357       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 158         |\n",
      "|    total_timesteps    | 17948672    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02360554  |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0152      |\n",
      "|    mean_step_reward   | 0.102715045 |\n",
      "|    n_updates          | 43.75 %     |\n",
      "|    policyGradLoss     | -0.0194     |\n",
      "|    value_loss         | 0.279       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 169         |\n",
      "|    total_timesteps    | 17956864    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023535307 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.946       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0386     |\n",
      "|    mean_step_reward   | 0.115818076 |\n",
      "|    n_updates          | 46.88 %     |\n",
      "|    policyGradLoss     | -0.0159     |\n",
      "|    value_loss         | 0.266       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 180         |\n",
      "|    total_timesteps    | 17965056    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020459592 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.95        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0283     |\n",
      "|    mean_step_reward   | 0.11140508  |\n",
      "|    n_updates          | 50.00 %     |\n",
      "|    policyGradLoss     | -0.017      |\n",
      "|    value_loss         | 0.275       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 191         |\n",
      "|    total_timesteps    | 17973248    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019463606 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.033      |\n",
      "|    mean_step_reward   | 0.122019365 |\n",
      "|    n_updates          | 53.12 %     |\n",
      "|    policyGradLoss     | -0.013      |\n",
      "|    value_loss         | 0.285       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 202         |\n",
      "|    total_timesteps    | 17981440    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028542887 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.049      |\n",
      "|    mean_step_reward   | 0.11212837  |\n",
      "|    n_updates          | 56.25 %     |\n",
      "|    policyGradLoss     | -0.017      |\n",
      "|    value_loss         | 0.213       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 765         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 213         |\n",
      "|    total_timesteps    | 17989632    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022529092 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.943       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0562     |\n",
      "|    mean_step_reward   | 0.099225625 |\n",
      "|    n_updates          | 59.38 %     |\n",
      "|    policyGradLoss     | -0.0182     |\n",
      "|    value_loss         | 0.289       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 762         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 225         |\n",
      "|    total_timesteps    | 17997824    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023682948 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.948       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0474     |\n",
      "|    mean_step_reward   | 0.10921909  |\n",
      "|    n_updates          | 62.50 %     |\n",
      "|    policyGradLoss     | -0.0198     |\n",
      "|    value_loss         | 0.259       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 760        |\n",
      "|    iterations         | 22         |\n",
      "|    time_elapsed       | 236        |\n",
      "|    total_timesteps    | 18006016   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02132526 |\n",
      "|    entropy_loss       | -1.85      |\n",
      "|    explained_variance | 0.953      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.0119     |\n",
      "|    mean_step_reward   | 0.10646473 |\n",
      "|    n_updates          | 65.62 %    |\n",
      "|    policyGradLoss     | -0.0189    |\n",
      "|    value_loss         | 0.262      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 759         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 248         |\n",
      "|    total_timesteps    | 18014208    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019095115 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0156     |\n",
      "|    mean_step_reward   | 0.091424525 |\n",
      "|    n_updates          | 68.75 %     |\n",
      "|    policyGradLoss     | -0.016      |\n",
      "|    value_loss         | 0.29        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 758        |\n",
      "|    iterations         | 24         |\n",
      "|    time_elapsed       | 259        |\n",
      "|    total_timesteps    | 18022400   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02695186 |\n",
      "|    entropy_loss       | -1.86      |\n",
      "|    explained_variance | 0.973      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0176    |\n",
      "|    mean_step_reward   | 0.11968945 |\n",
      "|    n_updates          | 71.88 %    |\n",
      "|    policyGradLoss     | -0.018     |\n",
      "|    value_loss         | 0.225      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 758         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 270         |\n",
      "|    total_timesteps    | 18030592    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021029778 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.955       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0263     |\n",
      "|    mean_step_reward   | 0.096707195 |\n",
      "|    n_updates          | 75.00 %     |\n",
      "|    policyGradLoss     | -0.0175     |\n",
      "|    value_loss         | 0.263       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 757         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 281         |\n",
      "|    total_timesteps    | 18038784    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021255536 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0677      |\n",
      "|    mean_step_reward   | 0.11068241  |\n",
      "|    n_updates          | 78.12 %     |\n",
      "|    policyGradLoss     | -0.0171     |\n",
      "|    value_loss         | 0.282       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 756         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 292         |\n",
      "|    total_timesteps    | 18046976    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018131282 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.946       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0406     |\n",
      "|    mean_step_reward   | 0.10312914  |\n",
      "|    n_updates          | 81.25 %     |\n",
      "|    policyGradLoss     | -0.016      |\n",
      "|    value_loss         | 0.233       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 754         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 304         |\n",
      "|    total_timesteps    | 18055168    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028825812 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0422     |\n",
      "|    mean_step_reward   | 0.13381864  |\n",
      "|    n_updates          | 84.38 %     |\n",
      "|    policyGradLoss     | -0.0182     |\n",
      "|    value_loss         | 0.193       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 752         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 315         |\n",
      "|    total_timesteps    | 18063360    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022041768 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.948       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0282     |\n",
      "|    mean_step_reward   | 0.10042525  |\n",
      "|    n_updates          | 87.50 %     |\n",
      "|    policyGradLoss     | -0.0177     |\n",
      "|    value_loss         | 0.299       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 751         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 327         |\n",
      "|    total_timesteps    | 18071552    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018980222 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0112      |\n",
      "|    mean_step_reward   | 0.10705922  |\n",
      "|    n_updates          | 90.62 %     |\n",
      "|    policyGradLoss     | -0.0174     |\n",
      "|    value_loss         | 0.332       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 751         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 338         |\n",
      "|    total_timesteps    | 18079744    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025327345 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0533     |\n",
      "|    mean_step_reward   | 0.12168181  |\n",
      "|    n_updates          | 93.75 %     |\n",
      "|    policyGradLoss     | -0.0189     |\n",
      "|    value_loss         | 0.191       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 750         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 349         |\n",
      "|    total_timesteps    | 18087936    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023201814 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.946       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0194     |\n",
      "|    mean_step_reward   | 0.08720088  |\n",
      "|    n_updates          | 96.88 %     |\n",
      "|    policyGradLoss     | -0.0179     |\n",
      "|    value_loss         | 0.245       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Run_68.zip\n",
      "[EVAL] Mean Return: 140.062, Best Return: 147.562\n",
      "Saved video to ./runs_smw/videos/Run/Run_68_140.06.mp4\n",
      "\n",
      "=== Round 70 | Learn 262144 steps (Total trained: 18087936) ===\n",
      "Logging to ./runs_smw/tb/Run_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1137     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 18096128 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 876         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 18104320    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020916387 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.943       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.106       |\n",
      "|    mean_step_reward   | 0.08723491  |\n",
      "|    n_updates          | 3.12 %      |\n",
      "|    policyGradLoss     | -0.0142     |\n",
      "|    value_loss         | 0.331       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 810         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 30          |\n",
      "|    total_timesteps    | 18112512    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020250523 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.047       |\n",
      "|    mean_step_reward   | 0.12243489  |\n",
      "|    n_updates          | 6.25 %      |\n",
      "|    policyGradLoss     | -0.0155     |\n",
      "|    value_loss         | 0.385       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 41          |\n",
      "|    total_timesteps    | 18120704    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.0274835   |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.951       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0671     |\n",
      "|    mean_step_reward   | 0.099759236 |\n",
      "|    n_updates          | 9.38 %      |\n",
      "|    policyGradLoss     | -0.0207     |\n",
      "|    value_loss         | 0.206       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 52          |\n",
      "|    total_timesteps    | 18128896    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019925702 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.945       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0393      |\n",
      "|    mean_step_reward   | 0.08440326  |\n",
      "|    n_updates          | 12.50 %     |\n",
      "|    policyGradLoss     | -0.0135     |\n",
      "|    value_loss         | 0.41        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 772        |\n",
      "|    iterations         | 6          |\n",
      "|    time_elapsed       | 63         |\n",
      "|    total_timesteps    | 18137088   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02150747 |\n",
      "|    entropy_loss       | -1.84      |\n",
      "|    explained_variance | 0.963      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0264    |\n",
      "|    mean_step_reward   | 0.12228563 |\n",
      "|    n_updates          | 15.62 %    |\n",
      "|    policyGradLoss     | -0.0169    |\n",
      "|    value_loss         | 0.298      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 789         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 72          |\n",
      "|    total_timesteps    | 18145280    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021041218 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.955       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0302     |\n",
      "|    mean_step_reward   | 0.095776536 |\n",
      "|    n_updates          | 18.75 %     |\n",
      "|    policyGradLoss     | -0.0174     |\n",
      "|    value_loss         | 0.285       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 799         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 81          |\n",
      "|    total_timesteps    | 18153472    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020729378 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0104      |\n",
      "|    mean_step_reward   | 0.12800282  |\n",
      "|    n_updates          | 21.88 %     |\n",
      "|    policyGradLoss     | -0.0176     |\n",
      "|    value_loss         | 0.278       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 804         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 91          |\n",
      "|    total_timesteps    | 18161664    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020688713 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.937       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0143     |\n",
      "|    mean_step_reward   | 0.09593396  |\n",
      "|    n_updates          | 25.00 %     |\n",
      "|    policyGradLoss     | -0.0189     |\n",
      "|    value_loss         | 0.333       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 799         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 102         |\n",
      "|    total_timesteps    | 18169856    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022267535 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.928       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0463      |\n",
      "|    mean_step_reward   | 0.09980491  |\n",
      "|    n_updates          | 28.12 %     |\n",
      "|    policyGradLoss     | -0.0185     |\n",
      "|    value_loss         | 0.351       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 790        |\n",
      "|    iterations         | 11         |\n",
      "|    time_elapsed       | 114        |\n",
      "|    total_timesteps    | 18178048   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02454083 |\n",
      "|    entropy_loss       | -1.94      |\n",
      "|    explained_variance | 0.951      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0664    |\n",
      "|    mean_step_reward   | 0.09231579 |\n",
      "|    n_updates          | 31.25 %    |\n",
      "|    policyGradLoss     | -0.0205    |\n",
      "|    value_loss         | 0.223      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 125         |\n",
      "|    total_timesteps    | 18186240    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024721816 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00304     |\n",
      "|    mean_step_reward   | 0.105726674 |\n",
      "|    n_updates          | 34.38 %     |\n",
      "|    policyGradLoss     | -0.0203     |\n",
      "|    value_loss         | 0.253       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 776        |\n",
      "|    iterations         | 13         |\n",
      "|    time_elapsed       | 137        |\n",
      "|    total_timesteps    | 18194432   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01927725 |\n",
      "|    entropy_loss       | -1.85      |\n",
      "|    explained_variance | 0.935      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.0184     |\n",
      "|    mean_step_reward   | 0.10735066 |\n",
      "|    n_updates          | 37.50 %    |\n",
      "|    policyGradLoss     | -0.0171    |\n",
      "|    value_loss         | 0.406      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 148         |\n",
      "|    total_timesteps    | 18202624    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022466999 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.925       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0461      |\n",
      "|    mean_step_reward   | 0.0979303   |\n",
      "|    n_updates          | 40.62 %     |\n",
      "|    policyGradLoss     | -0.0189     |\n",
      "|    value_loss         | 0.419       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 771        |\n",
      "|    iterations         | 15         |\n",
      "|    time_elapsed       | 159        |\n",
      "|    total_timesteps    | 18210816   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02364361 |\n",
      "|    entropy_loss       | -1.87      |\n",
      "|    explained_variance | 0.94       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.00528   |\n",
      "|    mean_step_reward   | 0.09327398 |\n",
      "|    n_updates          | 43.75 %    |\n",
      "|    policyGradLoss     | -0.0198    |\n",
      "|    value_loss         | 0.356      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 170         |\n",
      "|    total_timesteps    | 18219008    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023044238 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.941       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0202     |\n",
      "|    mean_step_reward   | 0.09384978  |\n",
      "|    n_updates          | 46.88 %     |\n",
      "|    policyGradLoss     | -0.02       |\n",
      "|    value_loss         | 0.373       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 181         |\n",
      "|    total_timesteps    | 18227200    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026018415 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.949       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0153     |\n",
      "|    mean_step_reward   | 0.099592075 |\n",
      "|    n_updates          | 50.00 %     |\n",
      "|    policyGradLoss     | -0.0194     |\n",
      "|    value_loss         | 0.305       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 763         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 193         |\n",
      "|    total_timesteps    | 18235392    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021522986 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.955       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0464      |\n",
      "|    mean_step_reward   | 0.10669996  |\n",
      "|    n_updates          | 53.12 %     |\n",
      "|    policyGradLoss     | -0.0196     |\n",
      "|    value_loss         | 0.296       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 759         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 204         |\n",
      "|    total_timesteps    | 18243584    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026293535 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0111     |\n",
      "|    mean_step_reward   | 0.114301644 |\n",
      "|    n_updates          | 56.25 %     |\n",
      "|    policyGradLoss     | -0.0202     |\n",
      "|    value_loss         | 0.22        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 757         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 216         |\n",
      "|    total_timesteps    | 18251776    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027472094 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.958       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0473     |\n",
      "|    mean_step_reward   | 0.11112318  |\n",
      "|    n_updates          | 59.38 %     |\n",
      "|    policyGradLoss     | -0.0182     |\n",
      "|    value_loss         | 0.24        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 756         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 227         |\n",
      "|    total_timesteps    | 18259968    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023617685 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.95        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0433     |\n",
      "|    mean_step_reward   | 0.09712276  |\n",
      "|    n_updates          | 62.50 %     |\n",
      "|    policyGradLoss     | -0.0179     |\n",
      "|    value_loss         | 0.24        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 755         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 238         |\n",
      "|    total_timesteps    | 18268160    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024318311 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.957       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0511      |\n",
      "|    mean_step_reward   | 0.11193539  |\n",
      "|    n_updates          | 65.62 %     |\n",
      "|    policyGradLoss     | -0.0176     |\n",
      "|    value_loss         | 0.254       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 755         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 249         |\n",
      "|    total_timesteps    | 18276352    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022358598 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0221     |\n",
      "|    mean_step_reward   | 0.10276723  |\n",
      "|    n_updates          | 68.75 %     |\n",
      "|    policyGradLoss     | -0.0184     |\n",
      "|    value_loss         | 0.254       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 754         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 260         |\n",
      "|    total_timesteps    | 18284544    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024063524 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.957       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.04       |\n",
      "|    mean_step_reward   | 0.11387348  |\n",
      "|    n_updates          | 71.88 %     |\n",
      "|    policyGradLoss     | -0.0204     |\n",
      "|    value_loss         | 0.28        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 753         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 271         |\n",
      "|    total_timesteps    | 18292736    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024940958 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.951       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.018      |\n",
      "|    mean_step_reward   | 0.104978666 |\n",
      "|    n_updates          | 75.00 %     |\n",
      "|    policyGradLoss     | -0.0206     |\n",
      "|    value_loss         | 0.293       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 751         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 283         |\n",
      "|    total_timesteps    | 18300928    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025508119 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0235     |\n",
      "|    mean_step_reward   | 0.118937895 |\n",
      "|    n_updates          | 78.12 %     |\n",
      "|    policyGradLoss     | -0.0194     |\n",
      "|    value_loss         | 0.305       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 749         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 295         |\n",
      "|    total_timesteps    | 18309120    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024018824 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.946       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0416     |\n",
      "|    mean_step_reward   | 0.090319455 |\n",
      "|    n_updates          | 81.25 %     |\n",
      "|    policyGradLoss     | -0.0136     |\n",
      "|    value_loss         | 0.283       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 749         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 306         |\n",
      "|    total_timesteps    | 18317312    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016911652 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.949       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0505      |\n",
      "|    mean_step_reward   | 0.11708173  |\n",
      "|    n_updates          | 84.38 %     |\n",
      "|    policyGradLoss     | -0.014      |\n",
      "|    value_loss         | 0.367       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 749        |\n",
      "|    iterations         | 29         |\n",
      "|    time_elapsed       | 317        |\n",
      "|    total_timesteps    | 18325504   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02517841 |\n",
      "|    entropy_loss       | -1.88      |\n",
      "|    explained_variance | 0.935      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0136    |\n",
      "|    mean_step_reward   | 0.10112265 |\n",
      "|    n_updates          | 87.50 %    |\n",
      "|    policyGradLoss     | -0.0146    |\n",
      "|    value_loss         | 0.294      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 748         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 328         |\n",
      "|    total_timesteps    | 18333696    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025814865 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0707     |\n",
      "|    mean_step_reward   | 0.12534638  |\n",
      "|    n_updates          | 90.62 %     |\n",
      "|    policyGradLoss     | -0.0203     |\n",
      "|    value_loss         | 0.162       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 748         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 339         |\n",
      "|    total_timesteps    | 18341888    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019973941 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.939       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0353      |\n",
      "|    mean_step_reward   | 0.11461031  |\n",
      "|    n_updates          | 93.75 %     |\n",
      "|    policyGradLoss     | -0.0128     |\n",
      "|    value_loss         | 0.359       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 747         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 350         |\n",
      "|    total_timesteps    | 18350080    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016017357 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.937       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0119     |\n",
      "|    mean_step_reward   | 0.10975212  |\n",
      "|    n_updates          | 96.88 %     |\n",
      "|    policyGradLoss     | -0.0148     |\n",
      "|    value_loss         | 0.337       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Run_69.zip\n",
      "[EVAL] Mean Return: 146.236, Best Return: 152.570\n",
      "Saved video to ./runs_smw/videos/Run/Run_69_146.24.mp4\n",
      "\n",
      "=== Round 71 | Learn 262144 steps (Total trained: 18350080) ===\n",
      "Logging to ./runs_smw/tb/Run_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1096     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 18358272 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 873         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 18366464    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020652438 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0145     |\n",
      "|    mean_step_reward   | 0.114677906 |\n",
      "|    n_updates          | 3.12 %      |\n",
      "|    policyGradLoss     | -0.0155     |\n",
      "|    value_loss         | 0.26        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 880         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 27          |\n",
      "|    total_timesteps    | 18374656    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020061024 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.947       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00888     |\n",
      "|    mean_step_reward   | 0.09481748  |\n",
      "|    n_updates          | 6.25 %      |\n",
      "|    policyGradLoss     | -0.0167     |\n",
      "|    value_loss         | 0.331       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 878        |\n",
      "|    iterations         | 4          |\n",
      "|    time_elapsed       | 37         |\n",
      "|    total_timesteps    | 18382848   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02079264 |\n",
      "|    entropy_loss       | -1.85      |\n",
      "|    explained_variance | 0.95       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.0157     |\n",
      "|    mean_step_reward   | 0.10775128 |\n",
      "|    n_updates          | 9.38 %     |\n",
      "|    policyGradLoss     | -0.0164    |\n",
      "|    value_loss         | 0.355      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 876         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 46          |\n",
      "|    total_timesteps    | 18391040    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026643548 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.945       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0263     |\n",
      "|    mean_step_reward   | 0.115758    |\n",
      "|    n_updates          | 12.50 %     |\n",
      "|    policyGradLoss     | -0.0193     |\n",
      "|    value_loss         | 0.336       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 856         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 57          |\n",
      "|    total_timesteps    | 18399232    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017565738 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.941       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0516     |\n",
      "|    mean_step_reward   | 0.10311121  |\n",
      "|    n_updates          | 15.62 %     |\n",
      "|    policyGradLoss     | -0.0146     |\n",
      "|    value_loss         | 0.241       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 841        |\n",
      "|    iterations         | 7          |\n",
      "|    time_elapsed       | 68         |\n",
      "|    total_timesteps    | 18407424   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02126237 |\n",
      "|    entropy_loss       | -1.87      |\n",
      "|    explained_variance | 0.937      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.0324     |\n",
      "|    mean_step_reward   | 0.09812704 |\n",
      "|    n_updates          | 18.75 %    |\n",
      "|    policyGradLoss     | -0.0153    |\n",
      "|    value_loss         | 0.331      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 826         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 79          |\n",
      "|    total_timesteps    | 18415616    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022075437 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.946       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0134     |\n",
      "|    mean_step_reward   | 0.108060405 |\n",
      "|    n_updates          | 21.88 %     |\n",
      "|    policyGradLoss     | -0.0188     |\n",
      "|    value_loss         | 0.311       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 90          |\n",
      "|    total_timesteps    | 18423808    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021889327 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.919       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0104     |\n",
      "|    mean_step_reward   | 0.09133068  |\n",
      "|    n_updates          | 25.00 %     |\n",
      "|    policyGradLoss     | -0.017      |\n",
      "|    value_loss         | 0.367       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 800         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 102         |\n",
      "|    total_timesteps    | 18432000    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017343247 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.929       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0935      |\n",
      "|    mean_step_reward   | 0.123774484 |\n",
      "|    n_updates          | 28.12 %     |\n",
      "|    policyGradLoss     | -0.0159     |\n",
      "|    value_loss         | 0.48        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 792         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 113         |\n",
      "|    total_timesteps    | 18440192    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023157712 |\n",
      "|    entropy_loss       | -1.97       |\n",
      "|    explained_variance | 0.952       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.052      |\n",
      "|    mean_step_reward   | 0.08487194  |\n",
      "|    n_updates          | 31.25 %     |\n",
      "|    policyGradLoss     | -0.0192     |\n",
      "|    value_loss         | 0.207       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 787        |\n",
      "|    iterations         | 12         |\n",
      "|    time_elapsed       | 124        |\n",
      "|    total_timesteps    | 18448384   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02080203 |\n",
      "|    entropy_loss       | -1.98      |\n",
      "|    explained_variance | 0.952      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0544    |\n",
      "|    mean_step_reward   | 0.07934752 |\n",
      "|    n_updates          | 34.38 %    |\n",
      "|    policyGradLoss     | -0.0169    |\n",
      "|    value_loss         | 0.228      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 136         |\n",
      "|    total_timesteps    | 18456576    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019664003 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.946       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0256     |\n",
      "|    mean_step_reward   | 0.09703565  |\n",
      "|    n_updates          | 37.50 %     |\n",
      "|    policyGradLoss     | -0.0155     |\n",
      "|    value_loss         | 0.253       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 147         |\n",
      "|    total_timesteps    | 18464768    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020466333 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.923       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 4.45e-05    |\n",
      "|    mean_step_reward   | 0.07763857  |\n",
      "|    n_updates          | 40.62 %     |\n",
      "|    policyGradLoss     | -0.0154     |\n",
      "|    value_loss         | 0.323       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 158         |\n",
      "|    total_timesteps    | 18472960    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020569488 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.952       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00962    |\n",
      "|    mean_step_reward   | 0.109277576 |\n",
      "|    n_updates          | 43.75 %     |\n",
      "|    policyGradLoss     | -0.0169     |\n",
      "|    value_loss         | 0.34        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 169         |\n",
      "|    total_timesteps    | 18481152    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016151149 |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.937       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0253      |\n",
      "|    mean_step_reward   | 0.08075603  |\n",
      "|    n_updates          | 46.88 %     |\n",
      "|    policyGradLoss     | -0.00929    |\n",
      "|    value_loss         | 0.339       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 181         |\n",
      "|    total_timesteps    | 18489344    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019978099 |\n",
      "|    entropy_loss       | -1.97       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0392     |\n",
      "|    mean_step_reward   | 0.09303621  |\n",
      "|    n_updates          | 50.00 %     |\n",
      "|    policyGradLoss     | -0.0159     |\n",
      "|    value_loss         | 0.241       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 764         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 192         |\n",
      "|    total_timesteps    | 18497536    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023106247 |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0688     |\n",
      "|    mean_step_reward   | 0.08324279  |\n",
      "|    n_updates          | 53.12 %     |\n",
      "|    policyGradLoss     | -0.0191     |\n",
      "|    value_loss         | 0.177       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 762        |\n",
      "|    iterations         | 19         |\n",
      "|    time_elapsed       | 204        |\n",
      "|    total_timesteps    | 18505728   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02244725 |\n",
      "|    entropy_loss       | -1.95      |\n",
      "|    explained_variance | 0.922      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0255    |\n",
      "|    mean_step_reward   | 0.06749043 |\n",
      "|    n_updates          | 56.25 %    |\n",
      "|    policyGradLoss     | -0.0156    |\n",
      "|    value_loss         | 0.338      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 762         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 214         |\n",
      "|    total_timesteps    | 18513920    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022355435 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0222     |\n",
      "|    mean_step_reward   | 0.109275386 |\n",
      "|    n_updates          | 59.38 %     |\n",
      "|    policyGradLoss     | -0.015      |\n",
      "|    value_loss         | 0.24        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 761         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 225         |\n",
      "|    total_timesteps    | 18522112    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023104249 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.041      |\n",
      "|    mean_step_reward   | 0.09120022  |\n",
      "|    n_updates          | 62.50 %     |\n",
      "|    policyGradLoss     | -0.0177     |\n",
      "|    value_loss         | 0.236       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 760         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 236         |\n",
      "|    total_timesteps    | 18530304    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023373635 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0342     |\n",
      "|    mean_step_reward   | 0.13296035  |\n",
      "|    n_updates          | 65.62 %     |\n",
      "|    policyGradLoss     | -0.0163     |\n",
      "|    value_loss         | 0.203       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 759         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 248         |\n",
      "|    total_timesteps    | 18538496    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022304421 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.954       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0048     |\n",
      "|    mean_step_reward   | 0.11002137  |\n",
      "|    n_updates          | 68.75 %     |\n",
      "|    policyGradLoss     | -0.0162     |\n",
      "|    value_loss         | 0.214       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 757         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 259         |\n",
      "|    total_timesteps    | 18546688    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017019644 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.952       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.12        |\n",
      "|    mean_step_reward   | 0.10132711  |\n",
      "|    n_updates          | 71.88 %     |\n",
      "|    policyGradLoss     | -0.0143     |\n",
      "|    value_loss         | 0.242       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 755        |\n",
      "|    iterations         | 25         |\n",
      "|    time_elapsed       | 271        |\n",
      "|    total_timesteps    | 18554880   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01919101 |\n",
      "|    entropy_loss       | -1.79      |\n",
      "|    explained_variance | 0.958      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0243    |\n",
      "|    mean_step_reward   | 0.13055463 |\n",
      "|    n_updates          | 75.00 %    |\n",
      "|    policyGradLoss     | -0.0159    |\n",
      "|    value_loss         | 0.252      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 754        |\n",
      "|    iterations         | 26         |\n",
      "|    time_elapsed       | 282        |\n",
      "|    total_timesteps    | 18563072   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.017501   |\n",
      "|    entropy_loss       | -1.92      |\n",
      "|    explained_variance | 0.917      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0331    |\n",
      "|    mean_step_reward   | 0.08760073 |\n",
      "|    n_updates          | 78.12 %    |\n",
      "|    policyGradLoss     | -0.0111    |\n",
      "|    value_loss         | 0.383      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 753        |\n",
      "|    iterations         | 27         |\n",
      "|    time_elapsed       | 293        |\n",
      "|    total_timesteps    | 18571264   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02255835 |\n",
      "|    entropy_loss       | -1.81      |\n",
      "|    explained_variance | 0.941      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.00295    |\n",
      "|    mean_step_reward   | 0.14193161 |\n",
      "|    n_updates          | 81.25 %    |\n",
      "|    policyGradLoss     | -0.0116    |\n",
      "|    value_loss         | 0.369      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 753        |\n",
      "|    iterations         | 28         |\n",
      "|    time_elapsed       | 304        |\n",
      "|    total_timesteps    | 18579456   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02015889 |\n",
      "|    entropy_loss       | -1.92      |\n",
      "|    explained_variance | 0.914      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.0441     |\n",
      "|    mean_step_reward   | 0.0775138  |\n",
      "|    n_updates          | 84.38 %    |\n",
      "|    policyGradLoss     | -0.0133    |\n",
      "|    value_loss         | 0.437      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 753         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 315         |\n",
      "|    total_timesteps    | 18587648    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020378608 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0451      |\n",
      "|    mean_step_reward   | 0.13007206  |\n",
      "|    n_updates          | 87.50 %     |\n",
      "|    policyGradLoss     | -0.0192     |\n",
      "|    value_loss         | 0.3         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 752         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 326         |\n",
      "|    total_timesteps    | 18595840    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022504546 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.947       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0258     |\n",
      "|    mean_step_reward   | 0.09432439  |\n",
      "|    n_updates          | 90.62 %     |\n",
      "|    policyGradLoss     | -0.0157     |\n",
      "|    value_loss         | 0.247       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 751         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 338         |\n",
      "|    total_timesteps    | 18604032    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028911166 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0189      |\n",
      "|    mean_step_reward   | 0.123811014 |\n",
      "|    n_updates          | 93.75 %     |\n",
      "|    policyGradLoss     | -0.02       |\n",
      "|    value_loss         | 0.23        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 749         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 349         |\n",
      "|    total_timesteps    | 18612224    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021893863 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.952       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.119       |\n",
      "|    mean_step_reward   | 0.105918564 |\n",
      "|    n_updates          | 96.88 %     |\n",
      "|    policyGradLoss     | -0.0185     |\n",
      "|    value_loss         | 0.33        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Run_70.zip\n",
      "[EVAL] Mean Return: 151.463, Best Return: 158.463\n",
      "Saved video to ./runs_smw/videos/Run/Run_70_151.46.mp4\n",
      "\n",
      "=== Round 72 | Learn 262144 steps (Total trained: 18612224) ===\n",
      "Logging to ./runs_smw/tb/Run_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1488     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 18620416 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 1112        |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 14          |\n",
      "|    total_timesteps    | 18628608    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022071071 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.949       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0389     |\n",
      "|    mean_step_reward   | 0.10720885  |\n",
      "|    n_updates          | 3.12 %      |\n",
      "|    policyGradLoss     | -0.0195     |\n",
      "|    value_loss         | 0.273       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 961        |\n",
      "|    iterations         | 3          |\n",
      "|    time_elapsed       | 25         |\n",
      "|    total_timesteps    | 18636800   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02374591 |\n",
      "|    entropy_loss       | -1.87      |\n",
      "|    explained_variance | 0.97       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0588    |\n",
      "|    mean_step_reward   | 0.1061288  |\n",
      "|    n_updates          | 6.25 %     |\n",
      "|    policyGradLoss     | -0.0193    |\n",
      "|    value_loss         | 0.157      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 884        |\n",
      "|    iterations         | 4          |\n",
      "|    time_elapsed       | 37         |\n",
      "|    total_timesteps    | 18644992   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02111272 |\n",
      "|    entropy_loss       | -1.85      |\n",
      "|    explained_variance | 0.947      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.047     |\n",
      "|    mean_step_reward   | 0.10713998 |\n",
      "|    n_updates          | 9.38 %     |\n",
      "|    policyGradLoss     | -0.0178    |\n",
      "|    value_loss         | 0.312      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 848         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 48          |\n",
      "|    total_timesteps    | 18653184    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022398338 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0229     |\n",
      "|    mean_step_reward   | 0.11513966  |\n",
      "|    n_updates          | 12.50 %     |\n",
      "|    policyGradLoss     | -0.0189     |\n",
      "|    value_loss         | 0.222       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 828         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 59          |\n",
      "|    total_timesteps    | 18661376    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023837265 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.946       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0513     |\n",
      "|    mean_step_reward   | 0.102555335 |\n",
      "|    n_updates          | 15.62 %     |\n",
      "|    policyGradLoss     | -0.0195     |\n",
      "|    value_loss         | 0.278       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 816         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 70          |\n",
      "|    total_timesteps    | 18669568    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019426275 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0211     |\n",
      "|    mean_step_reward   | 0.10517812  |\n",
      "|    n_updates          | 18.75 %     |\n",
      "|    policyGradLoss     | -0.0158     |\n",
      "|    value_loss         | 0.259       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 803        |\n",
      "|    iterations         | 8          |\n",
      "|    time_elapsed       | 81         |\n",
      "|    total_timesteps    | 18677760   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.0308881  |\n",
      "|    entropy_loss       | -1.86      |\n",
      "|    explained_variance | 0.957      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0417    |\n",
      "|    mean_step_reward   | 0.11256797 |\n",
      "|    n_updates          | 21.88 %    |\n",
      "|    policyGradLoss     | -0.0218    |\n",
      "|    value_loss         | 0.242      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 791         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 93          |\n",
      "|    total_timesteps    | 18685952    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022731321 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.942       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0128      |\n",
      "|    mean_step_reward   | 0.0890134   |\n",
      "|    n_updates          | 25.00 %     |\n",
      "|    policyGradLoss     | -0.0187     |\n",
      "|    value_loss         | 0.265       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 104         |\n",
      "|    total_timesteps    | 18694144    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018004324 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.951       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0256     |\n",
      "|    mean_step_reward   | 0.120456986 |\n",
      "|    n_updates          | 28.12 %     |\n",
      "|    policyGradLoss     | -0.0163     |\n",
      "|    value_loss         | 0.295       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 116         |\n",
      "|    total_timesteps    | 18702336    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024139479 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0681     |\n",
      "|    mean_step_reward   | 0.0933721   |\n",
      "|    n_updates          | 31.25 %     |\n",
      "|    policyGradLoss     | -0.0222     |\n",
      "|    value_loss         | 0.189       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 127         |\n",
      "|    total_timesteps    | 18710528    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025504544 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.954       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0454     |\n",
      "|    mean_step_reward   | 0.10272971  |\n",
      "|    n_updates          | 34.38 %     |\n",
      "|    policyGradLoss     | -0.0182     |\n",
      "|    value_loss         | 0.329       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 138         |\n",
      "|    total_timesteps    | 18718720    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027692638 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0445     |\n",
      "|    mean_step_reward   | 0.1132509   |\n",
      "|    n_updates          | 37.50 %     |\n",
      "|    policyGradLoss     | -0.0195     |\n",
      "|    value_loss         | 0.239       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 149         |\n",
      "|    total_timesteps    | 18726912    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018014878 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0449     |\n",
      "|    mean_step_reward   | 0.10076611  |\n",
      "|    n_updates          | 40.62 %     |\n",
      "|    policyGradLoss     | -0.017      |\n",
      "|    value_loss         | 0.215       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 765         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 160         |\n",
      "|    total_timesteps    | 18735104    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018449284 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.957       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00366    |\n",
      "|    mean_step_reward   | 0.121680014 |\n",
      "|    n_updates          | 43.75 %     |\n",
      "|    policyGradLoss     | -0.0145     |\n",
      "|    value_loss         | 0.357       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 762         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 171         |\n",
      "|    total_timesteps    | 18743296    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023587598 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0636     |\n",
      "|    mean_step_reward   | 0.11452909  |\n",
      "|    n_updates          | 46.88 %     |\n",
      "|    policyGradLoss     | -0.0213     |\n",
      "|    value_loss         | 0.196       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 758         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 183         |\n",
      "|    total_timesteps    | 18751488    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020784877 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0196     |\n",
      "|    mean_step_reward   | 0.11553851  |\n",
      "|    n_updates          | 50.00 %     |\n",
      "|    policyGradLoss     | -0.0197     |\n",
      "|    value_loss         | 0.287       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 752         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 195         |\n",
      "|    total_timesteps    | 18759680    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02455207  |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0561     |\n",
      "|    mean_step_reward   | 0.121234015 |\n",
      "|    n_updates          | 53.12 %     |\n",
      "|    policyGradLoss     | -0.0207     |\n",
      "|    value_loss         | 0.222       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 749         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 207         |\n",
      "|    total_timesteps    | 18767872    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021223914 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.936       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0155      |\n",
      "|    mean_step_reward   | 0.09764194  |\n",
      "|    n_updates          | 56.25 %     |\n",
      "|    policyGradLoss     | -0.015      |\n",
      "|    value_loss         | 0.388       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 747        |\n",
      "|    iterations         | 20         |\n",
      "|    time_elapsed       | 219        |\n",
      "|    total_timesteps    | 18776064   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02245068 |\n",
      "|    entropy_loss       | -1.85      |\n",
      "|    explained_variance | 0.966      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0478    |\n",
      "|    mean_step_reward   | 0.11385794 |\n",
      "|    n_updates          | 59.38 %    |\n",
      "|    policyGradLoss     | -0.0197    |\n",
      "|    value_loss         | 0.193      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 745         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 230         |\n",
      "|    total_timesteps    | 18784256    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024272256 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.954       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0489     |\n",
      "|    mean_step_reward   | 0.112087816 |\n",
      "|    n_updates          | 62.50 %     |\n",
      "|    policyGradLoss     | -0.018      |\n",
      "|    value_loss         | 0.185       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 742         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 242         |\n",
      "|    total_timesteps    | 18792448    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024377208 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0266     |\n",
      "|    mean_step_reward   | 0.10717936  |\n",
      "|    n_updates          | 65.62 %     |\n",
      "|    policyGradLoss     | -0.0154     |\n",
      "|    value_loss         | 0.261       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 740         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 254         |\n",
      "|    total_timesteps    | 18800640    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023849795 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0319     |\n",
      "|    mean_step_reward   | 0.13802993  |\n",
      "|    n_updates          | 68.75 %     |\n",
      "|    policyGradLoss     | -0.0171     |\n",
      "|    value_loss         | 0.188       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 736         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 267         |\n",
      "|    total_timesteps    | 18808832    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017396301 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.945       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0102     |\n",
      "|    mean_step_reward   | 0.09618907  |\n",
      "|    n_updates          | 71.88 %     |\n",
      "|    policyGradLoss     | -0.0147     |\n",
      "|    value_loss         | 0.312       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 732         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 279         |\n",
      "|    total_timesteps    | 18817024    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020870749 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.943       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0434      |\n",
      "|    mean_step_reward   | 0.115436785 |\n",
      "|    n_updates          | 75.00 %     |\n",
      "|    policyGradLoss     | -0.0186     |\n",
      "|    value_loss         | 0.383       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 730         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 291         |\n",
      "|    total_timesteps    | 18825216    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018793354 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.947       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0112     |\n",
      "|    mean_step_reward   | 0.1070807   |\n",
      "|    n_updates          | 78.12 %     |\n",
      "|    policyGradLoss     | -0.0164     |\n",
      "|    value_loss         | 0.317       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 729         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 303         |\n",
      "|    total_timesteps    | 18833408    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025802866 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.046      |\n",
      "|    mean_step_reward   | 0.11130637  |\n",
      "|    n_updates          | 81.25 %     |\n",
      "|    policyGradLoss     | -0.0188     |\n",
      "|    value_loss         | 0.239       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 729        |\n",
      "|    iterations         | 28         |\n",
      "|    time_elapsed       | 314        |\n",
      "|    total_timesteps    | 18841600   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01591481 |\n",
      "|    entropy_loss       | -1.86      |\n",
      "|    explained_variance | 0.937      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.0153     |\n",
      "|    mean_step_reward   | 0.10717961 |\n",
      "|    n_updates          | 84.38 %    |\n",
      "|    policyGradLoss     | -0.0156    |\n",
      "|    value_loss         | 0.361      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 729         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 325         |\n",
      "|    total_timesteps    | 18849792    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019752938 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0074     |\n",
      "|    mean_step_reward   | 0.124591984 |\n",
      "|    n_updates          | 87.50 %     |\n",
      "|    policyGradLoss     | -0.0179     |\n",
      "|    value_loss         | 0.286       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 729         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 336         |\n",
      "|    total_timesteps    | 18857984    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019861978 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.937       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00938     |\n",
      "|    mean_step_reward   | 0.1041484   |\n",
      "|    n_updates          | 90.62 %     |\n",
      "|    policyGradLoss     | -0.0182     |\n",
      "|    value_loss         | 0.296       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 731         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 347         |\n",
      "|    total_timesteps    | 18866176    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022916242 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0262     |\n",
      "|    mean_step_reward   | 0.12139097  |\n",
      "|    n_updates          | 93.75 %     |\n",
      "|    policyGradLoss     | -0.0173     |\n",
      "|    value_loss         | 0.34        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 736         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 356         |\n",
      "|    total_timesteps    | 18874368    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020936992 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.957       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0354     |\n",
      "|    mean_step_reward   | 0.11078879  |\n",
      "|    n_updates          | 96.88 %     |\n",
      "|    policyGradLoss     | -0.0185     |\n",
      "|    value_loss         | 0.242       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Run_71.zip\n",
      "[EVAL] Mean Return: 94.413, Best Return: 99.746\n",
      "Saved video to ./runs_smw/videos/Run/Run_71_94.41.mp4\n",
      "\n",
      "=== Round 73 | Learn 262144 steps (Total trained: 18874368) ===\n",
      "Logging to ./runs_smw/tb/Run_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1102     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 18882560 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 877         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 18890752    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024615325 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0482     |\n",
      "|    mean_step_reward   | 0.12191899  |\n",
      "|    n_updates          | 3.12 %      |\n",
      "|    policyGradLoss     | -0.0167     |\n",
      "|    value_loss         | 0.244       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 824         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 29          |\n",
      "|    total_timesteps    | 18898944    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029176073 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0616     |\n",
      "|    mean_step_reward   | 0.1291583   |\n",
      "|    n_updates          | 6.25 %      |\n",
      "|    policyGradLoss     | -0.019      |\n",
      "|    value_loss         | 0.15        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 803         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 40          |\n",
      "|    total_timesteps    | 18907136    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027537735 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.957       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00239     |\n",
      "|    mean_step_reward   | 0.111333266 |\n",
      "|    n_updates          | 9.38 %      |\n",
      "|    policyGradLoss     | -0.0184     |\n",
      "|    value_loss         | 0.283       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 789         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 51          |\n",
      "|    total_timesteps    | 18915328    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025613382 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0613     |\n",
      "|    mean_step_reward   | 0.14214456  |\n",
      "|    n_updates          | 12.50 %     |\n",
      "|    policyGradLoss     | -0.0182     |\n",
      "|    value_loss         | 0.202       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 63          |\n",
      "|    total_timesteps    | 18923520    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023722615 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.143       |\n",
      "|    mean_step_reward   | 0.1064024   |\n",
      "|    n_updates          | 15.62 %     |\n",
      "|    policyGradLoss     | -0.0172     |\n",
      "|    value_loss         | 0.24        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 74          |\n",
      "|    total_timesteps    | 18931712    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023851976 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0802      |\n",
      "|    mean_step_reward   | 0.12755758  |\n",
      "|    n_updates          | 18.75 %     |\n",
      "|    policyGradLoss     | -0.0156     |\n",
      "|    value_loss         | 0.212       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 758         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 86          |\n",
      "|    total_timesteps    | 18939904    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020547519 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0117      |\n",
      "|    mean_step_reward   | 0.11042029  |\n",
      "|    n_updates          | 21.88 %     |\n",
      "|    policyGradLoss     | -0.0189     |\n",
      "|    value_loss         | 0.262       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 755         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 97          |\n",
      "|    total_timesteps    | 18948096    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020749195 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0385     |\n",
      "|    mean_step_reward   | 0.124176025 |\n",
      "|    n_updates          | 25.00 %     |\n",
      "|    policyGradLoss     | -0.0162     |\n",
      "|    value_loss         | 0.222       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 754         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 108         |\n",
      "|    total_timesteps    | 18956288    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025565792 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0196     |\n",
      "|    mean_step_reward   | 0.11198035  |\n",
      "|    n_updates          | 28.12 %     |\n",
      "|    policyGradLoss     | -0.0185     |\n",
      "|    value_loss         | 0.237       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 752         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 119         |\n",
      "|    total_timesteps    | 18964480    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025977496 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0241     |\n",
      "|    mean_step_reward   | 0.13394544  |\n",
      "|    n_updates          | 31.25 %     |\n",
      "|    policyGradLoss     | -0.018      |\n",
      "|    value_loss         | 0.211       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 752         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 130         |\n",
      "|    total_timesteps    | 18972672    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024331696 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0337     |\n",
      "|    mean_step_reward   | 0.104351744 |\n",
      "|    n_updates          | 34.38 %     |\n",
      "|    policyGradLoss     | -0.018      |\n",
      "|    value_loss         | 0.207       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 750         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 141         |\n",
      "|    total_timesteps    | 18980864    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021635365 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.952       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.042       |\n",
      "|    mean_step_reward   | 0.10552311  |\n",
      "|    n_updates          | 37.50 %     |\n",
      "|    policyGradLoss     | -0.0135     |\n",
      "|    value_loss         | 0.395       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 747        |\n",
      "|    iterations         | 14         |\n",
      "|    time_elapsed       | 153        |\n",
      "|    total_timesteps    | 18989056   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01734868 |\n",
      "|    entropy_loss       | -1.84      |\n",
      "|    explained_variance | 0.945      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.00091   |\n",
      "|    mean_step_reward   | 0.12750845 |\n",
      "|    n_updates          | 40.62 %    |\n",
      "|    policyGradLoss     | -0.0148    |\n",
      "|    value_loss         | 0.303      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 744         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 165         |\n",
      "|    total_timesteps    | 18997248    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019865397 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.947       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.025      |\n",
      "|    mean_step_reward   | 0.11052103  |\n",
      "|    n_updates          | 43.75 %     |\n",
      "|    policyGradLoss     | -0.0143     |\n",
      "|    value_loss         | 0.29        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 742        |\n",
      "|    iterations         | 16         |\n",
      "|    time_elapsed       | 176        |\n",
      "|    total_timesteps    | 19005440   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02236104 |\n",
      "|    entropy_loss       | -1.82      |\n",
      "|    explained_variance | 0.947      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0239    |\n",
      "|    mean_step_reward   | 0.11461214 |\n",
      "|    n_updates          | 46.88 %    |\n",
      "|    policyGradLoss     | -0.0169    |\n",
      "|    value_loss         | 0.352      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 742         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 187         |\n",
      "|    total_timesteps    | 19013632    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024587568 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.947       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00794    |\n",
      "|    mean_step_reward   | 0.10864568  |\n",
      "|    n_updates          | 50.00 %     |\n",
      "|    policyGradLoss     | -0.0182     |\n",
      "|    value_loss         | 0.318       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 741         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 198         |\n",
      "|    total_timesteps    | 19021824    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019125894 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.935       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0218     |\n",
      "|    mean_step_reward   | 0.09783213  |\n",
      "|    n_updates          | 53.12 %     |\n",
      "|    policyGradLoss     | -0.0165     |\n",
      "|    value_loss         | 0.336       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 742         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 209         |\n",
      "|    total_timesteps    | 19030016    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018982707 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.938       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0127     |\n",
      "|    mean_step_reward   | 0.10683058  |\n",
      "|    n_updates          | 56.25 %     |\n",
      "|    policyGradLoss     | -0.0171     |\n",
      "|    value_loss         | 0.389       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 741         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 220         |\n",
      "|    total_timesteps    | 19038208    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021916652 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.934       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00474     |\n",
      "|    mean_step_reward   | 0.0989787   |\n",
      "|    n_updates          | 59.38 %     |\n",
      "|    policyGradLoss     | -0.0206     |\n",
      "|    value_loss         | 0.358       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 739        |\n",
      "|    iterations         | 21         |\n",
      "|    time_elapsed       | 232        |\n",
      "|    total_timesteps    | 19046400   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01973771 |\n",
      "|    entropy_loss       | -1.87      |\n",
      "|    explained_variance | 0.938      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0153    |\n",
      "|    mean_step_reward   | 0.09563355 |\n",
      "|    n_updates          | 62.50 %    |\n",
      "|    policyGradLoss     | -0.0173    |\n",
      "|    value_loss         | 0.333      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 738         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 244         |\n",
      "|    total_timesteps    | 19054592    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023581844 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0987      |\n",
      "|    mean_step_reward   | 0.110768914 |\n",
      "|    n_updates          | 65.62 %     |\n",
      "|    policyGradLoss     | -0.0191     |\n",
      "|    value_loss         | 0.242       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 737         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 255         |\n",
      "|    total_timesteps    | 19062784    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026937895 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0562     |\n",
      "|    mean_step_reward   | 0.09866583  |\n",
      "|    n_updates          | 68.75 %     |\n",
      "|    policyGradLoss     | -0.0211     |\n",
      "|    value_loss         | 0.235       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 736        |\n",
      "|    iterations         | 24         |\n",
      "|    time_elapsed       | 266        |\n",
      "|    total_timesteps    | 19070976   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02725275 |\n",
      "|    entropy_loss       | -1.79      |\n",
      "|    explained_variance | 0.957      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.019     |\n",
      "|    mean_step_reward   | 0.11493692 |\n",
      "|    n_updates          | 71.88 %    |\n",
      "|    policyGradLoss     | -0.0172    |\n",
      "|    value_loss         | 0.26       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 737         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 277         |\n",
      "|    total_timesteps    | 19079168    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026716396 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0394     |\n",
      "|    mean_step_reward   | 0.11197114  |\n",
      "|    n_updates          | 75.00 %     |\n",
      "|    policyGradLoss     | -0.0202     |\n",
      "|    value_loss         | 0.263       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 737         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 288         |\n",
      "|    total_timesteps    | 19087360    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020672096 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.943       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0133      |\n",
      "|    mean_step_reward   | 0.10721932  |\n",
      "|    n_updates          | 78.12 %     |\n",
      "|    policyGradLoss     | -0.0178     |\n",
      "|    value_loss         | 0.287       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 737         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 300         |\n",
      "|    total_timesteps    | 19095552    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028845843 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.031      |\n",
      "|    mean_step_reward   | 0.11159816  |\n",
      "|    n_updates          | 81.25 %     |\n",
      "|    policyGradLoss     | -0.0206     |\n",
      "|    value_loss         | 0.252       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 736        |\n",
      "|    iterations         | 28         |\n",
      "|    time_elapsed       | 311        |\n",
      "|    total_timesteps    | 19103744   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02287202 |\n",
      "|    entropy_loss       | -1.82      |\n",
      "|    explained_variance | 0.955      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0226    |\n",
      "|    mean_step_reward   | 0.11973411 |\n",
      "|    n_updates          | 84.38 %    |\n",
      "|    policyGradLoss     | -0.016     |\n",
      "|    value_loss         | 0.273      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 740         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 320         |\n",
      "|    total_timesteps    | 19111936    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020991363 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.958       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0217     |\n",
      "|    mean_step_reward   | 0.11424969  |\n",
      "|    n_updates          | 87.50 %     |\n",
      "|    policyGradLoss     | -0.0174     |\n",
      "|    value_loss         | 0.28        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 745         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 329         |\n",
      "|    total_timesteps    | 19120128    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023279307 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0241     |\n",
      "|    mean_step_reward   | 0.10199137  |\n",
      "|    n_updates          | 90.62 %     |\n",
      "|    policyGradLoss     | -0.0205     |\n",
      "|    value_loss         | 0.256       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 748         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 339         |\n",
      "|    total_timesteps    | 19128320    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023774376 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0289     |\n",
      "|    mean_step_reward   | 0.10016054  |\n",
      "|    n_updates          | 93.75 %     |\n",
      "|    policyGradLoss     | -0.0163     |\n",
      "|    value_loss         | 0.228       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 751         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 348         |\n",
      "|    total_timesteps    | 19136512    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021822523 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0611     |\n",
      "|    mean_step_reward   | 0.10715521  |\n",
      "|    n_updates          | 96.88 %     |\n",
      "|    policyGradLoss     | -0.0185     |\n",
      "|    value_loss         | 0.171       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Run_72.zip\n",
      "[EVAL] Mean Return: 87.489, Best Return: 92.156\n",
      "Saved video to ./runs_smw/videos/Run/Run_72_87.49.mp4\n",
      "\n",
      "=== Round 74 | Learn 262144 steps (Total trained: 19136512) ===\n",
      "Logging to ./runs_smw/tb/Run_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1115     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 19144704 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 891         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 19152896    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025727585 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.043      |\n",
      "|    mean_step_reward   | 0.12307948  |\n",
      "|    n_updates          | 3.12 %      |\n",
      "|    policyGradLoss     | -0.0164     |\n",
      "|    value_loss         | 0.144       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 833         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 29          |\n",
      "|    total_timesteps    | 19161088    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019969013 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00415     |\n",
      "|    mean_step_reward   | 0.09639838  |\n",
      "|    n_updates          | 6.25 %      |\n",
      "|    policyGradLoss     | -0.0187     |\n",
      "|    value_loss         | 0.281       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 804         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 40          |\n",
      "|    total_timesteps    | 19169280    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02319118  |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.954       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0333     |\n",
      "|    mean_step_reward   | 0.124864005 |\n",
      "|    n_updates          | 9.38 %      |\n",
      "|    policyGradLoss     | -0.018      |\n",
      "|    value_loss         | 0.283       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 52          |\n",
      "|    total_timesteps    | 19177472    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024705477 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.928       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0465     |\n",
      "|    mean_step_reward   | 0.07900546  |\n",
      "|    n_updates          | 12.50 %     |\n",
      "|    policyGradLoss     | -0.0183     |\n",
      "|    value_loss         | 0.288       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 770        |\n",
      "|    iterations         | 6          |\n",
      "|    time_elapsed       | 63         |\n",
      "|    total_timesteps    | 19185664   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02281125 |\n",
      "|    entropy_loss       | -1.82      |\n",
      "|    explained_variance | 0.964      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0138    |\n",
      "|    mean_step_reward   | 0.11991821 |\n",
      "|    n_updates          | 15.62 %    |\n",
      "|    policyGradLoss     | -0.0183    |\n",
      "|    value_loss         | 0.3        |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 760         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 75          |\n",
      "|    total_timesteps    | 19193856    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020679701 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0507     |\n",
      "|    mean_step_reward   | 0.11518136  |\n",
      "|    n_updates          | 18.75 %     |\n",
      "|    policyGradLoss     | -0.0195     |\n",
      "|    value_loss         | 0.18        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 754         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 86          |\n",
      "|    total_timesteps    | 19202048    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023154655 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0143     |\n",
      "|    mean_step_reward   | 0.111061096 |\n",
      "|    n_updates          | 21.88 %     |\n",
      "|    policyGradLoss     | -0.0184     |\n",
      "|    value_loss         | 0.239       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 754         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 97          |\n",
      "|    total_timesteps    | 19210240    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022098681 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.952       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0474     |\n",
      "|    mean_step_reward   | 0.10229945  |\n",
      "|    n_updates          | 25.00 %     |\n",
      "|    policyGradLoss     | -0.0173     |\n",
      "|    value_loss         | 0.288       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 753         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 108         |\n",
      "|    total_timesteps    | 19218432    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023234155 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.947       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0254      |\n",
      "|    mean_step_reward   | 0.094520226 |\n",
      "|    n_updates          | 28.12 %     |\n",
      "|    policyGradLoss     | -0.0195     |\n",
      "|    value_loss         | 0.272       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 752         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 119         |\n",
      "|    total_timesteps    | 19226624    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024551082 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0375     |\n",
      "|    mean_step_reward   | 0.12071979  |\n",
      "|    n_updates          | 31.25 %     |\n",
      "|    policyGradLoss     | -0.0187     |\n",
      "|    value_loss         | 0.229       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 749         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 131         |\n",
      "|    total_timesteps    | 19234816    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016623722 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.944       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.025       |\n",
      "|    mean_step_reward   | 0.114216074 |\n",
      "|    n_updates          | 34.38 %     |\n",
      "|    policyGradLoss     | -0.0141     |\n",
      "|    value_loss         | 0.346       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 745         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 142         |\n",
      "|    total_timesteps    | 19243008    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021043252 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.941       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0434     |\n",
      "|    mean_step_reward   | 0.08718133  |\n",
      "|    n_updates          | 37.50 %     |\n",
      "|    policyGradLoss     | -0.0173     |\n",
      "|    value_loss         | 0.258       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 741         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 154         |\n",
      "|    total_timesteps    | 19251200    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023329053 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.948       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0347     |\n",
      "|    mean_step_reward   | 0.09784144  |\n",
      "|    n_updates          | 40.62 %     |\n",
      "|    policyGradLoss     | -0.0182     |\n",
      "|    value_loss         | 0.294       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 740         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 166         |\n",
      "|    total_timesteps    | 19259392    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020391727 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.94        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0802      |\n",
      "|    mean_step_reward   | 0.10027084  |\n",
      "|    n_updates          | 43.75 %     |\n",
      "|    policyGradLoss     | -0.0191     |\n",
      "|    value_loss         | 0.397       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 739         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 177         |\n",
      "|    total_timesteps    | 19267584    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022306425 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.937       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0364     |\n",
      "|    mean_step_reward   | 0.10620955  |\n",
      "|    n_updates          | 46.88 %     |\n",
      "|    policyGradLoss     | -0.0173     |\n",
      "|    value_loss         | 0.307       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 739         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 188         |\n",
      "|    total_timesteps    | 19275776    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020468563 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.934       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0237      |\n",
      "|    mean_step_reward   | 0.10862203  |\n",
      "|    n_updates          | 50.00 %     |\n",
      "|    policyGradLoss     | -0.0183     |\n",
      "|    value_loss         | 0.364       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 740         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 199         |\n",
      "|    total_timesteps    | 19283968    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020076701 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.945       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0243     |\n",
      "|    mean_step_reward   | 0.09704078  |\n",
      "|    n_updates          | 53.12 %     |\n",
      "|    policyGradLoss     | -0.0194     |\n",
      "|    value_loss         | 0.25        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 739         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 210         |\n",
      "|    total_timesteps    | 19292160    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021210026 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.952       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0362     |\n",
      "|    mean_step_reward   | 0.11678982  |\n",
      "|    n_updates          | 56.25 %     |\n",
      "|    policyGradLoss     | -0.0147     |\n",
      "|    value_loss         | 0.28        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 738         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 221         |\n",
      "|    total_timesteps    | 19300352    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023495834 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.947       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0457     |\n",
      "|    mean_step_reward   | 0.100335896 |\n",
      "|    n_updates          | 59.38 %     |\n",
      "|    policyGradLoss     | -0.0223     |\n",
      "|    value_loss         | 0.239       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 736         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 233         |\n",
      "|    total_timesteps    | 19308544    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022860728 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.952       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0297      |\n",
      "|    mean_step_reward   | 0.09825562  |\n",
      "|    n_updates          | 62.50 %     |\n",
      "|    policyGradLoss     | -0.0182     |\n",
      "|    value_loss         | 0.297       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 734         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 245         |\n",
      "|    total_timesteps    | 19316736    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030195024 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0393     |\n",
      "|    mean_step_reward   | 0.120677285 |\n",
      "|    n_updates          | 65.62 %     |\n",
      "|    policyGradLoss     | -0.0197     |\n",
      "|    value_loss         | 0.188       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 734         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 256         |\n",
      "|    total_timesteps    | 19324928    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022112198 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.958       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0157     |\n",
      "|    mean_step_reward   | 0.099133    |\n",
      "|    n_updates          | 68.75 %     |\n",
      "|    policyGradLoss     | -0.0175     |\n",
      "|    value_loss         | 0.229       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 734         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 267         |\n",
      "|    total_timesteps    | 19333120    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023813184 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00461     |\n",
      "|    mean_step_reward   | 0.11087446  |\n",
      "|    n_updates          | 71.88 %     |\n",
      "|    policyGradLoss     | -0.0186     |\n",
      "|    value_loss         | 0.318       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 735         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 278         |\n",
      "|    total_timesteps    | 19341312    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020042516 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.94        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00715    |\n",
      "|    mean_step_reward   | 0.10232577  |\n",
      "|    n_updates          | 75.00 %     |\n",
      "|    policyGradLoss     | -0.0173     |\n",
      "|    value_loss         | 0.351       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 740         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 287         |\n",
      "|    total_timesteps    | 19349504    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017555742 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.943       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0866      |\n",
      "|    mean_step_reward   | 0.10885087  |\n",
      "|    n_updates          | 78.12 %     |\n",
      "|    policyGradLoss     | -0.0156     |\n",
      "|    value_loss         | 0.471       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 745         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 296         |\n",
      "|    total_timesteps    | 19357696    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026148085 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0156      |\n",
      "|    mean_step_reward   | 0.113354154 |\n",
      "|    n_updates          | 81.25 %     |\n",
      "|    policyGradLoss     | -0.0191     |\n",
      "|    value_loss         | 0.271       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 749        |\n",
      "|    iterations         | 28         |\n",
      "|    time_elapsed       | 306        |\n",
      "|    total_timesteps    | 19365888   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.0214849  |\n",
      "|    entropy_loss       | -1.85      |\n",
      "|    explained_variance | 0.957      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0479    |\n",
      "|    mean_step_reward   | 0.10495676 |\n",
      "|    n_updates          | 84.38 %    |\n",
      "|    policyGradLoss     | -0.0209    |\n",
      "|    value_loss         | 0.218      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 752         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 315         |\n",
      "|    total_timesteps    | 19374080    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024878234 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0682     |\n",
      "|    mean_step_reward   | 0.114197776 |\n",
      "|    n_updates          | 87.50 %     |\n",
      "|    policyGradLoss     | -0.0203     |\n",
      "|    value_loss         | 0.19        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 752        |\n",
      "|    iterations         | 30         |\n",
      "|    time_elapsed       | 326        |\n",
      "|    total_timesteps    | 19382272   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02327113 |\n",
      "|    entropy_loss       | -1.89      |\n",
      "|    explained_variance | 0.929      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0456    |\n",
      "|    mean_step_reward   | 0.08940503 |\n",
      "|    n_updates          | 90.62 %    |\n",
      "|    policyGradLoss     | -0.0179    |\n",
      "|    value_loss         | 0.254      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 751         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 337         |\n",
      "|    total_timesteps    | 19390464    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026501734 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.954       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0596      |\n",
      "|    mean_step_reward   | 0.10648805  |\n",
      "|    n_updates          | 93.75 %     |\n",
      "|    policyGradLoss     | -0.0181     |\n",
      "|    value_loss         | 0.289       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 751         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 348         |\n",
      "|    total_timesteps    | 19398656    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01892514  |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0426     |\n",
      "|    mean_step_reward   | 0.101469755 |\n",
      "|    n_updates          | 96.88 %     |\n",
      "|    policyGradLoss     | -0.0154     |\n",
      "|    value_loss         | 0.202       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Run_73.zip\n",
      "[EVAL] Mean Return: 139.329, Best Return: 145.996\n",
      "Saved video to ./runs_smw/videos/Run/Run_73_139.33.mp4\n",
      "\n",
      "=== Round 75 | Learn 262144 steps (Total trained: 19398656) ===\n",
      "Logging to ./runs_smw/tb/Run_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1108     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 19406848 |\n",
      "---------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 861        |\n",
      "|    iterations         | 2          |\n",
      "|    time_elapsed       | 19         |\n",
      "|    total_timesteps    | 19415040   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.0186177  |\n",
      "|    entropy_loss       | -1.86      |\n",
      "|    explained_variance | 0.912      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.00412   |\n",
      "|    mean_step_reward   | 0.09057943 |\n",
      "|    n_updates          | 3.12 %     |\n",
      "|    policyGradLoss     | -0.016     |\n",
      "|    value_loss         | 0.461      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 805         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 30          |\n",
      "|    total_timesteps    | 19423232    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019963484 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.95        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0164      |\n",
      "|    mean_step_reward   | 0.10175601  |\n",
      "|    n_updates          | 6.25 %      |\n",
      "|    policyGradLoss     | -0.0165     |\n",
      "|    value_loss         | 0.311       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 41          |\n",
      "|    total_timesteps    | 19431424    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028073866 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0727     |\n",
      "|    mean_step_reward   | 0.112770975 |\n",
      "|    n_updates          | 9.38 %      |\n",
      "|    policyGradLoss     | -0.0233     |\n",
      "|    value_loss         | 0.186       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 779        |\n",
      "|    iterations         | 5          |\n",
      "|    time_elapsed       | 52         |\n",
      "|    total_timesteps    | 19439616   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02504529 |\n",
      "|    entropy_loss       | -1.89      |\n",
      "|    explained_variance | 0.962      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0476    |\n",
      "|    mean_step_reward   | 0.10877508 |\n",
      "|    n_updates          | 12.50 %    |\n",
      "|    policyGradLoss     | -0.0203    |\n",
      "|    value_loss         | 0.186      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 772        |\n",
      "|    iterations         | 6          |\n",
      "|    time_elapsed       | 63         |\n",
      "|    total_timesteps    | 19447808   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02452529 |\n",
      "|    entropy_loss       | -1.83      |\n",
      "|    explained_variance | 0.968      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0499    |\n",
      "|    mean_step_reward   | 0.12692416 |\n",
      "|    n_updates          | 15.62 %    |\n",
      "|    policyGradLoss     | -0.0181    |\n",
      "|    value_loss         | 0.199      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 765         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 74          |\n",
      "|    total_timesteps    | 19456000    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025415655 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0165     |\n",
      "|    mean_step_reward   | 0.09893106  |\n",
      "|    n_updates          | 18.75 %     |\n",
      "|    policyGradLoss     | -0.0184     |\n",
      "|    value_loss         | 0.252       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 759         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 86          |\n",
      "|    total_timesteps    | 19464192    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020032715 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.948       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0281      |\n",
      "|    mean_step_reward   | 0.10226619  |\n",
      "|    n_updates          | 21.88 %     |\n",
      "|    policyGradLoss     | -0.017      |\n",
      "|    value_loss         | 0.428       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 752        |\n",
      "|    iterations         | 9          |\n",
      "|    time_elapsed       | 97         |\n",
      "|    total_timesteps    | 19472384   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01679647 |\n",
      "|    entropy_loss       | -1.87      |\n",
      "|    explained_variance | 0.945      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.00104    |\n",
      "|    mean_step_reward   | 0.09871126 |\n",
      "|    n_updates          | 25.00 %    |\n",
      "|    policyGradLoss     | -0.00973   |\n",
      "|    value_loss         | 0.361      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 747         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 109         |\n",
      "|    total_timesteps    | 19480576    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022435855 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.944       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0532     |\n",
      "|    mean_step_reward   | 0.076691404 |\n",
      "|    n_updates          | 28.12 %     |\n",
      "|    policyGradLoss     | -0.0168     |\n",
      "|    value_loss         | 0.278       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 745         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 120         |\n",
      "|    total_timesteps    | 19488768    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025299236 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0721     |\n",
      "|    mean_step_reward   | 0.10397996  |\n",
      "|    n_updates          | 31.25 %     |\n",
      "|    policyGradLoss     | -0.0225     |\n",
      "|    value_loss         | 0.219       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 745         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 131         |\n",
      "|    total_timesteps    | 19496960    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023306552 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.952       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0309     |\n",
      "|    mean_step_reward   | 0.105271086 |\n",
      "|    n_updates          | 34.38 %     |\n",
      "|    policyGradLoss     | -0.0168     |\n",
      "|    value_loss         | 0.271       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 745         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 142         |\n",
      "|    total_timesteps    | 19505152    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025475614 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.955       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0118      |\n",
      "|    mean_step_reward   | 0.13125958  |\n",
      "|    n_updates          | 37.50 %     |\n",
      "|    policyGradLoss     | -0.0184     |\n",
      "|    value_loss         | 0.232       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 744         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 154         |\n",
      "|    total_timesteps    | 19513344    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020487122 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.941       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0058      |\n",
      "|    mean_step_reward   | 0.08755895  |\n",
      "|    n_updates          | 40.62 %     |\n",
      "|    policyGradLoss     | -0.0142     |\n",
      "|    value_loss         | 0.233       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 742         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 165         |\n",
      "|    total_timesteps    | 19521536    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025094245 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.948       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0234      |\n",
      "|    mean_step_reward   | 0.1328128   |\n",
      "|    n_updates          | 43.75 %     |\n",
      "|    policyGradLoss     | -0.0181     |\n",
      "|    value_loss         | 0.358       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 739         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 177         |\n",
      "|    total_timesteps    | 19529728    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018355118 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.947       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0339      |\n",
      "|    mean_step_reward   | 0.09869444  |\n",
      "|    n_updates          | 46.88 %     |\n",
      "|    policyGradLoss     | -0.0134     |\n",
      "|    value_loss         | 0.241       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 738         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 188         |\n",
      "|    total_timesteps    | 19537920    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023358706 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0299     |\n",
      "|    mean_step_reward   | 0.121823154 |\n",
      "|    n_updates          | 50.00 %     |\n",
      "|    policyGradLoss     | -0.0187     |\n",
      "|    value_loss         | 0.202       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 737         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 199         |\n",
      "|    total_timesteps    | 19546112    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023990002 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.954       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.014      |\n",
      "|    mean_step_reward   | 0.099113144 |\n",
      "|    n_updates          | 53.12 %     |\n",
      "|    policyGradLoss     | -0.0205     |\n",
      "|    value_loss         | 0.277       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 737         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 211         |\n",
      "|    total_timesteps    | 19554304    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025274927 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0167     |\n",
      "|    mean_step_reward   | 0.11004872  |\n",
      "|    n_updates          | 56.25 %     |\n",
      "|    policyGradLoss     | -0.0185     |\n",
      "|    value_loss         | 0.22        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 737         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 222         |\n",
      "|    total_timesteps    | 19562496    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023041798 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0553     |\n",
      "|    mean_step_reward   | 0.13365555  |\n",
      "|    n_updates          | 59.38 %     |\n",
      "|    policyGradLoss     | -0.0154     |\n",
      "|    value_loss         | 0.282       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 737         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 233         |\n",
      "|    total_timesteps    | 19570688    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020687949 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.95        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0307     |\n",
      "|    mean_step_reward   | 0.092488565 |\n",
      "|    n_updates          | 62.50 %     |\n",
      "|    policyGradLoss     | -0.016      |\n",
      "|    value_loss         | 0.329       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 739         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 243         |\n",
      "|    total_timesteps    | 19578880    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021423178 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.026      |\n",
      "|    mean_step_reward   | 0.13132204  |\n",
      "|    n_updates          | 65.62 %     |\n",
      "|    policyGradLoss     | -0.0154     |\n",
      "|    value_loss         | 0.236       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 745         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 252         |\n",
      "|    total_timesteps    | 19587072    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023776568 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0262     |\n",
      "|    mean_step_reward   | 0.089444235 |\n",
      "|    n_updates          | 68.75 %     |\n",
      "|    policyGradLoss     | -0.0182     |\n",
      "|    value_loss         | 0.208       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 750         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 262         |\n",
      "|    total_timesteps    | 19595264    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025112882 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0357     |\n",
      "|    mean_step_reward   | 0.13429844  |\n",
      "|    n_updates          | 71.88 %     |\n",
      "|    policyGradLoss     | -0.0167     |\n",
      "|    value_loss         | 0.237       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 754         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 271         |\n",
      "|    total_timesteps    | 19603456    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022843935 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.942       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.047       |\n",
      "|    mean_step_reward   | 0.09361209  |\n",
      "|    n_updates          | 75.00 %     |\n",
      "|    policyGradLoss     | -0.0191     |\n",
      "|    value_loss         | 0.275       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 753         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 282         |\n",
      "|    total_timesteps    | 19611648    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019871088 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0426     |\n",
      "|    mean_step_reward   | 0.113541216 |\n",
      "|    n_updates          | 78.12 %     |\n",
      "|    policyGradLoss     | -0.0165     |\n",
      "|    value_loss         | 0.228       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 753         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 293         |\n",
      "|    total_timesteps    | 19619840    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020733654 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.937       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0387     |\n",
      "|    mean_step_reward   | 0.102920145 |\n",
      "|    n_updates          | 81.25 %     |\n",
      "|    policyGradLoss     | -0.0193     |\n",
      "|    value_loss         | 0.258       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 753         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 304         |\n",
      "|    total_timesteps    | 19628032    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027085047 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.946       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0244     |\n",
      "|    mean_step_reward   | 0.104585886 |\n",
      "|    n_updates          | 84.38 %     |\n",
      "|    policyGradLoss     | -0.0176     |\n",
      "|    value_loss         | 0.271       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 752         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 315         |\n",
      "|    total_timesteps    | 19636224    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020752072 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0454     |\n",
      "|    mean_step_reward   | 0.12260722  |\n",
      "|    n_updates          | 87.50 %     |\n",
      "|    policyGradLoss     | -0.016      |\n",
      "|    value_loss         | 0.239       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 751        |\n",
      "|    iterations         | 30         |\n",
      "|    time_elapsed       | 326        |\n",
      "|    total_timesteps    | 19644416   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02525109 |\n",
      "|    entropy_loss       | -1.84      |\n",
      "|    explained_variance | 0.947      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.00379    |\n",
      "|    mean_step_reward   | 0.10990818 |\n",
      "|    n_updates          | 90.62 %    |\n",
      "|    policyGradLoss     | -0.0148    |\n",
      "|    value_loss         | 0.278      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 750         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 338         |\n",
      "|    total_timesteps    | 19652608    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024845513 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0357     |\n",
      "|    mean_step_reward   | 0.12402626  |\n",
      "|    n_updates          | 93.75 %     |\n",
      "|    policyGradLoss     | -0.0201     |\n",
      "|    value_loss         | 0.206       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 748         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 350         |\n",
      "|    total_timesteps    | 19660800    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022970377 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.955       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.026      |\n",
      "|    mean_step_reward   | 0.103604436 |\n",
      "|    n_updates          | 96.88 %     |\n",
      "|    policyGradLoss     | -0.0183     |\n",
      "|    value_loss         | 0.24        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Run_74.zip\n",
      "[EVAL] Mean Return: 147.675, Best Return: 154.675\n",
      "Saved video to ./runs_smw/videos/Run/Run_74_147.67.mp4\n",
      "\n",
      "=== Round 76 | Learn 262144 steps (Total trained: 19660800) ===\n",
      "Logging to ./runs_smw/tb/Run_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1161     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 19668992 |\n",
      "---------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 916        |\n",
      "|    iterations         | 2          |\n",
      "|    time_elapsed       | 17         |\n",
      "|    total_timesteps    | 19677184   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01890644 |\n",
      "|    entropy_loss       | -1.85      |\n",
      "|    explained_variance | 0.946      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.0672     |\n",
      "|    mean_step_reward   | 0.10538682 |\n",
      "|    n_updates          | 3.12 %     |\n",
      "|    policyGradLoss     | -0.0136    |\n",
      "|    value_loss         | 0.312      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 844         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 29          |\n",
      "|    total_timesteps    | 19685376    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025286391 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.000392   |\n",
      "|    mean_step_reward   | 0.11277315  |\n",
      "|    n_updates          | 6.25 %      |\n",
      "|    policyGradLoss     | -0.0195     |\n",
      "|    value_loss         | 0.24        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 815         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 40          |\n",
      "|    total_timesteps    | 19693568    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024931537 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.958       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0603     |\n",
      "|    mean_step_reward   | 0.10393561  |\n",
      "|    n_updates          | 9.38 %      |\n",
      "|    policyGradLoss     | -0.0197     |\n",
      "|    value_loss         | 0.176       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 792         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 51          |\n",
      "|    total_timesteps    | 19701760    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026144475 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.000447   |\n",
      "|    mean_step_reward   | 0.1273117   |\n",
      "|    n_updates          | 12.50 %     |\n",
      "|    policyGradLoss     | -0.0193     |\n",
      "|    value_loss         | 0.211       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 775        |\n",
      "|    iterations         | 6          |\n",
      "|    time_elapsed       | 63         |\n",
      "|    total_timesteps    | 19709952   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02310064 |\n",
      "|    entropy_loss       | -1.84      |\n",
      "|    explained_variance | 0.949      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.0396     |\n",
      "|    mean_step_reward   | 0.11483048 |\n",
      "|    n_updates          | 15.62 %    |\n",
      "|    policyGradLoss     | -0.0144    |\n",
      "|    value_loss         | 0.353      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 74          |\n",
      "|    total_timesteps    | 19718144    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023915673 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.951       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00142     |\n",
      "|    mean_step_reward   | 0.1193078   |\n",
      "|    n_updates          | 18.75 %     |\n",
      "|    policyGradLoss     | -0.0184     |\n",
      "|    value_loss         | 0.263       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 763         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 85          |\n",
      "|    total_timesteps    | 19726336    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023859646 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.954       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0253     |\n",
      "|    mean_step_reward   | 0.104977496 |\n",
      "|    n_updates          | 21.88 %     |\n",
      "|    policyGradLoss     | -0.0183     |\n",
      "|    value_loss         | 0.259       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 760         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 96          |\n",
      "|    total_timesteps    | 19734528    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022198748 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0314     |\n",
      "|    mean_step_reward   | 0.113005325 |\n",
      "|    n_updates          | 25.00 %     |\n",
      "|    policyGradLoss     | -0.018      |\n",
      "|    value_loss         | 0.243       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 757         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 108         |\n",
      "|    total_timesteps    | 19742720    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024380477 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.95        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0405     |\n",
      "|    mean_step_reward   | 0.110573925 |\n",
      "|    n_updates          | 28.12 %     |\n",
      "|    policyGradLoss     | -0.019      |\n",
      "|    value_loss         | 0.211       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 754         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 119         |\n",
      "|    total_timesteps    | 19750912    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021391716 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.942       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0485     |\n",
      "|    mean_step_reward   | 0.1035276   |\n",
      "|    n_updates          | 31.25 %     |\n",
      "|    policyGradLoss     | -0.0162     |\n",
      "|    value_loss         | 0.271       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 751         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 130         |\n",
      "|    total_timesteps    | 19759104    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025168937 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0164      |\n",
      "|    mean_step_reward   | 0.120808944 |\n",
      "|    n_updates          | 34.38 %     |\n",
      "|    policyGradLoss     | -0.0179     |\n",
      "|    value_loss         | 0.3         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 747         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 142         |\n",
      "|    total_timesteps    | 19767296    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025369622 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0502     |\n",
      "|    mean_step_reward   | 0.101921774 |\n",
      "|    n_updates          | 37.50 %     |\n",
      "|    policyGradLoss     | -0.0189     |\n",
      "|    value_loss         | 0.247       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 744         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 154         |\n",
      "|    total_timesteps    | 19775488    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023870304 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0324     |\n",
      "|    mean_step_reward   | 0.12762222  |\n",
      "|    n_updates          | 40.62 %     |\n",
      "|    policyGradLoss     | -0.0193     |\n",
      "|    value_loss         | 0.252       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 743        |\n",
      "|    iterations         | 15         |\n",
      "|    time_elapsed       | 165        |\n",
      "|    total_timesteps    | 19783680   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01946707 |\n",
      "|    entropy_loss       | -1.9       |\n",
      "|    explained_variance | 0.96       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0017    |\n",
      "|    mean_step_reward   | 0.10027306 |\n",
      "|    n_updates          | 43.75 %    |\n",
      "|    policyGradLoss     | -0.0206    |\n",
      "|    value_loss         | 0.238      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 743         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 176         |\n",
      "|    total_timesteps    | 19791872    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019901982 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.918       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00588    |\n",
      "|    mean_step_reward   | 0.099990465 |\n",
      "|    n_updates          | 46.88 %     |\n",
      "|    policyGradLoss     | -0.0179     |\n",
      "|    value_loss         | 0.435       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 742         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 187         |\n",
      "|    total_timesteps    | 19800064    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024714742 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.948       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0221     |\n",
      "|    mean_step_reward   | 0.106294826 |\n",
      "|    n_updates          | 50.00 %     |\n",
      "|    policyGradLoss     | -0.0183     |\n",
      "|    value_loss         | 0.248       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 741         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 198         |\n",
      "|    total_timesteps    | 19808256    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019587707 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0533     |\n",
      "|    mean_step_reward   | 0.11408084  |\n",
      "|    n_updates          | 53.12 %     |\n",
      "|    policyGradLoss     | -0.0158     |\n",
      "|    value_loss         | 0.231       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 748         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 207         |\n",
      "|    total_timesteps    | 19816448    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023288732 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.957       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0645     |\n",
      "|    mean_step_reward   | 0.11888848  |\n",
      "|    n_updates          | 56.25 %     |\n",
      "|    policyGradLoss     | -0.0181     |\n",
      "|    value_loss         | 0.243       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 755         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 216         |\n",
      "|    total_timesteps    | 19824640    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024168136 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0549      |\n",
      "|    mean_step_reward   | 0.100025535 |\n",
      "|    n_updates          | 59.38 %     |\n",
      "|    policyGradLoss     | -0.016      |\n",
      "|    value_loss         | 0.36        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 760         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 226         |\n",
      "|    total_timesteps    | 19832832    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025689129 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0377     |\n",
      "|    mean_step_reward   | 0.12710646  |\n",
      "|    n_updates          | 62.50 %     |\n",
      "|    policyGradLoss     | -0.0157     |\n",
      "|    value_loss         | 0.263       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 764         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 235         |\n",
      "|    total_timesteps    | 19841024    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025099268 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.958       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0455     |\n",
      "|    mean_step_reward   | 0.110023946 |\n",
      "|    n_updates          | 65.62 %     |\n",
      "|    policyGradLoss     | -0.016      |\n",
      "|    value_loss         | 0.199       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 763         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 246         |\n",
      "|    total_timesteps    | 19849216    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025760032 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00728    |\n",
      "|    mean_step_reward   | 0.10995452  |\n",
      "|    n_updates          | 68.75 %     |\n",
      "|    policyGradLoss     | -0.0192     |\n",
      "|    value_loss         | 0.304       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 762         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 257         |\n",
      "|    total_timesteps    | 19857408    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028066266 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.957       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0228     |\n",
      "|    mean_step_reward   | 0.11735961  |\n",
      "|    n_updates          | 71.88 %     |\n",
      "|    policyGradLoss     | -0.0162     |\n",
      "|    value_loss         | 0.262       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 760        |\n",
      "|    iterations         | 25         |\n",
      "|    time_elapsed       | 269        |\n",
      "|    total_timesteps    | 19865600   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.0358688  |\n",
      "|    entropy_loss       | -1.82      |\n",
      "|    explained_variance | 0.973      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0513    |\n",
      "|    mean_step_reward   | 0.12587723 |\n",
      "|    n_updates          | 75.00 %    |\n",
      "|    policyGradLoss     | -0.0221    |\n",
      "|    value_loss         | 0.18       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 757         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 281         |\n",
      "|    total_timesteps    | 19873792    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026002627 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0458     |\n",
      "|    mean_step_reward   | 0.12114243  |\n",
      "|    n_updates          | 78.12 %     |\n",
      "|    policyGradLoss     | -0.0198     |\n",
      "|    value_loss         | 0.185       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 755         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 292         |\n",
      "|    total_timesteps    | 19881984    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028629474 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0567     |\n",
      "|    mean_step_reward   | 0.12439473  |\n",
      "|    n_updates          | 81.25 %     |\n",
      "|    policyGradLoss     | -0.0171     |\n",
      "|    value_loss         | 0.233       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 754         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 304         |\n",
      "|    total_timesteps    | 19890176    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026566887 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.032      |\n",
      "|    mean_step_reward   | 0.10363169  |\n",
      "|    n_updates          | 84.38 %     |\n",
      "|    policyGradLoss     | -0.0171     |\n",
      "|    value_loss         | 0.219       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 753         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 315         |\n",
      "|    total_timesteps    | 19898368    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024648778 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.041      |\n",
      "|    mean_step_reward   | 0.1370152   |\n",
      "|    n_updates          | 87.50 %     |\n",
      "|    policyGradLoss     | -0.0195     |\n",
      "|    value_loss         | 0.239       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 753         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 326         |\n",
      "|    total_timesteps    | 19906560    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027183633 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.958       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0607     |\n",
      "|    mean_step_reward   | 0.095234126 |\n",
      "|    n_updates          | 90.62 %     |\n",
      "|    policyGradLoss     | -0.0182     |\n",
      "|    value_loss         | 0.195       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 752         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 337         |\n",
      "|    total_timesteps    | 19914752    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020515751 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.945       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0112     |\n",
      "|    mean_step_reward   | 0.12635615  |\n",
      "|    n_updates          | 93.75 %     |\n",
      "|    policyGradLoss     | -0.0163     |\n",
      "|    value_loss         | 0.339       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 751         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 348         |\n",
      "|    total_timesteps    | 19922944    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026496377 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0196     |\n",
      "|    mean_step_reward   | 0.110064656 |\n",
      "|    n_updates          | 96.88 %     |\n",
      "|    policyGradLoss     | -0.0166     |\n",
      "|    value_loss         | 0.223       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Run_75.zip\n",
      "[EVAL] Mean Return: 151.602, Best Return: 158.268\n",
      "Saved video to ./runs_smw/videos/Run/Run_75_151.60.mp4\n",
      "\n",
      "=== Round 77 | Learn 262144 steps (Total trained: 19922944) ===\n",
      "Logging to ./runs_smw/tb/Run_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1071     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 19931136 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 854         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 19          |\n",
      "|    total_timesteps    | 19939328    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023568373 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0447     |\n",
      "|    mean_step_reward   | 0.12243797  |\n",
      "|    n_updates          | 3.12 %      |\n",
      "|    policyGradLoss     | -0.0198     |\n",
      "|    value_loss         | 0.193       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 804         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 30          |\n",
      "|    total_timesteps    | 19947520    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028509289 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00606     |\n",
      "|    mean_step_reward   | 0.10623837  |\n",
      "|    n_updates          | 6.25 %      |\n",
      "|    policyGradLoss     | -0.0198     |\n",
      "|    value_loss         | 0.234       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 786        |\n",
      "|    iterations         | 4          |\n",
      "|    time_elapsed       | 41         |\n",
      "|    total_timesteps    | 19955712   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02427112 |\n",
      "|    entropy_loss       | -1.84      |\n",
      "|    explained_variance | 0.966      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0396    |\n",
      "|    mean_step_reward   | 0.13065228 |\n",
      "|    n_updates          | 9.38 %     |\n",
      "|    policyGradLoss     | -0.0179    |\n",
      "|    value_loss         | 0.234      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 52          |\n",
      "|    total_timesteps    | 19963904    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026023075 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.952       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0188      |\n",
      "|    mean_step_reward   | 0.0969118   |\n",
      "|    n_updates          | 12.50 %     |\n",
      "|    policyGradLoss     | -0.0173     |\n",
      "|    value_loss         | 0.277       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 63          |\n",
      "|    total_timesteps    | 19972096    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022970345 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0324     |\n",
      "|    mean_step_reward   | 0.116447754 |\n",
      "|    n_updates          | 15.62 %     |\n",
      "|    policyGradLoss     | -0.02       |\n",
      "|    value_loss         | 0.222       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 764         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 75          |\n",
      "|    total_timesteps    | 19980288    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02328976  |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0319      |\n",
      "|    mean_step_reward   | 0.107426345 |\n",
      "|    n_updates          | 18.75 %     |\n",
      "|    policyGradLoss     | -0.02       |\n",
      "|    value_loss         | 0.221       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 756         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 86          |\n",
      "|    total_timesteps    | 19988480    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019391604 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0442     |\n",
      "|    mean_step_reward   | 0.12625328  |\n",
      "|    n_updates          | 21.88 %     |\n",
      "|    policyGradLoss     | -0.0151     |\n",
      "|    value_loss         | 0.266       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 749         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 98          |\n",
      "|    total_timesteps    | 19996672    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025184607 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.052      |\n",
      "|    mean_step_reward   | 0.11593825  |\n",
      "|    n_updates          | 25.00 %     |\n",
      "|    policyGradLoss     | -0.0176     |\n",
      "|    value_loss         | 0.159       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 746         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 109         |\n",
      "|    total_timesteps    | 20004864    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023087092 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.947       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0337     |\n",
      "|    mean_step_reward   | 0.12023011  |\n",
      "|    n_updates          | 28.12 %     |\n",
      "|    policyGradLoss     | -0.0162     |\n",
      "|    value_loss         | 0.341       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 745         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 120         |\n",
      "|    total_timesteps    | 20013056    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023713175 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.937       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00916    |\n",
      "|    mean_step_reward   | 0.091572024 |\n",
      "|    n_updates          | 31.25 %     |\n",
      "|    policyGradLoss     | -0.0163     |\n",
      "|    value_loss         | 0.269       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 744        |\n",
      "|    iterations         | 12         |\n",
      "|    time_elapsed       | 132        |\n",
      "|    total_timesteps    | 20021248   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02889894 |\n",
      "|    entropy_loss       | -1.82      |\n",
      "|    explained_variance | 0.967      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0375    |\n",
      "|    mean_step_reward   | 0.12790595 |\n",
      "|    n_updates          | 34.38 %    |\n",
      "|    policyGradLoss     | -0.022     |\n",
      "|    value_loss         | 0.244      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 743         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 143         |\n",
      "|    total_timesteps    | 20029440    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027370952 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0221     |\n",
      "|    mean_step_reward   | 0.11701592  |\n",
      "|    n_updates          | 37.50 %     |\n",
      "|    policyGradLoss     | -0.0182     |\n",
      "|    value_loss         | 0.204       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 742         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 154         |\n",
      "|    total_timesteps    | 20037632    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020454023 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0542      |\n",
      "|    mean_step_reward   | 0.11099045  |\n",
      "|    n_updates          | 40.62 %     |\n",
      "|    policyGradLoss     | -0.0167     |\n",
      "|    value_loss         | 0.319       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 745         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 164         |\n",
      "|    total_timesteps    | 20045824    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030468546 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0538     |\n",
      "|    mean_step_reward   | 0.1168333   |\n",
      "|    n_updates          | 43.75 %     |\n",
      "|    policyGradLoss     | -0.023      |\n",
      "|    value_loss         | 0.23        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 753         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 173         |\n",
      "|    total_timesteps    | 20054016    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019999515 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.912       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0375     |\n",
      "|    mean_step_reward   | 0.108039394 |\n",
      "|    n_updates          | 46.88 %     |\n",
      "|    policyGradLoss     | -0.017      |\n",
      "|    value_loss         | 0.308       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 759         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 183         |\n",
      "|    total_timesteps    | 20062208    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020693809 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.944       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0117      |\n",
      "|    mean_step_reward   | 0.10414171  |\n",
      "|    n_updates          | 50.00 %     |\n",
      "|    policyGradLoss     | -0.0152     |\n",
      "|    value_loss         | 0.381       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 192         |\n",
      "|    total_timesteps    | 20070400    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015339434 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.946       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0337      |\n",
      "|    mean_step_reward   | 0.10407272  |\n",
      "|    n_updates          | 53.12 %     |\n",
      "|    policyGradLoss     | -0.0156     |\n",
      "|    value_loss         | 0.356       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 764         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 203         |\n",
      "|    total_timesteps    | 20078592    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02093177  |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0348     |\n",
      "|    mean_step_reward   | 0.122664735 |\n",
      "|    n_updates          | 56.25 %     |\n",
      "|    policyGradLoss     | -0.0143     |\n",
      "|    value_loss         | 0.256       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 762         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 214         |\n",
      "|    total_timesteps    | 20086784    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027581792 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0641     |\n",
      "|    mean_step_reward   | 0.11699155  |\n",
      "|    n_updates          | 59.38 %     |\n",
      "|    policyGradLoss     | -0.0217     |\n",
      "|    value_loss         | 0.193       |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 761       |\n",
      "|    iterations         | 21        |\n",
      "|    time_elapsed       | 225       |\n",
      "|    total_timesteps    | 20094976  |\n",
      "| train/                |           |\n",
      "|    approx_kl          | 0.0222884 |\n",
      "|    entropy_loss       | -1.86     |\n",
      "|    explained_variance | 0.96      |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    loss               | 0.0476    |\n",
      "|    mean_step_reward   | 0.1184626 |\n",
      "|    n_updates          | 62.50 %   |\n",
      "|    policyGradLoss     | -0.0186   |\n",
      "|    value_loss         | 0.235     |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 760         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 236         |\n",
      "|    total_timesteps    | 20103168    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022110004 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.954       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0925      |\n",
      "|    mean_step_reward   | 0.106207386 |\n",
      "|    n_updates          | 65.62 %     |\n",
      "|    policyGradLoss     | -0.017      |\n",
      "|    value_loss         | 0.3         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 759         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 248         |\n",
      "|    total_timesteps    | 20111360    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028124213 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0277     |\n",
      "|    mean_step_reward   | 0.12593238  |\n",
      "|    n_updates          | 68.75 %     |\n",
      "|    policyGradLoss     | -0.0216     |\n",
      "|    value_loss         | 0.143       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 755         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 260         |\n",
      "|    total_timesteps    | 20119552    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026845958 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.952       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0161     |\n",
      "|    mean_step_reward   | 0.10144481  |\n",
      "|    n_updates          | 71.88 %     |\n",
      "|    policyGradLoss     | -0.0186     |\n",
      "|    value_loss         | 0.309       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 754         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 271         |\n",
      "|    total_timesteps    | 20127744    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026335606 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.029      |\n",
      "|    mean_step_reward   | 0.12945169  |\n",
      "|    n_updates          | 75.00 %     |\n",
      "|    policyGradLoss     | -0.0224     |\n",
      "|    value_loss         | 0.231       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 753         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 282         |\n",
      "|    total_timesteps    | 20135936    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025267541 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0349     |\n",
      "|    mean_step_reward   | 0.11108385  |\n",
      "|    n_updates          | 78.12 %     |\n",
      "|    policyGradLoss     | -0.0188     |\n",
      "|    value_loss         | 0.194       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 752        |\n",
      "|    iterations         | 27         |\n",
      "|    time_elapsed       | 293        |\n",
      "|    total_timesteps    | 20144128   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02272381 |\n",
      "|    entropy_loss       | -1.87      |\n",
      "|    explained_variance | 0.953      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.0785     |\n",
      "|    mean_step_reward   | 0.09416413 |\n",
      "|    n_updates          | 81.25 %    |\n",
      "|    policyGradLoss     | -0.015     |\n",
      "|    value_loss         | 0.4        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 752        |\n",
      "|    iterations         | 28         |\n",
      "|    time_elapsed       | 304        |\n",
      "|    total_timesteps    | 20152320   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02354145 |\n",
      "|    entropy_loss       | -1.82      |\n",
      "|    explained_variance | 0.964      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0179    |\n",
      "|    mean_step_reward   | 0.1184531  |\n",
      "|    n_updates          | 84.38 %    |\n",
      "|    policyGradLoss     | -0.017     |\n",
      "|    value_loss         | 0.303      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 751         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 316         |\n",
      "|    total_timesteps    | 20160512    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025035815 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0461     |\n",
      "|    mean_step_reward   | 0.09806967  |\n",
      "|    n_updates          | 87.50 %     |\n",
      "|    policyGradLoss     | -0.0192     |\n",
      "|    value_loss         | 0.216       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 750         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 327         |\n",
      "|    total_timesteps    | 20168704    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018911941 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0239     |\n",
      "|    mean_step_reward   | 0.12816152  |\n",
      "|    n_updates          | 90.62 %     |\n",
      "|    policyGradLoss     | -0.016      |\n",
      "|    value_loss         | 0.26        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 748         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 339         |\n",
      "|    total_timesteps    | 20176896    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024693282 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0535     |\n",
      "|    mean_step_reward   | 0.11547347  |\n",
      "|    n_updates          | 93.75 %     |\n",
      "|    policyGradLoss     | -0.0184     |\n",
      "|    value_loss         | 0.159       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 746         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 350         |\n",
      "|    total_timesteps    | 20185088    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020604543 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0359     |\n",
      "|    mean_step_reward   | 0.104256645 |\n",
      "|    n_updates          | 96.88 %     |\n",
      "|    policyGradLoss     | -0.0195     |\n",
      "|    value_loss         | 0.222       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Run_76.zip\n",
      "[EVAL] Mean Return: 155.424, Best Return: 162.090\n",
      "Saved video to ./runs_smw/videos/Run/Run_76_155.42.mp4\n",
      "\n",
      "=== Round 78 | Learn 262144 steps (Total trained: 20185088) ===\n",
      "Logging to ./runs_smw/tb/Run_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1185     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 20193280 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 917         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 20201472    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018473424 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.92        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.000739    |\n",
      "|    mean_step_reward   | 0.11595009  |\n",
      "|    n_updates          | 3.12 %      |\n",
      "|    policyGradLoss     | -0.0146     |\n",
      "|    value_loss         | 0.342       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 843        |\n",
      "|    iterations         | 3          |\n",
      "|    time_elapsed       | 29         |\n",
      "|    total_timesteps    | 20209664   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01843156 |\n",
      "|    entropy_loss       | -1.8       |\n",
      "|    explained_variance | 0.939      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.08       |\n",
      "|    mean_step_reward   | 0.11987008 |\n",
      "|    n_updates          | 6.25 %     |\n",
      "|    policyGradLoss     | -0.0151    |\n",
      "|    value_loss         | 0.427      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 804         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 40          |\n",
      "|    total_timesteps    | 20217856    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021437846 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.942       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0225     |\n",
      "|    mean_step_reward   | 0.09265657  |\n",
      "|    n_updates          | 9.38 %      |\n",
      "|    policyGradLoss     | -0.0186     |\n",
      "|    value_loss         | 0.3         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 52          |\n",
      "|    total_timesteps    | 20226048    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020661406 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.954       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0344     |\n",
      "|    mean_step_reward   | 0.12576875  |\n",
      "|    n_updates          | 12.50 %     |\n",
      "|    policyGradLoss     | -0.0157     |\n",
      "|    value_loss         | 0.288       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 63          |\n",
      "|    total_timesteps    | 20234240    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018279443 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.936       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0154     |\n",
      "|    mean_step_reward   | 0.10422346  |\n",
      "|    n_updates          | 15.62 %     |\n",
      "|    policyGradLoss     | -0.0164     |\n",
      "|    value_loss         | 0.276       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 765        |\n",
      "|    iterations         | 7          |\n",
      "|    time_elapsed       | 74         |\n",
      "|    total_timesteps    | 20242432   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01850129 |\n",
      "|    entropy_loss       | -1.88      |\n",
      "|    explained_variance | 0.941      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0176    |\n",
      "|    mean_step_reward   | 0.10327361 |\n",
      "|    n_updates          | 18.75 %    |\n",
      "|    policyGradLoss     | -0.0179    |\n",
      "|    value_loss         | 0.352      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 761         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 86          |\n",
      "|    total_timesteps    | 20250624    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.0195911   |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.95        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0283     |\n",
      "|    mean_step_reward   | 0.105280176 |\n",
      "|    n_updates          | 21.88 %     |\n",
      "|    policyGradLoss     | -0.0192     |\n",
      "|    value_loss         | 0.271       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 759         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 97          |\n",
      "|    total_timesteps    | 20258816    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021525986 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.949       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0371     |\n",
      "|    mean_step_reward   | 0.10745258  |\n",
      "|    n_updates          | 25.00 %     |\n",
      "|    policyGradLoss     | -0.0189     |\n",
      "|    value_loss         | 0.233       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 758         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 108         |\n",
      "|    total_timesteps    | 20267008    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022378571 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.949       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.035      |\n",
      "|    mean_step_reward   | 0.11559373  |\n",
      "|    n_updates          | 28.12 %     |\n",
      "|    policyGradLoss     | -0.0186     |\n",
      "|    value_loss         | 0.25        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 753         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 119         |\n",
      "|    total_timesteps    | 20275200    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028093107 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0387     |\n",
      "|    mean_step_reward   | 0.114068404 |\n",
      "|    n_updates          | 31.25 %     |\n",
      "|    policyGradLoss     | -0.0192     |\n",
      "|    value_loss         | 0.214       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 760         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 129         |\n",
      "|    total_timesteps    | 20283392    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023696594 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0125      |\n",
      "|    mean_step_reward   | 0.123340204 |\n",
      "|    n_updates          | 34.38 %     |\n",
      "|    policyGradLoss     | -0.019      |\n",
      "|    value_loss         | 0.288       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 768        |\n",
      "|    iterations         | 13         |\n",
      "|    time_elapsed       | 138        |\n",
      "|    total_timesteps    | 20291584   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02605521 |\n",
      "|    entropy_loss       | -1.92      |\n",
      "|    explained_variance | 0.967      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0267    |\n",
      "|    mean_step_reward   | 0.09520103 |\n",
      "|    n_updates          | 37.50 %    |\n",
      "|    policyGradLoss     | -0.0198    |\n",
      "|    value_loss         | 0.206      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 147         |\n",
      "|    total_timesteps    | 20299776    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021440316 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00825     |\n",
      "|    mean_step_reward   | 0.13180815  |\n",
      "|    n_updates          | 40.62 %     |\n",
      "|    policyGradLoss     | -0.0172     |\n",
      "|    value_loss         | 0.288       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 774        |\n",
      "|    iterations         | 15         |\n",
      "|    time_elapsed       | 158        |\n",
      "|    total_timesteps    | 20307968   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02511923 |\n",
      "|    entropy_loss       | -1.89      |\n",
      "|    explained_variance | 0.956      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.00694    |\n",
      "|    mean_step_reward   | 0.09805663 |\n",
      "|    n_updates          | 43.75 %    |\n",
      "|    policyGradLoss     | -0.0172    |\n",
      "|    value_loss         | 0.265      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 771        |\n",
      "|    iterations         | 16         |\n",
      "|    time_elapsed       | 169        |\n",
      "|    total_timesteps    | 20316160   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.0252728  |\n",
      "|    entropy_loss       | -1.83      |\n",
      "|    explained_variance | 0.965      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0356    |\n",
      "|    mean_step_reward   | 0.12496325 |\n",
      "|    n_updates          | 46.88 %    |\n",
      "|    policyGradLoss     | -0.0218    |\n",
      "|    value_loss         | 0.236      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 181         |\n",
      "|    total_timesteps    | 20324352    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024622058 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.044      |\n",
      "|    mean_step_reward   | 0.11066028  |\n",
      "|    n_updates          | 50.00 %     |\n",
      "|    policyGradLoss     | -0.018      |\n",
      "|    value_loss         | 0.258       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 192         |\n",
      "|    total_timesteps    | 20332544    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028256262 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.017       |\n",
      "|    mean_step_reward   | 0.12195231  |\n",
      "|    n_updates          | 53.12 %     |\n",
      "|    policyGradLoss     | -0.0217     |\n",
      "|    value_loss         | 0.198       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 765         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 203         |\n",
      "|    total_timesteps    | 20340736    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021691121 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.949       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00424    |\n",
      "|    mean_step_reward   | 0.10468974  |\n",
      "|    n_updates          | 56.25 %     |\n",
      "|    policyGradLoss     | -0.0151     |\n",
      "|    value_loss         | 0.292       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 762         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 214         |\n",
      "|    total_timesteps    | 20348928    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025100924 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00857     |\n",
      "|    mean_step_reward   | 0.106186666 |\n",
      "|    n_updates          | 59.38 %     |\n",
      "|    policyGradLoss     | -0.0205     |\n",
      "|    value_loss         | 0.254       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 760         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 226         |\n",
      "|    total_timesteps    | 20357120    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021630373 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.943       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.01       |\n",
      "|    mean_step_reward   | 0.10113897  |\n",
      "|    n_updates          | 62.50 %     |\n",
      "|    policyGradLoss     | -0.0182     |\n",
      "|    value_loss         | 0.36        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 757         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 237         |\n",
      "|    total_timesteps    | 20365312    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018912062 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0161      |\n",
      "|    mean_step_reward   | 0.11453609  |\n",
      "|    n_updates          | 65.62 %     |\n",
      "|    policyGradLoss     | -0.0182     |\n",
      "|    value_loss         | 0.311       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 755         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 249         |\n",
      "|    total_timesteps    | 20373504    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020546809 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.954       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.019      |\n",
      "|    mean_step_reward   | 0.119610935 |\n",
      "|    n_updates          | 68.75 %     |\n",
      "|    policyGradLoss     | -0.018      |\n",
      "|    value_loss         | 0.312       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 754         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 260         |\n",
      "|    total_timesteps    | 20381696    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.0197124   |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.022      |\n",
      "|    mean_step_reward   | 0.117855266 |\n",
      "|    n_updates          | 71.88 %     |\n",
      "|    policyGradLoss     | -0.0192     |\n",
      "|    value_loss         | 0.227       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 754         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 271         |\n",
      "|    total_timesteps    | 20389888    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024449773 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0312     |\n",
      "|    mean_step_reward   | 0.10247481  |\n",
      "|    n_updates          | 75.00 %     |\n",
      "|    policyGradLoss     | -0.0189     |\n",
      "|    value_loss         | 0.279       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 754         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 282         |\n",
      "|    total_timesteps    | 20398080    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022955444 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0155      |\n",
      "|    mean_step_reward   | 0.11379345  |\n",
      "|    n_updates          | 78.12 %     |\n",
      "|    policyGradLoss     | -0.0188     |\n",
      "|    value_loss         | 0.362       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 754         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 293         |\n",
      "|    total_timesteps    | 20406272    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025428193 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.957       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.013      |\n",
      "|    mean_step_reward   | 0.10377669  |\n",
      "|    n_updates          | 81.25 %     |\n",
      "|    policyGradLoss     | -0.0197     |\n",
      "|    value_loss         | 0.279       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 752         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 304         |\n",
      "|    total_timesteps    | 20414464    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020125609 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0133     |\n",
      "|    mean_step_reward   | 0.12773827  |\n",
      "|    n_updates          | 84.38 %     |\n",
      "|    policyGradLoss     | -0.0145     |\n",
      "|    value_loss         | 0.263       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 750         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 316         |\n",
      "|    total_timesteps    | 20422656    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027636232 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0301     |\n",
      "|    mean_step_reward   | 0.10522194  |\n",
      "|    n_updates          | 87.50 %     |\n",
      "|    policyGradLoss     | -0.0204     |\n",
      "|    value_loss         | 0.225       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 749         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 327         |\n",
      "|    total_timesteps    | 20430848    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028919933 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0202      |\n",
      "|    mean_step_reward   | 0.11840574  |\n",
      "|    n_updates          | 90.62 %     |\n",
      "|    policyGradLoss     | -0.0153     |\n",
      "|    value_loss         | 0.212       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 749        |\n",
      "|    iterations         | 31         |\n",
      "|    time_elapsed       | 338        |\n",
      "|    total_timesteps    | 20439040   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.0284729  |\n",
      "|    entropy_loss       | -1.85      |\n",
      "|    explained_variance | 0.966      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.0105     |\n",
      "|    mean_step_reward   | 0.10794437 |\n",
      "|    n_updates          | 93.75 %    |\n",
      "|    policyGradLoss     | -0.022     |\n",
      "|    value_loss         | 0.174      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 749         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 349         |\n",
      "|    total_timesteps    | 20447232    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021770924 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0388     |\n",
      "|    mean_step_reward   | 0.12171847  |\n",
      "|    n_updates          | 96.88 %     |\n",
      "|    policyGradLoss     | -0.0142     |\n",
      "|    value_loss         | 0.229       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Run_77.zip\n",
      "[EVAL] Mean Return: 82.918, Best Return: 87.251\n",
      "Saved video to ./runs_smw/videos/Run/Run_77_82.92.mp4\n",
      "\n",
      "=== Round 79 | Learn 262144 steps (Total trained: 20447232) ===\n",
      "Logging to ./runs_smw/tb/Run_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1139     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 20455424 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 893         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 20463616    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025453366 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0405     |\n",
      "|    mean_step_reward   | 0.12870435  |\n",
      "|    n_updates          | 3.12 %      |\n",
      "|    policyGradLoss     | -0.0178     |\n",
      "|    value_loss         | 0.228       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 834         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 29          |\n",
      "|    total_timesteps    | 20471808    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028380785 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00751    |\n",
      "|    mean_step_reward   | 0.109008685 |\n",
      "|    n_updates          | 6.25 %      |\n",
      "|    policyGradLoss     | -0.019      |\n",
      "|    value_loss         | 0.202       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 40          |\n",
      "|    total_timesteps    | 20480000    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023335528 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.944       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0375     |\n",
      "|    mean_step_reward   | 0.118710585 |\n",
      "|    n_updates          | 9.38 %      |\n",
      "|    policyGradLoss     | -0.0153     |\n",
      "|    value_loss         | 0.302       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 794         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 51          |\n",
      "|    total_timesteps    | 20488192    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027637161 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.957       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0171     |\n",
      "|    mean_step_reward   | 0.10874209  |\n",
      "|    n_updates          | 12.50 %     |\n",
      "|    policyGradLoss     | -0.0159     |\n",
      "|    value_loss         | 0.234       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 63          |\n",
      "|    total_timesteps    | 20496384    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020841934 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.939       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0986      |\n",
      "|    mean_step_reward   | 0.110538036 |\n",
      "|    n_updates          | 15.62 %     |\n",
      "|    policyGradLoss     | -0.0138     |\n",
      "|    value_loss         | 0.394       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 74          |\n",
      "|    total_timesteps    | 20504576    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020651706 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.932       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -2.68e-05   |\n",
      "|    mean_step_reward   | 0.1146484   |\n",
      "|    n_updates          | 18.75 %     |\n",
      "|    policyGradLoss     | -0.0167     |\n",
      "|    value_loss         | 0.353       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 764        |\n",
      "|    iterations         | 8          |\n",
      "|    time_elapsed       | 85         |\n",
      "|    total_timesteps    | 20512768   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01954421 |\n",
      "|    entropy_loss       | -1.89      |\n",
      "|    explained_variance | 0.921      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.00674    |\n",
      "|    mean_step_reward   | 0.09712212 |\n",
      "|    n_updates          | 21.88 %    |\n",
      "|    policyGradLoss     | -0.0141    |\n",
      "|    value_loss         | 0.391      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 94          |\n",
      "|    total_timesteps    | 20520960    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026605403 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.038      |\n",
      "|    mean_step_reward   | 0.124823436 |\n",
      "|    n_updates          | 25.00 %     |\n",
      "|    policyGradLoss     | -0.0207     |\n",
      "|    value_loss         | 0.223       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 789        |\n",
      "|    iterations         | 10         |\n",
      "|    time_elapsed       | 103        |\n",
      "|    total_timesteps    | 20529152   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02389037 |\n",
      "|    entropy_loss       | -1.88      |\n",
      "|    explained_variance | 0.949      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.0497     |\n",
      "|    mean_step_reward   | 0.10468702 |\n",
      "|    n_updates          | 28.12 %    |\n",
      "|    policyGradLoss     | -0.0184    |\n",
      "|    value_loss         | 0.253      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 796        |\n",
      "|    iterations         | 11         |\n",
      "|    time_elapsed       | 113        |\n",
      "|    total_timesteps    | 20537344   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02415134 |\n",
      "|    entropy_loss       | -1.83      |\n",
      "|    explained_variance | 0.97       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.015     |\n",
      "|    mean_step_reward   | 0.11707706 |\n",
      "|    n_updates          | 31.25 %    |\n",
      "|    policyGradLoss     | -0.0201    |\n",
      "|    value_loss         | 0.249      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 796         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 123         |\n",
      "|    total_timesteps    | 20545536    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023696242 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.954       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00736    |\n",
      "|    mean_step_reward   | 0.12116032  |\n",
      "|    n_updates          | 34.38 %     |\n",
      "|    policyGradLoss     | -0.0172     |\n",
      "|    value_loss         | 0.294       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 790         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 134         |\n",
      "|    total_timesteps    | 20553728    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025122382 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0105     |\n",
      "|    mean_step_reward   | 0.1072985   |\n",
      "|    n_updates          | 37.50 %     |\n",
      "|    policyGradLoss     | -0.0193     |\n",
      "|    value_loss         | 0.23        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 145         |\n",
      "|    total_timesteps    | 20561920    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01762885  |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.945       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0214     |\n",
      "|    mean_step_reward   | 0.118529804 |\n",
      "|    n_updates          | 40.62 %     |\n",
      "|    policyGradLoss     | -0.0131     |\n",
      "|    value_loss         | 0.315       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 156         |\n",
      "|    total_timesteps    | 20570112    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028316386 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.02       |\n",
      "|    mean_step_reward   | 0.10625601  |\n",
      "|    n_updates          | 43.75 %     |\n",
      "|    policyGradLoss     | -0.0214     |\n",
      "|    value_loss         | 0.19        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 167         |\n",
      "|    total_timesteps    | 20578304    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020537578 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.926       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00205    |\n",
      "|    mean_step_reward   | 0.09911761  |\n",
      "|    n_updates          | 46.88 %     |\n",
      "|    policyGradLoss     | -0.00968    |\n",
      "|    value_loss         | 0.421       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 178         |\n",
      "|    total_timesteps    | 20586496    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02684552  |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.954       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.032      |\n",
      "|    mean_step_reward   | 0.116993695 |\n",
      "|    n_updates          | 50.00 %     |\n",
      "|    policyGradLoss     | -0.0194     |\n",
      "|    value_loss         | 0.276       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 190         |\n",
      "|    total_timesteps    | 20594688    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02676319  |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0298     |\n",
      "|    mean_step_reward   | 0.105034724 |\n",
      "|    n_updates          | 53.12 %     |\n",
      "|    policyGradLoss     | -0.0188     |\n",
      "|    value_loss         | 0.223       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 201         |\n",
      "|    total_timesteps    | 20602880    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024923254 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.954       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0615      |\n",
      "|    mean_step_reward   | 0.10665322  |\n",
      "|    n_updates          | 56.25 %     |\n",
      "|    policyGradLoss     | -0.0176     |\n",
      "|    value_loss         | 0.316       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 213         |\n",
      "|    total_timesteps    | 20611072    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021998357 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.946       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0461     |\n",
      "|    mean_step_reward   | 0.108627796 |\n",
      "|    n_updates          | 59.38 %     |\n",
      "|    policyGradLoss     | -0.017      |\n",
      "|    value_loss         | 0.263       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 224         |\n",
      "|    total_timesteps    | 20619264    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027132709 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0349     |\n",
      "|    mean_step_reward   | 0.110847384 |\n",
      "|    n_updates          | 62.50 %     |\n",
      "|    policyGradLoss     | -0.0186     |\n",
      "|    value_loss         | 0.255       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 765        |\n",
      "|    iterations         | 22         |\n",
      "|    time_elapsed       | 235        |\n",
      "|    total_timesteps    | 20627456   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03023021 |\n",
      "|    entropy_loss       | -1.81      |\n",
      "|    explained_variance | 0.968      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0636    |\n",
      "|    mean_step_reward   | 0.12558421 |\n",
      "|    n_updates          | 65.62 %    |\n",
      "|    policyGradLoss     | -0.0213    |\n",
      "|    value_loss         | 0.159      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 764         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 246         |\n",
      "|    total_timesteps    | 20635648    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023049276 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.035      |\n",
      "|    mean_step_reward   | 0.10144841  |\n",
      "|    n_updates          | 68.75 %     |\n",
      "|    policyGradLoss     | -0.0185     |\n",
      "|    value_loss         | 0.307       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 762         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 257         |\n",
      "|    total_timesteps    | 20643840    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026092589 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.952       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0118     |\n",
      "|    mean_step_reward   | 0.12467803  |\n",
      "|    n_updates          | 71.88 %     |\n",
      "|    policyGradLoss     | -0.0172     |\n",
      "|    value_loss         | 0.286       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 761         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 269         |\n",
      "|    total_timesteps    | 20652032    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026459435 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.945       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.143       |\n",
      "|    mean_step_reward   | 0.08439253  |\n",
      "|    n_updates          | 75.00 %     |\n",
      "|    policyGradLoss     | -0.0165     |\n",
      "|    value_loss         | 0.436       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 758         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 280         |\n",
      "|    total_timesteps    | 20660224    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024106685 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0626     |\n",
      "|    mean_step_reward   | 0.1375288   |\n",
      "|    n_updates          | 78.12 %     |\n",
      "|    policyGradLoss     | -0.0194     |\n",
      "|    value_loss         | 0.194       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 756         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 292         |\n",
      "|    total_timesteps    | 20668416    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025678309 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0114     |\n",
      "|    mean_step_reward   | 0.106074125 |\n",
      "|    n_updates          | 81.25 %     |\n",
      "|    policyGradLoss     | -0.0172     |\n",
      "|    value_loss         | 0.198       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 755        |\n",
      "|    iterations         | 28         |\n",
      "|    time_elapsed       | 303        |\n",
      "|    total_timesteps    | 20676608   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02581925 |\n",
      "|    entropy_loss       | -1.81      |\n",
      "|    explained_variance | 0.964      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0512    |\n",
      "|    mean_step_reward   | 0.12304096 |\n",
      "|    n_updates          | 84.38 %    |\n",
      "|    policyGradLoss     | -0.0188    |\n",
      "|    value_loss         | 0.221      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 754        |\n",
      "|    iterations         | 29         |\n",
      "|    time_elapsed       | 314        |\n",
      "|    total_timesteps    | 20684800   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02563441 |\n",
      "|    entropy_loss       | -1.85      |\n",
      "|    explained_variance | 0.957      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0196    |\n",
      "|    mean_step_reward   | 0.10712825 |\n",
      "|    n_updates          | 87.50 %    |\n",
      "|    policyGradLoss     | -0.0201    |\n",
      "|    value_loss         | 0.257      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 753         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 326         |\n",
      "|    total_timesteps    | 20692992    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030448748 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0351     |\n",
      "|    mean_step_reward   | 0.11740829  |\n",
      "|    n_updates          | 90.62 %     |\n",
      "|    policyGradLoss     | -0.0203     |\n",
      "|    value_loss         | 0.179       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 753        |\n",
      "|    iterations         | 31         |\n",
      "|    time_elapsed       | 336        |\n",
      "|    total_timesteps    | 20701184   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03072967 |\n",
      "|    entropy_loss       | -1.8       |\n",
      "|    explained_variance | 0.969      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.048     |\n",
      "|    mean_step_reward   | 0.12580615 |\n",
      "|    n_updates          | 93.75 %    |\n",
      "|    policyGradLoss     | -0.0207    |\n",
      "|    value_loss         | 0.193      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 753         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 348         |\n",
      "|    total_timesteps    | 20709376    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025278797 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.945       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0219      |\n",
      "|    mean_step_reward   | 0.099956244 |\n",
      "|    n_updates          | 96.88 %     |\n",
      "|    policyGradLoss     | -0.0146     |\n",
      "|    value_loss         | 0.345       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Run_78.zip\n",
      "[EVAL] Mean Return: 153.911, Best Return: 160.911\n",
      "Saved video to ./runs_smw/videos/Run/Run_78_153.91.mp4\n",
      "\n",
      "=== Round 80 | Learn 262144 steps (Total trained: 20709376) ===\n",
      "Logging to ./runs_smw/tb/Run_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1081     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 20717568 |\n",
      "---------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 861        |\n",
      "|    iterations         | 2          |\n",
      "|    time_elapsed       | 19         |\n",
      "|    total_timesteps    | 20725760   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02174374 |\n",
      "|    entropy_loss       | -1.86      |\n",
      "|    explained_variance | 0.969      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0596    |\n",
      "|    mean_step_reward   | 0.1058431  |\n",
      "|    n_updates          | 3.12 %     |\n",
      "|    policyGradLoss     | -0.0202    |\n",
      "|    value_loss         | 0.218      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 815         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 30          |\n",
      "|    total_timesteps    | 20733952    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019694254 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.949       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0566      |\n",
      "|    mean_step_reward   | 0.13633081  |\n",
      "|    n_updates          | 6.25 %      |\n",
      "|    policyGradLoss     | -0.0149     |\n",
      "|    value_loss         | 0.293       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 794        |\n",
      "|    iterations         | 4          |\n",
      "|    time_elapsed       | 41         |\n",
      "|    total_timesteps    | 20742144   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02491779 |\n",
      "|    entropy_loss       | -1.83      |\n",
      "|    explained_variance | 0.965      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0366    |\n",
      "|    mean_step_reward   | 0.10717063 |\n",
      "|    n_updates          | 9.38 %     |\n",
      "|    policyGradLoss     | -0.0199    |\n",
      "|    value_loss         | 0.2        |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 802         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 51          |\n",
      "|    total_timesteps    | 20750336    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017600011 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.944       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0363     |\n",
      "|    mean_step_reward   | 0.119550265 |\n",
      "|    n_updates          | 12.50 %     |\n",
      "|    policyGradLoss     | -0.0149     |\n",
      "|    value_loss         | 0.309       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 820        |\n",
      "|    iterations         | 6          |\n",
      "|    time_elapsed       | 59         |\n",
      "|    total_timesteps    | 20758528   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.0205772  |\n",
      "|    entropy_loss       | -1.83      |\n",
      "|    explained_variance | 0.958      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0443    |\n",
      "|    mean_step_reward   | 0.11587305 |\n",
      "|    n_updates          | 15.62 %    |\n",
      "|    policyGradLoss     | -0.0186    |\n",
      "|    value_loss         | 0.187      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 829        |\n",
      "|    iterations         | 7          |\n",
      "|    time_elapsed       | 69         |\n",
      "|    total_timesteps    | 20766720   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02073615 |\n",
      "|    entropy_loss       | -1.81      |\n",
      "|    explained_variance | 0.949      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0186    |\n",
      "|    mean_step_reward   | 0.11491379 |\n",
      "|    n_updates          | 18.75 %    |\n",
      "|    policyGradLoss     | -0.018     |\n",
      "|    value_loss         | 0.286      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 833        |\n",
      "|    iterations         | 8          |\n",
      "|    time_elapsed       | 78         |\n",
      "|    total_timesteps    | 20774912   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03109628 |\n",
      "|    entropy_loss       | -1.81      |\n",
      "|    explained_variance | 0.974      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.045     |\n",
      "|    mean_step_reward   | 0.13164948 |\n",
      "|    n_updates          | 21.88 %    |\n",
      "|    policyGradLoss     | -0.0222    |\n",
      "|    value_loss         | 0.156      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 831         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 88          |\n",
      "|    total_timesteps    | 20783104    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020748049 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.94        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.000701   |\n",
      "|    mean_step_reward   | 0.10412288  |\n",
      "|    n_updates          | 25.00 %     |\n",
      "|    policyGradLoss     | -0.017      |\n",
      "|    value_loss         | 0.337       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 819         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 99          |\n",
      "|    total_timesteps    | 20791296    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024457358 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0345     |\n",
      "|    mean_step_reward   | 0.124619916 |\n",
      "|    n_updates          | 28.12 %     |\n",
      "|    policyGradLoss     | -0.0175     |\n",
      "|    value_loss         | 0.179       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 806         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 111         |\n",
      "|    total_timesteps    | 20799488    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027387548 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.958       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0949      |\n",
      "|    mean_step_reward   | 0.10519284  |\n",
      "|    n_updates          | 31.25 %     |\n",
      "|    policyGradLoss     | -0.0179     |\n",
      "|    value_loss         | 0.243       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 797         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 123         |\n",
      "|    total_timesteps    | 20807680    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024096623 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0583     |\n",
      "|    mean_step_reward   | 0.12670243  |\n",
      "|    n_updates          | 34.38 %     |\n",
      "|    policyGradLoss     | -0.018      |\n",
      "|    value_loss         | 0.208       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 791         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 134         |\n",
      "|    total_timesteps    | 20815872    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026786407 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0452     |\n",
      "|    mean_step_reward   | 0.11273407  |\n",
      "|    n_updates          | 37.50 %     |\n",
      "|    policyGradLoss     | -0.0195     |\n",
      "|    value_loss         | 0.18        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 145         |\n",
      "|    total_timesteps    | 20824064    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029232522 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0239     |\n",
      "|    mean_step_reward   | 0.12486237  |\n",
      "|    n_updates          | 40.62 %     |\n",
      "|    policyGradLoss     | -0.0205     |\n",
      "|    value_loss         | 0.204       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 156         |\n",
      "|    total_timesteps    | 20832256    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027831582 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0416     |\n",
      "|    mean_step_reward   | 0.11184096  |\n",
      "|    n_updates          | 43.75 %     |\n",
      "|    policyGradLoss     | -0.0225     |\n",
      "|    value_loss         | 0.195       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 167         |\n",
      "|    total_timesteps    | 20840448    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025378957 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0508     |\n",
      "|    mean_step_reward   | 0.107053116 |\n",
      "|    n_updates          | 46.88 %     |\n",
      "|    policyGradLoss     | -0.0191     |\n",
      "|    value_loss         | 0.179       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 179         |\n",
      "|    total_timesteps    | 20848640    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026859572 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0435     |\n",
      "|    mean_step_reward   | 0.12883495  |\n",
      "|    n_updates          | 50.00 %     |\n",
      "|    policyGradLoss     | -0.0227     |\n",
      "|    value_loss         | 0.201       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 190         |\n",
      "|    total_timesteps    | 20856832    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027682811 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0361     |\n",
      "|    mean_step_reward   | 0.10816456  |\n",
      "|    n_updates          | 53.12 %     |\n",
      "|    policyGradLoss     | -0.0207     |\n",
      "|    value_loss         | 0.254       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 202         |\n",
      "|    total_timesteps    | 20865024    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028743926 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.954       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0232     |\n",
      "|    mean_step_reward   | 0.13750345  |\n",
      "|    n_updates          | 56.25 %     |\n",
      "|    policyGradLoss     | -0.0176     |\n",
      "|    value_loss         | 0.276       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 213         |\n",
      "|    total_timesteps    | 20873216    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024702322 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.954       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0422      |\n",
      "|    mean_step_reward   | 0.083184    |\n",
      "|    n_updates          | 59.38 %     |\n",
      "|    policyGradLoss     | -0.0158     |\n",
      "|    value_loss         | 0.307       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 764         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 224         |\n",
      "|    total_timesteps    | 20881408    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.031535797 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00346    |\n",
      "|    mean_step_reward   | 0.13744363  |\n",
      "|    n_updates          | 62.50 %     |\n",
      "|    policyGradLoss     | -0.0192     |\n",
      "|    value_loss         | 0.231       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 763        |\n",
      "|    iterations         | 22         |\n",
      "|    time_elapsed       | 236        |\n",
      "|    total_timesteps    | 20889600   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02669346 |\n",
      "|    entropy_loss       | -1.86      |\n",
      "|    explained_variance | 0.968      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0458    |\n",
      "|    mean_step_reward   | 0.10496102 |\n",
      "|    n_updates          | 65.62 %    |\n",
      "|    policyGradLoss     | -0.0205    |\n",
      "|    value_loss         | 0.167      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 762         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 247         |\n",
      "|    total_timesteps    | 20897792    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025601128 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0601     |\n",
      "|    mean_step_reward   | 0.12139383  |\n",
      "|    n_updates          | 68.75 %     |\n",
      "|    policyGradLoss     | -0.0209     |\n",
      "|    value_loss         | 0.226       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 761         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 258         |\n",
      "|    total_timesteps    | 20905984    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030680627 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0331     |\n",
      "|    mean_step_reward   | 0.11634378  |\n",
      "|    n_updates          | 71.88 %     |\n",
      "|    policyGradLoss     | -0.0216     |\n",
      "|    value_loss         | 0.173       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 759         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 269         |\n",
      "|    total_timesteps    | 20914176    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026938587 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0685     |\n",
      "|    mean_step_reward   | 0.10882749  |\n",
      "|    n_updates          | 75.00 %     |\n",
      "|    policyGradLoss     | -0.0215     |\n",
      "|    value_loss         | 0.175       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 756         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 281         |\n",
      "|    total_timesteps    | 20922368    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024171595 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0286     |\n",
      "|    mean_step_reward   | 0.11785067  |\n",
      "|    n_updates          | 78.12 %     |\n",
      "|    policyGradLoss     | -0.0161     |\n",
      "|    value_loss         | 0.287       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 755         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 292         |\n",
      "|    total_timesteps    | 20930560    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026014745 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0212     |\n",
      "|    mean_step_reward   | 0.120058194 |\n",
      "|    n_updates          | 81.25 %     |\n",
      "|    policyGradLoss     | -0.0197     |\n",
      "|    value_loss         | 0.203       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 754         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 303         |\n",
      "|    total_timesteps    | 20938752    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029998073 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0482     |\n",
      "|    mean_step_reward   | 0.12743379  |\n",
      "|    n_updates          | 84.38 %     |\n",
      "|    policyGradLoss     | -0.0195     |\n",
      "|    value_loss         | 0.196       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 754         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 314         |\n",
      "|    total_timesteps    | 20946944    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028877975 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0498     |\n",
      "|    mean_step_reward   | 0.13102993  |\n",
      "|    n_updates          | 87.50 %     |\n",
      "|    policyGradLoss     | -0.0208     |\n",
      "|    value_loss         | 0.158       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 753         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 326         |\n",
      "|    total_timesteps    | 20955136    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027355818 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0301     |\n",
      "|    mean_step_reward   | 0.12859936  |\n",
      "|    n_updates          | 90.62 %     |\n",
      "|    policyGradLoss     | -0.0188     |\n",
      "|    value_loss         | 0.211       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 752         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 337         |\n",
      "|    total_timesteps    | 20963328    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.032370716 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0843      |\n",
      "|    mean_step_reward   | 0.11712928  |\n",
      "|    n_updates          | 93.75 %     |\n",
      "|    policyGradLoss     | -0.0192     |\n",
      "|    value_loss         | 0.218       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 751         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 348         |\n",
      "|    total_timesteps    | 20971520    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025808726 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0108      |\n",
      "|    mean_step_reward   | 0.12438091  |\n",
      "|    n_updates          | 96.88 %     |\n",
      "|    policyGradLoss     | -0.0173     |\n",
      "|    value_loss         | 0.258       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Run_79.zip\n",
      "[EVAL] Mean Return: 130.623, Best Return: 138.123\n",
      "Saved video to ./runs_smw/videos/Run/Run_79_130.62.mp4\n",
      "\n",
      "=== Round 81 | Learn 262144 steps (Total trained: 20971520) ===\n",
      "Logging to ./runs_smw/tb/Run_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1122     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 20979712 |\n",
      "---------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 900        |\n",
      "|    iterations         | 2          |\n",
      "|    time_elapsed       | 18         |\n",
      "|    total_timesteps    | 20987904   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02540932 |\n",
      "|    entropy_loss       | -1.81      |\n",
      "|    explained_variance | 0.96       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.059     |\n",
      "|    mean_step_reward   | 0.11206593 |\n",
      "|    n_updates          | 3.12 %     |\n",
      "|    policyGradLoss     | -0.0194    |\n",
      "|    value_loss         | 0.208      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 909        |\n",
      "|    iterations         | 3          |\n",
      "|    time_elapsed       | 27         |\n",
      "|    total_timesteps    | 20996096   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02831208 |\n",
      "|    entropy_loss       | -1.8       |\n",
      "|    explained_variance | 0.962      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0233    |\n",
      "|    mean_step_reward   | 0.12346773 |\n",
      "|    n_updates          | 6.25 %     |\n",
      "|    policyGradLoss     | -0.0165    |\n",
      "|    value_loss         | 0.222      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 903         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 36          |\n",
      "|    total_timesteps    | 21004288    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025115443 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0143     |\n",
      "|    mean_step_reward   | 0.12284761  |\n",
      "|    n_updates          | 9.38 %      |\n",
      "|    policyGradLoss     | -0.0197     |\n",
      "|    value_loss         | 0.295       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 897        |\n",
      "|    iterations         | 5          |\n",
      "|    time_elapsed       | 45         |\n",
      "|    total_timesteps    | 21012480   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03006175 |\n",
      "|    entropy_loss       | -1.84      |\n",
      "|    explained_variance | 0.957      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0298    |\n",
      "|    mean_step_reward   | 0.10042445 |\n",
      "|    n_updates          | 12.50 %    |\n",
      "|    policyGradLoss     | -0.0194    |\n",
      "|    value_loss         | 0.247      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 870         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 56          |\n",
      "|    total_timesteps    | 21020672    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025685783 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0688     |\n",
      "|    mean_step_reward   | 0.13474956  |\n",
      "|    n_updates          | 15.62 %     |\n",
      "|    policyGradLoss     | -0.0195     |\n",
      "|    value_loss         | 0.139       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 845         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 67          |\n",
      "|    total_timesteps    | 21028864    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024129491 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0448     |\n",
      "|    mean_step_reward   | 0.12055887  |\n",
      "|    n_updates          | 18.75 %     |\n",
      "|    policyGradLoss     | -0.0175     |\n",
      "|    value_loss         | 0.177       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 826         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 79          |\n",
      "|    total_timesteps    | 21037056    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025308553 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0162     |\n",
      "|    mean_step_reward   | 0.13802913  |\n",
      "|    n_updates          | 21.88 %     |\n",
      "|    policyGradLoss     | -0.0179     |\n",
      "|    value_loss         | 0.249       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 815         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 90          |\n",
      "|    total_timesteps    | 21045248    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026446812 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.055      |\n",
      "|    mean_step_reward   | 0.096583396 |\n",
      "|    n_updates          | 25.00 %     |\n",
      "|    policyGradLoss     | -0.0197     |\n",
      "|    value_loss         | 0.18        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 806         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 101         |\n",
      "|    total_timesteps    | 21053440    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029705957 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0218      |\n",
      "|    mean_step_reward   | 0.11675778  |\n",
      "|    n_updates          | 28.12 %     |\n",
      "|    policyGradLoss     | -0.0184     |\n",
      "|    value_loss         | 0.331       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 800         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 112         |\n",
      "|    total_timesteps    | 21061632    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025587108 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.052      |\n",
      "|    mean_step_reward   | 0.12646636  |\n",
      "|    n_updates          | 31.25 %     |\n",
      "|    policyGradLoss     | -0.0199     |\n",
      "|    value_loss         | 0.212       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 794         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 123         |\n",
      "|    total_timesteps    | 21069824    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023843467 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.955       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0342      |\n",
      "|    mean_step_reward   | 0.10274516  |\n",
      "|    n_updates          | 34.38 %     |\n",
      "|    policyGradLoss     | -0.0179     |\n",
      "|    value_loss         | 0.288       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 135         |\n",
      "|    total_timesteps    | 21078016    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025453113 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0158     |\n",
      "|    mean_step_reward   | 0.104227945 |\n",
      "|    n_updates          | 37.50 %     |\n",
      "|    policyGradLoss     | -0.0179     |\n",
      "|    value_loss         | 0.284       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 146         |\n",
      "|    total_timesteps    | 21086208    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.0277775   |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0634     |\n",
      "|    mean_step_reward   | 0.117869526 |\n",
      "|    n_updates          | 40.62 %     |\n",
      "|    policyGradLoss     | -0.0202     |\n",
      "|    value_loss         | 0.26        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 777        |\n",
      "|    iterations         | 15         |\n",
      "|    time_elapsed       | 158        |\n",
      "|    total_timesteps    | 21094400   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02449457 |\n",
      "|    entropy_loss       | -1.82      |\n",
      "|    explained_variance | 0.963      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0301    |\n",
      "|    mean_step_reward   | 0.12924819 |\n",
      "|    n_updates          | 43.75 %    |\n",
      "|    policyGradLoss     | -0.0177    |\n",
      "|    value_loss         | 0.215      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 168         |\n",
      "|    total_timesteps    | 21102592    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027327858 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0162     |\n",
      "|    mean_step_reward   | 0.10897639  |\n",
      "|    n_updates          | 46.88 %     |\n",
      "|    policyGradLoss     | -0.0208     |\n",
      "|    value_loss         | 0.222       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 179         |\n",
      "|    total_timesteps    | 21110784    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02366531  |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.03       |\n",
      "|    mean_step_reward   | 0.111410744 |\n",
      "|    n_updates          | 50.00 %     |\n",
      "|    policyGradLoss     | -0.0169     |\n",
      "|    value_loss         | 0.297       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 190         |\n",
      "|    total_timesteps    | 21118976    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022572149 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.958       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0335     |\n",
      "|    mean_step_reward   | 0.121358715 |\n",
      "|    n_updates          | 53.12 %     |\n",
      "|    policyGradLoss     | -0.0171     |\n",
      "|    value_loss         | 0.24        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 202         |\n",
      "|    total_timesteps    | 21127168    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028148852 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0302     |\n",
      "|    mean_step_reward   | 0.11489609  |\n",
      "|    n_updates          | 56.25 %     |\n",
      "|    policyGradLoss     | -0.0198     |\n",
      "|    value_loss         | 0.219       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 765         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 213         |\n",
      "|    total_timesteps    | 21135360    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020988988 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.951       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -5.92e-05   |\n",
      "|    mean_step_reward   | 0.10501984  |\n",
      "|    n_updates          | 59.38 %     |\n",
      "|    policyGradLoss     | -0.0158     |\n",
      "|    value_loss         | 0.327       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 762         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 225         |\n",
      "|    total_timesteps    | 21143552    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022129174 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0585     |\n",
      "|    mean_step_reward   | 0.1328953   |\n",
      "|    n_updates          | 62.50 %     |\n",
      "|    policyGradLoss     | -0.0179     |\n",
      "|    value_loss         | 0.202       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 760         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 237         |\n",
      "|    total_timesteps    | 21151744    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027630027 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0495     |\n",
      "|    mean_step_reward   | 0.09979167  |\n",
      "|    n_updates          | 65.62 %     |\n",
      "|    policyGradLoss     | -0.0199     |\n",
      "|    value_loss         | 0.2         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 759         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 248         |\n",
      "|    total_timesteps    | 21159936    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025312148 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.955       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00479    |\n",
      "|    mean_step_reward   | 0.121211275 |\n",
      "|    n_updates          | 68.75 %     |\n",
      "|    policyGradLoss     | -0.0173     |\n",
      "|    value_loss         | 0.396       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 758         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 259         |\n",
      "|    total_timesteps    | 21168128    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020247038 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.947       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0318     |\n",
      "|    mean_step_reward   | 0.10283774  |\n",
      "|    n_updates          | 71.88 %     |\n",
      "|    policyGradLoss     | -0.0155     |\n",
      "|    value_loss         | 0.248       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 756         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 270         |\n",
      "|    total_timesteps    | 21176320    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025119785 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0449     |\n",
      "|    mean_step_reward   | 0.123107776 |\n",
      "|    n_updates          | 75.00 %     |\n",
      "|    policyGradLoss     | -0.0167     |\n",
      "|    value_loss         | 0.231       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 755        |\n",
      "|    iterations         | 26         |\n",
      "|    time_elapsed       | 281        |\n",
      "|    total_timesteps    | 21184512   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02234669 |\n",
      "|    entropy_loss       | -1.84      |\n",
      "|    explained_variance | 0.951      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0225    |\n",
      "|    mean_step_reward   | 0.10801917 |\n",
      "|    n_updates          | 78.12 %    |\n",
      "|    policyGradLoss     | -0.0171    |\n",
      "|    value_loss         | 0.288      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 753        |\n",
      "|    iterations         | 27         |\n",
      "|    time_elapsed       | 293        |\n",
      "|    total_timesteps    | 21192704   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02498329 |\n",
      "|    entropy_loss       | -1.83      |\n",
      "|    explained_variance | 0.963      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0213    |\n",
      "|    mean_step_reward   | 0.11824629 |\n",
      "|    n_updates          | 81.25 %    |\n",
      "|    policyGradLoss     | -0.0217    |\n",
      "|    value_loss         | 0.211      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 751         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 305         |\n",
      "|    total_timesteps    | 21200896    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02324846  |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0539     |\n",
      "|    mean_step_reward   | 0.118261166 |\n",
      "|    n_updates          | 84.38 %     |\n",
      "|    policyGradLoss     | -0.0187     |\n",
      "|    value_loss         | 0.189       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 750         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 316         |\n",
      "|    total_timesteps    | 21209088    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027477978 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0152     |\n",
      "|    mean_step_reward   | 0.09613373  |\n",
      "|    n_updates          | 87.50 %     |\n",
      "|    policyGradLoss     | -0.0172     |\n",
      "|    value_loss         | 0.37        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 750         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 327         |\n",
      "|    total_timesteps    | 21217280    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029099617 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0471     |\n",
      "|    mean_step_reward   | 0.1188481   |\n",
      "|    n_updates          | 90.62 %     |\n",
      "|    policyGradLoss     | -0.019      |\n",
      "|    value_loss         | 0.295       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 749         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 338         |\n",
      "|    total_timesteps    | 21225472    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024454953 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.954       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.038      |\n",
      "|    mean_step_reward   | 0.11649671  |\n",
      "|    n_updates          | 93.75 %     |\n",
      "|    policyGradLoss     | -0.0165     |\n",
      "|    value_loss         | 0.261       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 749        |\n",
      "|    iterations         | 32         |\n",
      "|    time_elapsed       | 349        |\n",
      "|    total_timesteps    | 21233664   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02664019 |\n",
      "|    entropy_loss       | -1.81      |\n",
      "|    explained_variance | 0.953      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.00657   |\n",
      "|    mean_step_reward   | 0.11830582 |\n",
      "|    n_updates          | 96.88 %    |\n",
      "|    policyGradLoss     | -0.0173    |\n",
      "|    value_loss         | 0.307      |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Run_80.zip\n",
      "[EVAL] Mean Return: 153.688, Best Return: 160.688\n",
      "Saved video to ./runs_smw/videos/Run/Run_80_153.69.mp4\n",
      "\n",
      "=== Round 82 | Learn 262144 steps (Total trained: 21233664) ===\n",
      "Logging to ./runs_smw/tb/Run_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1407     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 21241856 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 1051        |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 15          |\n",
      "|    total_timesteps    | 21250048    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028966289 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0447     |\n",
      "|    mean_step_reward   | 0.10996853  |\n",
      "|    n_updates          | 3.12 %      |\n",
      "|    policyGradLoss     | -0.0189     |\n",
      "|    value_loss         | 0.272       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 903         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 27          |\n",
      "|    total_timesteps    | 21258240    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024511725 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00472    |\n",
      "|    mean_step_reward   | 0.12723677  |\n",
      "|    n_updates          | 6.25 %      |\n",
      "|    policyGradLoss     | -0.0181     |\n",
      "|    value_loss         | 0.265       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 848         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 38          |\n",
      "|    total_timesteps    | 21266432    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022350747 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.937       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0219     |\n",
      "|    mean_step_reward   | 0.118636146 |\n",
      "|    n_updates          | 9.38 %      |\n",
      "|    policyGradLoss     | -0.0176     |\n",
      "|    value_loss         | 0.322       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 827         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 49          |\n",
      "|    total_timesteps    | 21274624    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020705666 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.955       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0468     |\n",
      "|    mean_step_reward   | 0.1163099   |\n",
      "|    n_updates          | 12.50 %     |\n",
      "|    policyGradLoss     | -0.0175     |\n",
      "|    value_loss         | 0.292       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 810         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 60          |\n",
      "|    total_timesteps    | 21282816    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022061078 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0282     |\n",
      "|    mean_step_reward   | 0.10717684  |\n",
      "|    n_updates          | 15.62 %     |\n",
      "|    policyGradLoss     | -0.0195     |\n",
      "|    value_loss         | 0.286       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 798         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 71          |\n",
      "|    total_timesteps    | 21291008    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022172613 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.951       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0226     |\n",
      "|    mean_step_reward   | 0.12848285  |\n",
      "|    n_updates          | 18.75 %     |\n",
      "|    policyGradLoss     | -0.0154     |\n",
      "|    value_loss         | 0.358       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 83          |\n",
      "|    total_timesteps    | 21299200    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019763732 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.911       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0107     |\n",
      "|    mean_step_reward   | 0.080776066 |\n",
      "|    n_updates          | 21.88 %     |\n",
      "|    policyGradLoss     | -0.0139     |\n",
      "|    value_loss         | 0.42        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 94          |\n",
      "|    total_timesteps    | 21307392    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018046152 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.942       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0137      |\n",
      "|    mean_step_reward   | 0.121354006 |\n",
      "|    n_updates          | 25.00 %     |\n",
      "|    policyGradLoss     | -0.015      |\n",
      "|    value_loss         | 0.382       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 106         |\n",
      "|    total_timesteps    | 21315584    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023337381 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.939       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0152     |\n",
      "|    mean_step_reward   | 0.09839036  |\n",
      "|    n_updates          | 28.12 %     |\n",
      "|    policyGradLoss     | -0.0196     |\n",
      "|    value_loss         | 0.339       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 764         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 117         |\n",
      "|    total_timesteps    | 21323776    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021048814 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.925       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0614      |\n",
      "|    mean_step_reward   | 0.09002428  |\n",
      "|    n_updates          | 31.25 %     |\n",
      "|    policyGradLoss     | -0.0149     |\n",
      "|    value_loss         | 0.381       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 762         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 128         |\n",
      "|    total_timesteps    | 21331968    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022202343 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.954       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0496     |\n",
      "|    mean_step_reward   | 0.09777306  |\n",
      "|    n_updates          | 34.38 %     |\n",
      "|    policyGradLoss     | -0.0193     |\n",
      "|    value_loss         | 0.262       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 760        |\n",
      "|    iterations         | 13         |\n",
      "|    time_elapsed       | 139        |\n",
      "|    total_timesteps    | 21340160   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02113234 |\n",
      "|    entropy_loss       | -1.79      |\n",
      "|    explained_variance | 0.95       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.017     |\n",
      "|    mean_step_reward   | 0.12843809 |\n",
      "|    n_updates          | 37.50 %    |\n",
      "|    policyGradLoss     | -0.0185    |\n",
      "|    value_loss         | 0.335      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 761         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 150         |\n",
      "|    total_timesteps    | 21348352    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028253973 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.05       |\n",
      "|    mean_step_reward   | 0.1053506   |\n",
      "|    n_updates          | 40.62 %     |\n",
      "|    policyGradLoss     | -0.0208     |\n",
      "|    value_loss         | 0.166       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 759         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 161         |\n",
      "|    total_timesteps    | 21356544    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023890663 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0359     |\n",
      "|    mean_step_reward   | 0.13311622  |\n",
      "|    n_updates          | 43.75 %     |\n",
      "|    policyGradLoss     | -0.017      |\n",
      "|    value_loss         | 0.226       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 756         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 173         |\n",
      "|    total_timesteps    | 21364736    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020597365 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00814    |\n",
      "|    mean_step_reward   | 0.108683184 |\n",
      "|    n_updates          | 46.88 %     |\n",
      "|    policyGradLoss     | -0.0172     |\n",
      "|    value_loss         | 0.271       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 753         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 184         |\n",
      "|    total_timesteps    | 21372928    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025993703 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0621     |\n",
      "|    mean_step_reward   | 0.12925106  |\n",
      "|    n_updates          | 50.00 %     |\n",
      "|    policyGradLoss     | -0.0167     |\n",
      "|    value_loss         | 0.213       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 751         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 196         |\n",
      "|    total_timesteps    | 21381120    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025976554 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.947       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.036      |\n",
      "|    mean_step_reward   | 0.11786398  |\n",
      "|    n_updates          | 53.12 %     |\n",
      "|    policyGradLoss     | -0.0161     |\n",
      "|    value_loss         | 0.247       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 750         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 207         |\n",
      "|    total_timesteps    | 21389312    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022662994 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.946       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00451    |\n",
      "|    mean_step_reward   | 0.10671268  |\n",
      "|    n_updates          | 56.25 %     |\n",
      "|    policyGradLoss     | -0.0182     |\n",
      "|    value_loss         | 0.299       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 750         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 218         |\n",
      "|    total_timesteps    | 21397504    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016442623 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.927       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.034       |\n",
      "|    mean_step_reward   | 0.11700848  |\n",
      "|    n_updates          | 59.38 %     |\n",
      "|    policyGradLoss     | -0.0137     |\n",
      "|    value_loss         | 0.465       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 750         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 229         |\n",
      "|    total_timesteps    | 21405696    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019796144 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.939       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00728    |\n",
      "|    mean_step_reward   | 0.12477338  |\n",
      "|    n_updates          | 62.50 %     |\n",
      "|    policyGradLoss     | -0.0166     |\n",
      "|    value_loss         | 0.296       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 749         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 240         |\n",
      "|    total_timesteps    | 21413888    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027791273 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.954       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0443     |\n",
      "|    mean_step_reward   | 0.11211828  |\n",
      "|    n_updates          | 65.62 %     |\n",
      "|    policyGradLoss     | -0.0183     |\n",
      "|    value_loss         | 0.244       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 747         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 252         |\n",
      "|    total_timesteps    | 21422080    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022892416 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0497     |\n",
      "|    mean_step_reward   | 0.12538587  |\n",
      "|    n_updates          | 68.75 %     |\n",
      "|    policyGradLoss     | -0.0193     |\n",
      "|    value_loss         | 0.203       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 745         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 263         |\n",
      "|    total_timesteps    | 21430272    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021294545 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.934       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0155     |\n",
      "|    mean_step_reward   | 0.10053727  |\n",
      "|    n_updates          | 71.88 %     |\n",
      "|    policyGradLoss     | -0.0161     |\n",
      "|    value_loss         | 0.321       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 744         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 275         |\n",
      "|    total_timesteps    | 21438464    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021671733 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.941       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0312     |\n",
      "|    mean_step_reward   | 0.10999013  |\n",
      "|    n_updates          | 75.00 %     |\n",
      "|    policyGradLoss     | -0.0154     |\n",
      "|    value_loss         | 0.306       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 743        |\n",
      "|    iterations         | 26         |\n",
      "|    time_elapsed       | 286        |\n",
      "|    total_timesteps    | 21446656   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02338535 |\n",
      "|    entropy_loss       | -1.85      |\n",
      "|    explained_variance | 0.95       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.0855     |\n",
      "|    mean_step_reward   | 0.11874251 |\n",
      "|    n_updates          | 78.12 %    |\n",
      "|    policyGradLoss     | -0.0155    |\n",
      "|    value_loss         | 0.352      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 743         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 297         |\n",
      "|    total_timesteps    | 21454848    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023762006 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0433     |\n",
      "|    mean_step_reward   | 0.12534049  |\n",
      "|    n_updates          | 81.25 %     |\n",
      "|    policyGradLoss     | -0.0197     |\n",
      "|    value_loss         | 0.22        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 743         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 308         |\n",
      "|    total_timesteps    | 21463040    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026043514 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0589     |\n",
      "|    mean_step_reward   | 0.11693856  |\n",
      "|    n_updates          | 84.38 %     |\n",
      "|    policyGradLoss     | -0.0189     |\n",
      "|    value_loss         | 0.228       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 743         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 319         |\n",
      "|    total_timesteps    | 21471232    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024556244 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0551     |\n",
      "|    mean_step_reward   | 0.11447091  |\n",
      "|    n_updates          | 87.50 %     |\n",
      "|    policyGradLoss     | -0.0206     |\n",
      "|    value_loss         | 0.161       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 741         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 331         |\n",
      "|    total_timesteps    | 21479424    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022146696 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.957       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0214      |\n",
      "|    mean_step_reward   | 0.11566858  |\n",
      "|    n_updates          | 90.62 %     |\n",
      "|    policyGradLoss     | -0.0156     |\n",
      "|    value_loss         | 0.259       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 744         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 341         |\n",
      "|    total_timesteps    | 21487616    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015722543 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.951       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00881    |\n",
      "|    mean_step_reward   | 0.11668075  |\n",
      "|    n_updates          | 93.75 %     |\n",
      "|    policyGradLoss     | -0.0174     |\n",
      "|    value_loss         | 0.307       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 748         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 350         |\n",
      "|    total_timesteps    | 21495808    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022121055 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.952       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00178     |\n",
      "|    mean_step_reward   | 0.108348355 |\n",
      "|    n_updates          | 96.88 %     |\n",
      "|    policyGradLoss     | -0.019      |\n",
      "|    value_loss         | 0.291       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Run_81.zip\n",
      "[EVAL] Mean Return: 152.947, Best Return: 159.947\n",
      "Saved video to ./runs_smw/videos/Run/Run_81_152.95.mp4\n",
      "\n",
      "=== Round 83 | Learn 262144 steps (Total trained: 21495808) ===\n",
      "Logging to ./runs_smw/tb/Run_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1097     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 21504000 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 852         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 19          |\n",
      "|    total_timesteps    | 21512192    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025006909 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0546     |\n",
      "|    mean_step_reward   | 0.11422008  |\n",
      "|    n_updates          | 3.12 %      |\n",
      "|    policyGradLoss     | -0.0215     |\n",
      "|    value_loss         | 0.202       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 803        |\n",
      "|    iterations         | 3          |\n",
      "|    time_elapsed       | 30         |\n",
      "|    total_timesteps    | 21520384   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02984973 |\n",
      "|    entropy_loss       | -1.8       |\n",
      "|    explained_variance | 0.979      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0632    |\n",
      "|    mean_step_reward   | 0.12660372 |\n",
      "|    n_updates          | 6.25 %     |\n",
      "|    policyGradLoss     | -0.0194    |\n",
      "|    value_loss         | 0.144      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 787        |\n",
      "|    iterations         | 4          |\n",
      "|    time_elapsed       | 41         |\n",
      "|    total_timesteps    | 21528576   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02546807 |\n",
      "|    entropy_loss       | -1.8       |\n",
      "|    explained_variance | 0.959      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.00245   |\n",
      "|    mean_step_reward   | 0.10207207 |\n",
      "|    n_updates          | 9.38 %     |\n",
      "|    policyGradLoss     | -0.0169    |\n",
      "|    value_loss         | 0.289      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 52          |\n",
      "|    total_timesteps    | 21536768    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018632002 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.954       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.158       |\n",
      "|    mean_step_reward   | 0.109907    |\n",
      "|    n_updates          | 12.50 %     |\n",
      "|    policyGradLoss     | -0.0154     |\n",
      "|    value_loss         | 0.349       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 63          |\n",
      "|    total_timesteps    | 21544960    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026886933 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0108     |\n",
      "|    mean_step_reward   | 0.11834775  |\n",
      "|    n_updates          | 15.62 %     |\n",
      "|    policyGradLoss     | -0.0191     |\n",
      "|    value_loss         | 0.234       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 74          |\n",
      "|    total_timesteps    | 21553152    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027438886 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0569     |\n",
      "|    mean_step_reward   | 0.13080412  |\n",
      "|    n_updates          | 18.75 %     |\n",
      "|    policyGradLoss     | -0.0171     |\n",
      "|    value_loss         | 0.193       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 759         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 86          |\n",
      "|    total_timesteps    | 21561344    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025599005 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.949       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0108      |\n",
      "|    mean_step_reward   | 0.112192005 |\n",
      "|    n_updates          | 21.88 %     |\n",
      "|    policyGradLoss     | -0.0183     |\n",
      "|    value_loss         | 0.279       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 752         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 98          |\n",
      "|    total_timesteps    | 21569536    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026038133 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0402     |\n",
      "|    mean_step_reward   | 0.13298896  |\n",
      "|    n_updates          | 25.00 %     |\n",
      "|    policyGradLoss     | -0.0187     |\n",
      "|    value_loss         | 0.198       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 748         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 109         |\n",
      "|    total_timesteps    | 21577728    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022387076 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0175     |\n",
      "|    mean_step_reward   | 0.11674653  |\n",
      "|    n_updates          | 28.12 %     |\n",
      "|    policyGradLoss     | -0.0159     |\n",
      "|    value_loss         | 0.227       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 747         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 120         |\n",
      "|    total_timesteps    | 21585920    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.034172118 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0715     |\n",
      "|    mean_step_reward   | 0.13653429  |\n",
      "|    n_updates          | 31.25 %     |\n",
      "|    policyGradLoss     | -0.0188     |\n",
      "|    value_loss         | 0.166       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 748         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 131         |\n",
      "|    total_timesteps    | 21594112    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025121028 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.958       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0118     |\n",
      "|    mean_step_reward   | 0.120777994 |\n",
      "|    n_updates          | 34.38 %     |\n",
      "|    policyGradLoss     | -0.0155     |\n",
      "|    value_loss         | 0.269       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 747         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 142         |\n",
      "|    total_timesteps    | 21602304    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024167765 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0527     |\n",
      "|    mean_step_reward   | 0.12263454  |\n",
      "|    n_updates          | 37.50 %     |\n",
      "|    policyGradLoss     | -0.0171     |\n",
      "|    value_loss         | 0.162       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 747         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 153         |\n",
      "|    total_timesteps    | 21610496    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.032702256 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0559     |\n",
      "|    mean_step_reward   | 0.12549266  |\n",
      "|    n_updates          | 40.62 %     |\n",
      "|    policyGradLoss     | -0.0218     |\n",
      "|    value_loss         | 0.155       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 744         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 164         |\n",
      "|    total_timesteps    | 21618688    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028934509 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.014      |\n",
      "|    mean_step_reward   | 0.11767399  |\n",
      "|    n_updates          | 43.75 %     |\n",
      "|    policyGradLoss     | -0.0179     |\n",
      "|    value_loss         | 0.23        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 742         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 176         |\n",
      "|    total_timesteps    | 21626880    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023470314 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.955       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0436     |\n",
      "|    mean_step_reward   | 0.11534443  |\n",
      "|    n_updates          | 46.88 %     |\n",
      "|    policyGradLoss     | -0.019      |\n",
      "|    value_loss         | 0.244       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 740         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 188         |\n",
      "|    total_timesteps    | 21635072    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025813576 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00969    |\n",
      "|    mean_step_reward   | 0.11290758  |\n",
      "|    n_updates          | 50.00 %     |\n",
      "|    policyGradLoss     | -0.0193     |\n",
      "|    value_loss         | 0.283       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 739         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 199         |\n",
      "|    total_timesteps    | 21643264    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023320425 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0052     |\n",
      "|    mean_step_reward   | 0.12091042  |\n",
      "|    n_updates          | 53.12 %     |\n",
      "|    policyGradLoss     | -0.0171     |\n",
      "|    value_loss         | 0.29        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 739         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 210         |\n",
      "|    total_timesteps    | 21651456    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019835856 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.958       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.026      |\n",
      "|    mean_step_reward   | 0.11543612  |\n",
      "|    n_updates          | 56.25 %     |\n",
      "|    policyGradLoss     | -0.0146     |\n",
      "|    value_loss         | 0.247       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 740         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 221         |\n",
      "|    total_timesteps    | 21659648    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023905698 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0586     |\n",
      "|    mean_step_reward   | 0.12099131  |\n",
      "|    n_updates          | 59.38 %     |\n",
      "|    policyGradLoss     | -0.0207     |\n",
      "|    value_loss         | 0.189       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 740         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 232         |\n",
      "|    total_timesteps    | 21667840    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018804051 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.036       |\n",
      "|    mean_step_reward   | 0.10055588  |\n",
      "|    n_updates          | 62.50 %     |\n",
      "|    policyGradLoss     | -0.0149     |\n",
      "|    value_loss         | 0.249       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 740         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 243         |\n",
      "|    total_timesteps    | 21676032    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.031235427 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0592     |\n",
      "|    mean_step_reward   | 0.11524056  |\n",
      "|    n_updates          | 65.62 %     |\n",
      "|    policyGradLoss     | -0.0175     |\n",
      "|    value_loss         | 0.23        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 738         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 254         |\n",
      "|    total_timesteps    | 21684224    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024462247 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0549     |\n",
      "|    mean_step_reward   | 0.100538835 |\n",
      "|    n_updates          | 68.75 %     |\n",
      "|    policyGradLoss     | -0.0157     |\n",
      "|    value_loss         | 0.237       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 737         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 266         |\n",
      "|    total_timesteps    | 21692416    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025065076 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.949       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00463    |\n",
      "|    mean_step_reward   | 0.1069285   |\n",
      "|    n_updates          | 71.88 %     |\n",
      "|    policyGradLoss     | -0.0163     |\n",
      "|    value_loss         | 0.341       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 737         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 277         |\n",
      "|    total_timesteps    | 21700608    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025095135 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0202     |\n",
      "|    mean_step_reward   | 0.11713385  |\n",
      "|    n_updates          | 75.00 %     |\n",
      "|    policyGradLoss     | -0.0192     |\n",
      "|    value_loss         | 0.236       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 737         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 288         |\n",
      "|    total_timesteps    | 21708800    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024280194 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.951       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0223     |\n",
      "|    mean_step_reward   | 0.11343433  |\n",
      "|    n_updates          | 78.12 %     |\n",
      "|    policyGradLoss     | -0.0195     |\n",
      "|    value_loss         | 0.31        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 738         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 299         |\n",
      "|    total_timesteps    | 21716992    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026190018 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0308     |\n",
      "|    mean_step_reward   | 0.115663856 |\n",
      "|    n_updates          | 81.25 %     |\n",
      "|    policyGradLoss     | -0.019      |\n",
      "|    value_loss         | 0.219       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 742        |\n",
      "|    iterations         | 28         |\n",
      "|    time_elapsed       | 308        |\n",
      "|    total_timesteps    | 21725184   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02234966 |\n",
      "|    entropy_loss       | -1.81      |\n",
      "|    explained_variance | 0.952      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.007      |\n",
      "|    mean_step_reward   | 0.12101601 |\n",
      "|    n_updates          | 84.38 %    |\n",
      "|    policyGradLoss     | -0.0146    |\n",
      "|    value_loss         | 0.356      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 746         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 318         |\n",
      "|    total_timesteps    | 21733376    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024815572 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00884    |\n",
      "|    mean_step_reward   | 0.117039144 |\n",
      "|    n_updates          | 87.50 %     |\n",
      "|    policyGradLoss     | -0.0175     |\n",
      "|    value_loss         | 0.232       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 749         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 327         |\n",
      "|    total_timesteps    | 21741568    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024226684 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.038       |\n",
      "|    mean_step_reward   | 0.12764877  |\n",
      "|    n_updates          | 90.62 %     |\n",
      "|    policyGradLoss     | -0.0147     |\n",
      "|    value_loss         | 0.281       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 750         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 338         |\n",
      "|    total_timesteps    | 21749760    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027722165 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0088     |\n",
      "|    mean_step_reward   | 0.10786458  |\n",
      "|    n_updates          | 93.75 %     |\n",
      "|    policyGradLoss     | -0.0176     |\n",
      "|    value_loss         | 0.277       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 749         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 349         |\n",
      "|    total_timesteps    | 21757952    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022137653 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0343     |\n",
      "|    mean_step_reward   | 0.12764986  |\n",
      "|    n_updates          | 96.88 %     |\n",
      "|    policyGradLoss     | -0.0163     |\n",
      "|    value_loss         | 0.213       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Run_82.zip\n",
      "[EVAL] Mean Return: 151.997, Best Return: 158.664\n",
      "Saved video to ./runs_smw/videos/Run/Run_82_152.00.mp4\n",
      "\n",
      "=== Round 84 | Learn 262144 steps (Total trained: 21757952) ===\n",
      "Logging to ./runs_smw/tb/Run_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1087     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 21766144 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 859         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 19          |\n",
      "|    total_timesteps    | 21774336    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018201653 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.949       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0106     |\n",
      "|    mean_step_reward   | 0.12096662  |\n",
      "|    n_updates          | 3.12 %      |\n",
      "|    policyGradLoss     | -0.0138     |\n",
      "|    value_loss         | 0.259       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 807         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 30          |\n",
      "|    total_timesteps    | 21782528    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023328338 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.941       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00238    |\n",
      "|    mean_step_reward   | 0.10490547  |\n",
      "|    n_updates          | 6.25 %      |\n",
      "|    policyGradLoss     | -0.016      |\n",
      "|    value_loss         | 0.335       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 791         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 41          |\n",
      "|    total_timesteps    | 21790720    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024619073 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.955       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0369     |\n",
      "|    mean_step_reward   | 0.1037863   |\n",
      "|    n_updates          | 9.38 %      |\n",
      "|    policyGradLoss     | -0.0183     |\n",
      "|    value_loss         | 0.234       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 52          |\n",
      "|    total_timesteps    | 21798912    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025083203 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.028       |\n",
      "|    mean_step_reward   | 0.11335133  |\n",
      "|    n_updates          | 12.50 %     |\n",
      "|    policyGradLoss     | -0.0191     |\n",
      "|    value_loss         | 0.224       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 63          |\n",
      "|    total_timesteps    | 21807104    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023115024 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.955       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.014      |\n",
      "|    mean_step_reward   | 0.109008886 |\n",
      "|    n_updates          | 15.62 %     |\n",
      "|    policyGradLoss     | -0.0162     |\n",
      "|    value_loss         | 0.299       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 761         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 75          |\n",
      "|    total_timesteps    | 21815296    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023708804 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.035      |\n",
      "|    mean_step_reward   | 0.111289985 |\n",
      "|    n_updates          | 18.75 %     |\n",
      "|    policyGradLoss     | -0.0185     |\n",
      "|    value_loss         | 0.286       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 753         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 86          |\n",
      "|    total_timesteps    | 21823488    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025920644 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0117      |\n",
      "|    mean_step_reward   | 0.0901615   |\n",
      "|    n_updates          | 21.88 %     |\n",
      "|    policyGradLoss     | -0.0184     |\n",
      "|    value_loss         | 0.256       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 747         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 98          |\n",
      "|    total_timesteps    | 21831680    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026273666 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.954       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0374     |\n",
      "|    mean_step_reward   | 0.11427259  |\n",
      "|    n_updates          | 25.00 %     |\n",
      "|    policyGradLoss     | -0.0143     |\n",
      "|    value_loss         | 0.296       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 745         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 109         |\n",
      "|    total_timesteps    | 21839872    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022400644 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.942       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0394     |\n",
      "|    mean_step_reward   | 0.09161922  |\n",
      "|    n_updates          | 28.12 %     |\n",
      "|    policyGradLoss     | -0.0193     |\n",
      "|    value_loss         | 0.281       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 745         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 120         |\n",
      "|    total_timesteps    | 21848064    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030493371 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0496     |\n",
      "|    mean_step_reward   | 0.12970032  |\n",
      "|    n_updates          | 31.25 %     |\n",
      "|    policyGradLoss     | -0.0168     |\n",
      "|    value_loss         | 0.235       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 746         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 131         |\n",
      "|    total_timesteps    | 21856256    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023415051 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0373     |\n",
      "|    mean_step_reward   | 0.09763564  |\n",
      "|    n_updates          | 34.38 %     |\n",
      "|    policyGradLoss     | -0.0157     |\n",
      "|    value_loss         | 0.298       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 746         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 142         |\n",
      "|    total_timesteps    | 21864448    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01954947  |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0183     |\n",
      "|    mean_step_reward   | 0.099175885 |\n",
      "|    n_updates          | 37.50 %     |\n",
      "|    policyGradLoss     | -0.014      |\n",
      "|    value_loss         | 0.28        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 744         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 154         |\n",
      "|    total_timesteps    | 21872640    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026535174 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0434     |\n",
      "|    mean_step_reward   | 0.11432911  |\n",
      "|    n_updates          | 40.62 %     |\n",
      "|    policyGradLoss     | -0.0196     |\n",
      "|    value_loss         | 0.239       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 741        |\n",
      "|    iterations         | 15         |\n",
      "|    time_elapsed       | 165        |\n",
      "|    total_timesteps    | 21880832   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02219195 |\n",
      "|    entropy_loss       | -1.92      |\n",
      "|    explained_variance | 0.95       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.0114     |\n",
      "|    mean_step_reward   | 0.09081796 |\n",
      "|    n_updates          | 43.75 %    |\n",
      "|    policyGradLoss     | -0.0163    |\n",
      "|    value_loss         | 0.28       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 739         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 177         |\n",
      "|    total_timesteps    | 21889024    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030748237 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0688     |\n",
      "|    mean_step_reward   | 0.11436668  |\n",
      "|    n_updates          | 46.88 %     |\n",
      "|    policyGradLoss     | -0.017      |\n",
      "|    value_loss         | 0.167       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 738         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 188         |\n",
      "|    total_timesteps    | 21897216    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027101232 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0497     |\n",
      "|    mean_step_reward   | 0.0978467   |\n",
      "|    n_updates          | 50.00 %     |\n",
      "|    policyGradLoss     | -0.0238     |\n",
      "|    value_loss         | 0.119       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 737         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 199         |\n",
      "|    total_timesteps    | 21905408    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025633305 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0591     |\n",
      "|    mean_step_reward   | 0.12865347  |\n",
      "|    n_updates          | 53.12 %     |\n",
      "|    policyGradLoss     | -0.0211     |\n",
      "|    value_loss         | 0.161       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 737         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 211         |\n",
      "|    total_timesteps    | 21913600    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020173557 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.958       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0405     |\n",
      "|    mean_step_reward   | 0.09587817  |\n",
      "|    n_updates          | 56.25 %     |\n",
      "|    policyGradLoss     | -0.0156     |\n",
      "|    value_loss         | 0.206       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 737         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 222         |\n",
      "|    total_timesteps    | 21921792    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027090201 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0237      |\n",
      "|    mean_step_reward   | 0.11830518  |\n",
      "|    n_updates          | 59.38 %     |\n",
      "|    policyGradLoss     | -0.0157     |\n",
      "|    value_loss         | 0.31        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 737         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 233         |\n",
      "|    total_timesteps    | 21929984    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.031008352 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0434     |\n",
      "|    mean_step_reward   | 0.11781978  |\n",
      "|    n_updates          | 62.50 %     |\n",
      "|    policyGradLoss     | -0.0213     |\n",
      "|    value_loss         | 0.221       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 736         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 244         |\n",
      "|    total_timesteps    | 21938176    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018982753 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.941       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0551      |\n",
      "|    mean_step_reward   | 0.10335238  |\n",
      "|    n_updates          | 65.62 %     |\n",
      "|    policyGradLoss     | -0.0152     |\n",
      "|    value_loss         | 0.259       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 734         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 256         |\n",
      "|    total_timesteps    | 21946368    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018730845 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.933       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00187    |\n",
      "|    mean_step_reward   | 0.10465915  |\n",
      "|    n_updates          | 68.75 %     |\n",
      "|    policyGradLoss     | -0.0143     |\n",
      "|    value_loss         | 0.283       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 740         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 265         |\n",
      "|    total_timesteps    | 21954560    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023781182 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0651     |\n",
      "|    mean_step_reward   | 0.10827098  |\n",
      "|    n_updates          | 71.88 %     |\n",
      "|    policyGradLoss     | -0.0166     |\n",
      "|    value_loss         | 0.193       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 746         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 274         |\n",
      "|    total_timesteps    | 21962752    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024283662 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.955       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0422     |\n",
      "|    mean_step_reward   | 0.11804949  |\n",
      "|    n_updates          | 75.00 %     |\n",
      "|    policyGradLoss     | -0.0191     |\n",
      "|    value_loss         | 0.253       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 750         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 283         |\n",
      "|    total_timesteps    | 21970944    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022816174 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.945       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0417     |\n",
      "|    mean_step_reward   | 0.09327701  |\n",
      "|    n_updates          | 78.12 %     |\n",
      "|    policyGradLoss     | -0.0195     |\n",
      "|    value_loss         | 0.241       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 754         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 293         |\n",
      "|    total_timesteps    | 21979136    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024795253 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.958       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00692     |\n",
      "|    mean_step_reward   | 0.113896824 |\n",
      "|    n_updates          | 81.25 %     |\n",
      "|    policyGradLoss     | -0.0184     |\n",
      "|    value_loss         | 0.268       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 752        |\n",
      "|    iterations         | 28         |\n",
      "|    time_elapsed       | 304        |\n",
      "|    total_timesteps    | 21987328   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02193503 |\n",
      "|    entropy_loss       | -1.83      |\n",
      "|    explained_variance | 0.95       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0175    |\n",
      "|    mean_step_reward   | 0.12610152 |\n",
      "|    n_updates          | 84.38 %    |\n",
      "|    policyGradLoss     | -0.0176    |\n",
      "|    value_loss         | 0.28       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 751         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 316         |\n",
      "|    total_timesteps    | 21995520    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025373623 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.038       |\n",
      "|    mean_step_reward   | 0.11084565  |\n",
      "|    n_updates          | 87.50 %     |\n",
      "|    policyGradLoss     | -0.021      |\n",
      "|    value_loss         | 0.19        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 750         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 327         |\n",
      "|    total_timesteps    | 22003712    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024700172 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0337      |\n",
      "|    mean_step_reward   | 0.12932712  |\n",
      "|    n_updates          | 90.62 %     |\n",
      "|    policyGradLoss     | -0.0191     |\n",
      "|    value_loss         | 0.247       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 750        |\n",
      "|    iterations         | 31         |\n",
      "|    time_elapsed       | 338        |\n",
      "|    total_timesteps    | 22011904   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02300539 |\n",
      "|    entropy_loss       | -1.91      |\n",
      "|    explained_variance | 0.948      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.0712     |\n",
      "|    mean_step_reward   | 0.08831363 |\n",
      "|    n_updates          | 93.75 %    |\n",
      "|    policyGradLoss     | -0.0171    |\n",
      "|    value_loss         | 0.343      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 749        |\n",
      "|    iterations         | 32         |\n",
      "|    time_elapsed       | 349        |\n",
      "|    total_timesteps    | 22020096   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02504025 |\n",
      "|    entropy_loss       | -1.85      |\n",
      "|    explained_variance | 0.937      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.00476   |\n",
      "|    mean_step_reward   | 0.09722401 |\n",
      "|    n_updates          | 96.88 %    |\n",
      "|    policyGradLoss     | -0.0125    |\n",
      "|    value_loss         | 0.361      |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Run_83.zip\n",
      "[EVAL] Mean Return: 153.640, Best Return: 160.640\n",
      "Saved video to ./runs_smw/videos/Run/Run_83_153.64.mp4\n",
      "\n",
      "=== Round 85 | Learn 262144 steps (Total trained: 22020096) ===\n",
      "Logging to ./runs_smw/tb/Run_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1148     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 22028288 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 884         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 22036480    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025538363 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.941       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0957      |\n",
      "|    mean_step_reward   | 0.10953924  |\n",
      "|    n_updates          | 3.12 %      |\n",
      "|    policyGradLoss     | -0.0173     |\n",
      "|    value_loss         | 0.423       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 811         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 30          |\n",
      "|    total_timesteps    | 22044672    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029462554 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0357     |\n",
      "|    mean_step_reward   | 0.12481443  |\n",
      "|    n_updates          | 6.25 %      |\n",
      "|    policyGradLoss     | -0.0215     |\n",
      "|    value_loss         | 0.215       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 41          |\n",
      "|    total_timesteps    | 22052864    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027926868 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0552     |\n",
      "|    mean_step_reward   | 0.11611089  |\n",
      "|    n_updates          | 9.38 %      |\n",
      "|    policyGradLoss     | -0.0175     |\n",
      "|    value_loss         | 0.195       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 53          |\n",
      "|    total_timesteps    | 22061056    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026016945 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.925       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.000944    |\n",
      "|    mean_step_reward   | 0.104808316 |\n",
      "|    n_updates          | 12.50 %     |\n",
      "|    policyGradLoss     | -0.0177     |\n",
      "|    value_loss         | 0.437       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 64          |\n",
      "|    total_timesteps    | 22069248    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026114143 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.944       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0488     |\n",
      "|    mean_step_reward   | 0.122397415 |\n",
      "|    n_updates          | 15.62 %     |\n",
      "|    policyGradLoss     | -0.0163     |\n",
      "|    value_loss         | 0.29        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 762         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 75          |\n",
      "|    total_timesteps    | 22077440    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027395118 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0494     |\n",
      "|    mean_step_reward   | 0.10892148  |\n",
      "|    n_updates          | 18.75 %     |\n",
      "|    policyGradLoss     | -0.0205     |\n",
      "|    value_loss         | 0.166       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 757         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 86          |\n",
      "|    total_timesteps    | 22085632    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020157032 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.948       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0167     |\n",
      "|    mean_step_reward   | 0.13354042  |\n",
      "|    n_updates          | 21.88 %     |\n",
      "|    policyGradLoss     | -0.0149     |\n",
      "|    value_loss         | 0.339       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 753         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 97          |\n",
      "|    total_timesteps    | 22093824    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030640554 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0177     |\n",
      "|    mean_step_reward   | 0.12017013  |\n",
      "|    n_updates          | 25.00 %     |\n",
      "|    policyGradLoss     | -0.0182     |\n",
      "|    value_loss         | 0.231       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 748         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 109         |\n",
      "|    total_timesteps    | 22102016    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030143782 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0385     |\n",
      "|    mean_step_reward   | 0.12401472  |\n",
      "|    n_updates          | 28.12 %     |\n",
      "|    policyGradLoss     | -0.02       |\n",
      "|    value_loss         | 0.246       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 744         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 121         |\n",
      "|    total_timesteps    | 22110208    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030586794 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.07       |\n",
      "|    mean_step_reward   | 0.12021048  |\n",
      "|    n_updates          | 31.25 %     |\n",
      "|    policyGradLoss     | -0.0228     |\n",
      "|    value_loss         | 0.164       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 742         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 132         |\n",
      "|    total_timesteps    | 22118400    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021664647 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0167     |\n",
      "|    mean_step_reward   | 0.119306505 |\n",
      "|    n_updates          | 34.38 %     |\n",
      "|    policyGradLoss     | -0.0158     |\n",
      "|    value_loss         | 0.235       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 741         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 143         |\n",
      "|    total_timesteps    | 22126592    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024590243 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.952       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0539     |\n",
      "|    mean_step_reward   | 0.12186015  |\n",
      "|    n_updates          | 37.50 %     |\n",
      "|    policyGradLoss     | -0.0182     |\n",
      "|    value_loss         | 0.269       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 742        |\n",
      "|    iterations         | 14         |\n",
      "|    time_elapsed       | 154        |\n",
      "|    total_timesteps    | 22134784   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03048762 |\n",
      "|    entropy_loss       | -1.83      |\n",
      "|    explained_variance | 0.97       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0314    |\n",
      "|    mean_step_reward   | 0.11648205 |\n",
      "|    n_updates          | 40.62 %    |\n",
      "|    policyGradLoss     | -0.0211    |\n",
      "|    value_loss         | 0.206      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 741         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 165         |\n",
      "|    total_timesteps    | 22142976    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023654312 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.957       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0128     |\n",
      "|    mean_step_reward   | 0.112891614 |\n",
      "|    n_updates          | 43.75 %     |\n",
      "|    policyGradLoss     | -0.0171     |\n",
      "|    value_loss         | 0.292       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 740         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 176         |\n",
      "|    total_timesteps    | 22151168    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026323173 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00619     |\n",
      "|    mean_step_reward   | 0.123478845 |\n",
      "|    n_updates          | 46.88 %     |\n",
      "|    policyGradLoss     | -0.0183     |\n",
      "|    value_loss         | 0.281       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 738         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 188         |\n",
      "|    total_timesteps    | 22159360    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029416189 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.043      |\n",
      "|    mean_step_reward   | 0.11872139  |\n",
      "|    n_updates          | 50.00 %     |\n",
      "|    policyGradLoss     | -0.0213     |\n",
      "|    value_loss         | 0.173       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 736        |\n",
      "|    iterations         | 18         |\n",
      "|    time_elapsed       | 200        |\n",
      "|    total_timesteps    | 22167552   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02887943 |\n",
      "|    entropy_loss       | -1.83      |\n",
      "|    explained_variance | 0.975      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0597    |\n",
      "|    mean_step_reward   | 0.12547179 |\n",
      "|    n_updates          | 53.12 %    |\n",
      "|    policyGradLoss     | -0.0235    |\n",
      "|    value_loss         | 0.157      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 735         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 211         |\n",
      "|    total_timesteps    | 22175744    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020544503 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0174     |\n",
      "|    mean_step_reward   | 0.112127155 |\n",
      "|    n_updates          | 56.25 %     |\n",
      "|    policyGradLoss     | -0.0173     |\n",
      "|    value_loss         | 0.265       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 735         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 222         |\n",
      "|    total_timesteps    | 22183936    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029585198 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0515     |\n",
      "|    mean_step_reward   | 0.13688226  |\n",
      "|    n_updates          | 59.38 %     |\n",
      "|    policyGradLoss     | -0.0179     |\n",
      "|    value_loss         | 0.173       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 743        |\n",
      "|    iterations         | 21         |\n",
      "|    time_elapsed       | 231        |\n",
      "|    total_timesteps    | 22192128   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02619035 |\n",
      "|    entropy_loss       | -1.84      |\n",
      "|    explained_variance | 0.953      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0149    |\n",
      "|    mean_step_reward   | 0.09397498 |\n",
      "|    n_updates          | 62.50 %    |\n",
      "|    policyGradLoss     | -0.0156    |\n",
      "|    value_loss         | 0.309      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 749         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 240         |\n",
      "|    total_timesteps    | 22200320    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030761378 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.055      |\n",
      "|    mean_step_reward   | 0.13349283  |\n",
      "|    n_updates          | 65.62 %     |\n",
      "|    policyGradLoss     | -0.0193     |\n",
      "|    value_loss         | 0.199       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 754         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 249         |\n",
      "|    total_timesteps    | 22208512    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028499573 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0653     |\n",
      "|    mean_step_reward   | 0.12740111  |\n",
      "|    n_updates          | 68.75 %     |\n",
      "|    policyGradLoss     | -0.0174     |\n",
      "|    value_loss         | 0.135       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 755         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 260         |\n",
      "|    total_timesteps    | 22216704    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017314654 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.949       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0316     |\n",
      "|    mean_step_reward   | 0.11259921  |\n",
      "|    n_updates          | 71.88 %     |\n",
      "|    policyGradLoss     | -0.0102     |\n",
      "|    value_loss         | 0.237       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 753         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 271         |\n",
      "|    total_timesteps    | 22224896    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024250444 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.952       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0365     |\n",
      "|    mean_step_reward   | 0.111818805 |\n",
      "|    n_updates          | 75.00 %     |\n",
      "|    policyGradLoss     | -0.0183     |\n",
      "|    value_loss         | 0.193       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 751         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 283         |\n",
      "|    total_timesteps    | 22233088    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022648782 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.931       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0494     |\n",
      "|    mean_step_reward   | 0.099455684 |\n",
      "|    n_updates          | 78.12 %     |\n",
      "|    policyGradLoss     | -0.0164     |\n",
      "|    value_loss         | 0.322       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 751         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 294         |\n",
      "|    total_timesteps    | 22241280    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020748965 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.94        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0487      |\n",
      "|    mean_step_reward   | 0.105184376 |\n",
      "|    n_updates          | 81.25 %     |\n",
      "|    policyGradLoss     | -0.0176     |\n",
      "|    value_loss         | 0.411       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 751         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 305         |\n",
      "|    total_timesteps    | 22249472    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024504298 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00825    |\n",
      "|    mean_step_reward   | 0.115409166 |\n",
      "|    n_updates          | 84.38 %     |\n",
      "|    policyGradLoss     | -0.0198     |\n",
      "|    value_loss         | 0.272       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 750        |\n",
      "|    iterations         | 29         |\n",
      "|    time_elapsed       | 316        |\n",
      "|    total_timesteps    | 22257664   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02125995 |\n",
      "|    entropy_loss       | -1.83      |\n",
      "|    explained_variance | 0.963      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.00962    |\n",
      "|    mean_step_reward   | 0.11239448 |\n",
      "|    n_updates          | 87.50 %    |\n",
      "|    policyGradLoss     | -0.0201    |\n",
      "|    value_loss         | 0.32       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 750         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 327         |\n",
      "|    total_timesteps    | 22265856    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022084212 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0284     |\n",
      "|    mean_step_reward   | 0.12900838  |\n",
      "|    n_updates          | 90.62 %     |\n",
      "|    policyGradLoss     | -0.0211     |\n",
      "|    value_loss         | 0.261       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 748         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 339         |\n",
      "|    total_timesteps    | 22274048    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023529537 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0314     |\n",
      "|    mean_step_reward   | 0.11880792  |\n",
      "|    n_updates          | 93.75 %     |\n",
      "|    policyGradLoss     | -0.021      |\n",
      "|    value_loss         | 0.214       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 747         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 350         |\n",
      "|    total_timesteps    | 22282240    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027711654 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.955       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.03       |\n",
      "|    mean_step_reward   | 0.11818847  |\n",
      "|    n_updates          | 96.88 %     |\n",
      "|    policyGradLoss     | -0.0187     |\n",
      "|    value_loss         | 0.243       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Run_84.zip\n",
      "[EVAL] Mean Return: 153.382, Best Return: 160.048\n",
      "Saved video to ./runs_smw/videos/Run/Run_84_153.38.mp4\n",
      "\n",
      "=== Round 86 | Learn 262144 steps (Total trained: 22282240) ===\n",
      "Logging to ./runs_smw/tb/Run_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1167     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 22290432 |\n",
      "---------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 911        |\n",
      "|    iterations         | 2          |\n",
      "|    time_elapsed       | 17         |\n",
      "|    total_timesteps    | 22298624   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01948456 |\n",
      "|    entropy_loss       | -1.89      |\n",
      "|    explained_variance | 0.944      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.00423    |\n",
      "|    mean_step_reward   | 0.11124082 |\n",
      "|    n_updates          | 3.12 %     |\n",
      "|    policyGradLoss     | -0.0164    |\n",
      "|    value_loss         | 0.314      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 841         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 29          |\n",
      "|    total_timesteps    | 22306816    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022413969 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0339     |\n",
      "|    mean_step_reward   | 0.12213792  |\n",
      "|    n_updates          | 6.25 %      |\n",
      "|    policyGradLoss     | -0.0203     |\n",
      "|    value_loss         | 0.249       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 804         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 40          |\n",
      "|    total_timesteps    | 22315008    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021166328 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.954       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0552     |\n",
      "|    mean_step_reward   | 0.09620473  |\n",
      "|    n_updates          | 9.38 %      |\n",
      "|    policyGradLoss     | -0.0179     |\n",
      "|    value_loss         | 0.168       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 52          |\n",
      "|    total_timesteps    | 22323200    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025127012 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.95        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0264      |\n",
      "|    mean_step_reward   | 0.10942059  |\n",
      "|    n_updates          | 12.50 %     |\n",
      "|    policyGradLoss     | -0.0165     |\n",
      "|    value_loss         | 0.275       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 63          |\n",
      "|    total_timesteps    | 22331392    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022180583 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00438    |\n",
      "|    mean_step_reward   | 0.09832795  |\n",
      "|    n_updates          | 15.62 %     |\n",
      "|    policyGradLoss     | -0.0195     |\n",
      "|    value_loss         | 0.26        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 762         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 75          |\n",
      "|    total_timesteps    | 22339584    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023705099 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00505    |\n",
      "|    mean_step_reward   | 0.116820335 |\n",
      "|    n_updates          | 18.75 %     |\n",
      "|    policyGradLoss     | -0.0209     |\n",
      "|    value_loss         | 0.272       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 760         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 86          |\n",
      "|    total_timesteps    | 22347776    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023147205 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0175     |\n",
      "|    mean_step_reward   | 0.1194534   |\n",
      "|    n_updates          | 21.88 %     |\n",
      "|    policyGradLoss     | -0.0174     |\n",
      "|    value_loss         | 0.264       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 759        |\n",
      "|    iterations         | 9          |\n",
      "|    time_elapsed       | 97         |\n",
      "|    total_timesteps    | 22355968   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02676021 |\n",
      "|    entropy_loss       | -1.82      |\n",
      "|    explained_variance | 0.956      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0406    |\n",
      "|    mean_step_reward   | 0.11298882 |\n",
      "|    n_updates          | 25.00 %    |\n",
      "|    policyGradLoss     | -0.0159    |\n",
      "|    value_loss         | 0.258      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 758         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 107         |\n",
      "|    total_timesteps    | 22364160    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024288606 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0465     |\n",
      "|    mean_step_reward   | 0.10941466  |\n",
      "|    n_updates          | 28.12 %     |\n",
      "|    policyGradLoss     | -0.0153     |\n",
      "|    value_loss         | 0.191       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 754        |\n",
      "|    iterations         | 11         |\n",
      "|    time_elapsed       | 119        |\n",
      "|    total_timesteps    | 22372352   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02703302 |\n",
      "|    entropy_loss       | -1.85      |\n",
      "|    explained_variance | 0.962      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.11       |\n",
      "|    mean_step_reward   | 0.11672346 |\n",
      "|    n_updates          | 31.25 %    |\n",
      "|    policyGradLoss     | -0.0197    |\n",
      "|    value_loss         | 0.266      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 750         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 130         |\n",
      "|    total_timesteps    | 22380544    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027163388 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00911    |\n",
      "|    mean_step_reward   | 0.13061836  |\n",
      "|    n_updates          | 34.38 %     |\n",
      "|    policyGradLoss     | -0.0183     |\n",
      "|    value_loss         | 0.189       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 746         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 142         |\n",
      "|    total_timesteps    | 22388736    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024768699 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.039      |\n",
      "|    mean_step_reward   | 0.116148785 |\n",
      "|    n_updates          | 37.50 %     |\n",
      "|    policyGradLoss     | -0.0194     |\n",
      "|    value_loss         | 0.219       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 745         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 153         |\n",
      "|    total_timesteps    | 22396928    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026369391 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.027      |\n",
      "|    mean_step_reward   | 0.11261631  |\n",
      "|    n_updates          | 40.62 %     |\n",
      "|    policyGradLoss     | -0.0186     |\n",
      "|    value_loss         | 0.247       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 745         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 164         |\n",
      "|    total_timesteps    | 22405120    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.039717816 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.957       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0207     |\n",
      "|    mean_step_reward   | 0.09573818  |\n",
      "|    n_updates          | 43.75 %     |\n",
      "|    policyGradLoss     | -0.0212     |\n",
      "|    value_loss         | 0.268       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 745         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 175         |\n",
      "|    total_timesteps    | 22413312    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028818458 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0396     |\n",
      "|    mean_step_reward   | 0.1287596   |\n",
      "|    n_updates          | 46.88 %     |\n",
      "|    policyGradLoss     | -0.0213     |\n",
      "|    value_loss         | 0.187       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 751         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 185         |\n",
      "|    total_timesteps    | 22421504    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.031849984 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0437     |\n",
      "|    mean_step_reward   | 0.11012094  |\n",
      "|    n_updates          | 50.00 %     |\n",
      "|    policyGradLoss     | -0.0222     |\n",
      "|    value_loss         | 0.167       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 759        |\n",
      "|    iterations         | 18         |\n",
      "|    time_elapsed       | 194        |\n",
      "|    total_timesteps    | 22429696   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03279846 |\n",
      "|    entropy_loss       | -1.84      |\n",
      "|    explained_variance | 0.979      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0663    |\n",
      "|    mean_step_reward   | 0.11702311 |\n",
      "|    n_updates          | 53.12 %    |\n",
      "|    policyGradLoss     | -0.0221    |\n",
      "|    value_loss         | 0.122      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 764        |\n",
      "|    iterations         | 19         |\n",
      "|    time_elapsed       | 203        |\n",
      "|    total_timesteps    | 22437888   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02384309 |\n",
      "|    entropy_loss       | -1.84      |\n",
      "|    explained_variance | 0.954      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.0839     |\n",
      "|    mean_step_reward   | 0.11018034 |\n",
      "|    n_updates          | 56.25 %    |\n",
      "|    policyGradLoss     | -0.0166    |\n",
      "|    value_loss         | 0.315      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 213         |\n",
      "|    total_timesteps    | 22446080    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021342799 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.957       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00709    |\n",
      "|    mean_step_reward   | 0.10354967  |\n",
      "|    n_updates          | 59.38 %     |\n",
      "|    policyGradLoss     | -0.0164     |\n",
      "|    value_loss         | 0.297       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 223         |\n",
      "|    total_timesteps    | 22454272    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022872968 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0187     |\n",
      "|    mean_step_reward   | 0.08956383  |\n",
      "|    n_updates          | 62.50 %     |\n",
      "|    policyGradLoss     | -0.0142     |\n",
      "|    value_loss         | 0.27        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 234         |\n",
      "|    total_timesteps    | 22462464    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028334696 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0271     |\n",
      "|    mean_step_reward   | 0.099093    |\n",
      "|    n_updates          | 65.62 %     |\n",
      "|    policyGradLoss     | -0.0186     |\n",
      "|    value_loss         | 0.22        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 245         |\n",
      "|    total_timesteps    | 22470656    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026172258 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0292     |\n",
      "|    mean_step_reward   | 0.11771562  |\n",
      "|    n_updates          | 68.75 %     |\n",
      "|    policyGradLoss     | -0.0191     |\n",
      "|    value_loss         | 0.249       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 764        |\n",
      "|    iterations         | 24         |\n",
      "|    time_elapsed       | 257        |\n",
      "|    total_timesteps    | 22478848   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02716387 |\n",
      "|    entropy_loss       | -1.84      |\n",
      "|    explained_variance | 0.972      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0599    |\n",
      "|    mean_step_reward   | 0.1195544  |\n",
      "|    n_updates          | 71.88 %    |\n",
      "|    policyGradLoss     | -0.0183    |\n",
      "|    value_loss         | 0.174      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 762         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 268         |\n",
      "|    total_timesteps    | 22487040    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023631783 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0163     |\n",
      "|    mean_step_reward   | 0.10466241  |\n",
      "|    n_updates          | 75.00 %     |\n",
      "|    policyGradLoss     | -0.0183     |\n",
      "|    value_loss         | 0.21        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 760         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 280         |\n",
      "|    total_timesteps    | 22495232    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020958237 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.925       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0102     |\n",
      "|    mean_step_reward   | 0.111092076 |\n",
      "|    n_updates          | 78.12 %     |\n",
      "|    policyGradLoss     | -0.0123     |\n",
      "|    value_loss         | 0.38        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 758         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 291         |\n",
      "|    total_timesteps    | 22503424    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023333471 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.039      |\n",
      "|    mean_step_reward   | 0.10196848  |\n",
      "|    n_updates          | 81.25 %     |\n",
      "|    policyGradLoss     | -0.0167     |\n",
      "|    value_loss         | 0.25        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 757         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 302         |\n",
      "|    total_timesteps    | 22511616    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021496374 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.957       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0111     |\n",
      "|    mean_step_reward   | 0.09631959  |\n",
      "|    n_updates          | 84.38 %     |\n",
      "|    policyGradLoss     | -0.0185     |\n",
      "|    value_loss         | 0.299       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 756        |\n",
      "|    iterations         | 29         |\n",
      "|    time_elapsed       | 313        |\n",
      "|    total_timesteps    | 22519808   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02510577 |\n",
      "|    entropy_loss       | -1.86      |\n",
      "|    explained_variance | 0.955      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0159    |\n",
      "|    mean_step_reward   | 0.09904645 |\n",
      "|    n_updates          | 87.50 %    |\n",
      "|    policyGradLoss     | -0.0164    |\n",
      "|    value_loss         | 0.311      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 756        |\n",
      "|    iterations         | 30         |\n",
      "|    time_elapsed       | 324        |\n",
      "|    total_timesteps    | 22528000   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01751902 |\n",
      "|    entropy_loss       | -1.8       |\n",
      "|    explained_variance | 0.93       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.0625     |\n",
      "|    mean_step_reward   | 0.12093163 |\n",
      "|    n_updates          | 90.62 %    |\n",
      "|    policyGradLoss     | -0.0129    |\n",
      "|    value_loss         | 0.445      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 754        |\n",
      "|    iterations         | 31         |\n",
      "|    time_elapsed       | 336        |\n",
      "|    total_timesteps    | 22536192   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01884085 |\n",
      "|    entropy_loss       | -1.84      |\n",
      "|    explained_variance | 0.948      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.00247    |\n",
      "|    mean_step_reward   | 0.11622764 |\n",
      "|    n_updates          | 93.75 %    |\n",
      "|    policyGradLoss     | -0.0148    |\n",
      "|    value_loss         | 0.308      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 753         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 348         |\n",
      "|    total_timesteps    | 22544384    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016623609 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.948       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0344     |\n",
      "|    mean_step_reward   | 0.115927726 |\n",
      "|    n_updates          | 96.88 %     |\n",
      "|    policyGradLoss     | -0.0134     |\n",
      "|    value_loss         | 0.262       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Run_85.zip\n",
      "[EVAL] Mean Return: 142.183, Best Return: 148.850\n",
      "Saved video to ./runs_smw/videos/Run/Run_85_142.18.mp4\n",
      "\n",
      "=== Round 87 | Learn 262144 steps (Total trained: 22544384) ===\n",
      "Logging to ./runs_smw/tb/Run_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1145     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 22552576 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 892         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 22560768    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027785089 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0692      |\n",
      "|    mean_step_reward   | 0.106611654 |\n",
      "|    n_updates          | 3.12 %      |\n",
      "|    policyGradLoss     | -0.0202     |\n",
      "|    value_loss         | 0.199       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 839        |\n",
      "|    iterations         | 3          |\n",
      "|    time_elapsed       | 29         |\n",
      "|    total_timesteps    | 22568960   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02707553 |\n",
      "|    entropy_loss       | -1.79      |\n",
      "|    explained_variance | 0.965      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.00542    |\n",
      "|    mean_step_reward   | 0.13798648 |\n",
      "|    n_updates          | 6.25 %     |\n",
      "|    policyGradLoss     | -0.0163    |\n",
      "|    value_loss         | 0.263      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 811         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 40          |\n",
      "|    total_timesteps    | 22577152    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024787737 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -5.78e-05   |\n",
      "|    mean_step_reward   | 0.11580739  |\n",
      "|    n_updates          | 9.38 %      |\n",
      "|    policyGradLoss     | -0.0168     |\n",
      "|    value_loss         | 0.186       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 789         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 51          |\n",
      "|    total_timesteps    | 22585344    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018136859 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.014      |\n",
      "|    mean_step_reward   | 0.14159948  |\n",
      "|    n_updates          | 12.50 %     |\n",
      "|    policyGradLoss     | -0.0164     |\n",
      "|    value_loss         | 0.266       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 773        |\n",
      "|    iterations         | 6          |\n",
      "|    time_elapsed       | 63         |\n",
      "|    total_timesteps    | 22593536   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02412751 |\n",
      "|    entropy_loss       | -1.83      |\n",
      "|    explained_variance | 0.96       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0529    |\n",
      "|    mean_step_reward   | 0.110416   |\n",
      "|    n_updates          | 15.62 %    |\n",
      "|    policyGradLoss     | -0.018     |\n",
      "|    value_loss         | 0.202      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 74          |\n",
      "|    total_timesteps    | 22601728    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020594425 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.948       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.03       |\n",
      "|    mean_step_reward   | 0.115887284 |\n",
      "|    n_updates          | 18.75 %     |\n",
      "|    policyGradLoss     | -0.0156     |\n",
      "|    value_loss         | 0.336       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 762         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 86          |\n",
      "|    total_timesteps    | 22609920    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022741254 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0413      |\n",
      "|    mean_step_reward   | 0.12544218  |\n",
      "|    n_updates          | 21.88 %     |\n",
      "|    policyGradLoss     | -0.017      |\n",
      "|    value_loss         | 0.216       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 760         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 96          |\n",
      "|    total_timesteps    | 22618112    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026914421 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0517     |\n",
      "|    mean_step_reward   | 0.13073933  |\n",
      "|    n_updates          | 25.00 %     |\n",
      "|    policyGradLoss     | -0.0194     |\n",
      "|    value_loss         | 0.191       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 758         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 107         |\n",
      "|    total_timesteps    | 22626304    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022795841 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0456      |\n",
      "|    mean_step_reward   | 0.12913671  |\n",
      "|    n_updates          | 28.12 %     |\n",
      "|    policyGradLoss     | -0.0156     |\n",
      "|    value_loss         | 0.262       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 755         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 119         |\n",
      "|    total_timesteps    | 22634496    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025206514 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.000141    |\n",
      "|    mean_step_reward   | 0.11265987  |\n",
      "|    n_updates          | 31.25 %     |\n",
      "|    policyGradLoss     | -0.0185     |\n",
      "|    value_loss         | 0.244       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 751         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 130         |\n",
      "|    total_timesteps    | 22642688    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.035762005 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0623     |\n",
      "|    mean_step_reward   | 0.1300563   |\n",
      "|    n_updates          | 34.38 %     |\n",
      "|    policyGradLoss     | -0.0231     |\n",
      "|    value_loss         | 0.131       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 748         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 142         |\n",
      "|    total_timesteps    | 22650880    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021869851 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0442     |\n",
      "|    mean_step_reward   | 0.124514446 |\n",
      "|    n_updates          | 37.50 %     |\n",
      "|    policyGradLoss     | -0.0193     |\n",
      "|    value_loss         | 0.164       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 750         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 152         |\n",
      "|    total_timesteps    | 22659072    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027467884 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0635     |\n",
      "|    mean_step_reward   | 0.13705537  |\n",
      "|    n_updates          | 40.62 %     |\n",
      "|    policyGradLoss     | -0.0206     |\n",
      "|    value_loss         | 0.132       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 760         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 161         |\n",
      "|    total_timesteps    | 22667264    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027064048 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0506     |\n",
      "|    mean_step_reward   | 0.10927085  |\n",
      "|    n_updates          | 43.75 %     |\n",
      "|    policyGradLoss     | -0.0172     |\n",
      "|    value_loss         | 0.194       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 170         |\n",
      "|    total_timesteps    | 22675456    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.031638943 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00695    |\n",
      "|    mean_step_reward   | 0.13262385  |\n",
      "|    n_updates          | 46.88 %     |\n",
      "|    policyGradLoss     | -0.0228     |\n",
      "|    value_loss         | 0.131       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 180         |\n",
      "|    total_timesteps    | 22683648    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.032784294 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0605     |\n",
      "|    mean_step_reward   | 0.115945674 |\n",
      "|    n_updates          | 50.00 %     |\n",
      "|    policyGradLoss     | -0.0207     |\n",
      "|    value_loss         | 0.157       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 191         |\n",
      "|    total_timesteps    | 22691840    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023372278 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0313     |\n",
      "|    mean_step_reward   | 0.13700905  |\n",
      "|    n_updates          | 53.12 %     |\n",
      "|    policyGradLoss     | -0.0155     |\n",
      "|    value_loss         | 0.255       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 203         |\n",
      "|    total_timesteps    | 22700032    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023335466 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0142     |\n",
      "|    mean_step_reward   | 0.11415452  |\n",
      "|    n_updates          | 56.25 %     |\n",
      "|    policyGradLoss     | -0.0179     |\n",
      "|    value_loss         | 0.203       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 764         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 214         |\n",
      "|    total_timesteps    | 22708224    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029065916 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0544     |\n",
      "|    mean_step_reward   | 0.12900239  |\n",
      "|    n_updates          | 59.38 %     |\n",
      "|    policyGradLoss     | -0.0193     |\n",
      "|    value_loss         | 0.138       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 762         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 225         |\n",
      "|    total_timesteps    | 22716416    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025709555 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.951       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.000215    |\n",
      "|    mean_step_reward   | 0.11230736  |\n",
      "|    n_updates          | 62.50 %     |\n",
      "|    policyGradLoss     | -0.016      |\n",
      "|    value_loss         | 0.349       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 761         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 236         |\n",
      "|    total_timesteps    | 22724608    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022441586 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.957       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00114     |\n",
      "|    mean_step_reward   | 0.11257921  |\n",
      "|    n_updates          | 65.62 %     |\n",
      "|    policyGradLoss     | -0.0179     |\n",
      "|    value_loss         | 0.252       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 760        |\n",
      "|    iterations         | 23         |\n",
      "|    time_elapsed       | 247        |\n",
      "|    total_timesteps    | 22732800   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02230876 |\n",
      "|    entropy_loss       | -1.8       |\n",
      "|    explained_variance | 0.973      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.1        |\n",
      "|    mean_step_reward   | 0.12081385 |\n",
      "|    n_updates          | 68.75 %    |\n",
      "|    policyGradLoss     | -0.0178    |\n",
      "|    value_loss         | 0.232      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 759         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 258         |\n",
      "|    total_timesteps    | 22740992    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019760732 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.949       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.032      |\n",
      "|    mean_step_reward   | 0.12242967  |\n",
      "|    n_updates          | 71.88 %     |\n",
      "|    policyGradLoss     | -0.0167     |\n",
      "|    value_loss         | 0.282       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 756        |\n",
      "|    iterations         | 25         |\n",
      "|    time_elapsed       | 270        |\n",
      "|    total_timesteps    | 22749184   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02044773 |\n",
      "|    entropy_loss       | -1.84      |\n",
      "|    explained_variance | 0.948      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.00881   |\n",
      "|    mean_step_reward   | 0.12085337 |\n",
      "|    n_updates          | 75.00 %    |\n",
      "|    policyGradLoss     | -0.0151    |\n",
      "|    value_loss         | 0.258      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 754         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 282         |\n",
      "|    total_timesteps    | 22757376    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02336078  |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0351     |\n",
      "|    mean_step_reward   | 0.114898175 |\n",
      "|    n_updates          | 78.12 %     |\n",
      "|    policyGradLoss     | -0.0206     |\n",
      "|    value_loss         | 0.217       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 753         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 293         |\n",
      "|    total_timesteps    | 22765568    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022682423 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.958       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00889     |\n",
      "|    mean_step_reward   | 0.123915695 |\n",
      "|    n_updates          | 81.25 %     |\n",
      "|    policyGradLoss     | -0.0175     |\n",
      "|    value_loss         | 0.289       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 752         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 304         |\n",
      "|    total_timesteps    | 22773760    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021068037 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0165     |\n",
      "|    mean_step_reward   | 0.13248289  |\n",
      "|    n_updates          | 84.38 %     |\n",
      "|    policyGradLoss     | -0.0153     |\n",
      "|    value_loss         | 0.238       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 752         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 315         |\n",
      "|    total_timesteps    | 22781952    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027214527 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.065      |\n",
      "|    mean_step_reward   | 0.116473794 |\n",
      "|    n_updates          | 87.50 %     |\n",
      "|    policyGradLoss     | -0.0212     |\n",
      "|    value_loss         | 0.123       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 751         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 326         |\n",
      "|    total_timesteps    | 22790144    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027778225 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0419     |\n",
      "|    mean_step_reward   | 0.12890905  |\n",
      "|    n_updates          | 90.62 %     |\n",
      "|    policyGradLoss     | -0.0144     |\n",
      "|    value_loss         | 0.194       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 751         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 337         |\n",
      "|    total_timesteps    | 22798336    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020898737 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0279     |\n",
      "|    mean_step_reward   | 0.1227313   |\n",
      "|    n_updates          | 93.75 %     |\n",
      "|    policyGradLoss     | -0.0157     |\n",
      "|    value_loss         | 0.221       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 750         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 349         |\n",
      "|    total_timesteps    | 22806528    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022212008 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.957       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00591    |\n",
      "|    mean_step_reward   | 0.11703911  |\n",
      "|    n_updates          | 96.88 %     |\n",
      "|    policyGradLoss     | -0.0178     |\n",
      "|    value_loss         | 0.358       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Run_86.zip\n",
      "[EVAL] Mean Return: 154.329, Best Return: 161.329\n",
      "Saved video to ./runs_smw/videos/Run/Run_86_154.33.mp4\n",
      "\n",
      "=== Round 88 | Learn 262144 steps (Total trained: 22806528) ===\n",
      "Logging to ./runs_smw/tb/Run_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1090     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 22814720 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 874         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 22822912    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020861886 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.951       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00875    |\n",
      "|    mean_step_reward   | 0.11609556  |\n",
      "|    n_updates          | 3.12 %      |\n",
      "|    policyGradLoss     | -0.0182     |\n",
      "|    value_loss         | 0.278       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 820         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 29          |\n",
      "|    total_timesteps    | 22831104    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022351995 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.957       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.117       |\n",
      "|    mean_step_reward   | 0.12767294  |\n",
      "|    n_updates          | 6.25 %      |\n",
      "|    policyGradLoss     | -0.0154     |\n",
      "|    value_loss         | 0.326       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 800        |\n",
      "|    iterations         | 4          |\n",
      "|    time_elapsed       | 40         |\n",
      "|    total_timesteps    | 22839296   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02760524 |\n",
      "|    entropy_loss       | -1.93      |\n",
      "|    explained_variance | 0.909      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0412    |\n",
      "|    mean_step_reward   | 0.08630553 |\n",
      "|    n_updates          | 9.38 %     |\n",
      "|    policyGradLoss     | -0.0154    |\n",
      "|    value_loss         | 0.288      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 52          |\n",
      "|    total_timesteps    | 22847488    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021523267 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.958       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0564     |\n",
      "|    mean_step_reward   | 0.12270549  |\n",
      "|    n_updates          | 12.50 %     |\n",
      "|    policyGradLoss     | -0.018      |\n",
      "|    value_loss         | 0.221       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 772        |\n",
      "|    iterations         | 6          |\n",
      "|    time_elapsed       | 63         |\n",
      "|    total_timesteps    | 22855680   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02225176 |\n",
      "|    entropy_loss       | -1.91      |\n",
      "|    explained_variance | 0.958      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0368    |\n",
      "|    mean_step_reward   | 0.10221566 |\n",
      "|    n_updates          | 15.62 %    |\n",
      "|    policyGradLoss     | -0.0187    |\n",
      "|    value_loss         | 0.233      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 761         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 75          |\n",
      "|    total_timesteps    | 22863872    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021264909 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0261     |\n",
      "|    mean_step_reward   | 0.1196296   |\n",
      "|    n_updates          | 18.75 %     |\n",
      "|    policyGradLoss     | -0.0179     |\n",
      "|    value_loss         | 0.309       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 755        |\n",
      "|    iterations         | 8          |\n",
      "|    time_elapsed       | 86         |\n",
      "|    total_timesteps    | 22872064   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02284727 |\n",
      "|    entropy_loss       | -1.81      |\n",
      "|    explained_variance | 0.967      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0422    |\n",
      "|    mean_step_reward   | 0.12137321 |\n",
      "|    n_updates          | 21.88 %    |\n",
      "|    policyGradLoss     | -0.0216    |\n",
      "|    value_loss         | 0.225      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 752        |\n",
      "|    iterations         | 9          |\n",
      "|    time_elapsed       | 97         |\n",
      "|    total_timesteps    | 22880256   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02072849 |\n",
      "|    entropy_loss       | -1.84      |\n",
      "|    explained_variance | 0.966      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0499    |\n",
      "|    mean_step_reward   | 0.11838579 |\n",
      "|    n_updates          | 25.00 %    |\n",
      "|    policyGradLoss     | -0.0182    |\n",
      "|    value_loss         | 0.262      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 752         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 108         |\n",
      "|    total_timesteps    | 22888448    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021940582 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.951       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0183      |\n",
      "|    mean_step_reward   | 0.106571846 |\n",
      "|    n_updates          | 28.12 %     |\n",
      "|    policyGradLoss     | -0.0175     |\n",
      "|    value_loss         | 0.376       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 761         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 118         |\n",
      "|    total_timesteps    | 22896640    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024298511 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0418     |\n",
      "|    mean_step_reward   | 0.1211769   |\n",
      "|    n_updates          | 31.25 %     |\n",
      "|    policyGradLoss     | -0.0197     |\n",
      "|    value_loss         | 0.2         |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 768        |\n",
      "|    iterations         | 12         |\n",
      "|    time_elapsed       | 127        |\n",
      "|    total_timesteps    | 22904832   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02268352 |\n",
      "|    entropy_loss       | -1.86      |\n",
      "|    explained_variance | 0.967      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0513    |\n",
      "|    mean_step_reward   | 0.11968695 |\n",
      "|    n_updates          | 34.38 %    |\n",
      "|    policyGradLoss     | -0.0187    |\n",
      "|    value_loss         | 0.172      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 138         |\n",
      "|    total_timesteps    | 22913024    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020240264 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.056       |\n",
      "|    mean_step_reward   | 0.11268582  |\n",
      "|    n_updates          | 37.50 %     |\n",
      "|    policyGradLoss     | -0.0149     |\n",
      "|    value_loss         | 0.25        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 765         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 149         |\n",
      "|    total_timesteps    | 22921216    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019933386 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0375     |\n",
      "|    mean_step_reward   | 0.107310124 |\n",
      "|    n_updates          | 40.62 %     |\n",
      "|    policyGradLoss     | -0.0199     |\n",
      "|    value_loss         | 0.23        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 762         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 161         |\n",
      "|    total_timesteps    | 22929408    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022691675 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0542     |\n",
      "|    mean_step_reward   | 0.12293795  |\n",
      "|    n_updates          | 43.75 %     |\n",
      "|    policyGradLoss     | -0.0171     |\n",
      "|    value_loss         | 0.215       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 759         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 172         |\n",
      "|    total_timesteps    | 22937600    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028869256 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.952       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0954      |\n",
      "|    mean_step_reward   | 0.09541735  |\n",
      "|    n_updates          | 46.88 %     |\n",
      "|    policyGradLoss     | -0.0174     |\n",
      "|    value_loss         | 0.338       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 759         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 183         |\n",
      "|    total_timesteps    | 22945792    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029132798 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0472     |\n",
      "|    mean_step_reward   | 0.12745425  |\n",
      "|    n_updates          | 50.00 %     |\n",
      "|    policyGradLoss     | -0.0175     |\n",
      "|    value_loss         | 0.198       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 758         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 194         |\n",
      "|    total_timesteps    | 22953984    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026536264 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0484     |\n",
      "|    mean_step_reward   | 0.10591094  |\n",
      "|    n_updates          | 53.12 %     |\n",
      "|    policyGradLoss     | -0.0173     |\n",
      "|    value_loss         | 0.212       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 757         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 205         |\n",
      "|    total_timesteps    | 22962176    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023274858 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0371     |\n",
      "|    mean_step_reward   | 0.10346228  |\n",
      "|    n_updates          | 56.25 %     |\n",
      "|    policyGradLoss     | -0.0195     |\n",
      "|    value_loss         | 0.25        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 755         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 216         |\n",
      "|    total_timesteps    | 22970368    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018305052 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.919       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0176     |\n",
      "|    mean_step_reward   | 0.079133675 |\n",
      "|    n_updates          | 59.38 %     |\n",
      "|    policyGradLoss     | -0.0143     |\n",
      "|    value_loss         | 0.347       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 752        |\n",
      "|    iterations         | 21         |\n",
      "|    time_elapsed       | 228        |\n",
      "|    total_timesteps    | 22978560   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01990359 |\n",
      "|    entropy_loss       | -1.89      |\n",
      "|    explained_variance | 0.95       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0452    |\n",
      "|    mean_step_reward   | 0.1207234  |\n",
      "|    n_updates          | 62.50 %    |\n",
      "|    policyGradLoss     | -0.013     |\n",
      "|    value_loss         | 0.327      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 750        |\n",
      "|    iterations         | 22         |\n",
      "|    time_elapsed       | 240        |\n",
      "|    total_timesteps    | 22986752   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02154706 |\n",
      "|    entropy_loss       | -1.89      |\n",
      "|    explained_variance | 0.942      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.00972   |\n",
      "|    mean_step_reward   | 0.09837582 |\n",
      "|    n_updates          | 65.62 %    |\n",
      "|    policyGradLoss     | -0.0161    |\n",
      "|    value_loss         | 0.308      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 749         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 251         |\n",
      "|    total_timesteps    | 22994944    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016344395 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0212      |\n",
      "|    mean_step_reward   | 0.14078124  |\n",
      "|    n_updates          | 68.75 %     |\n",
      "|    policyGradLoss     | -0.0122     |\n",
      "|    value_loss         | 0.234       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 749         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 262         |\n",
      "|    total_timesteps    | 23003136    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020061774 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.921       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0446      |\n",
      "|    mean_step_reward   | 0.0979374   |\n",
      "|    n_updates          | 71.88 %     |\n",
      "|    policyGradLoss     | -0.0129     |\n",
      "|    value_loss         | 0.358       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 748        |\n",
      "|    iterations         | 25         |\n",
      "|    time_elapsed       | 273        |\n",
      "|    total_timesteps    | 23011328   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01695378 |\n",
      "|    entropy_loss       | -1.85      |\n",
      "|    explained_variance | 0.941      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.0107     |\n",
      "|    mean_step_reward   | 0.11862047 |\n",
      "|    n_updates          | 75.00 %    |\n",
      "|    policyGradLoss     | -0.0124    |\n",
      "|    value_loss         | 0.445      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 748         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 284         |\n",
      "|    total_timesteps    | 23019520    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022497598 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00187     |\n",
      "|    mean_step_reward   | 0.10628202  |\n",
      "|    n_updates          | 78.12 %     |\n",
      "|    policyGradLoss     | -0.0184     |\n",
      "|    value_loss         | 0.236       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 747         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 295         |\n",
      "|    total_timesteps    | 23027712    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022007022 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.954       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0429      |\n",
      "|    mean_step_reward   | 0.124000296 |\n",
      "|    n_updates          | 81.25 %     |\n",
      "|    policyGradLoss     | -0.0182     |\n",
      "|    value_loss         | 0.345       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 745         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 307         |\n",
      "|    total_timesteps    | 23035904    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025949685 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0244     |\n",
      "|    mean_step_reward   | 0.11201629  |\n",
      "|    n_updates          | 84.38 %     |\n",
      "|    policyGradLoss     | -0.0197     |\n",
      "|    value_loss         | 0.258       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 744         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 319         |\n",
      "|    total_timesteps    | 23044096    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023403041 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0104     |\n",
      "|    mean_step_reward   | 0.12560704  |\n",
      "|    n_updates          | 87.50 %     |\n",
      "|    policyGradLoss     | -0.0146     |\n",
      "|    value_loss         | 0.247       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 743         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 330         |\n",
      "|    total_timesteps    | 23052288    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021037195 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0459     |\n",
      "|    mean_step_reward   | 0.12870866  |\n",
      "|    n_updates          | 90.62 %     |\n",
      "|    policyGradLoss     | -0.02       |\n",
      "|    value_loss         | 0.189       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 743         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 341         |\n",
      "|    total_timesteps    | 23060480    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022216883 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.945       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00834     |\n",
      "|    mean_step_reward   | 0.11480245  |\n",
      "|    n_updates          | 93.75 %     |\n",
      "|    policyGradLoss     | -0.0175     |\n",
      "|    value_loss         | 0.276       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 743         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 352         |\n",
      "|    total_timesteps    | 23068672    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021743976 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.948       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0764      |\n",
      "|    mean_step_reward   | 0.093848154 |\n",
      "|    n_updates          | 96.88 %     |\n",
      "|    policyGradLoss     | -0.0184     |\n",
      "|    value_loss         | 0.389       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Run_87.zip\n",
      "[EVAL] Mean Return: 151.580, Best Return: 158.247\n",
      "Saved video to ./runs_smw/videos/Run/Run_87_151.58.mp4\n",
      "\n",
      "=== Round 89 | Learn 262144 steps (Total trained: 23068672) ===\n",
      "Logging to ./runs_smw/tb/Run_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1120     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 23076864 |\n",
      "---------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 866        |\n",
      "|    iterations         | 2          |\n",
      "|    time_elapsed       | 18         |\n",
      "|    total_timesteps    | 23085056   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02536338 |\n",
      "|    entropy_loss       | -1.84      |\n",
      "|    explained_variance | 0.948      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0187    |\n",
      "|    mean_step_reward   | 0.10599108 |\n",
      "|    n_updates          | 3.12 %     |\n",
      "|    policyGradLoss     | -0.0199    |\n",
      "|    value_loss         | 0.286      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 804         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 30          |\n",
      "|    total_timesteps    | 23093248    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023096994 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0604     |\n",
      "|    mean_step_reward   | 0.12762178  |\n",
      "|    n_updates          | 6.25 %      |\n",
      "|    policyGradLoss     | -0.0201     |\n",
      "|    value_loss         | 0.215       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 41          |\n",
      "|    total_timesteps    | 23101440    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.031366125 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.033      |\n",
      "|    mean_step_reward   | 0.13226241  |\n",
      "|    n_updates          | 9.38 %      |\n",
      "|    policyGradLoss     | -0.0213     |\n",
      "|    value_loss         | 0.156       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 773        |\n",
      "|    iterations         | 5          |\n",
      "|    time_elapsed       | 52         |\n",
      "|    total_timesteps    | 23109632   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02960824 |\n",
      "|    entropy_loss       | -1.89      |\n",
      "|    explained_variance | 0.963      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0461    |\n",
      "|    mean_step_reward   | 0.10555373 |\n",
      "|    n_updates          | 12.50 %    |\n",
      "|    policyGradLoss     | -0.0178    |\n",
      "|    value_loss         | 0.192      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 63          |\n",
      "|    total_timesteps    | 23117824    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026892629 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0251     |\n",
      "|    mean_step_reward   | 0.11825065  |\n",
      "|    n_updates          | 15.62 %     |\n",
      "|    policyGradLoss     | -0.0157     |\n",
      "|    value_loss         | 0.293       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 793         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 72          |\n",
      "|    total_timesteps    | 23126016    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.034047827 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0673     |\n",
      "|    mean_step_reward   | 0.13702422  |\n",
      "|    n_updates          | 18.75 %     |\n",
      "|    policyGradLoss     | -0.021      |\n",
      "|    value_loss         | 0.165       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 801         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 81          |\n",
      "|    total_timesteps    | 23134208    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021779489 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.933       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.109       |\n",
      "|    mean_step_reward   | 0.10843998  |\n",
      "|    n_updates          | 21.88 %     |\n",
      "|    policyGradLoss     | -0.0147     |\n",
      "|    value_loss         | 0.435       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 809         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 91          |\n",
      "|    total_timesteps    | 23142400    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021418164 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0189     |\n",
      "|    mean_step_reward   | 0.14065148  |\n",
      "|    n_updates          | 25.00 %     |\n",
      "|    policyGradLoss     | -0.0161     |\n",
      "|    value_loss         | 0.297       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 801         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 102         |\n",
      "|    total_timesteps    | 23150592    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026602564 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0286      |\n",
      "|    mean_step_reward   | 0.11177333  |\n",
      "|    n_updates          | 28.12 %     |\n",
      "|    policyGradLoss     | -0.0174     |\n",
      "|    value_loss         | 0.257       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 792        |\n",
      "|    iterations         | 11         |\n",
      "|    time_elapsed       | 113        |\n",
      "|    total_timesteps    | 23158784   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02979451 |\n",
      "|    entropy_loss       | -1.78      |\n",
      "|    explained_variance | 0.982      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0422    |\n",
      "|    mean_step_reward   | 0.13508953 |\n",
      "|    n_updates          | 31.25 %    |\n",
      "|    policyGradLoss     | -0.0203    |\n",
      "|    value_loss         | 0.127      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 125         |\n",
      "|    total_timesteps    | 23166976    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026256707 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0491      |\n",
      "|    mean_step_reward   | 0.11105783  |\n",
      "|    n_updates          | 34.38 %     |\n",
      "|    policyGradLoss     | -0.0174     |\n",
      "|    value_loss         | 0.256       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 782        |\n",
      "|    iterations         | 13         |\n",
      "|    time_elapsed       | 136        |\n",
      "|    total_timesteps    | 23175168   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02121566 |\n",
      "|    entropy_loss       | -1.83      |\n",
      "|    explained_variance | 0.963      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0301    |\n",
      "|    mean_step_reward   | 0.11240431 |\n",
      "|    n_updates          | 37.50 %    |\n",
      "|    policyGradLoss     | -0.0143    |\n",
      "|    value_loss         | 0.293      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 147         |\n",
      "|    total_timesteps    | 23183360    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030228876 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0359     |\n",
      "|    mean_step_reward   | 0.13112864  |\n",
      "|    n_updates          | 40.62 %     |\n",
      "|    policyGradLoss     | -0.0212     |\n",
      "|    value_loss         | 0.147       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 158         |\n",
      "|    total_timesteps    | 23191552    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019553948 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.944       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.011       |\n",
      "|    mean_step_reward   | 0.09801316  |\n",
      "|    n_updates          | 43.75 %     |\n",
      "|    policyGradLoss     | -0.0168     |\n",
      "|    value_loss         | 0.319       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 169         |\n",
      "|    total_timesteps    | 23199744    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022715252 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.958       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0449     |\n",
      "|    mean_step_reward   | 0.12520659  |\n",
      "|    n_updates          | 46.88 %     |\n",
      "|    policyGradLoss     | -0.0173     |\n",
      "|    value_loss         | 0.272       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 180         |\n",
      "|    total_timesteps    | 23207936    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024658255 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.954       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0209     |\n",
      "|    mean_step_reward   | 0.11653535  |\n",
      "|    n_updates          | 50.00 %     |\n",
      "|    policyGradLoss     | -0.0179     |\n",
      "|    value_loss         | 0.21        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 764         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 192         |\n",
      "|    total_timesteps    | 23216128    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023765836 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.952       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0117     |\n",
      "|    mean_step_reward   | 0.11425126  |\n",
      "|    n_updates          | 53.12 %     |\n",
      "|    policyGradLoss     | -0.0219     |\n",
      "|    value_loss         | 0.334       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 762         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 204         |\n",
      "|    total_timesteps    | 23224320    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02468009  |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.944       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0361      |\n",
      "|    mean_step_reward   | 0.109822676 |\n",
      "|    n_updates          | 56.25 %     |\n",
      "|    policyGradLoss     | -0.0178     |\n",
      "|    value_loss         | 0.341       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 761         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 215         |\n",
      "|    total_timesteps    | 23232512    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02821605  |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.952       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0343     |\n",
      "|    mean_step_reward   | 0.103706576 |\n",
      "|    n_updates          | 59.38 %     |\n",
      "|    policyGradLoss     | -0.0223     |\n",
      "|    value_loss         | 0.26        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 760        |\n",
      "|    iterations         | 21         |\n",
      "|    time_elapsed       | 226        |\n",
      "|    total_timesteps    | 23240704   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02574348 |\n",
      "|    entropy_loss       | -1.79      |\n",
      "|    explained_variance | 0.962      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.015     |\n",
      "|    mean_step_reward   | 0.13058805 |\n",
      "|    n_updates          | 62.50 %    |\n",
      "|    policyGradLoss     | -0.0187    |\n",
      "|    value_loss         | 0.268      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 759         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 237         |\n",
      "|    total_timesteps    | 23248896    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029127926 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0314     |\n",
      "|    mean_step_reward   | 0.10684004  |\n",
      "|    n_updates          | 65.62 %     |\n",
      "|    policyGradLoss     | -0.0203     |\n",
      "|    value_loss         | 0.203       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 758         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 248         |\n",
      "|    total_timesteps    | 23257088    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023500085 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0618     |\n",
      "|    mean_step_reward   | 0.13352598  |\n",
      "|    n_updates          | 68.75 %     |\n",
      "|    policyGradLoss     | -0.0177     |\n",
      "|    value_loss         | 0.248       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 756        |\n",
      "|    iterations         | 24         |\n",
      "|    time_elapsed       | 260        |\n",
      "|    total_timesteps    | 23265280   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03243602 |\n",
      "|    entropy_loss       | -1.82      |\n",
      "|    explained_variance | 0.972      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0255    |\n",
      "|    mean_step_reward   | 0.12069023 |\n",
      "|    n_updates          | 71.88 %    |\n",
      "|    policyGradLoss     | -0.0205    |\n",
      "|    value_loss         | 0.216      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 753         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 271         |\n",
      "|    total_timesteps    | 23273472    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027479459 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.954       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0453     |\n",
      "|    mean_step_reward   | 0.12690906  |\n",
      "|    n_updates          | 75.00 %     |\n",
      "|    policyGradLoss     | -0.0195     |\n",
      "|    value_loss         | 0.255       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 751         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 283         |\n",
      "|    total_timesteps    | 23281664    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026210628 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0482     |\n",
      "|    mean_step_reward   | 0.12619306  |\n",
      "|    n_updates          | 78.12 %     |\n",
      "|    policyGradLoss     | -0.0187     |\n",
      "|    value_loss         | 0.241       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 750         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 294         |\n",
      "|    total_timesteps    | 23289856    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030867122 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.068      |\n",
      "|    mean_step_reward   | 0.12945792  |\n",
      "|    n_updates          | 81.25 %     |\n",
      "|    policyGradLoss     | -0.0247     |\n",
      "|    value_loss         | 0.129       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 750         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 305         |\n",
      "|    total_timesteps    | 23298048    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022500614 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0235     |\n",
      "|    mean_step_reward   | 0.11978782  |\n",
      "|    n_updates          | 84.38 %     |\n",
      "|    policyGradLoss     | -0.0149     |\n",
      "|    value_loss         | 0.263       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 750         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 316         |\n",
      "|    total_timesteps    | 23306240    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026178028 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0277     |\n",
      "|    mean_step_reward   | 0.112083    |\n",
      "|    n_updates          | 87.50 %     |\n",
      "|    policyGradLoss     | -0.0198     |\n",
      "|    value_loss         | 0.252       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 749         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 327         |\n",
      "|    total_timesteps    | 23314432    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030499201 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0478     |\n",
      "|    mean_step_reward   | 0.133356    |\n",
      "|    n_updates          | 90.62 %     |\n",
      "|    policyGradLoss     | -0.0195     |\n",
      "|    value_loss         | 0.186       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 748         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 339         |\n",
      "|    total_timesteps    | 23322624    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029484991 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0506     |\n",
      "|    mean_step_reward   | 0.10734894  |\n",
      "|    n_updates          | 93.75 %     |\n",
      "|    policyGradLoss     | -0.0189     |\n",
      "|    value_loss         | 0.141       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 746         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 351         |\n",
      "|    total_timesteps    | 23330816    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027593063 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0388     |\n",
      "|    mean_step_reward   | 0.114256665 |\n",
      "|    n_updates          | 96.88 %     |\n",
      "|    policyGradLoss     | -0.0187     |\n",
      "|    value_loss         | 0.249       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Run_88.zip\n",
      "[EVAL] Mean Return: 149.858, Best Return: 156.858\n",
      "Saved video to ./runs_smw/videos/Run/Run_88_149.86.mp4\n",
      "\n",
      "=== Round 90 | Learn 262144 steps (Total trained: 23330816) ===\n",
      "Logging to ./runs_smw/tb/Run_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1165     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 23339008 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 906         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 23347200    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029423356 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0383     |\n",
      "|    mean_step_reward   | 0.14404026  |\n",
      "|    n_updates          | 3.12 %      |\n",
      "|    policyGradLoss     | -0.0223     |\n",
      "|    value_loss         | 0.18        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 904        |\n",
      "|    iterations         | 3          |\n",
      "|    time_elapsed       | 27         |\n",
      "|    total_timesteps    | 23355392   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02585746 |\n",
      "|    entropy_loss       | -1.82      |\n",
      "|    explained_variance | 0.966      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0489    |\n",
      "|    mean_step_reward   | 0.1157317  |\n",
      "|    n_updates          | 6.25 %     |\n",
      "|    policyGradLoss     | -0.0178    |\n",
      "|    value_loss         | 0.193      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 904         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 36          |\n",
      "|    total_timesteps    | 23363584    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027823713 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0458     |\n",
      "|    mean_step_reward   | 0.14107127  |\n",
      "|    n_updates          | 9.38 %      |\n",
      "|    policyGradLoss     | -0.0196     |\n",
      "|    value_loss         | 0.188       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 897         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 45          |\n",
      "|    total_timesteps    | 23371776    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024586476 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0384     |\n",
      "|    mean_step_reward   | 0.11525247  |\n",
      "|    n_updates          | 12.50 %     |\n",
      "|    policyGradLoss     | -0.0174     |\n",
      "|    value_loss         | 0.203       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 884         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 55          |\n",
      "|    total_timesteps    | 23379968    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.031013124 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0563     |\n",
      "|    mean_step_reward   | 0.13838604  |\n",
      "|    n_updates          | 15.62 %     |\n",
      "|    policyGradLoss     | -0.0223     |\n",
      "|    value_loss         | 0.209       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 860        |\n",
      "|    iterations         | 7          |\n",
      "|    time_elapsed       | 66         |\n",
      "|    total_timesteps    | 23388160   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02949816 |\n",
      "|    entropy_loss       | -1.82      |\n",
      "|    explained_variance | 0.97       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0253    |\n",
      "|    mean_step_reward   | 0.11477035 |\n",
      "|    n_updates          | 18.75 %    |\n",
      "|    policyGradLoss     | -0.0224    |\n",
      "|    value_loss         | 0.168      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 842         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 77          |\n",
      "|    total_timesteps    | 23396352    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029351953 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0023      |\n",
      "|    mean_step_reward   | 0.13106906  |\n",
      "|    n_updates          | 21.88 %     |\n",
      "|    policyGradLoss     | -0.0215     |\n",
      "|    value_loss         | 0.195       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 830        |\n",
      "|    iterations         | 9          |\n",
      "|    time_elapsed       | 88         |\n",
      "|    total_timesteps    | 23404544   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02542871 |\n",
      "|    entropy_loss       | -1.82      |\n",
      "|    explained_variance | 0.946      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.034     |\n",
      "|    mean_step_reward   | 0.10190298 |\n",
      "|    n_updates          | 25.00 %    |\n",
      "|    policyGradLoss     | -0.0197    |\n",
      "|    value_loss         | 0.268      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 819         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 99          |\n",
      "|    total_timesteps    | 23412736    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028783165 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00134     |\n",
      "|    mean_step_reward   | 0.11465571  |\n",
      "|    n_updates          | 28.12 %     |\n",
      "|    policyGradLoss     | -0.0181     |\n",
      "|    value_loss         | 0.249       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 811         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 111         |\n",
      "|    total_timesteps    | 23420928    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026616689 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.951       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0477     |\n",
      "|    mean_step_reward   | 0.12097342  |\n",
      "|    n_updates          | 31.25 %     |\n",
      "|    policyGradLoss     | -0.0186     |\n",
      "|    value_loss         | 0.215       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 801         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 122         |\n",
      "|    total_timesteps    | 23429120    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029017134 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0295     |\n",
      "|    mean_step_reward   | 0.11229183  |\n",
      "|    n_updates          | 34.38 %     |\n",
      "|    policyGradLoss     | -0.0165     |\n",
      "|    value_loss         | 0.228       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 793         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 134         |\n",
      "|    total_timesteps    | 23437312    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027138114 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00119    |\n",
      "|    mean_step_reward   | 0.115608886 |\n",
      "|    n_updates          | 37.50 %     |\n",
      "|    policyGradLoss     | -0.0181     |\n",
      "|    value_loss         | 0.285       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 788         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 145         |\n",
      "|    total_timesteps    | 23445504    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024291687 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.949       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0351     |\n",
      "|    mean_step_reward   | 0.111726575 |\n",
      "|    n_updates          | 40.62 %     |\n",
      "|    policyGradLoss     | -0.0152     |\n",
      "|    value_loss         | 0.287       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 784        |\n",
      "|    iterations         | 15         |\n",
      "|    time_elapsed       | 156        |\n",
      "|    total_timesteps    | 23453696   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01925001 |\n",
      "|    entropy_loss       | -1.82      |\n",
      "|    explained_variance | 0.94       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.0159     |\n",
      "|    mean_step_reward   | 0.12686905 |\n",
      "|    n_updates          | 43.75 %    |\n",
      "|    policyGradLoss     | -0.0165    |\n",
      "|    value_loss         | 0.388      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 167         |\n",
      "|    total_timesteps    | 23461888    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024165208 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.952       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0234     |\n",
      "|    mean_step_reward   | 0.10697642  |\n",
      "|    n_updates          | 46.88 %     |\n",
      "|    policyGradLoss     | -0.02       |\n",
      "|    value_loss         | 0.304       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 178         |\n",
      "|    total_timesteps    | 23470080    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026556436 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.073      |\n",
      "|    mean_step_reward   | 0.13021564  |\n",
      "|    n_updates          | 50.00 %     |\n",
      "|    policyGradLoss     | -0.0174     |\n",
      "|    value_loss         | 0.177       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 190         |\n",
      "|    total_timesteps    | 23478272    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024226755 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00835    |\n",
      "|    mean_step_reward   | 0.09925147  |\n",
      "|    n_updates          | 53.12 %     |\n",
      "|    policyGradLoss     | -0.0172     |\n",
      "|    value_loss         | 0.24        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 201         |\n",
      "|    total_timesteps    | 23486464    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021795625 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0598     |\n",
      "|    mean_step_reward   | 0.12162921  |\n",
      "|    n_updates          | 56.25 %     |\n",
      "|    policyGradLoss     | -0.0177     |\n",
      "|    value_loss         | 0.207       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 213         |\n",
      "|    total_timesteps    | 23494656    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023764262 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.951       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0217     |\n",
      "|    mean_step_reward   | 0.09899275  |\n",
      "|    n_updates          | 59.38 %     |\n",
      "|    policyGradLoss     | -0.0179     |\n",
      "|    value_loss         | 0.337       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 224         |\n",
      "|    total_timesteps    | 23502848    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025495578 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0536     |\n",
      "|    mean_step_reward   | 0.12991303  |\n",
      "|    n_updates          | 62.50 %     |\n",
      "|    policyGradLoss     | -0.0213     |\n",
      "|    value_loss         | 0.185       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 764         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 235         |\n",
      "|    total_timesteps    | 23511040    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020109933 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.931       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.124       |\n",
      "|    mean_step_reward   | 0.08608683  |\n",
      "|    n_updates          | 65.62 %     |\n",
      "|    policyGradLoss     | -0.0166     |\n",
      "|    value_loss         | 0.39        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 762         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 247         |\n",
      "|    total_timesteps    | 23519232    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026900642 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0424     |\n",
      "|    mean_step_reward   | 0.12825456  |\n",
      "|    n_updates          | 68.75 %     |\n",
      "|    policyGradLoss     | -0.0148     |\n",
      "|    value_loss         | 0.248       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 761         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 258         |\n",
      "|    total_timesteps    | 23527424    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026247595 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.946       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0309      |\n",
      "|    mean_step_reward   | 0.10792796  |\n",
      "|    n_updates          | 71.88 %     |\n",
      "|    policyGradLoss     | -0.0207     |\n",
      "|    value_loss         | 0.292       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 760         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 269         |\n",
      "|    total_timesteps    | 23535616    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025560945 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0157      |\n",
      "|    mean_step_reward   | 0.110841334 |\n",
      "|    n_updates          | 75.00 %     |\n",
      "|    policyGradLoss     | -0.0179     |\n",
      "|    value_loss         | 0.335       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 758         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 280         |\n",
      "|    total_timesteps    | 23543808    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023104144 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.935       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00958    |\n",
      "|    mean_step_reward   | 0.10333593  |\n",
      "|    n_updates          | 78.12 %     |\n",
      "|    policyGradLoss     | -0.0177     |\n",
      "|    value_loss         | 0.322       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 755         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 292         |\n",
      "|    total_timesteps    | 23552000    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020933546 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.949       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0723      |\n",
      "|    mean_step_reward   | 0.09612662  |\n",
      "|    n_updates          | 81.25 %     |\n",
      "|    policyGradLoss     | -0.017      |\n",
      "|    value_loss         | 0.388       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 754        |\n",
      "|    iterations         | 28         |\n",
      "|    time_elapsed       | 303        |\n",
      "|    total_timesteps    | 23560192   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02453276 |\n",
      "|    entropy_loss       | -1.83      |\n",
      "|    explained_variance | 0.96       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0125    |\n",
      "|    mean_step_reward   | 0.13166937 |\n",
      "|    n_updates          | 84.38 %    |\n",
      "|    policyGradLoss     | -0.0178    |\n",
      "|    value_loss         | 0.245      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 753         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 315         |\n",
      "|    total_timesteps    | 23568384    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021965928 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.911       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0313     |\n",
      "|    mean_step_reward   | 0.093221225 |\n",
      "|    n_updates          | 87.50 %     |\n",
      "|    policyGradLoss     | -0.0147     |\n",
      "|    value_loss         | 0.286       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 753         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 326         |\n",
      "|    total_timesteps    | 23576576    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023726774 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.954       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.105       |\n",
      "|    mean_step_reward   | 0.12922996  |\n",
      "|    n_updates          | 90.62 %     |\n",
      "|    policyGradLoss     | -0.0168     |\n",
      "|    value_loss         | 0.388       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 752         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 337         |\n",
      "|    total_timesteps    | 23584768    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025061235 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.947       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0137     |\n",
      "|    mean_step_reward   | 0.09751798  |\n",
      "|    n_updates          | 93.75 %     |\n",
      "|    policyGradLoss     | -0.0198     |\n",
      "|    value_loss         | 0.271       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 751         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 348         |\n",
      "|    total_timesteps    | 23592960    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025107333 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.948       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0488     |\n",
      "|    mean_step_reward   | 0.11856731  |\n",
      "|    n_updates          | 96.88 %     |\n",
      "|    policyGradLoss     | -0.02       |\n",
      "|    value_loss         | 0.248       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Run_89.zip\n",
      "[EVAL] Mean Return: -10.139, Best Return: -10.139\n",
      "Saved video to ./runs_smw/videos/Run/Run_89_-10.14.mp4\n",
      "\n",
      "=== Round 91 | Learn 262144 steps (Total trained: 23592960) ===\n",
      "Logging to ./runs_smw/tb/Run_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1421     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 23601152 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 1072        |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 15          |\n",
      "|    total_timesteps    | 23609344    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030730005 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0559     |\n",
      "|    mean_step_reward   | 0.123258606 |\n",
      "|    n_updates          | 3.12 %      |\n",
      "|    policyGradLoss     | -0.0214     |\n",
      "|    value_loss         | 0.191       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 986         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 24          |\n",
      "|    total_timesteps    | 23617536    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025947627 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0385     |\n",
      "|    mean_step_reward   | 0.115481585 |\n",
      "|    n_updates          | 6.25 %      |\n",
      "|    policyGradLoss     | -0.0226     |\n",
      "|    value_loss         | 0.198       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 895         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 36          |\n",
      "|    total_timesteps    | 23625728    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027394235 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0156      |\n",
      "|    mean_step_reward   | 0.11534342  |\n",
      "|    n_updates          | 9.38 %      |\n",
      "|    policyGradLoss     | -0.0192     |\n",
      "|    value_loss         | 0.205       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 854         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 47          |\n",
      "|    total_timesteps    | 23633920    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025139332 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.955       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0481     |\n",
      "|    mean_step_reward   | 0.110107124 |\n",
      "|    n_updates          | 12.50 %     |\n",
      "|    policyGradLoss     | -0.0214     |\n",
      "|    value_loss         | 0.266       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 831        |\n",
      "|    iterations         | 6          |\n",
      "|    time_elapsed       | 59         |\n",
      "|    total_timesteps    | 23642112   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02468119 |\n",
      "|    entropy_loss       | -1.81      |\n",
      "|    explained_variance | 0.976      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0556    |\n",
      "|    mean_step_reward   | 0.13194966 |\n",
      "|    n_updates          | 15.62 %    |\n",
      "|    policyGradLoss     | -0.02      |\n",
      "|    value_loss         | 0.184      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 818         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 70          |\n",
      "|    total_timesteps    | 23650304    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026201222 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.952       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.068       |\n",
      "|    mean_step_reward   | 0.11855495  |\n",
      "|    n_updates          | 18.75 %     |\n",
      "|    policyGradLoss     | -0.019      |\n",
      "|    value_loss         | 0.244       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 806         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 81          |\n",
      "|    total_timesteps    | 23658496    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021615274 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.948       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0219     |\n",
      "|    mean_step_reward   | 0.112144925 |\n",
      "|    n_updates          | 21.88 %     |\n",
      "|    policyGradLoss     | -0.0155     |\n",
      "|    value_loss         | 0.268       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 795         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 92          |\n",
      "|    total_timesteps    | 23666688    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024238747 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.949       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0215     |\n",
      "|    mean_step_reward   | 0.116135314 |\n",
      "|    n_updates          | 25.00 %     |\n",
      "|    policyGradLoss     | -0.0175     |\n",
      "|    value_loss         | 0.27        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 104         |\n",
      "|    total_timesteps    | 23674880    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025777899 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.958       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0322     |\n",
      "|    mean_step_reward   | 0.11649014  |\n",
      "|    n_updates          | 28.12 %     |\n",
      "|    policyGradLoss     | -0.016      |\n",
      "|    value_loss         | 0.254       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 117         |\n",
      "|    total_timesteps    | 23683072    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021853587 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.946       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00929     |\n",
      "|    mean_step_reward   | 0.102623604 |\n",
      "|    n_updates          | 31.25 %     |\n",
      "|    policyGradLoss     | -0.0152     |\n",
      "|    value_loss         | 0.371       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 759        |\n",
      "|    iterations         | 12         |\n",
      "|    time_elapsed       | 129        |\n",
      "|    total_timesteps    | 23691264   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02151954 |\n",
      "|    entropy_loss       | -1.86      |\n",
      "|    explained_variance | 0.945      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.00917   |\n",
      "|    mean_step_reward   | 0.0992493  |\n",
      "|    n_updates          | 34.38 %    |\n",
      "|    policyGradLoss     | -0.0193    |\n",
      "|    value_loss         | 0.34       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 753         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 141         |\n",
      "|    total_timesteps    | 23699456    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024481729 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.918       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0497      |\n",
      "|    mean_step_reward   | 0.11173014  |\n",
      "|    n_updates          | 37.50 %     |\n",
      "|    policyGradLoss     | -0.0139     |\n",
      "|    value_loss         | 0.549       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 749         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 152         |\n",
      "|    total_timesteps    | 23707648    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025148164 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0166     |\n",
      "|    mean_step_reward   | 0.119500145 |\n",
      "|    n_updates          | 40.62 %     |\n",
      "|    policyGradLoss     | -0.0196     |\n",
      "|    value_loss         | 0.211       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 745        |\n",
      "|    iterations         | 15         |\n",
      "|    time_elapsed       | 164        |\n",
      "|    total_timesteps    | 23715840   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02741988 |\n",
      "|    entropy_loss       | -1.82      |\n",
      "|    explained_variance | 0.971      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0463    |\n",
      "|    mean_step_reward   | 0.1285641  |\n",
      "|    n_updates          | 43.75 %    |\n",
      "|    policyGradLoss     | -0.0201    |\n",
      "|    value_loss         | 0.209      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 741         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 176         |\n",
      "|    total_timesteps    | 23724032    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022075804 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.949       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0063     |\n",
      "|    mean_step_reward   | 0.096182495 |\n",
      "|    n_updates          | 46.88 %     |\n",
      "|    policyGradLoss     | -0.0175     |\n",
      "|    value_loss         | 0.358       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 737         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 188         |\n",
      "|    total_timesteps    | 23732224    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025928134 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.075      |\n",
      "|    mean_step_reward   | 0.11871879  |\n",
      "|    n_updates          | 50.00 %     |\n",
      "|    policyGradLoss     | -0.0218     |\n",
      "|    value_loss         | 0.209       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 732         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 201         |\n",
      "|    total_timesteps    | 23740416    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.032192335 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0778     |\n",
      "|    mean_step_reward   | 0.11518072  |\n",
      "|    n_updates          | 53.12 %     |\n",
      "|    policyGradLoss     | -0.0202     |\n",
      "|    value_loss         | 0.166       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 727         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 213         |\n",
      "|    total_timesteps    | 23748608    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022909056 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0441     |\n",
      "|    mean_step_reward   | 0.120079234 |\n",
      "|    n_updates          | 56.25 %     |\n",
      "|    policyGradLoss     | -0.0192     |\n",
      "|    value_loss         | 0.252       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 724        |\n",
      "|    iterations         | 20         |\n",
      "|    time_elapsed       | 226        |\n",
      "|    total_timesteps    | 23756800   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02829281 |\n",
      "|    entropy_loss       | -1.84      |\n",
      "|    explained_variance | 0.976      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0569    |\n",
      "|    mean_step_reward   | 0.13164389 |\n",
      "|    n_updates          | 59.38 %    |\n",
      "|    policyGradLoss     | -0.0233    |\n",
      "|    value_loss         | 0.149      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 723         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 237         |\n",
      "|    total_timesteps    | 23764992    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022326801 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00306    |\n",
      "|    mean_step_reward   | 0.11760555  |\n",
      "|    n_updates          | 62.50 %     |\n",
      "|    policyGradLoss     | -0.0174     |\n",
      "|    value_loss         | 0.254       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 724        |\n",
      "|    iterations         | 22         |\n",
      "|    time_elapsed       | 248        |\n",
      "|    total_timesteps    | 23773184   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02898207 |\n",
      "|    entropy_loss       | -1.83      |\n",
      "|    explained_variance | 0.965      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0475    |\n",
      "|    mean_step_reward   | 0.11451159 |\n",
      "|    n_updates          | 65.62 %    |\n",
      "|    policyGradLoss     | -0.0176    |\n",
      "|    value_loss         | 0.227      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 724         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 259         |\n",
      "|    total_timesteps    | 23781376    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025750395 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0293     |\n",
      "|    mean_step_reward   | 0.118980095 |\n",
      "|    n_updates          | 68.75 %     |\n",
      "|    policyGradLoss     | -0.021      |\n",
      "|    value_loss         | 0.203       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 725        |\n",
      "|    iterations         | 24         |\n",
      "|    time_elapsed       | 271        |\n",
      "|    total_timesteps    | 23789568   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03139352 |\n",
      "|    entropy_loss       | -1.8       |\n",
      "|    explained_variance | 0.972      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0602    |\n",
      "|    mean_step_reward   | 0.1302486  |\n",
      "|    n_updates          | 71.88 %    |\n",
      "|    policyGradLoss     | -0.023     |\n",
      "|    value_loss         | 0.161      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 724         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 282         |\n",
      "|    total_timesteps    | 23797760    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030091967 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.957       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0494     |\n",
      "|    mean_step_reward   | 0.10084484  |\n",
      "|    n_updates          | 75.00 %     |\n",
      "|    policyGradLoss     | -0.0226     |\n",
      "|    value_loss         | 0.215       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 723         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 294         |\n",
      "|    total_timesteps    | 23805952    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02246705  |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.918       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.023      |\n",
      "|    mean_step_reward   | 0.121640235 |\n",
      "|    n_updates          | 78.12 %     |\n",
      "|    policyGradLoss     | -0.0161     |\n",
      "|    value_loss         | 0.381       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 722         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 306         |\n",
      "|    total_timesteps    | 23814144    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025477974 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.941       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0143     |\n",
      "|    mean_step_reward   | 0.09511603  |\n",
      "|    n_updates          | 81.25 %     |\n",
      "|    policyGradLoss     | -0.0169     |\n",
      "|    value_loss         | 0.287       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 722         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 317         |\n",
      "|    total_timesteps    | 23822336    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025941797 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.952       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.018       |\n",
      "|    mean_step_reward   | 0.10151367  |\n",
      "|    n_updates          | 84.38 %     |\n",
      "|    policyGradLoss     | -0.0201     |\n",
      "|    value_loss         | 0.283       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 723        |\n",
      "|    iterations         | 29         |\n",
      "|    time_elapsed       | 328        |\n",
      "|    total_timesteps    | 23830528   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02581956 |\n",
      "|    entropy_loss       | -1.8       |\n",
      "|    explained_variance | 0.946      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0244    |\n",
      "|    mean_step_reward   | 0.12131636 |\n",
      "|    n_updates          | 87.50 %    |\n",
      "|    policyGradLoss     | -0.0156    |\n",
      "|    value_loss         | 0.289      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 723         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 339         |\n",
      "|    total_timesteps    | 23838720    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030491244 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0718     |\n",
      "|    mean_step_reward   | 0.112994716 |\n",
      "|    n_updates          | 90.62 %     |\n",
      "|    policyGradLoss     | -0.0195     |\n",
      "|    value_loss         | 0.201       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 723         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 350         |\n",
      "|    total_timesteps    | 23846912    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023734514 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.958       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0264      |\n",
      "|    mean_step_reward   | 0.12496361  |\n",
      "|    n_updates          | 93.75 %     |\n",
      "|    policyGradLoss     | -0.0195     |\n",
      "|    value_loss         | 0.261       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 727         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 360         |\n",
      "|    total_timesteps    | 23855104    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027412992 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0213      |\n",
      "|    mean_step_reward   | 0.122527435 |\n",
      "|    n_updates          | 96.88 %     |\n",
      "|    policyGradLoss     | -0.0212     |\n",
      "|    value_loss         | 0.217       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Run_90.zip\n",
      "[EVAL] Mean Return: 152.850, Best Return: 160.184\n",
      "Saved video to ./runs_smw/videos/Run/Run_90_152.85.mp4\n",
      "\n",
      "=== Round 92 | Learn 262144 steps (Total trained: 23855104) ===\n",
      "Logging to ./runs_smw/tb/Run_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1094     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 23863296 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 868         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 23871488    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027209083 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.949       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0153     |\n",
      "|    mean_step_reward   | 0.11473385  |\n",
      "|    n_updates          | 3.12 %      |\n",
      "|    policyGradLoss     | -0.0176     |\n",
      "|    value_loss         | 0.227       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 814         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 30          |\n",
      "|    total_timesteps    | 23879680    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025842804 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0577     |\n",
      "|    mean_step_reward   | 0.11935733  |\n",
      "|    n_updates          | 6.25 %      |\n",
      "|    policyGradLoss     | -0.0194     |\n",
      "|    value_loss         | 0.185       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 794         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 41          |\n",
      "|    total_timesteps    | 23887872    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026876329 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.958       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0211     |\n",
      "|    mean_step_reward   | 0.11633101  |\n",
      "|    n_updates          | 9.38 %      |\n",
      "|    policyGradLoss     | -0.0199     |\n",
      "|    value_loss         | 0.305       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 52          |\n",
      "|    total_timesteps    | 23896064    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028534949 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.958       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0316     |\n",
      "|    mean_step_reward   | 0.1138192   |\n",
      "|    n_updates          | 12.50 %     |\n",
      "|    policyGradLoss     | -0.0218     |\n",
      "|    value_loss         | 0.246       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 63          |\n",
      "|    total_timesteps    | 23904256    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025163878 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0263     |\n",
      "|    mean_step_reward   | 0.114296675 |\n",
      "|    n_updates          | 15.62 %     |\n",
      "|    policyGradLoss     | -0.0165     |\n",
      "|    value_loss         | 0.271       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 761         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 75          |\n",
      "|    total_timesteps    | 23912448    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.032029383 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0516     |\n",
      "|    mean_step_reward   | 0.12497249  |\n",
      "|    n_updates          | 18.75 %     |\n",
      "|    policyGradLoss     | -0.0165     |\n",
      "|    value_loss         | 0.234       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 754         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 86          |\n",
      "|    total_timesteps    | 23920640    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025691822 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.955       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0354     |\n",
      "|    mean_step_reward   | 0.11879151  |\n",
      "|    n_updates          | 21.88 %     |\n",
      "|    policyGradLoss     | -0.0186     |\n",
      "|    value_loss         | 0.238       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 750         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 98          |\n",
      "|    total_timesteps    | 23928832    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030419398 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0358     |\n",
      "|    mean_step_reward   | 0.12344511  |\n",
      "|    n_updates          | 25.00 %     |\n",
      "|    policyGradLoss     | -0.021      |\n",
      "|    value_loss         | 0.191       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 750         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 109         |\n",
      "|    total_timesteps    | 23937024    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028375965 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0101     |\n",
      "|    mean_step_reward   | 0.1131935   |\n",
      "|    n_updates          | 28.12 %     |\n",
      "|    policyGradLoss     | -0.0184     |\n",
      "|    value_loss         | 0.26        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 749         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 120         |\n",
      "|    total_timesteps    | 23945216    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030092739 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0494     |\n",
      "|    mean_step_reward   | 0.12660292  |\n",
      "|    n_updates          | 31.25 %     |\n",
      "|    policyGradLoss     | -0.0185     |\n",
      "|    value_loss         | 0.236       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 748         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 131         |\n",
      "|    total_timesteps    | 23953408    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026230477 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0108     |\n",
      "|    mean_step_reward   | 0.111932844 |\n",
      "|    n_updates          | 34.38 %     |\n",
      "|    policyGradLoss     | -0.0202     |\n",
      "|    value_loss         | 0.256       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 746         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 142         |\n",
      "|    total_timesteps    | 23961600    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027361691 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0712      |\n",
      "|    mean_step_reward   | 0.1164007   |\n",
      "|    n_updates          | 37.50 %     |\n",
      "|    policyGradLoss     | -0.0192     |\n",
      "|    value_loss         | 0.297       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 744         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 154         |\n",
      "|    total_timesteps    | 23969792    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028711088 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0391     |\n",
      "|    mean_step_reward   | 0.122961506 |\n",
      "|    n_updates          | 40.62 %     |\n",
      "|    policyGradLoss     | -0.0206     |\n",
      "|    value_loss         | 0.23        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 741         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 165         |\n",
      "|    total_timesteps    | 23977984    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025002616 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0316     |\n",
      "|    mean_step_reward   | 0.11501875  |\n",
      "|    n_updates          | 43.75 %     |\n",
      "|    policyGradLoss     | -0.0177     |\n",
      "|    value_loss         | 0.241       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 739        |\n",
      "|    iterations         | 16         |\n",
      "|    time_elapsed       | 177        |\n",
      "|    total_timesteps    | 23986176   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02745296 |\n",
      "|    entropy_loss       | -1.81      |\n",
      "|    explained_variance | 0.96       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.00523    |\n",
      "|    mean_step_reward   | 0.10697219 |\n",
      "|    n_updates          | 46.88 %    |\n",
      "|    policyGradLoss     | -0.0183    |\n",
      "|    value_loss         | 0.278      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 739        |\n",
      "|    iterations         | 17         |\n",
      "|    time_elapsed       | 188        |\n",
      "|    total_timesteps    | 23994368   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02988242 |\n",
      "|    entropy_loss       | -1.82      |\n",
      "|    explained_variance | 0.967      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0531    |\n",
      "|    mean_step_reward   | 0.12372249 |\n",
      "|    n_updates          | 50.00 %    |\n",
      "|    policyGradLoss     | -0.0199    |\n",
      "|    value_loss         | 0.184      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 739         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 199         |\n",
      "|    total_timesteps    | 24002560    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029162204 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0733     |\n",
      "|    mean_step_reward   | 0.11804987  |\n",
      "|    n_updates          | 53.12 %     |\n",
      "|    policyGradLoss     | -0.0206     |\n",
      "|    value_loss         | 0.169       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 740         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 210         |\n",
      "|    total_timesteps    | 24010752    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.033950385 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0536     |\n",
      "|    mean_step_reward   | 0.12803291  |\n",
      "|    n_updates          | 56.25 %     |\n",
      "|    policyGradLoss     | -0.0207     |\n",
      "|    value_loss         | 0.238       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 739        |\n",
      "|    iterations         | 20         |\n",
      "|    time_elapsed       | 221        |\n",
      "|    total_timesteps    | 24018944   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02561652 |\n",
      "|    entropy_loss       | -1.82      |\n",
      "|    explained_variance | 0.953      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.00452   |\n",
      "|    mean_step_reward   | 0.11080611 |\n",
      "|    n_updates          | 59.38 %    |\n",
      "|    policyGradLoss     | -0.0181    |\n",
      "|    value_loss         | 0.286      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 738         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 232         |\n",
      "|    total_timesteps    | 24027136    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.032122385 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0566     |\n",
      "|    mean_step_reward   | 0.11689189  |\n",
      "|    n_updates          | 62.50 %     |\n",
      "|    policyGradLoss     | -0.0208     |\n",
      "|    value_loss         | 0.221       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 736         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 244         |\n",
      "|    total_timesteps    | 24035328    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024231175 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0297     |\n",
      "|    mean_step_reward   | 0.11389752  |\n",
      "|    n_updates          | 65.62 %     |\n",
      "|    policyGradLoss     | -0.0169     |\n",
      "|    value_loss         | 0.219       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 735         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 256         |\n",
      "|    total_timesteps    | 24043520    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.032215785 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0455     |\n",
      "|    mean_step_reward   | 0.12161322  |\n",
      "|    n_updates          | 68.75 %     |\n",
      "|    policyGradLoss     | -0.0237     |\n",
      "|    value_loss         | 0.201       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 734         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 267         |\n",
      "|    total_timesteps    | 24051712    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027819594 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0173     |\n",
      "|    mean_step_reward   | 0.11378473  |\n",
      "|    n_updates          | 71.88 %     |\n",
      "|    policyGradLoss     | -0.0214     |\n",
      "|    value_loss         | 0.218       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 735         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 278         |\n",
      "|    total_timesteps    | 24059904    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027791047 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0507     |\n",
      "|    mean_step_reward   | 0.11591583  |\n",
      "|    n_updates          | 75.00 %     |\n",
      "|    policyGradLoss     | -0.0188     |\n",
      "|    value_loss         | 0.279       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 735        |\n",
      "|    iterations         | 26         |\n",
      "|    time_elapsed       | 289        |\n",
      "|    total_timesteps    | 24068096   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.0329157  |\n",
      "|    entropy_loss       | -1.83      |\n",
      "|    explained_variance | 0.971      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0484    |\n",
      "|    mean_step_reward   | 0.11745452 |\n",
      "|    n_updates          | 78.12 %    |\n",
      "|    policyGradLoss     | -0.0222    |\n",
      "|    value_loss         | 0.162      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 735        |\n",
      "|    iterations         | 27         |\n",
      "|    time_elapsed       | 300        |\n",
      "|    total_timesteps    | 24076288   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03116495 |\n",
      "|    entropy_loss       | -1.78      |\n",
      "|    explained_variance | 0.981      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0748    |\n",
      "|    mean_step_reward   | 0.13805082 |\n",
      "|    n_updates          | 81.25 %    |\n",
      "|    policyGradLoss     | -0.0224    |\n",
      "|    value_loss         | 0.12       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 737         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 311         |\n",
      "|    total_timesteps    | 24084480    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030017432 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0636     |\n",
      "|    mean_step_reward   | 0.11723622  |\n",
      "|    n_updates          | 84.38 %     |\n",
      "|    policyGradLoss     | -0.024      |\n",
      "|    value_loss         | 0.133       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 741         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 320         |\n",
      "|    total_timesteps    | 24092672    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022255778 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.95        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0203     |\n",
      "|    mean_step_reward   | 0.12317909  |\n",
      "|    n_updates          | 87.50 %     |\n",
      "|    policyGradLoss     | -0.0192     |\n",
      "|    value_loss         | 0.325       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 746        |\n",
      "|    iterations         | 30         |\n",
      "|    time_elapsed       | 329        |\n",
      "|    total_timesteps    | 24100864   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02343568 |\n",
      "|    entropy_loss       | -1.81      |\n",
      "|    explained_variance | 0.945      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.026     |\n",
      "|    mean_step_reward   | 0.09455401 |\n",
      "|    n_updates          | 90.62 %    |\n",
      "|    policyGradLoss     | -0.018     |\n",
      "|    value_loss         | 0.288      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 748        |\n",
      "|    iterations         | 31         |\n",
      "|    time_elapsed       | 339        |\n",
      "|    total_timesteps    | 24109056   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.0434063  |\n",
      "|    entropy_loss       | -1.81      |\n",
      "|    explained_variance | 0.941      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.02       |\n",
      "|    mean_step_reward   | 0.11452591 |\n",
      "|    n_updates          | 93.75 %    |\n",
      "|    policyGradLoss     | -0.0159    |\n",
      "|    value_loss         | 0.335      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 749         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 349         |\n",
      "|    total_timesteps    | 24117248    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019704944 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00138    |\n",
      "|    mean_step_reward   | 0.119471356 |\n",
      "|    n_updates          | 96.88 %     |\n",
      "|    policyGradLoss     | -0.0158     |\n",
      "|    value_loss         | 0.234       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Run_91.zip\n",
      "[EVAL] Mean Return: 153.251, Best Return: 160.417\n",
      "Saved video to ./runs_smw/videos/Run/Run_91_153.25.mp4\n",
      "\n",
      "=== Round 93 | Learn 262144 steps (Total trained: 24117248) ===\n",
      "Logging to ./runs_smw/tb/Run_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1133     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 24125440 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 911         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 24133632    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026826901 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.045      |\n",
      "|    mean_step_reward   | 0.11874603  |\n",
      "|    n_updates          | 3.12 %      |\n",
      "|    policyGradLoss     | -0.0185     |\n",
      "|    value_loss         | 0.257       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 859         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 24141824    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022456693 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0555     |\n",
      "|    mean_step_reward   | 0.12891766  |\n",
      "|    n_updates          | 6.25 %      |\n",
      "|    policyGradLoss     | -0.0163     |\n",
      "|    value_loss         | 0.199       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 837         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 24150016    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.032558553 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0565     |\n",
      "|    mean_step_reward   | 0.12664863  |\n",
      "|    n_updates          | 9.38 %      |\n",
      "|    policyGradLoss     | -0.02       |\n",
      "|    value_loss         | 0.174       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 822        |\n",
      "|    iterations         | 5          |\n",
      "|    time_elapsed       | 49         |\n",
      "|    total_timesteps    | 24158208   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03205752 |\n",
      "|    entropy_loss       | -1.8       |\n",
      "|    explained_variance | 0.97       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0516    |\n",
      "|    mean_step_reward   | 0.12547454 |\n",
      "|    n_updates          | 12.50 %    |\n",
      "|    policyGradLoss     | -0.0168    |\n",
      "|    value_loss         | 0.161      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 810         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 60          |\n",
      "|    total_timesteps    | 24166400    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029303245 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0268     |\n",
      "|    mean_step_reward   | 0.12880558  |\n",
      "|    n_updates          | 15.62 %     |\n",
      "|    policyGradLoss     | -0.0159     |\n",
      "|    value_loss         | 0.236       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 801         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 71          |\n",
      "|    total_timesteps    | 24174592    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026498267 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0566     |\n",
      "|    mean_step_reward   | 0.12028847  |\n",
      "|    n_updates          | 18.75 %     |\n",
      "|    policyGradLoss     | -0.0145     |\n",
      "|    value_loss         | 0.222       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 796         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 82          |\n",
      "|    total_timesteps    | 24182784    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.031236567 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0573     |\n",
      "|    mean_step_reward   | 0.1389823   |\n",
      "|    n_updates          | 21.88 %     |\n",
      "|    policyGradLoss     | -0.0184     |\n",
      "|    value_loss         | 0.146       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 792         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 93          |\n",
      "|    total_timesteps    | 24190976    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.034204658 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0549     |\n",
      "|    mean_step_reward   | 0.12070563  |\n",
      "|    n_updates          | 25.00 %     |\n",
      "|    policyGradLoss     | -0.0168     |\n",
      "|    value_loss         | 0.124       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 788         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 103         |\n",
      "|    total_timesteps    | 24199168    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029788705 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0446     |\n",
      "|    mean_step_reward   | 0.1341891   |\n",
      "|    n_updates          | 28.12 %     |\n",
      "|    policyGradLoss     | -0.0216     |\n",
      "|    value_loss         | 0.15        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 114         |\n",
      "|    total_timesteps    | 24207360    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023721714 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0264     |\n",
      "|    mean_step_reward   | 0.113724    |\n",
      "|    n_updates          | 31.25 %     |\n",
      "|    policyGradLoss     | -0.0157     |\n",
      "|    value_loss         | 0.261       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 786        |\n",
      "|    iterations         | 12         |\n",
      "|    time_elapsed       | 124        |\n",
      "|    total_timesteps    | 24215552   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02411706 |\n",
      "|    entropy_loss       | -1.77      |\n",
      "|    explained_variance | 0.967      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.0166     |\n",
      "|    mean_step_reward   | 0.1192687  |\n",
      "|    n_updates          | 34.38 %    |\n",
      "|    policyGradLoss     | -0.0178    |\n",
      "|    value_loss         | 0.272      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 135         |\n",
      "|    total_timesteps    | 24223744    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030636555 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0581     |\n",
      "|    mean_step_reward   | 0.12868044  |\n",
      "|    n_updates          | 37.50 %     |\n",
      "|    policyGradLoss     | -0.0172     |\n",
      "|    value_loss         | 0.173       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 146         |\n",
      "|    total_timesteps    | 24231936    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030972334 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0626     |\n",
      "|    mean_step_reward   | 0.12255179  |\n",
      "|    n_updates          | 40.62 %     |\n",
      "|    policyGradLoss     | -0.0228     |\n",
      "|    value_loss         | 0.145       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 157         |\n",
      "|    total_timesteps    | 24240128    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025049273 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00327    |\n",
      "|    mean_step_reward   | 0.13060886  |\n",
      "|    n_updates          | 43.75 %     |\n",
      "|    policyGradLoss     | -0.0172     |\n",
      "|    value_loss         | 0.222       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 167         |\n",
      "|    total_timesteps    | 24248320    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020909484 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0264     |\n",
      "|    mean_step_reward   | 0.10858084  |\n",
      "|    n_updates          | 46.88 %     |\n",
      "|    policyGradLoss     | -0.0162     |\n",
      "|    value_loss         | 0.286       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 779        |\n",
      "|    iterations         | 17         |\n",
      "|    time_elapsed       | 178        |\n",
      "|    total_timesteps    | 24256512   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02505744 |\n",
      "|    entropy_loss       | -1.76      |\n",
      "|    explained_variance | 0.967      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0428    |\n",
      "|    mean_step_reward   | 0.1322371  |\n",
      "|    n_updates          | 50.00 %    |\n",
      "|    policyGradLoss     | -0.0162    |\n",
      "|    value_loss         | 0.254      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 777        |\n",
      "|    iterations         | 18         |\n",
      "|    time_elapsed       | 189        |\n",
      "|    total_timesteps    | 24264704   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03099288 |\n",
      "|    entropy_loss       | -1.82      |\n",
      "|    explained_variance | 0.974      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0657    |\n",
      "|    mean_step_reward   | 0.11933604 |\n",
      "|    n_updates          | 53.12 %    |\n",
      "|    policyGradLoss     | -0.0184    |\n",
      "|    value_loss         | 0.177      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 200         |\n",
      "|    total_timesteps    | 24272896    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023969939 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.957       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00235     |\n",
      "|    mean_step_reward   | 0.13742487  |\n",
      "|    n_updates          | 56.25 %     |\n",
      "|    policyGradLoss     | -0.0149     |\n",
      "|    value_loss         | 0.291       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 210         |\n",
      "|    total_timesteps    | 24281088    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017320182 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.932       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0428      |\n",
      "|    mean_step_reward   | 0.1025635   |\n",
      "|    n_updates          | 59.38 %     |\n",
      "|    policyGradLoss     | -0.0153     |\n",
      "|    value_loss         | 0.336       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 221         |\n",
      "|    total_timesteps    | 24289280    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023783363 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0276     |\n",
      "|    mean_step_reward   | 0.12962386  |\n",
      "|    n_updates          | 62.50 %     |\n",
      "|    policyGradLoss     | -0.0171     |\n",
      "|    value_loss         | 0.31        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 232         |\n",
      "|    total_timesteps    | 24297472    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026990313 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.957       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0173     |\n",
      "|    mean_step_reward   | 0.108792216 |\n",
      "|    n_updates          | 65.62 %     |\n",
      "|    policyGradLoss     | -0.0188     |\n",
      "|    value_loss         | 0.269       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 243         |\n",
      "|    total_timesteps    | 24305664    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.034401372 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0593     |\n",
      "|    mean_step_reward   | 0.13767284  |\n",
      "|    n_updates          | 68.75 %     |\n",
      "|    policyGradLoss     | -0.0206     |\n",
      "|    value_loss         | 0.153       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 253         |\n",
      "|    total_timesteps    | 24313856    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027039845 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.031      |\n",
      "|    mean_step_reward   | 0.09268987  |\n",
      "|    n_updates          | 71.88 %     |\n",
      "|    policyGradLoss     | -0.0229     |\n",
      "|    value_loss         | 0.24        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 264         |\n",
      "|    total_timesteps    | 24322048    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030703146 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0451     |\n",
      "|    mean_step_reward   | 0.1301458   |\n",
      "|    n_updates          | 75.00 %     |\n",
      "|    policyGradLoss     | -0.0198     |\n",
      "|    value_loss         | 0.219       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 773        |\n",
      "|    iterations         | 26         |\n",
      "|    time_elapsed       | 275        |\n",
      "|    total_timesteps    | 24330240   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03142657 |\n",
      "|    entropy_loss       | -1.8       |\n",
      "|    explained_variance | 0.974      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0383    |\n",
      "|    mean_step_reward   | 0.1171417  |\n",
      "|    n_updates          | 78.12 %    |\n",
      "|    policyGradLoss     | -0.021     |\n",
      "|    value_loss         | 0.185      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 286         |\n",
      "|    total_timesteps    | 24338432    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.033411555 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0622     |\n",
      "|    mean_step_reward   | 0.13080098  |\n",
      "|    n_updates          | 81.25 %     |\n",
      "|    policyGradLoss     | -0.0223     |\n",
      "|    value_loss         | 0.103       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 772        |\n",
      "|    iterations         | 28         |\n",
      "|    time_elapsed       | 296        |\n",
      "|    total_timesteps    | 24346624   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02678619 |\n",
      "|    entropy_loss       | -1.8       |\n",
      "|    explained_variance | 0.969      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.059     |\n",
      "|    mean_step_reward   | 0.13123451 |\n",
      "|    n_updates          | 84.38 %    |\n",
      "|    policyGradLoss     | -0.0186    |\n",
      "|    value_loss         | 0.196      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 307         |\n",
      "|    total_timesteps    | 24354816    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021786816 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.948       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.019      |\n",
      "|    mean_step_reward   | 0.10484847  |\n",
      "|    n_updates          | 87.50 %     |\n",
      "|    policyGradLoss     | -0.0163     |\n",
      "|    value_loss         | 0.301       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 318         |\n",
      "|    total_timesteps    | 24363008    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026569301 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.957       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0207     |\n",
      "|    mean_step_reward   | 0.12659304  |\n",
      "|    n_updates          | 90.62 %     |\n",
      "|    policyGradLoss     | -0.0146     |\n",
      "|    value_loss         | 0.326       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 771        |\n",
      "|    iterations         | 31         |\n",
      "|    time_elapsed       | 329        |\n",
      "|    total_timesteps    | 24371200   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02858055 |\n",
      "|    entropy_loss       | -1.82      |\n",
      "|    explained_variance | 0.974      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.058     |\n",
      "|    mean_step_reward   | 0.1208995  |\n",
      "|    n_updates          | 93.75 %    |\n",
      "|    policyGradLoss     | -0.022     |\n",
      "|    value_loss         | 0.147      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 340         |\n",
      "|    total_timesteps    | 24379392    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025995385 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0822      |\n",
      "|    mean_step_reward   | 0.109007046 |\n",
      "|    n_updates          | 96.88 %     |\n",
      "|    policyGradLoss     | -0.0181     |\n",
      "|    value_loss         | 0.342       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Run_92.zip\n",
      "[EVAL] Mean Return: 156.097, Best Return: 163.097\n",
      "Saved video to ./runs_smw/videos/Run/Run_92_156.10.mp4\n",
      "\n",
      "=== Round 94 | Learn 262144 steps (Total trained: 24379392) ===\n",
      "Logging to ./runs_smw/tb/Run_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1086     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 24387584 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 887         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 24395776    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023879819 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0244      |\n",
      "|    mean_step_reward   | 0.107338145 |\n",
      "|    n_updates          | 3.12 %      |\n",
      "|    policyGradLoss     | -0.0125     |\n",
      "|    value_loss         | 0.288       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 846         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 29          |\n",
      "|    total_timesteps    | 24403968    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028654939 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0491     |\n",
      "|    mean_step_reward   | 0.114667706 |\n",
      "|    n_updates          | 6.25 %      |\n",
      "|    policyGradLoss     | -0.0208     |\n",
      "|    value_loss         | 0.159       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 822         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 24412160    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030623969 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0753     |\n",
      "|    mean_step_reward   | 0.120965794 |\n",
      "|    n_updates          | 9.38 %      |\n",
      "|    policyGradLoss     | -0.0214     |\n",
      "|    value_loss         | 0.153       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 808         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 50          |\n",
      "|    total_timesteps    | 24420352    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029584035 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0385     |\n",
      "|    mean_step_reward   | 0.114767805 |\n",
      "|    n_updates          | 12.50 %     |\n",
      "|    policyGradLoss     | -0.0198     |\n",
      "|    value_loss         | 0.152       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 801         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 61          |\n",
      "|    total_timesteps    | 24428544    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025117684 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.958       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0134     |\n",
      "|    mean_step_reward   | 0.10586161  |\n",
      "|    n_updates          | 15.62 %     |\n",
      "|    policyGradLoss     | -0.0172     |\n",
      "|    value_loss         | 0.317       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 795        |\n",
      "|    iterations         | 7          |\n",
      "|    time_elapsed       | 72         |\n",
      "|    total_timesteps    | 24436736   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02329329 |\n",
      "|    entropy_loss       | -1.83      |\n",
      "|    explained_variance | 0.968      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0344    |\n",
      "|    mean_step_reward   | 0.12147601 |\n",
      "|    n_updates          | 18.75 %    |\n",
      "|    policyGradLoss     | -0.0155    |\n",
      "|    value_loss         | 0.222      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 789         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 83          |\n",
      "|    total_timesteps    | 24444928    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025799133 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0295     |\n",
      "|    mean_step_reward   | 0.12750077  |\n",
      "|    n_updates          | 21.88 %     |\n",
      "|    policyGradLoss     | -0.0173     |\n",
      "|    value_loss         | 0.227       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 93          |\n",
      "|    total_timesteps    | 24453120    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030312948 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0456     |\n",
      "|    mean_step_reward   | 0.106317684 |\n",
      "|    n_updates          | 25.00 %     |\n",
      "|    policyGradLoss     | -0.0208     |\n",
      "|    value_loss         | 0.229       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 104         |\n",
      "|    total_timesteps    | 24461312    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029931435 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0522     |\n",
      "|    mean_step_reward   | 0.11958313  |\n",
      "|    n_updates          | 28.12 %     |\n",
      "|    policyGradLoss     | -0.0201     |\n",
      "|    value_loss         | 0.243       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 114         |\n",
      "|    total_timesteps    | 24469504    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026732147 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00807    |\n",
      "|    mean_step_reward   | 0.1195871   |\n",
      "|    n_updates          | 31.25 %     |\n",
      "|    policyGradLoss     | -0.0144     |\n",
      "|    value_loss         | 0.213       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 125         |\n",
      "|    total_timesteps    | 24477696    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.031996056 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0563     |\n",
      "|    mean_step_reward   | 0.12267975  |\n",
      "|    n_updates          | 34.38 %     |\n",
      "|    policyGradLoss     | -0.0217     |\n",
      "|    value_loss         | 0.173       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 136         |\n",
      "|    total_timesteps    | 24485888    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.031055659 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0172     |\n",
      "|    mean_step_reward   | 0.12980732  |\n",
      "|    n_updates          | 37.50 %     |\n",
      "|    policyGradLoss     | -0.0195     |\n",
      "|    value_loss         | 0.191       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 146         |\n",
      "|    total_timesteps    | 24494080    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026894161 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0369     |\n",
      "|    mean_step_reward   | 0.12287585  |\n",
      "|    n_updates          | 40.62 %     |\n",
      "|    policyGradLoss     | -0.0194     |\n",
      "|    value_loss         | 0.206       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 157         |\n",
      "|    total_timesteps    | 24502272    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024747543 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.944       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0348      |\n",
      "|    mean_step_reward   | 0.107548416 |\n",
      "|    n_updates          | 43.75 %     |\n",
      "|    policyGradLoss     | -0.0138     |\n",
      "|    value_loss         | 0.32        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 168         |\n",
      "|    total_timesteps    | 24510464    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029802525 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0464     |\n",
      "|    mean_step_reward   | 0.10930199  |\n",
      "|    n_updates          | 46.88 %     |\n",
      "|    policyGradLoss     | -0.025      |\n",
      "|    value_loss         | 0.17        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 179         |\n",
      "|    total_timesteps    | 24518656    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029891498 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0221     |\n",
      "|    mean_step_reward   | 0.11854241  |\n",
      "|    n_updates          | 50.00 %     |\n",
      "|    policyGradLoss     | -0.0216     |\n",
      "|    value_loss         | 0.191       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 190         |\n",
      "|    total_timesteps    | 24526848    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023814086 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0503     |\n",
      "|    mean_step_reward   | 0.13272406  |\n",
      "|    n_updates          | 53.12 %     |\n",
      "|    policyGradLoss     | -0.0179     |\n",
      "|    value_loss         | 0.244       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 200         |\n",
      "|    total_timesteps    | 24535040    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024161233 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.948       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.045       |\n",
      "|    mean_step_reward   | 0.09528098  |\n",
      "|    n_updates          | 56.25 %     |\n",
      "|    policyGradLoss     | -0.0171     |\n",
      "|    value_loss         | 0.325       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 211         |\n",
      "|    total_timesteps    | 24543232    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.032156054 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00651     |\n",
      "|    mean_step_reward   | 0.1276741   |\n",
      "|    n_updates          | 59.38 %     |\n",
      "|    policyGradLoss     | -0.0177     |\n",
      "|    value_loss         | 0.275       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 222         |\n",
      "|    total_timesteps    | 24551424    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029496063 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.072      |\n",
      "|    mean_step_reward   | 0.121457525 |\n",
      "|    n_updates          | 62.50 %     |\n",
      "|    policyGradLoss     | -0.0213     |\n",
      "|    value_loss         | 0.173       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 233         |\n",
      "|    total_timesteps    | 24559616    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029972127 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.021       |\n",
      "|    mean_step_reward   | 0.11539541  |\n",
      "|    n_updates          | 65.62 %     |\n",
      "|    policyGradLoss     | -0.0186     |\n",
      "|    value_loss         | 0.246       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 244         |\n",
      "|    total_timesteps    | 24567808    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025121652 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0361     |\n",
      "|    mean_step_reward   | 0.12208127  |\n",
      "|    n_updates          | 68.75 %     |\n",
      "|    policyGradLoss     | -0.0191     |\n",
      "|    value_loss         | 0.221       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 254         |\n",
      "|    total_timesteps    | 24576000    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029381063 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0646     |\n",
      "|    mean_step_reward   | 0.12298014  |\n",
      "|    n_updates          | 71.88 %     |\n",
      "|    policyGradLoss     | -0.0243     |\n",
      "|    value_loss         | 0.149       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 265         |\n",
      "|    total_timesteps    | 24584192    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030170394 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0373     |\n",
      "|    mean_step_reward   | 0.10686964  |\n",
      "|    n_updates          | 75.00 %     |\n",
      "|    policyGradLoss     | -0.0216     |\n",
      "|    value_loss         | 0.198       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 276         |\n",
      "|    total_timesteps    | 24592384    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026194576 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.958       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.062      |\n",
      "|    mean_step_reward   | 0.12678264  |\n",
      "|    n_updates          | 78.12 %     |\n",
      "|    policyGradLoss     | -0.0149     |\n",
      "|    value_loss         | 0.259       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 286         |\n",
      "|    total_timesteps    | 24600576    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.032644317 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.957       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0172     |\n",
      "|    mean_step_reward   | 0.11393899  |\n",
      "|    n_updates          | 81.25 %     |\n",
      "|    policyGradLoss     | -0.0176     |\n",
      "|    value_loss         | 0.187       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 297         |\n",
      "|    total_timesteps    | 24608768    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029872425 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0253     |\n",
      "|    mean_step_reward   | 0.1343696   |\n",
      "|    n_updates          | 84.38 %     |\n",
      "|    policyGradLoss     | -0.0199     |\n",
      "|    value_loss         | 0.159       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 308         |\n",
      "|    total_timesteps    | 24616960    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029770013 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0437     |\n",
      "|    mean_step_reward   | 0.11904593  |\n",
      "|    n_updates          | 87.50 %     |\n",
      "|    policyGradLoss     | -0.0188     |\n",
      "|    value_loss         | 0.204       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 318         |\n",
      "|    total_timesteps    | 24625152    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023931101 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0491     |\n",
      "|    mean_step_reward   | 0.1270064   |\n",
      "|    n_updates          | 90.62 %     |\n",
      "|    policyGradLoss     | -0.0173     |\n",
      "|    value_loss         | 0.209       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 329         |\n",
      "|    total_timesteps    | 24633344    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025618069 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00483     |\n",
      "|    mean_step_reward   | 0.11708923  |\n",
      "|    n_updates          | 93.75 %     |\n",
      "|    policyGradLoss     | -0.0173     |\n",
      "|    value_loss         | 0.192       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 340         |\n",
      "|    total_timesteps    | 24641536    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026010215 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0595     |\n",
      "|    mean_step_reward   | 0.114578776 |\n",
      "|    n_updates          | 96.88 %     |\n",
      "|    policyGradLoss     | -0.0186     |\n",
      "|    value_loss         | 0.188       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Run_93.zip\n",
      "[EVAL] Mean Return: 154.867, Best Return: 161.867\n",
      "Saved video to ./runs_smw/videos/Run/Run_93_154.87.mp4\n",
      "\n",
      "=== Round 95 | Learn 262144 steps (Total trained: 24641536) ===\n",
      "Logging to ./runs_smw/tb/Run_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1105     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 24649728 |\n",
      "---------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 917        |\n",
      "|    iterations         | 2          |\n",
      "|    time_elapsed       | 17         |\n",
      "|    total_timesteps    | 24657920   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02180229 |\n",
      "|    entropy_loss       | -1.81      |\n",
      "|    explained_variance | 0.947      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.0156     |\n",
      "|    mean_step_reward   | 0.11843361 |\n",
      "|    n_updates          | 3.12 %     |\n",
      "|    policyGradLoss     | -0.0148    |\n",
      "|    value_loss         | 0.27       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 864         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 24666112    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020629754 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.949       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0136      |\n",
      "|    mean_step_reward   | 0.11776901  |\n",
      "|    n_updates          | 6.25 %      |\n",
      "|    policyGradLoss     | -0.0156     |\n",
      "|    value_loss         | 0.377       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 834         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 24674304    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027860705 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0326     |\n",
      "|    mean_step_reward   | 0.11218776  |\n",
      "|    n_updates          | 9.38 %      |\n",
      "|    policyGradLoss     | -0.0202     |\n",
      "|    value_loss         | 0.22        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 816         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 50          |\n",
      "|    total_timesteps    | 24682496    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025434803 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0383     |\n",
      "|    mean_step_reward   | 0.13565755  |\n",
      "|    n_updates          | 12.50 %     |\n",
      "|    policyGradLoss     | -0.0205     |\n",
      "|    value_loss         | 0.178       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 808        |\n",
      "|    iterations         | 6          |\n",
      "|    time_elapsed       | 60         |\n",
      "|    total_timesteps    | 24690688   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02418819 |\n",
      "|    entropy_loss       | -1.82      |\n",
      "|    explained_variance | 0.958      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0151    |\n",
      "|    mean_step_reward   | 0.10878222 |\n",
      "|    n_updates          | 15.62 %    |\n",
      "|    policyGradLoss     | -0.016     |\n",
      "|    value_loss         | 0.271      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 801         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 71          |\n",
      "|    total_timesteps    | 24698880    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026377069 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0168     |\n",
      "|    mean_step_reward   | 0.12714136  |\n",
      "|    n_updates          | 18.75 %     |\n",
      "|    policyGradLoss     | -0.019      |\n",
      "|    value_loss         | 0.213       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 798         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 82          |\n",
      "|    total_timesteps    | 24707072    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025912873 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.955       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0394     |\n",
      "|    mean_step_reward   | 0.110720776 |\n",
      "|    n_updates          | 21.88 %     |\n",
      "|    policyGradLoss     | -0.0194     |\n",
      "|    value_loss         | 0.221       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 793         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 92          |\n",
      "|    total_timesteps    | 24715264    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028174188 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0189     |\n",
      "|    mean_step_reward   | 0.13535461  |\n",
      "|    n_updates          | 25.00 %     |\n",
      "|    policyGradLoss     | -0.0209     |\n",
      "|    value_loss         | 0.233       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 789         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 103         |\n",
      "|    total_timesteps    | 24723456    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02812257  |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0396      |\n",
      "|    mean_step_reward   | 0.107009046 |\n",
      "|    n_updates          | 28.12 %     |\n",
      "|    policyGradLoss     | -0.0225     |\n",
      "|    value_loss         | 0.187       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 114         |\n",
      "|    total_timesteps    | 24731648    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019716833 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.942       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.042      |\n",
      "|    mean_step_reward   | 0.10931763  |\n",
      "|    n_updates          | 31.25 %     |\n",
      "|    policyGradLoss     | -0.0179     |\n",
      "|    value_loss         | 0.388       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 783        |\n",
      "|    iterations         | 12         |\n",
      "|    time_elapsed       | 125        |\n",
      "|    total_timesteps    | 24739840   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02072927 |\n",
      "|    entropy_loss       | -1.83      |\n",
      "|    explained_variance | 0.942      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.0228     |\n",
      "|    mean_step_reward   | 0.11392333 |\n",
      "|    n_updates          | 34.38 %    |\n",
      "|    policyGradLoss     | -0.0138    |\n",
      "|    value_loss         | 0.352      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 136         |\n",
      "|    total_timesteps    | 24748032    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022825407 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0223     |\n",
      "|    mean_step_reward   | 0.11849     |\n",
      "|    n_updates          | 37.50 %     |\n",
      "|    policyGradLoss     | -0.018      |\n",
      "|    value_loss         | 0.218       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 147         |\n",
      "|    total_timesteps    | 24756224    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021416495 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0249     |\n",
      "|    mean_step_reward   | 0.10173994  |\n",
      "|    n_updates          | 40.62 %     |\n",
      "|    policyGradLoss     | -0.0202     |\n",
      "|    value_loss         | 0.266       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 779        |\n",
      "|    iterations         | 15         |\n",
      "|    time_elapsed       | 157        |\n",
      "|    total_timesteps    | 24764416   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02586405 |\n",
      "|    entropy_loss       | -1.83      |\n",
      "|    explained_variance | 0.965      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0211    |\n",
      "|    mean_step_reward   | 0.11823079 |\n",
      "|    n_updates          | 43.75 %    |\n",
      "|    policyGradLoss     | -0.0223    |\n",
      "|    value_loss         | 0.242      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 168         |\n",
      "|    total_timesteps    | 24772608    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025605919 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0263     |\n",
      "|    mean_step_reward   | 0.10845192  |\n",
      "|    n_updates          | 46.88 %     |\n",
      "|    policyGradLoss     | -0.021      |\n",
      "|    value_loss         | 0.175       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 179         |\n",
      "|    total_timesteps    | 24780800    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023835404 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.958       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0498     |\n",
      "|    mean_step_reward   | 0.102446474 |\n",
      "|    n_updates          | 50.00 %     |\n",
      "|    policyGradLoss     | -0.022      |\n",
      "|    value_loss         | 0.17        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 189         |\n",
      "|    total_timesteps    | 24788992    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023675598 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0441     |\n",
      "|    mean_step_reward   | 0.10534893  |\n",
      "|    n_updates          | 53.12 %     |\n",
      "|    policyGradLoss     | -0.0197     |\n",
      "|    value_loss         | 0.208       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 200         |\n",
      "|    total_timesteps    | 24797184    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024141664 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0438      |\n",
      "|    mean_step_reward   | 0.12608     |\n",
      "|    n_updates          | 56.25 %     |\n",
      "|    policyGradLoss     | -0.0195     |\n",
      "|    value_loss         | 0.234       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 211         |\n",
      "|    total_timesteps    | 24805376    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024719136 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.939       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.016      |\n",
      "|    mean_step_reward   | 0.11660936  |\n",
      "|    n_updates          | 59.38 %     |\n",
      "|    policyGradLoss     | -0.014      |\n",
      "|    value_loss         | 0.308       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 773        |\n",
      "|    iterations         | 21         |\n",
      "|    time_elapsed       | 222        |\n",
      "|    total_timesteps    | 24813568   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01832974 |\n",
      "|    entropy_loss       | -1.84      |\n",
      "|    explained_variance | 0.941      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.00732   |\n",
      "|    mean_step_reward   | 0.10649669 |\n",
      "|    n_updates          | 62.50 %    |\n",
      "|    policyGradLoss     | -0.0139    |\n",
      "|    value_loss         | 0.329      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 232         |\n",
      "|    total_timesteps    | 24821760    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02368914  |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0254     |\n",
      "|    mean_step_reward   | 0.106512636 |\n",
      "|    n_updates          | 65.62 %     |\n",
      "|    policyGradLoss     | -0.0199     |\n",
      "|    value_loss         | 0.306       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 243         |\n",
      "|    total_timesteps    | 24829952    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.035453457 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.909       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0726      |\n",
      "|    mean_step_reward   | 0.12820794  |\n",
      "|    n_updates          | 68.75 %     |\n",
      "|    policyGradLoss     | -0.00809    |\n",
      "|    value_loss         | 0.46        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 254         |\n",
      "|    total_timesteps    | 24838144    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018830908 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.939       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0533     |\n",
      "|    mean_step_reward   | 0.10913443  |\n",
      "|    n_updates          | 71.88 %     |\n",
      "|    policyGradLoss     | -0.0153     |\n",
      "|    value_loss         | 0.228       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 265         |\n",
      "|    total_timesteps    | 24846336    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017510733 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.875       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.1         |\n",
      "|    mean_step_reward   | 0.092409715 |\n",
      "|    n_updates          | 75.00 %     |\n",
      "|    policyGradLoss     | -0.014      |\n",
      "|    value_loss         | 0.608       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 276         |\n",
      "|    total_timesteps    | 24854528    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026619632 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.936       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0378     |\n",
      "|    mean_step_reward   | 0.088493    |\n",
      "|    n_updates          | 78.12 %     |\n",
      "|    policyGradLoss     | -0.0184     |\n",
      "|    value_loss         | 0.273       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 286         |\n",
      "|    total_timesteps    | 24862720    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018537883 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.943       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0292      |\n",
      "|    mean_step_reward   | 0.123690374 |\n",
      "|    n_updates          | 81.25 %     |\n",
      "|    policyGradLoss     | -0.011      |\n",
      "|    value_loss         | 0.432       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 297         |\n",
      "|    total_timesteps    | 24870912    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027279604 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0439     |\n",
      "|    mean_step_reward   | 0.10500084  |\n",
      "|    n_updates          | 84.38 %     |\n",
      "|    policyGradLoss     | -0.0215     |\n",
      "|    value_loss         | 0.236       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 308         |\n",
      "|    total_timesteps    | 24879104    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026492734 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.946       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0185     |\n",
      "|    mean_step_reward   | 0.10098888  |\n",
      "|    n_updates          | 87.50 %     |\n",
      "|    policyGradLoss     | -0.0202     |\n",
      "|    value_loss         | 0.266       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 319         |\n",
      "|    total_timesteps    | 24887296    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028476581 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0298     |\n",
      "|    mean_step_reward   | 0.11380685  |\n",
      "|    n_updates          | 90.62 %     |\n",
      "|    policyGradLoss     | -0.0199     |\n",
      "|    value_loss         | 0.232       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 330         |\n",
      "|    total_timesteps    | 24895488    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025724927 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.943       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0419     |\n",
      "|    mean_step_reward   | 0.09957664  |\n",
      "|    n_updates          | 93.75 %     |\n",
      "|    policyGradLoss     | -0.0154     |\n",
      "|    value_loss         | 0.281       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 340         |\n",
      "|    total_timesteps    | 24903680    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027323656 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0539     |\n",
      "|    mean_step_reward   | 0.11931262  |\n",
      "|    n_updates          | 96.88 %     |\n",
      "|    policyGradLoss     | -0.019      |\n",
      "|    value_loss         | 0.211       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Run_94.zip\n",
      "[EVAL] Mean Return: 155.614, Best Return: 162.614\n",
      "Saved video to ./runs_smw/videos/Run/Run_94_155.61.mp4\n",
      "\n",
      "=== Round 96 | Learn 262144 steps (Total trained: 24903680) ===\n",
      "Logging to ./runs_smw/tb/Run_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1122     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 24911872 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 897         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 24920064    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02600263  |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.948       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.021      |\n",
      "|    mean_step_reward   | 0.105158255 |\n",
      "|    n_updates          | 3.12 %      |\n",
      "|    policyGradLoss     | -0.0189     |\n",
      "|    value_loss         | 0.248       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 843         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 29          |\n",
      "|    total_timesteps    | 24928256    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023425573 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0263     |\n",
      "|    mean_step_reward   | 0.105214015 |\n",
      "|    n_updates          | 6.25 %      |\n",
      "|    policyGradLoss     | -0.0199     |\n",
      "|    value_loss         | 0.291       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 824         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 24936448    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026498828 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0123     |\n",
      "|    mean_step_reward   | 0.13021567  |\n",
      "|    n_updates          | 9.38 %      |\n",
      "|    policyGradLoss     | -0.0206     |\n",
      "|    value_loss         | 0.225       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 50          |\n",
      "|    total_timesteps    | 24944640    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.032039702 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0689     |\n",
      "|    mean_step_reward   | 0.11584533  |\n",
      "|    n_updates          | 12.50 %     |\n",
      "|    policyGradLoss     | -0.0224     |\n",
      "|    value_loss         | 0.132       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 806         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 60          |\n",
      "|    total_timesteps    | 24952832    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027486514 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.051      |\n",
      "|    mean_step_reward   | 0.117410704 |\n",
      "|    n_updates          | 15.62 %     |\n",
      "|    policyGradLoss     | -0.0217     |\n",
      "|    value_loss         | 0.198       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 802         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 71          |\n",
      "|    total_timesteps    | 24961024    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026672151 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0437     |\n",
      "|    mean_step_reward   | 0.11055419  |\n",
      "|    n_updates          | 18.75 %     |\n",
      "|    policyGradLoss     | -0.0214     |\n",
      "|    value_loss         | 0.215       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 797        |\n",
      "|    iterations         | 8          |\n",
      "|    time_elapsed       | 82         |\n",
      "|    total_timesteps    | 24969216   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03089369 |\n",
      "|    entropy_loss       | -1.79      |\n",
      "|    explained_variance | 0.973      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0434    |\n",
      "|    mean_step_reward   | 0.12955374 |\n",
      "|    n_updates          | 21.88 %    |\n",
      "|    policyGradLoss     | -0.018     |\n",
      "|    value_loss         | 0.192      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 794         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 92          |\n",
      "|    total_timesteps    | 24977408    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022972558 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.95        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0398     |\n",
      "|    mean_step_reward   | 0.09504831  |\n",
      "|    n_updates          | 25.00 %     |\n",
      "|    policyGradLoss     | -0.0166     |\n",
      "|    value_loss         | 0.271       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 791         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 103         |\n",
      "|    total_timesteps    | 24985600    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021058856 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00181    |\n",
      "|    mean_step_reward   | 0.1226508   |\n",
      "|    n_updates          | 28.12 %     |\n",
      "|    policyGradLoss     | -0.0169     |\n",
      "|    value_loss         | 0.322       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 789         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 114         |\n",
      "|    total_timesteps    | 24993792    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026834613 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.954       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0391     |\n",
      "|    mean_step_reward   | 0.10872698  |\n",
      "|    n_updates          | 31.25 %     |\n",
      "|    policyGradLoss     | -0.0186     |\n",
      "|    value_loss         | 0.219       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 788         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 124         |\n",
      "|    total_timesteps    | 25001984    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023996318 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0293     |\n",
      "|    mean_step_reward   | 0.13208738  |\n",
      "|    n_updates          | 34.38 %     |\n",
      "|    policyGradLoss     | -0.016      |\n",
      "|    value_loss         | 0.242       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 135         |\n",
      "|    total_timesteps    | 25010176    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.03063168  |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0361     |\n",
      "|    mean_step_reward   | 0.123594396 |\n",
      "|    n_updates          | 37.50 %     |\n",
      "|    policyGradLoss     | -0.0215     |\n",
      "|    value_loss         | 0.191       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 146         |\n",
      "|    total_timesteps    | 25018368    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028852079 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0195     |\n",
      "|    mean_step_reward   | 0.11393732  |\n",
      "|    n_updates          | 40.62 %     |\n",
      "|    policyGradLoss     | -0.0188     |\n",
      "|    value_loss         | 0.252       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 157         |\n",
      "|    total_timesteps    | 25026560    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029780567 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0383     |\n",
      "|    mean_step_reward   | 0.119766384 |\n",
      "|    n_updates          | 43.75 %     |\n",
      "|    policyGradLoss     | -0.0201     |\n",
      "|    value_loss         | 0.188       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 168         |\n",
      "|    total_timesteps    | 25034752    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.03495447  |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0396     |\n",
      "|    mean_step_reward   | 0.122704804 |\n",
      "|    n_updates          | 46.88 %     |\n",
      "|    policyGradLoss     | -0.0196     |\n",
      "|    value_loss         | 0.183       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 178         |\n",
      "|    total_timesteps    | 25042944    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021107681 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0735      |\n",
      "|    mean_step_reward   | 0.1045866   |\n",
      "|    n_updates          | 50.00 %     |\n",
      "|    policyGradLoss     | -0.0166     |\n",
      "|    value_loss         | 0.285       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 777        |\n",
      "|    iterations         | 18         |\n",
      "|    time_elapsed       | 189        |\n",
      "|    total_timesteps    | 25051136   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.0257239  |\n",
      "|    entropy_loss       | -1.79      |\n",
      "|    explained_variance | 0.944      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.0536     |\n",
      "|    mean_step_reward   | 0.10098137 |\n",
      "|    n_updates          | 53.12 %    |\n",
      "|    policyGradLoss     | -0.017     |\n",
      "|    value_loss         | 0.407      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 200         |\n",
      "|    total_timesteps    | 25059328    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027953867 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0612     |\n",
      "|    mean_step_reward   | 0.14275819  |\n",
      "|    n_updates          | 56.25 %     |\n",
      "|    policyGradLoss     | -0.0214     |\n",
      "|    value_loss         | 0.142       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 211         |\n",
      "|    total_timesteps    | 25067520    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027697967 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.944       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.012       |\n",
      "|    mean_step_reward   | 0.094628885 |\n",
      "|    n_updates          | 59.38 %     |\n",
      "|    policyGradLoss     | -0.0144     |\n",
      "|    value_loss         | 0.23        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 775        |\n",
      "|    iterations         | 21         |\n",
      "|    time_elapsed       | 221        |\n",
      "|    total_timesteps    | 25075712   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.0272162  |\n",
      "|    entropy_loss       | -1.75      |\n",
      "|    explained_variance | 0.97       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0225    |\n",
      "|    mean_step_reward   | 0.14717188 |\n",
      "|    n_updates          | 62.50 %    |\n",
      "|    policyGradLoss     | -0.0143    |\n",
      "|    value_loss         | 0.275      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 232         |\n",
      "|    total_timesteps    | 25083904    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025835764 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0401      |\n",
      "|    mean_step_reward   | 0.101216696 |\n",
      "|    n_updates          | 65.62 %     |\n",
      "|    policyGradLoss     | -0.0151     |\n",
      "|    value_loss         | 0.25        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 775        |\n",
      "|    iterations         | 23         |\n",
      "|    time_elapsed       | 242        |\n",
      "|    total_timesteps    | 25092096   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02962747 |\n",
      "|    entropy_loss       | -1.76      |\n",
      "|    explained_variance | 0.967      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0326    |\n",
      "|    mean_step_reward   | 0.1252891  |\n",
      "|    n_updates          | 68.75 %    |\n",
      "|    policyGradLoss     | -0.0176    |\n",
      "|    value_loss         | 0.281      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 253         |\n",
      "|    total_timesteps    | 25100288    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024702776 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.958       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0302      |\n",
      "|    mean_step_reward   | 0.10045655  |\n",
      "|    n_updates          | 71.88 %     |\n",
      "|    policyGradLoss     | -0.0174     |\n",
      "|    value_loss         | 0.209       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 264         |\n",
      "|    total_timesteps    | 25108480    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029918991 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0127      |\n",
      "|    mean_step_reward   | 0.13208461  |\n",
      "|    n_updates          | 75.00 %     |\n",
      "|    policyGradLoss     | -0.0173     |\n",
      "|    value_loss         | 0.242       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 774        |\n",
      "|    iterations         | 26         |\n",
      "|    time_elapsed       | 274        |\n",
      "|    total_timesteps    | 25116672   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03375166 |\n",
      "|    entropy_loss       | -1.82      |\n",
      "|    explained_variance | 0.967      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0635    |\n",
      "|    mean_step_reward   | 0.10955336 |\n",
      "|    n_updates          | 78.12 %    |\n",
      "|    policyGradLoss     | -0.0224    |\n",
      "|    value_loss         | 0.174      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 285         |\n",
      "|    total_timesteps    | 25124864    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02790932  |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0286     |\n",
      "|    mean_step_reward   | 0.120716214 |\n",
      "|    n_updates          | 81.25 %     |\n",
      "|    policyGradLoss     | -0.0184     |\n",
      "|    value_loss         | 0.231       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 773        |\n",
      "|    iterations         | 28         |\n",
      "|    time_elapsed       | 296        |\n",
      "|    total_timesteps    | 25133056   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01848727 |\n",
      "|    entropy_loss       | -1.78      |\n",
      "|    explained_variance | 0.95       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.0137     |\n",
      "|    mean_step_reward   | 0.11906062 |\n",
      "|    n_updates          | 84.38 %    |\n",
      "|    policyGradLoss     | -0.0138    |\n",
      "|    value_loss         | 0.315      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 772        |\n",
      "|    iterations         | 29         |\n",
      "|    time_elapsed       | 307        |\n",
      "|    total_timesteps    | 25141248   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03455018 |\n",
      "|    entropy_loss       | -1.83      |\n",
      "|    explained_variance | 0.967      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0506    |\n",
      "|    mean_step_reward   | 0.11961831 |\n",
      "|    n_updates          | 87.50 %    |\n",
      "|    policyGradLoss     | -0.0195    |\n",
      "|    value_loss         | 0.19       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 317         |\n",
      "|    total_timesteps    | 25149440    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029212434 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0492      |\n",
      "|    mean_step_reward   | 0.13508528  |\n",
      "|    n_updates          | 90.62 %     |\n",
      "|    policyGradLoss     | -0.0193     |\n",
      "|    value_loss         | 0.195       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 328         |\n",
      "|    total_timesteps    | 25157632    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026585886 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0233     |\n",
      "|    mean_step_reward   | 0.11650111  |\n",
      "|    n_updates          | 93.75 %     |\n",
      "|    policyGradLoss     | -0.017      |\n",
      "|    value_loss         | 0.219       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 773        |\n",
      "|    iterations         | 32         |\n",
      "|    time_elapsed       | 339        |\n",
      "|    total_timesteps    | 25165824   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03093679 |\n",
      "|    entropy_loss       | -1.79      |\n",
      "|    explained_variance | 0.963      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0304    |\n",
      "|    mean_step_reward   | 0.11731003 |\n",
      "|    n_updates          | 96.88 %    |\n",
      "|    policyGradLoss     | -0.0181    |\n",
      "|    value_loss         | 0.244      |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Run_95.zip\n",
      "[EVAL] Mean Return: 150.701, Best Return: 157.867\n",
      "Saved video to ./runs_smw/videos/Run/Run_95_150.70.mp4\n",
      "\n",
      "=== Round 97 | Learn 262144 steps (Total trained: 25165824) ===\n",
      "Logging to ./runs_smw/tb/Run_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1108     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 25174016 |\n",
      "---------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 903        |\n",
      "|    iterations         | 2          |\n",
      "|    time_elapsed       | 18         |\n",
      "|    total_timesteps    | 25182208   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02213607 |\n",
      "|    entropy_loss       | -1.81      |\n",
      "|    explained_variance | 0.963      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.0161     |\n",
      "|    mean_step_reward   | 0.11792127 |\n",
      "|    n_updates          | 3.12 %     |\n",
      "|    policyGradLoss     | -0.0142    |\n",
      "|    value_loss         | 0.263      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 845        |\n",
      "|    iterations         | 3          |\n",
      "|    time_elapsed       | 29         |\n",
      "|    total_timesteps    | 25190400   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02542838 |\n",
      "|    entropy_loss       | -1.73      |\n",
      "|    explained_variance | 0.968      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0224    |\n",
      "|    mean_step_reward   | 0.14468533 |\n",
      "|    n_updates          | 6.25 %     |\n",
      "|    policyGradLoss     | -0.0151    |\n",
      "|    value_loss         | 0.261      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 826         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 25198592    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028176352 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00242    |\n",
      "|    mean_step_reward   | 0.11265921  |\n",
      "|    n_updates          | 9.38 %      |\n",
      "|    policyGradLoss     | -0.0158     |\n",
      "|    value_loss         | 0.238       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 817         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 50          |\n",
      "|    total_timesteps    | 25206784    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028426366 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0317     |\n",
      "|    mean_step_reward   | 0.13928491  |\n",
      "|    n_updates          | 12.50 %     |\n",
      "|    policyGradLoss     | -0.0181     |\n",
      "|    value_loss         | 0.168       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 805         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 61          |\n",
      "|    total_timesteps    | 25214976    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02573028  |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.954       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.126       |\n",
      "|    mean_step_reward   | 0.111629315 |\n",
      "|    n_updates          | 15.62 %     |\n",
      "|    policyGradLoss     | -0.0178     |\n",
      "|    value_loss         | 0.338       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 797         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 71          |\n",
      "|    total_timesteps    | 25223168    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023806572 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0498     |\n",
      "|    mean_step_reward   | 0.13674447  |\n",
      "|    n_updates          | 18.75 %     |\n",
      "|    policyGradLoss     | -0.0162     |\n",
      "|    value_loss         | 0.228       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 794         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 82          |\n",
      "|    total_timesteps    | 25231360    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023890782 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.949       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -7.08e-05   |\n",
      "|    mean_step_reward   | 0.1051497   |\n",
      "|    n_updates          | 21.88 %     |\n",
      "|    policyGradLoss     | -0.0173     |\n",
      "|    value_loss         | 0.294       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 794         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 92          |\n",
      "|    total_timesteps    | 25239552    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029518183 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00698     |\n",
      "|    mean_step_reward   | 0.1285035   |\n",
      "|    n_updates          | 25.00 %     |\n",
      "|    policyGradLoss     | -0.0174     |\n",
      "|    value_loss         | 0.326       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 790         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 103         |\n",
      "|    total_timesteps    | 25247744    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025507912 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.945       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0015     |\n",
      "|    mean_step_reward   | 0.12522145  |\n",
      "|    n_updates          | 28.12 %     |\n",
      "|    policyGradLoss     | -0.0177     |\n",
      "|    value_loss         | 0.29        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 788         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 114         |\n",
      "|    total_timesteps    | 25255936    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024549412 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.000747    |\n",
      "|    mean_step_reward   | 0.12056853  |\n",
      "|    n_updates          | 31.25 %     |\n",
      "|    policyGradLoss     | -0.0168     |\n",
      "|    value_loss         | 0.208       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 786        |\n",
      "|    iterations         | 12         |\n",
      "|    time_elapsed       | 124        |\n",
      "|    total_timesteps    | 25264128   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03236013 |\n",
      "|    entropy_loss       | -1.78      |\n",
      "|    explained_variance | 0.977      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.061     |\n",
      "|    mean_step_reward   | 0.13798055 |\n",
      "|    n_updates          | 34.38 %    |\n",
      "|    policyGradLoss     | -0.0187    |\n",
      "|    value_loss         | 0.166      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 135         |\n",
      "|    total_timesteps    | 25272320    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027960781 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0352     |\n",
      "|    mean_step_reward   | 0.102875754 |\n",
      "|    n_updates          | 37.50 %     |\n",
      "|    policyGradLoss     | -0.0166     |\n",
      "|    value_loss         | 0.2         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 146         |\n",
      "|    total_timesteps    | 25280512    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025998104 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0075     |\n",
      "|    mean_step_reward   | 0.13648626  |\n",
      "|    n_updates          | 40.62 %     |\n",
      "|    policyGradLoss     | -0.0149     |\n",
      "|    value_loss         | 0.272       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 157         |\n",
      "|    total_timesteps    | 25288704    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026629569 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0488     |\n",
      "|    mean_step_reward   | 0.116977066 |\n",
      "|    n_updates          | 43.75 %     |\n",
      "|    policyGradLoss     | -0.0188     |\n",
      "|    value_loss         | 0.183       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 167         |\n",
      "|    total_timesteps    | 25296896    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027002882 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00534    |\n",
      "|    mean_step_reward   | 0.13455305  |\n",
      "|    n_updates          | 46.88 %     |\n",
      "|    policyGradLoss     | -0.0169     |\n",
      "|    value_loss         | 0.276       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 178         |\n",
      "|    total_timesteps    | 25305088    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.038508732 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0301     |\n",
      "|    mean_step_reward   | 0.09637376  |\n",
      "|    n_updates          | 50.00 %     |\n",
      "|    policyGradLoss     | -0.0228     |\n",
      "|    value_loss         | 0.191       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 189         |\n",
      "|    total_timesteps    | 25313280    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025684776 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0698     |\n",
      "|    mean_step_reward   | 0.12667397  |\n",
      "|    n_updates          | 53.12 %     |\n",
      "|    policyGradLoss     | -0.0201     |\n",
      "|    value_loss         | 0.165       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 200         |\n",
      "|    total_timesteps    | 25321472    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030781012 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0192      |\n",
      "|    mean_step_reward   | 0.11096693  |\n",
      "|    n_updates          | 56.25 %     |\n",
      "|    policyGradLoss     | -0.019      |\n",
      "|    value_loss         | 0.207       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 211         |\n",
      "|    total_timesteps    | 25329664    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028637856 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0275      |\n",
      "|    mean_step_reward   | 0.124823265 |\n",
      "|    n_updates          | 59.38 %     |\n",
      "|    policyGradLoss     | -0.0198     |\n",
      "|    value_loss         | 0.213       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 774        |\n",
      "|    iterations         | 21         |\n",
      "|    time_elapsed       | 222        |\n",
      "|    total_timesteps    | 25337856   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02591142 |\n",
      "|    entropy_loss       | -1.81      |\n",
      "|    explained_variance | 0.96       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0414    |\n",
      "|    mean_step_reward   | 0.12564383 |\n",
      "|    n_updates          | 62.50 %    |\n",
      "|    policyGradLoss     | -0.0204    |\n",
      "|    value_loss         | 0.274      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 232         |\n",
      "|    total_timesteps    | 25346048    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025346674 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.000459   |\n",
      "|    mean_step_reward   | 0.11006556  |\n",
      "|    n_updates          | 65.62 %     |\n",
      "|    policyGradLoss     | -0.019      |\n",
      "|    value_loss         | 0.277       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 243         |\n",
      "|    total_timesteps    | 25354240    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022799782 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00854    |\n",
      "|    mean_step_reward   | 0.13214883  |\n",
      "|    n_updates          | 68.75 %     |\n",
      "|    policyGradLoss     | -0.0153     |\n",
      "|    value_loss         | 0.328       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 772        |\n",
      "|    iterations         | 24         |\n",
      "|    time_elapsed       | 254        |\n",
      "|    total_timesteps    | 25362432   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02038208 |\n",
      "|    entropy_loss       | -1.82      |\n",
      "|    explained_variance | 0.955      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0139    |\n",
      "|    mean_step_reward   | 0.1134699  |\n",
      "|    n_updates          | 71.88 %    |\n",
      "|    policyGradLoss     | -0.0162    |\n",
      "|    value_loss         | 0.267      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 265         |\n",
      "|    total_timesteps    | 25370624    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02707579  |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.954       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0137     |\n",
      "|    mean_step_reward   | 0.124244094 |\n",
      "|    n_updates          | 75.00 %     |\n",
      "|    policyGradLoss     | -0.0191     |\n",
      "|    value_loss         | 0.29        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 276         |\n",
      "|    total_timesteps    | 25378816    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030961886 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.943       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0341     |\n",
      "|    mean_step_reward   | 0.11600873  |\n",
      "|    n_updates          | 78.12 %     |\n",
      "|    policyGradLoss     | -0.0182     |\n",
      "|    value_loss         | 0.261       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 771        |\n",
      "|    iterations         | 27         |\n",
      "|    time_elapsed       | 286        |\n",
      "|    total_timesteps    | 25387008   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02652881 |\n",
      "|    entropy_loss       | -1.81      |\n",
      "|    explained_variance | 0.952      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0184    |\n",
      "|    mean_step_reward   | 0.1147663  |\n",
      "|    n_updates          | 81.25 %    |\n",
      "|    policyGradLoss     | -0.0179    |\n",
      "|    value_loss         | 0.312      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 297         |\n",
      "|    total_timesteps    | 25395200    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022172567 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.958       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0313     |\n",
      "|    mean_step_reward   | 0.12761712  |\n",
      "|    n_updates          | 84.38 %     |\n",
      "|    policyGradLoss     | -0.0173     |\n",
      "|    value_loss         | 0.243       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 308         |\n",
      "|    total_timesteps    | 25403392    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024161397 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00471     |\n",
      "|    mean_step_reward   | 0.12091921  |\n",
      "|    n_updates          | 87.50 %     |\n",
      "|    policyGradLoss     | -0.0169     |\n",
      "|    value_loss         | 0.292       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 319         |\n",
      "|    total_timesteps    | 25411584    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028916264 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0489     |\n",
      "|    mean_step_reward   | 0.12711343  |\n",
      "|    n_updates          | 90.62 %     |\n",
      "|    policyGradLoss     | -0.019      |\n",
      "|    value_loss         | 0.242       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 330         |\n",
      "|    total_timesteps    | 25419776    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024507873 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0509     |\n",
      "|    mean_step_reward   | 0.11161949  |\n",
      "|    n_updates          | 93.75 %     |\n",
      "|    policyGradLoss     | -0.0181     |\n",
      "|    value_loss         | 0.26        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 768        |\n",
      "|    iterations         | 32         |\n",
      "|    time_elapsed       | 341        |\n",
      "|    total_timesteps    | 25427968   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02654602 |\n",
      "|    entropy_loss       | -1.82      |\n",
      "|    explained_variance | 0.975      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.0503     |\n",
      "|    mean_step_reward   | 0.12326217 |\n",
      "|    n_updates          | 96.88 %    |\n",
      "|    policyGradLoss     | -0.0196    |\n",
      "|    value_loss         | 0.192      |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Run_96.zip\n",
      "[EVAL] Mean Return: 156.155, Best Return: 163.155\n",
      "Saved video to ./runs_smw/videos/Run/Run_96_156.16.mp4\n",
      "\n",
      "=== Round 98 | Learn 262144 steps (Total trained: 25427968) ===\n",
      "Logging to ./runs_smw/tb/Run_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1101     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 25436160 |\n",
      "---------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 908        |\n",
      "|    iterations         | 2          |\n",
      "|    time_elapsed       | 18         |\n",
      "|    total_timesteps    | 25444352   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02808245 |\n",
      "|    entropy_loss       | -1.83      |\n",
      "|    explained_variance | 0.979      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.0494     |\n",
      "|    mean_step_reward   | 0.12276604 |\n",
      "|    n_updates          | 3.12 %     |\n",
      "|    policyGradLoss     | -0.0219    |\n",
      "|    value_loss         | 0.148      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 853         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 25452544    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016623408 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.955       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00187    |\n",
      "|    mean_step_reward   | 0.12332934  |\n",
      "|    n_updates          | 6.25 %      |\n",
      "|    policyGradLoss     | -0.0155     |\n",
      "|    value_loss         | 0.309       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 825         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 25460736    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022654649 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.949       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00597    |\n",
      "|    mean_step_reward   | 0.11628883  |\n",
      "|    n_updates          | 9.38 %      |\n",
      "|    policyGradLoss     | -0.0191     |\n",
      "|    value_loss         | 0.266       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 814         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 50          |\n",
      "|    total_timesteps    | 25468928    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024725849 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0254     |\n",
      "|    mean_step_reward   | 0.1258001   |\n",
      "|    n_updates          | 12.50 %     |\n",
      "|    policyGradLoss     | -0.0194     |\n",
      "|    value_loss         | 0.252       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 803         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 61          |\n",
      "|    total_timesteps    | 25477120    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015132165 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0234     |\n",
      "|    mean_step_reward   | 0.12368433  |\n",
      "|    n_updates          | 15.62 %     |\n",
      "|    policyGradLoss     | -0.0169     |\n",
      "|    value_loss         | 0.251       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 796         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 71          |\n",
      "|    total_timesteps    | 25485312    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020507134 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.95        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.038      |\n",
      "|    mean_step_reward   | 0.12047016  |\n",
      "|    n_updates          | 18.75 %     |\n",
      "|    policyGradLoss     | -0.0178     |\n",
      "|    value_loss         | 0.27        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 793         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 82          |\n",
      "|    total_timesteps    | 25493504    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026465911 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0329     |\n",
      "|    mean_step_reward   | 0.13042483  |\n",
      "|    n_updates          | 21.88 %     |\n",
      "|    policyGradLoss     | -0.018      |\n",
      "|    value_loss         | 0.222       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 789        |\n",
      "|    iterations         | 9          |\n",
      "|    time_elapsed       | 93         |\n",
      "|    total_timesteps    | 25501696   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02680903 |\n",
      "|    entropy_loss       | -1.83      |\n",
      "|    explained_variance | 0.953      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0195    |\n",
      "|    mean_step_reward   | 0.1090402  |\n",
      "|    n_updates          | 25.00 %    |\n",
      "|    policyGradLoss     | -0.0172    |\n",
      "|    value_loss         | 0.342      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 104         |\n",
      "|    total_timesteps    | 25509888    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02280397  |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.945       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0474     |\n",
      "|    mean_step_reward   | 0.119921945 |\n",
      "|    n_updates          | 28.12 %     |\n",
      "|    policyGradLoss     | -0.0181     |\n",
      "|    value_loss         | 0.328       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 114         |\n",
      "|    total_timesteps    | 25518080    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029393336 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0452     |\n",
      "|    mean_step_reward   | 0.117180265 |\n",
      "|    n_updates          | 31.25 %     |\n",
      "|    policyGradLoss     | -0.0192     |\n",
      "|    value_loss         | 0.19        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 125         |\n",
      "|    total_timesteps    | 25526272    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029423885 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0455     |\n",
      "|    mean_step_reward   | 0.13108261  |\n",
      "|    n_updates          | 34.38 %     |\n",
      "|    policyGradLoss     | -0.0202     |\n",
      "|    value_loss         | 0.204       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 136         |\n",
      "|    total_timesteps    | 25534464    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019961122 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0741      |\n",
      "|    mean_step_reward   | 0.11942494  |\n",
      "|    n_updates          | 37.50 %     |\n",
      "|    policyGradLoss     | -0.0165     |\n",
      "|    value_loss         | 0.297       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 146         |\n",
      "|    total_timesteps    | 25542656    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029069072 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0493     |\n",
      "|    mean_step_reward   | 0.13049689  |\n",
      "|    n_updates          | 40.62 %     |\n",
      "|    policyGradLoss     | -0.0171     |\n",
      "|    value_loss         | 0.212       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 157         |\n",
      "|    total_timesteps    | 25550848    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028554928 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0394     |\n",
      "|    mean_step_reward   | 0.11996582  |\n",
      "|    n_updates          | 43.75 %     |\n",
      "|    policyGradLoss     | -0.02       |\n",
      "|    value_loss         | 0.23        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 168         |\n",
      "|    total_timesteps    | 25559040    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029218847 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0373     |\n",
      "|    mean_step_reward   | 0.13177076  |\n",
      "|    n_updates          | 46.88 %     |\n",
      "|    policyGradLoss     | -0.0178     |\n",
      "|    value_loss         | 0.2         |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 778        |\n",
      "|    iterations         | 17         |\n",
      "|    time_elapsed       | 178        |\n",
      "|    total_timesteps    | 25567232   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01873961 |\n",
      "|    entropy_loss       | -1.85      |\n",
      "|    explained_variance | 0.909      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0189    |\n",
      "|    mean_step_reward   | 0.10660276 |\n",
      "|    n_updates          | 50.00 %    |\n",
      "|    policyGradLoss     | -0.0143    |\n",
      "|    value_loss         | 0.342      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 778        |\n",
      "|    iterations         | 18         |\n",
      "|    time_elapsed       | 189        |\n",
      "|    total_timesteps    | 25575424   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02657802 |\n",
      "|    entropy_loss       | -1.8       |\n",
      "|    explained_variance | 0.971      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0135    |\n",
      "|    mean_step_reward   | 0.13150346 |\n",
      "|    n_updates          | 53.12 %    |\n",
      "|    policyGradLoss     | -0.0156    |\n",
      "|    value_loss         | 0.202      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 200         |\n",
      "|    total_timesteps    | 25583616    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.031982657 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0116     |\n",
      "|    mean_step_reward   | 0.1090328   |\n",
      "|    n_updates          | 56.25 %     |\n",
      "|    policyGradLoss     | -0.0195     |\n",
      "|    value_loss         | 0.233       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 210         |\n",
      "|    total_timesteps    | 25591808    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.033305064 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0632     |\n",
      "|    mean_step_reward   | 0.12700808  |\n",
      "|    n_updates          | 59.38 %     |\n",
      "|    policyGradLoss     | -0.0198     |\n",
      "|    value_loss         | 0.171       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 221         |\n",
      "|    total_timesteps    | 25600000    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02799255  |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.952       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0398     |\n",
      "|    mean_step_reward   | 0.124915086 |\n",
      "|    n_updates          | 62.50 %     |\n",
      "|    policyGradLoss     | -0.0187     |\n",
      "|    value_loss         | 0.251       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 232         |\n",
      "|    total_timesteps    | 25608192    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018171646 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.94        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0359      |\n",
      "|    mean_step_reward   | 0.10507539  |\n",
      "|    n_updates          | 65.62 %     |\n",
      "|    policyGradLoss     | -0.015      |\n",
      "|    value_loss         | 0.332       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 243         |\n",
      "|    total_timesteps    | 25616384    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026874423 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.946       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00296    |\n",
      "|    mean_step_reward   | 0.11466214  |\n",
      "|    n_updates          | 68.75 %     |\n",
      "|    policyGradLoss     | -0.0221     |\n",
      "|    value_loss         | 0.347       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 253         |\n",
      "|    total_timesteps    | 25624576    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023685774 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00844    |\n",
      "|    mean_step_reward   | 0.119060226 |\n",
      "|    n_updates          | 71.88 %     |\n",
      "|    policyGradLoss     | -0.0211     |\n",
      "|    value_loss         | 0.252       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 264         |\n",
      "|    total_timesteps    | 25632768    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023316458 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.937       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0109     |\n",
      "|    mean_step_reward   | 0.10686783  |\n",
      "|    n_updates          | 75.00 %     |\n",
      "|    policyGradLoss     | -0.0182     |\n",
      "|    value_loss         | 0.359       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 774        |\n",
      "|    iterations         | 26         |\n",
      "|    time_elapsed       | 275        |\n",
      "|    total_timesteps    | 25640960   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02443076 |\n",
      "|    entropy_loss       | -1.85      |\n",
      "|    explained_variance | 0.96       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0288    |\n",
      "|    mean_step_reward   | 0.11676437 |\n",
      "|    n_updates          | 78.12 %    |\n",
      "|    policyGradLoss     | -0.0202    |\n",
      "|    value_loss         | 0.289      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 285         |\n",
      "|    total_timesteps    | 25649152    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020856312 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.941       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.000587   |\n",
      "|    mean_step_reward   | 0.10627101  |\n",
      "|    n_updates          | 81.25 %     |\n",
      "|    policyGradLoss     | -0.0157     |\n",
      "|    value_loss         | 0.444       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 296         |\n",
      "|    total_timesteps    | 25657344    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022194233 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.948       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0423     |\n",
      "|    mean_step_reward   | 0.104617506 |\n",
      "|    n_updates          | 84.38 %     |\n",
      "|    policyGradLoss     | -0.0203     |\n",
      "|    value_loss         | 0.292       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 307         |\n",
      "|    total_timesteps    | 25665536    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026333416 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0296     |\n",
      "|    mean_step_reward   | 0.13664435  |\n",
      "|    n_updates          | 87.50 %     |\n",
      "|    policyGradLoss     | -0.0203     |\n",
      "|    value_loss         | 0.213       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 318         |\n",
      "|    total_timesteps    | 25673728    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026857436 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.957       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0597     |\n",
      "|    mean_step_reward   | 0.11788727  |\n",
      "|    n_updates          | 90.62 %     |\n",
      "|    policyGradLoss     | -0.0204     |\n",
      "|    value_loss         | 0.198       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 328         |\n",
      "|    total_timesteps    | 25681920    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025880009 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0356     |\n",
      "|    mean_step_reward   | 0.11133722  |\n",
      "|    n_updates          | 93.75 %     |\n",
      "|    policyGradLoss     | -0.0207     |\n",
      "|    value_loss         | 0.301       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 339         |\n",
      "|    total_timesteps    | 25690112    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027800433 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.957       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0295     |\n",
      "|    mean_step_reward   | 0.11048728  |\n",
      "|    n_updates          | 96.88 %     |\n",
      "|    policyGradLoss     | -0.0198     |\n",
      "|    value_loss         | 0.256       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Run_97.zip\n",
      "[EVAL] Mean Return: 156.083, Best Return: 163.083\n",
      "Saved video to ./runs_smw/videos/Run/Run_97_156.08.mp4\n",
      "\n",
      "=== Round 99 | Learn 262144 steps (Total trained: 25690112) ===\n",
      "Logging to ./runs_smw/tb/Run_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1127     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 25698304 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 916         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 25706496    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.032261856 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00995     |\n",
      "|    mean_step_reward   | 0.12018703  |\n",
      "|    n_updates          | 3.12 %      |\n",
      "|    policyGradLoss     | -0.0198     |\n",
      "|    value_loss         | 0.291       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 863         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 25714688    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027112138 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00343     |\n",
      "|    mean_step_reward   | 0.12281312  |\n",
      "|    n_updates          | 6.25 %      |\n",
      "|    policyGradLoss     | -0.0201     |\n",
      "|    value_loss         | 0.164       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 837         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 25722880    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.033581182 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0388     |\n",
      "|    mean_step_reward   | 0.1396026   |\n",
      "|    n_updates          | 9.38 %      |\n",
      "|    policyGradLoss     | -0.0186     |\n",
      "|    value_loss         | 0.224       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 826         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 49          |\n",
      "|    total_timesteps    | 25731072    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024307432 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0293     |\n",
      "|    mean_step_reward   | 0.1083114   |\n",
      "|    n_updates          | 12.50 %     |\n",
      "|    policyGradLoss     | -0.0171     |\n",
      "|    value_loss         | 0.263       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 819         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 60          |\n",
      "|    total_timesteps    | 25739264    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024492748 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.945       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00528     |\n",
      "|    mean_step_reward   | 0.13879338  |\n",
      "|    n_updates          | 15.62 %     |\n",
      "|    policyGradLoss     | -0.0143     |\n",
      "|    value_loss         | 0.366       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 812        |\n",
      "|    iterations         | 7          |\n",
      "|    time_elapsed       | 70         |\n",
      "|    total_timesteps    | 25747456   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03320219 |\n",
      "|    entropy_loss       | -1.88      |\n",
      "|    explained_variance | 0.98       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0633    |\n",
      "|    mean_step_reward   | 0.1093284  |\n",
      "|    n_updates          | 18.75 %    |\n",
      "|    policyGradLoss     | -0.0222    |\n",
      "|    value_loss         | 0.109      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 807        |\n",
      "|    iterations         | 8          |\n",
      "|    time_elapsed       | 81         |\n",
      "|    total_timesteps    | 25755648   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02185851 |\n",
      "|    entropy_loss       | -1.76      |\n",
      "|    explained_variance | 0.952      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.0588     |\n",
      "|    mean_step_reward   | 0.14868662 |\n",
      "|    n_updates          | 21.88 %    |\n",
      "|    policyGradLoss     | -0.0119    |\n",
      "|    value_loss         | 0.29       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 802         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 91          |\n",
      "|    total_timesteps    | 25763840    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025090259 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.935       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0498      |\n",
      "|    mean_step_reward   | 0.090983935 |\n",
      "|    n_updates          | 25.00 %     |\n",
      "|    policyGradLoss     | -0.0179     |\n",
      "|    value_loss         | 0.331       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 798         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 102         |\n",
      "|    total_timesteps    | 25772032    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028904475 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0486     |\n",
      "|    mean_step_reward   | 0.13710544  |\n",
      "|    n_updates          | 28.12 %     |\n",
      "|    policyGradLoss     | -0.0213     |\n",
      "|    value_loss         | 0.174       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 796         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 113         |\n",
      "|    total_timesteps    | 25780224    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02748409  |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00812    |\n",
      "|    mean_step_reward   | 0.122307524 |\n",
      "|    n_updates          | 31.25 %     |\n",
      "|    policyGradLoss     | -0.019      |\n",
      "|    value_loss         | 0.186       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 794         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 123         |\n",
      "|    total_timesteps    | 25788416    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.032595053 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0509     |\n",
      "|    mean_step_reward   | 0.12136958  |\n",
      "|    n_updates          | 34.38 %     |\n",
      "|    policyGradLoss     | -0.0237     |\n",
      "|    value_loss         | 0.128       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 792         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 134         |\n",
      "|    total_timesteps    | 25796608    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.031846724 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0353     |\n",
      "|    mean_step_reward   | 0.12685886  |\n",
      "|    n_updates          | 37.50 %     |\n",
      "|    policyGradLoss     | -0.0206     |\n",
      "|    value_loss         | 0.239       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 791         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 144         |\n",
      "|    total_timesteps    | 25804800    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020095967 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.954       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.115       |\n",
      "|    mean_step_reward   | 0.11774827  |\n",
      "|    n_updates          | 40.62 %     |\n",
      "|    policyGradLoss     | -0.017      |\n",
      "|    value_loss         | 0.28        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 791         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 155         |\n",
      "|    total_timesteps    | 25812992    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029619992 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0134     |\n",
      "|    mean_step_reward   | 0.14195278  |\n",
      "|    n_updates          | 43.75 %     |\n",
      "|    policyGradLoss     | -0.0197     |\n",
      "|    value_loss         | 0.194       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 790        |\n",
      "|    iterations         | 16         |\n",
      "|    time_elapsed       | 165        |\n",
      "|    total_timesteps    | 25821184   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02774449 |\n",
      "|    entropy_loss       | -1.84      |\n",
      "|    explained_variance | 0.965      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.00493   |\n",
      "|    mean_step_reward   | 0.1121607  |\n",
      "|    n_updates          | 46.88 %    |\n",
      "|    policyGradLoss     | -0.0161    |\n",
      "|    value_loss         | 0.232      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 788         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 176         |\n",
      "|    total_timesteps    | 25829376    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030526228 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0445     |\n",
      "|    mean_step_reward   | 0.14393681  |\n",
      "|    n_updates          | 50.00 %     |\n",
      "|    policyGradLoss     | -0.019      |\n",
      "|    value_loss         | 0.18        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 187         |\n",
      "|    total_timesteps    | 25837568    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027803633 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0368     |\n",
      "|    mean_step_reward   | 0.10652171  |\n",
      "|    n_updates          | 53.12 %     |\n",
      "|    policyGradLoss     | -0.0187     |\n",
      "|    value_loss         | 0.188       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 197         |\n",
      "|    total_timesteps    | 25845760    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020361982 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.952       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0827      |\n",
      "|    mean_step_reward   | 0.13235804  |\n",
      "|    n_updates          | 56.25 %     |\n",
      "|    policyGradLoss     | -0.015      |\n",
      "|    value_loss         | 0.346       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 208         |\n",
      "|    total_timesteps    | 25853952    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025981413 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.945       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0335     |\n",
      "|    mean_step_reward   | 0.08811221  |\n",
      "|    n_updates          | 59.38 %     |\n",
      "|    policyGradLoss     | -0.0188     |\n",
      "|    value_loss         | 0.259       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 219         |\n",
      "|    total_timesteps    | 25862144    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025238086 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0239     |\n",
      "|    mean_step_reward   | 0.13635352  |\n",
      "|    n_updates          | 62.50 %     |\n",
      "|    policyGradLoss     | -0.0167     |\n",
      "|    value_loss         | 0.242       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 230         |\n",
      "|    total_timesteps    | 25870336    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020926096 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.951       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00442     |\n",
      "|    mean_step_reward   | 0.10959683  |\n",
      "|    n_updates          | 65.62 %     |\n",
      "|    policyGradLoss     | -0.0166     |\n",
      "|    value_loss         | 0.315       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 241         |\n",
      "|    total_timesteps    | 25878528    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017520124 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.933       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.072       |\n",
      "|    mean_step_reward   | 0.1131797   |\n",
      "|    n_updates          | 68.75 %     |\n",
      "|    policyGradLoss     | -0.0161     |\n",
      "|    value_loss         | 0.501       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 251         |\n",
      "|    total_timesteps    | 25886720    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019476518 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.954       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00491     |\n",
      "|    mean_step_reward   | 0.11480087  |\n",
      "|    n_updates          | 71.88 %     |\n",
      "|    policyGradLoss     | -0.0178     |\n",
      "|    value_loss         | 0.353       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 262         |\n",
      "|    total_timesteps    | 25894912    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023234725 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.945       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0383     |\n",
      "|    mean_step_reward   | 0.09938871  |\n",
      "|    n_updates          | 75.00 %     |\n",
      "|    policyGradLoss     | -0.021      |\n",
      "|    value_loss         | 0.277       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 273         |\n",
      "|    total_timesteps    | 25903104    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023348294 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.923       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0493      |\n",
      "|    mean_step_reward   | 0.11109497  |\n",
      "|    n_updates          | 78.12 %     |\n",
      "|    policyGradLoss     | -0.0148     |\n",
      "|    value_loss         | 0.423       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 284         |\n",
      "|    total_timesteps    | 25911296    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023320941 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.948       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0141     |\n",
      "|    mean_step_reward   | 0.11352007  |\n",
      "|    n_updates          | 81.25 %     |\n",
      "|    policyGradLoss     | -0.0185     |\n",
      "|    value_loss         | 0.301       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 294         |\n",
      "|    total_timesteps    | 25919488    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024783406 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.000153   |\n",
      "|    mean_step_reward   | 0.11958953  |\n",
      "|    n_updates          | 84.38 %     |\n",
      "|    policyGradLoss     | -0.0214     |\n",
      "|    value_loss         | 0.221       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 305         |\n",
      "|    total_timesteps    | 25927680    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022745088 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0286      |\n",
      "|    mean_step_reward   | 0.10735749  |\n",
      "|    n_updates          | 87.50 %     |\n",
      "|    policyGradLoss     | -0.0212     |\n",
      "|    value_loss         | 0.278       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 316         |\n",
      "|    total_timesteps    | 25935872    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028012585 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0638     |\n",
      "|    mean_step_reward   | 0.13060153  |\n",
      "|    n_updates          | 90.62 %     |\n",
      "|    policyGradLoss     | -0.0177     |\n",
      "|    value_loss         | 0.244       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 326         |\n",
      "|    total_timesteps    | 25944064    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017516827 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.95        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0738      |\n",
      "|    mean_step_reward   | 0.10181949  |\n",
      "|    n_updates          | 93.75 %     |\n",
      "|    policyGradLoss     | -0.019      |\n",
      "|    value_loss         | 0.338       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 337         |\n",
      "|    total_timesteps    | 25952256    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024235196 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.95        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.031       |\n",
      "|    mean_step_reward   | 0.11640233  |\n",
      "|    n_updates          | 96.88 %     |\n",
      "|    policyGradLoss     | -0.02       |\n",
      "|    value_loss         | 0.355       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Run_98.zip\n",
      "[EVAL] Mean Return: 156.810, Best Return: 163.810\n",
      "Saved video to ./runs_smw/videos/Run/Run_98_156.81.mp4\n",
      "\n",
      "=== Round 100 | Learn 262144 steps (Total trained: 25952256) ===\n",
      "Logging to ./runs_smw/tb/Run_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1095     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 25960448 |\n",
      "---------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 891        |\n",
      "|    iterations         | 2          |\n",
      "|    time_elapsed       | 18         |\n",
      "|    total_timesteps    | 25968640   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01693855 |\n",
      "|    entropy_loss       | -1.85      |\n",
      "|    explained_variance | 0.958      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.0392     |\n",
      "|    mean_step_reward   | 0.1109699  |\n",
      "|    n_updates          | 3.12 %     |\n",
      "|    policyGradLoss     | -0.0181    |\n",
      "|    value_loss         | 0.329      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 842         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 29          |\n",
      "|    total_timesteps    | 25976832    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017440552 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0299     |\n",
      "|    mean_step_reward   | 0.10663361  |\n",
      "|    n_updates          | 6.25 %      |\n",
      "|    policyGradLoss     | -0.0199     |\n",
      "|    value_loss         | 0.256       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 820         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 25985024    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026139766 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0221      |\n",
      "|    mean_step_reward   | 0.11931073  |\n",
      "|    n_updates          | 9.38 %      |\n",
      "|    policyGradLoss     | -0.0217     |\n",
      "|    value_loss         | 0.211       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 807         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 50          |\n",
      "|    total_timesteps    | 25993216    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02269454  |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0392     |\n",
      "|    mean_step_reward   | 0.116884075 |\n",
      "|    n_updates          | 12.50 %     |\n",
      "|    policyGradLoss     | -0.0204     |\n",
      "|    value_loss         | 0.264       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 796         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 61          |\n",
      "|    total_timesteps    | 26001408    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025973566 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.957       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0156     |\n",
      "|    mean_step_reward   | 0.12237858  |\n",
      "|    n_updates          | 15.62 %     |\n",
      "|    policyGradLoss     | -0.0206     |\n",
      "|    value_loss         | 0.299       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 791         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 72          |\n",
      "|    total_timesteps    | 26009600    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021697003 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.955       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0777      |\n",
      "|    mean_step_reward   | 0.11155852  |\n",
      "|    n_updates          | 18.75 %     |\n",
      "|    policyGradLoss     | -0.0174     |\n",
      "|    value_loss         | 0.337       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 83          |\n",
      "|    total_timesteps    | 26017792    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030604452 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0594     |\n",
      "|    mean_step_reward   | 0.12402373  |\n",
      "|    n_updates          | 21.88 %     |\n",
      "|    policyGradLoss     | -0.0224     |\n",
      "|    value_loss         | 0.212       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 93          |\n",
      "|    total_timesteps    | 26025984    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024902528 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.915       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00639    |\n",
      "|    mean_step_reward   | 0.093852475 |\n",
      "|    n_updates          | 25.00 %     |\n",
      "|    policyGradLoss     | -0.017      |\n",
      "|    value_loss         | 0.415       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 104         |\n",
      "|    total_timesteps    | 26034176    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023011666 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0229     |\n",
      "|    mean_step_reward   | 0.12777385  |\n",
      "|    n_updates          | 28.12 %     |\n",
      "|    policyGradLoss     | -0.0181     |\n",
      "|    value_loss         | 0.309       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 115         |\n",
      "|    total_timesteps    | 26042368    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023096105 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0702     |\n",
      "|    mean_step_reward   | 0.11747809  |\n",
      "|    n_updates          | 31.25 %     |\n",
      "|    policyGradLoss     | -0.0192     |\n",
      "|    value_loss         | 0.18        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 126         |\n",
      "|    total_timesteps    | 26050560    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025237996 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0599     |\n",
      "|    mean_step_reward   | 0.10342455  |\n",
      "|    n_updates          | 34.38 %     |\n",
      "|    policyGradLoss     | -0.0203     |\n",
      "|    value_loss         | 0.226       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 137         |\n",
      "|    total_timesteps    | 26058752    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026238471 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0574     |\n",
      "|    mean_step_reward   | 0.12708336  |\n",
      "|    n_updates          | 37.50 %     |\n",
      "|    policyGradLoss     | -0.0187     |\n",
      "|    value_loss         | 0.145       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 147         |\n",
      "|    total_timesteps    | 26066944    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027933601 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0144     |\n",
      "|    mean_step_reward   | 0.10227193  |\n",
      "|    n_updates          | 40.62 %     |\n",
      "|    policyGradLoss     | -0.0172     |\n",
      "|    value_loss         | 0.244       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 158         |\n",
      "|    total_timesteps    | 26075136    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024002228 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.958       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0066     |\n",
      "|    mean_step_reward   | 0.1260986   |\n",
      "|    n_updates          | 43.75 %     |\n",
      "|    policyGradLoss     | -0.0177     |\n",
      "|    value_loss         | 0.305       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 169         |\n",
      "|    total_timesteps    | 26083328    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020239964 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.951       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0265      |\n",
      "|    mean_step_reward   | 0.11490606  |\n",
      "|    n_updates          | 46.88 %     |\n",
      "|    policyGradLoss     | -0.0153     |\n",
      "|    value_loss         | 0.355       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 180         |\n",
      "|    total_timesteps    | 26091520    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018351091 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0069     |\n",
      "|    mean_step_reward   | 0.12570256  |\n",
      "|    n_updates          | 50.00 %     |\n",
      "|    policyGradLoss     | -0.0151     |\n",
      "|    value_loss         | 0.29        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 772        |\n",
      "|    iterations         | 18         |\n",
      "|    time_elapsed       | 190        |\n",
      "|    total_timesteps    | 26099712   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02442072 |\n",
      "|    entropy_loss       | -1.83      |\n",
      "|    explained_variance | 0.939      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0399    |\n",
      "|    mean_step_reward   | 0.11537154 |\n",
      "|    n_updates          | 53.12 %    |\n",
      "|    policyGradLoss     | -0.0162    |\n",
      "|    value_loss         | 0.291      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 201         |\n",
      "|    total_timesteps    | 26107904    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02205613  |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.952       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0542      |\n",
      "|    mean_step_reward   | 0.114619665 |\n",
      "|    n_updates          | 56.25 %     |\n",
      "|    policyGradLoss     | -0.0174     |\n",
      "|    value_loss         | 0.344       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 772        |\n",
      "|    iterations         | 20         |\n",
      "|    time_elapsed       | 212        |\n",
      "|    total_timesteps    | 26116096   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02709743 |\n",
      "|    entropy_loss       | -1.84      |\n",
      "|    explained_variance | 0.968      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0527    |\n",
      "|    mean_step_reward   | 0.12295352 |\n",
      "|    n_updates          | 59.38 %    |\n",
      "|    policyGradLoss     | -0.0208    |\n",
      "|    value_loss         | 0.168      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 222         |\n",
      "|    total_timesteps    | 26124288    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020575903 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.952       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0131     |\n",
      "|    mean_step_reward   | 0.117167674 |\n",
      "|    n_updates          | 62.50 %     |\n",
      "|    policyGradLoss     | -0.0144     |\n",
      "|    value_loss         | 0.292       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 233         |\n",
      "|    total_timesteps    | 26132480    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024970967 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0119     |\n",
      "|    mean_step_reward   | 0.113193996 |\n",
      "|    n_updates          | 65.62 %     |\n",
      "|    policyGradLoss     | -0.0192     |\n",
      "|    value_loss         | 0.266       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 244         |\n",
      "|    total_timesteps    | 26140672    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02872885  |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.954       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0277     |\n",
      "|    mean_step_reward   | 0.120810434 |\n",
      "|    n_updates          | 68.75 %     |\n",
      "|    policyGradLoss     | -0.0147     |\n",
      "|    value_loss         | 0.268       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 770        |\n",
      "|    iterations         | 24         |\n",
      "|    time_elapsed       | 255        |\n",
      "|    total_timesteps    | 26148864   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02524409 |\n",
      "|    entropy_loss       | -1.81      |\n",
      "|    explained_variance | 0.978      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0554    |\n",
      "|    mean_step_reward   | 0.14099658 |\n",
      "|    n_updates          | 71.88 %    |\n",
      "|    policyGradLoss     | -0.0171    |\n",
      "|    value_loss         | 0.155      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 266         |\n",
      "|    total_timesteps    | 26157056    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027125003 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0474     |\n",
      "|    mean_step_reward   | 0.11226648  |\n",
      "|    n_updates          | 75.00 %     |\n",
      "|    policyGradLoss     | -0.0216     |\n",
      "|    value_loss         | 0.243       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 277         |\n",
      "|    total_timesteps    | 26165248    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.031769603 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0636     |\n",
      "|    mean_step_reward   | 0.123143226 |\n",
      "|    n_updates          | 78.12 %     |\n",
      "|    policyGradLoss     | -0.0228     |\n",
      "|    value_loss         | 0.122       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 287         |\n",
      "|    total_timesteps    | 26173440    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029219164 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0188     |\n",
      "|    mean_step_reward   | 0.122080415 |\n",
      "|    n_updates          | 81.25 %     |\n",
      "|    policyGradLoss     | -0.0192     |\n",
      "|    value_loss         | 0.257       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 298         |\n",
      "|    total_timesteps    | 26181632    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02793275  |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0312     |\n",
      "|    mean_step_reward   | 0.119363785 |\n",
      "|    n_updates          | 84.38 %     |\n",
      "|    policyGradLoss     | -0.0192     |\n",
      "|    value_loss         | 0.233       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 309         |\n",
      "|    total_timesteps    | 26189824    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025934046 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0646     |\n",
      "|    mean_step_reward   | 0.11778504  |\n",
      "|    n_updates          | 87.50 %     |\n",
      "|    policyGradLoss     | -0.0199     |\n",
      "|    value_loss         | 0.201       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 320         |\n",
      "|    total_timesteps    | 26198016    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026769873 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0293     |\n",
      "|    mean_step_reward   | 0.12253467  |\n",
      "|    n_updates          | 90.62 %     |\n",
      "|    policyGradLoss     | -0.0182     |\n",
      "|    value_loss         | 0.252       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 331         |\n",
      "|    total_timesteps    | 26206208    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029163856 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0213      |\n",
      "|    mean_step_reward   | 0.12889986  |\n",
      "|    n_updates          | 93.75 %     |\n",
      "|    policyGradLoss     | -0.0192     |\n",
      "|    value_loss         | 0.238       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 342         |\n",
      "|    total_timesteps    | 26214400    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02577407  |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0424     |\n",
      "|    mean_step_reward   | 0.118779205 |\n",
      "|    n_updates          | 96.88 %     |\n",
      "|    policyGradLoss     | -0.0193     |\n",
      "|    value_loss         | 0.189       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Run_99.zip\n",
      "[EVAL] Mean Return: 20.751, Best Return: 22.084\n",
      "Saved video to ./runs_smw/videos/Run/Run_99_20.75.mp4\n",
      "\n",
      "=== Round 101 | Learn 262144 steps (Total trained: 26214400) ===\n",
      "Logging to ./runs_smw/tb/Run_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1096     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 26222592 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 905         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 26230784    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015362481 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.931       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0127      |\n",
      "|    mean_step_reward   | 0.11847396  |\n",
      "|    n_updates          | 3.12 %      |\n",
      "|    policyGradLoss     | -0.0133     |\n",
      "|    value_loss         | 0.37        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 850         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 26238976    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027914368 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0331     |\n",
      "|    mean_step_reward   | 0.13188162  |\n",
      "|    n_updates          | 6.25 %      |\n",
      "|    policyGradLoss     | -0.0195     |\n",
      "|    value_loss         | 0.165       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 831         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 26247168    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020661816 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0151     |\n",
      "|    mean_step_reward   | 0.113783    |\n",
      "|    n_updates          | 9.38 %      |\n",
      "|    policyGradLoss     | -0.0144     |\n",
      "|    value_loss         | 0.208       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 818         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 50          |\n",
      "|    total_timesteps    | 26255360    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026348721 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.048      |\n",
      "|    mean_step_reward   | 0.1406652   |\n",
      "|    n_updates          | 12.50 %     |\n",
      "|    policyGradLoss     | -0.0194     |\n",
      "|    value_loss         | 0.155       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 806        |\n",
      "|    iterations         | 6          |\n",
      "|    time_elapsed       | 60         |\n",
      "|    total_timesteps    | 26263552   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02375129 |\n",
      "|    entropy_loss       | -1.87      |\n",
      "|    explained_variance | 0.955      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0356    |\n",
      "|    mean_step_reward   | 0.11009696 |\n",
      "|    n_updates          | 15.62 %    |\n",
      "|    policyGradLoss     | -0.0102    |\n",
      "|    value_loss         | 0.204      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 799         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 71          |\n",
      "|    total_timesteps    | 26271744    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025046285 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0571     |\n",
      "|    mean_step_reward   | 0.13850017  |\n",
      "|    n_updates          | 18.75 %     |\n",
      "|    policyGradLoss     | -0.0169     |\n",
      "|    value_loss         | 0.224       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 796         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 82          |\n",
      "|    total_timesteps    | 26279936    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.031498164 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0608     |\n",
      "|    mean_step_reward   | 0.13037851  |\n",
      "|    n_updates          | 21.88 %     |\n",
      "|    policyGradLoss     | -0.0183     |\n",
      "|    value_loss         | 0.146       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 792         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 93          |\n",
      "|    total_timesteps    | 26288128    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030738361 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0737      |\n",
      "|    mean_step_reward   | 0.11472293  |\n",
      "|    n_updates          | 25.00 %     |\n",
      "|    policyGradLoss     | -0.0171     |\n",
      "|    value_loss         | 0.267       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 789        |\n",
      "|    iterations         | 10         |\n",
      "|    time_elapsed       | 103        |\n",
      "|    total_timesteps    | 26296320   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.0233845  |\n",
      "|    entropy_loss       | -1.81      |\n",
      "|    explained_variance | 0.957      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.0307     |\n",
      "|    mean_step_reward   | 0.10582128 |\n",
      "|    n_updates          | 28.12 %    |\n",
      "|    policyGradLoss     | -0.0173    |\n",
      "|    value_loss         | 0.32       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 114         |\n",
      "|    total_timesteps    | 26304512    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025998287 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0376     |\n",
      "|    mean_step_reward   | 0.14443855  |\n",
      "|    n_updates          | 31.25 %     |\n",
      "|    policyGradLoss     | -0.0198     |\n",
      "|    value_loss         | 0.232       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 125         |\n",
      "|    total_timesteps    | 26312704    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.036295366 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0364     |\n",
      "|    mean_step_reward   | 0.12010345  |\n",
      "|    n_updates          | 34.38 %     |\n",
      "|    policyGradLoss     | -0.0211     |\n",
      "|    value_loss         | 0.24        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 135         |\n",
      "|    total_timesteps    | 26320896    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021642309 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.933       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0228     |\n",
      "|    mean_step_reward   | 0.11387891  |\n",
      "|    n_updates          | 37.50 %     |\n",
      "|    policyGradLoss     | -0.0152     |\n",
      "|    value_loss         | 0.347       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 146         |\n",
      "|    total_timesteps    | 26329088    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022045173 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0216      |\n",
      "|    mean_step_reward   | 0.13464329  |\n",
      "|    n_updates          | 40.62 %     |\n",
      "|    policyGradLoss     | -0.0146     |\n",
      "|    value_loss         | 0.273       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 157         |\n",
      "|    total_timesteps    | 26337280    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026989061 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0286     |\n",
      "|    mean_step_reward   | 0.12662372  |\n",
      "|    n_updates          | 43.75 %     |\n",
      "|    policyGradLoss     | -0.0188     |\n",
      "|    value_loss         | 0.231       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 778        |\n",
      "|    iterations         | 16         |\n",
      "|    time_elapsed       | 168        |\n",
      "|    total_timesteps    | 26345472   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02254501 |\n",
      "|    entropy_loss       | -1.79      |\n",
      "|    explained_variance | 0.966      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.035     |\n",
      "|    mean_step_reward   | 0.12377711 |\n",
      "|    n_updates          | 46.88 %    |\n",
      "|    policyGradLoss     | -0.016     |\n",
      "|    value_loss         | 0.254      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 178         |\n",
      "|    total_timesteps    | 26353664    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.033055246 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0561     |\n",
      "|    mean_step_reward   | 0.133076    |\n",
      "|    n_updates          | 50.00 %     |\n",
      "|    policyGradLoss     | -0.0194     |\n",
      "|    value_loss         | 0.165       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 189         |\n",
      "|    total_timesteps    | 26361856    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030170744 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0303     |\n",
      "|    mean_step_reward   | 0.12636447  |\n",
      "|    n_updates          | 53.12 %     |\n",
      "|    policyGradLoss     | -0.0177     |\n",
      "|    value_loss         | 0.205       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 776        |\n",
      "|    iterations         | 19         |\n",
      "|    time_elapsed       | 200        |\n",
      "|    total_timesteps    | 26370048   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02144001 |\n",
      "|    entropy_loss       | -1.81      |\n",
      "|    explained_variance | 0.972      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.00745    |\n",
      "|    mean_step_reward   | 0.1302555  |\n",
      "|    n_updates          | 56.25 %    |\n",
      "|    policyGradLoss     | -0.0162    |\n",
      "|    value_loss         | 0.196      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 775        |\n",
      "|    iterations         | 20         |\n",
      "|    time_elapsed       | 211        |\n",
      "|    total_timesteps    | 26378240   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02642538 |\n",
      "|    entropy_loss       | -1.78      |\n",
      "|    explained_variance | 0.965      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.00106   |\n",
      "|    mean_step_reward   | 0.12690555 |\n",
      "|    n_updates          | 59.38 %    |\n",
      "|    policyGradLoss     | -0.0181    |\n",
      "|    value_loss         | 0.252      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 222         |\n",
      "|    total_timesteps    | 26386432    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027415704 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0572     |\n",
      "|    mean_step_reward   | 0.12505797  |\n",
      "|    n_updates          | 62.50 %     |\n",
      "|    policyGradLoss     | -0.0184     |\n",
      "|    value_loss         | 0.129       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 774        |\n",
      "|    iterations         | 22         |\n",
      "|    time_elapsed       | 232        |\n",
      "|    total_timesteps    | 26394624   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02752256 |\n",
      "|    entropy_loss       | -1.76      |\n",
      "|    explained_variance | 0.965      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0417    |\n",
      "|    mean_step_reward   | 0.13702375 |\n",
      "|    n_updates          | 65.62 %    |\n",
      "|    policyGradLoss     | -0.0204    |\n",
      "|    value_loss         | 0.224      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 243         |\n",
      "|    total_timesteps    | 26402816    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025797002 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0331     |\n",
      "|    mean_step_reward   | 0.113406    |\n",
      "|    n_updates          | 68.75 %     |\n",
      "|    policyGradLoss     | -0.0176     |\n",
      "|    value_loss         | 0.226       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 772        |\n",
      "|    iterations         | 24         |\n",
      "|    time_elapsed       | 254        |\n",
      "|    total_timesteps    | 26411008   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.0268225  |\n",
      "|    entropy_loss       | -1.78      |\n",
      "|    explained_variance | 0.982      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0498    |\n",
      "|    mean_step_reward   | 0.14153942 |\n",
      "|    n_updates          | 71.88 %    |\n",
      "|    policyGradLoss     | -0.0208    |\n",
      "|    value_loss         | 0.15       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 265         |\n",
      "|    total_timesteps    | 26419200    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021903723 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0287     |\n",
      "|    mean_step_reward   | 0.12980749  |\n",
      "|    n_updates          | 75.00 %     |\n",
      "|    policyGradLoss     | -0.0205     |\n",
      "|    value_loss         | 0.174       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 276         |\n",
      "|    total_timesteps    | 26427392    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024145976 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0656      |\n",
      "|    mean_step_reward   | 0.1181339   |\n",
      "|    n_updates          | 78.12 %     |\n",
      "|    policyGradLoss     | -0.0176     |\n",
      "|    value_loss         | 0.191       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 770        |\n",
      "|    iterations         | 27         |\n",
      "|    time_elapsed       | 286        |\n",
      "|    total_timesteps    | 26435584   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03483855 |\n",
      "|    entropy_loss       | -1.77      |\n",
      "|    explained_variance | 0.977      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0544    |\n",
      "|    mean_step_reward   | 0.1332815  |\n",
      "|    n_updates          | 81.25 %    |\n",
      "|    policyGradLoss     | -0.0241    |\n",
      "|    value_loss         | 0.12       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 297         |\n",
      "|    total_timesteps    | 26443776    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030825617 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0148     |\n",
      "|    mean_step_reward   | 0.13264073  |\n",
      "|    n_updates          | 84.38 %     |\n",
      "|    policyGradLoss     | -0.018      |\n",
      "|    value_loss         | 0.131       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 308         |\n",
      "|    total_timesteps    | 26451968    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024747107 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0338      |\n",
      "|    mean_step_reward   | 0.13333322  |\n",
      "|    n_updates          | 87.50 %     |\n",
      "|    policyGradLoss     | -0.0175     |\n",
      "|    value_loss         | 0.18        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 319         |\n",
      "|    total_timesteps    | 26460160    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.031458553 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0506     |\n",
      "|    mean_step_reward   | 0.12821162  |\n",
      "|    n_updates          | 90.62 %     |\n",
      "|    policyGradLoss     | -0.0175     |\n",
      "|    value_loss         | 0.22        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 329         |\n",
      "|    total_timesteps    | 26468352    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.034745067 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0148     |\n",
      "|    mean_step_reward   | 0.12787412  |\n",
      "|    n_updates          | 93.75 %     |\n",
      "|    policyGradLoss     | -0.0172     |\n",
      "|    value_loss         | 0.272       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 340         |\n",
      "|    total_timesteps    | 26476544    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030993648 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0248     |\n",
      "|    mean_step_reward   | 0.1244365   |\n",
      "|    n_updates          | 96.88 %     |\n",
      "|    policyGradLoss     | -0.0191     |\n",
      "|    value_loss         | 0.225       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Run_100.zip\n",
      "[EVAL] Mean Return: 155.387, Best Return: 162.387\n",
      "Saved video to ./runs_smw/videos/Run/Run_100_155.39.mp4\n",
      "\n",
      "=== Round 102 | Learn 262144 steps (Total trained: 26476544) ===\n",
      "Logging to ./runs_smw/tb/Run_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1119     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 26484736 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 913         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 26492928    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023912037 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0436     |\n",
      "|    mean_step_reward   | 0.14272298  |\n",
      "|    n_updates          | 3.12 %      |\n",
      "|    policyGradLoss     | -0.0188     |\n",
      "|    value_loss         | 0.199       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 861         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 26501120    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023977783 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.957       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0268     |\n",
      "|    mean_step_reward   | 0.12215771  |\n",
      "|    n_updates          | 6.25 %      |\n",
      "|    policyGradLoss     | -0.015      |\n",
      "|    value_loss         | 0.26        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 837         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 26509312    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024533242 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.954       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0345     |\n",
      "|    mean_step_reward   | 0.12455815  |\n",
      "|    n_updates          | 9.38 %      |\n",
      "|    policyGradLoss     | -0.0152     |\n",
      "|    value_loss         | 0.324       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 823         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 49          |\n",
      "|    total_timesteps    | 26517504    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027283126 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00658     |\n",
      "|    mean_step_reward   | 0.12003272  |\n",
      "|    n_updates          | 12.50 %     |\n",
      "|    policyGradLoss     | -0.0177     |\n",
      "|    value_loss         | 0.278       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 813         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 60          |\n",
      "|    total_timesteps    | 26525696    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029368531 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0257     |\n",
      "|    mean_step_reward   | 0.11427043  |\n",
      "|    n_updates          | 15.62 %     |\n",
      "|    policyGradLoss     | -0.0213     |\n",
      "|    value_loss         | 0.25        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 808         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 70          |\n",
      "|    total_timesteps    | 26533888    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022511512 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.939       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0484     |\n",
      "|    mean_step_reward   | 0.12872358  |\n",
      "|    n_updates          | 18.75 %     |\n",
      "|    policyGradLoss     | -0.0155     |\n",
      "|    value_loss         | 0.281       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 802        |\n",
      "|    iterations         | 8          |\n",
      "|    time_elapsed       | 81         |\n",
      "|    total_timesteps    | 26542080   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03269889 |\n",
      "|    entropy_loss       | -1.83      |\n",
      "|    explained_variance | 0.975      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.0305     |\n",
      "|    mean_step_reward   | 0.12686291 |\n",
      "|    n_updates          | 21.88 %    |\n",
      "|    policyGradLoss     | -0.0199    |\n",
      "|    value_loss         | 0.156      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 797        |\n",
      "|    iterations         | 9          |\n",
      "|    time_elapsed       | 92         |\n",
      "|    total_timesteps    | 26550272   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03080505 |\n",
      "|    entropy_loss       | -1.8       |\n",
      "|    explained_variance | 0.973      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0516    |\n",
      "|    mean_step_reward   | 0.1383434  |\n",
      "|    n_updates          | 25.00 %    |\n",
      "|    policyGradLoss     | -0.021     |\n",
      "|    value_loss         | 0.169      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 794        |\n",
      "|    iterations         | 10         |\n",
      "|    time_elapsed       | 103        |\n",
      "|    total_timesteps    | 26558464   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03057345 |\n",
      "|    entropy_loss       | -1.84      |\n",
      "|    explained_variance | 0.968      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.074      |\n",
      "|    mean_step_reward   | 0.11429727 |\n",
      "|    n_updates          | 28.12 %    |\n",
      "|    policyGradLoss     | -0.0157    |\n",
      "|    value_loss         | 0.262      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 790         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 113         |\n",
      "|    total_timesteps    | 26566656    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020871654 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.013      |\n",
      "|    mean_step_reward   | 0.140856    |\n",
      "|    n_updates          | 31.25 %     |\n",
      "|    policyGradLoss     | -0.0134     |\n",
      "|    value_loss         | 0.247       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 124         |\n",
      "|    total_timesteps    | 26574848    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024848226 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.948       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0291     |\n",
      "|    mean_step_reward   | 0.10989323  |\n",
      "|    n_updates          | 34.38 %     |\n",
      "|    policyGradLoss     | -0.0189     |\n",
      "|    value_loss         | 0.272       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 786        |\n",
      "|    iterations         | 13         |\n",
      "|    time_elapsed       | 135        |\n",
      "|    total_timesteps    | 26583040   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.0212802  |\n",
      "|    entropy_loss       | -1.79      |\n",
      "|    explained_variance | 0.97       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.00072   |\n",
      "|    mean_step_reward   | 0.12996623 |\n",
      "|    n_updates          | 37.50 %    |\n",
      "|    policyGradLoss     | -0.0159    |\n",
      "|    value_loss         | 0.266      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 146         |\n",
      "|    total_timesteps    | 26591232    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.034756076 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0841     |\n",
      "|    mean_step_reward   | 0.14054528  |\n",
      "|    n_updates          | 40.62 %     |\n",
      "|    policyGradLoss     | -0.026      |\n",
      "|    value_loss         | 0.0993      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 156         |\n",
      "|    total_timesteps    | 26599424    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026970387 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.958       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00649     |\n",
      "|    mean_step_reward   | 0.114052534 |\n",
      "|    n_updates          | 43.75 %     |\n",
      "|    policyGradLoss     | -0.0147     |\n",
      "|    value_loss         | 0.323       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 167         |\n",
      "|    total_timesteps    | 26607616    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030286495 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0291     |\n",
      "|    mean_step_reward   | 0.12209609  |\n",
      "|    n_updates          | 46.88 %     |\n",
      "|    policyGradLoss     | -0.0217     |\n",
      "|    value_loss         | 0.235       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 178         |\n",
      "|    total_timesteps    | 26615808    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02950586  |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0537     |\n",
      "|    mean_step_reward   | 0.120644756 |\n",
      "|    n_updates          | 50.00 %     |\n",
      "|    policyGradLoss     | -0.0187     |\n",
      "|    value_loss         | 0.179       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 189         |\n",
      "|    total_timesteps    | 26624000    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017593835 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0118     |\n",
      "|    mean_step_reward   | 0.122679666 |\n",
      "|    n_updates          | 53.12 %     |\n",
      "|    policyGradLoss     | -0.0177     |\n",
      "|    value_loss         | 0.269       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 199         |\n",
      "|    total_timesteps    | 26632192    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030766264 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0592     |\n",
      "|    mean_step_reward   | 0.12305263  |\n",
      "|    n_updates          | 56.25 %     |\n",
      "|    policyGradLoss     | -0.0222     |\n",
      "|    value_loss         | 0.153       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 210         |\n",
      "|    total_timesteps    | 26640384    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.031873263 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0703     |\n",
      "|    mean_step_reward   | 0.12597616  |\n",
      "|    n_updates          | 59.38 %     |\n",
      "|    policyGradLoss     | -0.0214     |\n",
      "|    value_loss         | 0.145       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 220         |\n",
      "|    total_timesteps    | 26648576    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02723677  |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.955       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0477     |\n",
      "|    mean_step_reward   | 0.110290244 |\n",
      "|    n_updates          | 62.50 %     |\n",
      "|    policyGradLoss     | -0.0162     |\n",
      "|    value_loss         | 0.224       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 231         |\n",
      "|    total_timesteps    | 26656768    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030026117 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0168      |\n",
      "|    mean_step_reward   | 0.13063225  |\n",
      "|    n_updates          | 65.62 %     |\n",
      "|    policyGradLoss     | -0.0166     |\n",
      "|    value_loss         | 0.285       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 242         |\n",
      "|    total_timesteps    | 26664960    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030237403 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.034      |\n",
      "|    mean_step_reward   | 0.12667078  |\n",
      "|    n_updates          | 68.75 %     |\n",
      "|    policyGradLoss     | -0.0216     |\n",
      "|    value_loss         | 0.178       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 252         |\n",
      "|    total_timesteps    | 26673152    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028569195 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0509     |\n",
      "|    mean_step_reward   | 0.13551237  |\n",
      "|    n_updates          | 71.88 %     |\n",
      "|    policyGradLoss     | -0.022      |\n",
      "|    value_loss         | 0.164       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 263         |\n",
      "|    total_timesteps    | 26681344    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030295841 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0196     |\n",
      "|    mean_step_reward   | 0.12880234  |\n",
      "|    n_updates          | 75.00 %     |\n",
      "|    policyGradLoss     | -0.0191     |\n",
      "|    value_loss         | 0.191       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 273         |\n",
      "|    total_timesteps    | 26689536    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027717387 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0368     |\n",
      "|    mean_step_reward   | 0.12538248  |\n",
      "|    n_updates          | 78.12 %     |\n",
      "|    policyGradLoss     | -0.0197     |\n",
      "|    value_loss         | 0.189       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 284         |\n",
      "|    total_timesteps    | 26697728    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018583776 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.935       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0158     |\n",
      "|    mean_step_reward   | 0.1124893   |\n",
      "|    n_updates          | 81.25 %     |\n",
      "|    policyGradLoss     | -0.0148     |\n",
      "|    value_loss         | 0.295       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 776        |\n",
      "|    iterations         | 28         |\n",
      "|    time_elapsed       | 295        |\n",
      "|    total_timesteps    | 26705920   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02446558 |\n",
      "|    entropy_loss       | -1.79      |\n",
      "|    explained_variance | 0.963      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0035    |\n",
      "|    mean_step_reward   | 0.12594892 |\n",
      "|    n_updates          | 84.38 %    |\n",
      "|    policyGradLoss     | -0.0201    |\n",
      "|    value_loss         | 0.217      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 306         |\n",
      "|    total_timesteps    | 26714112    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028172439 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.955       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00674     |\n",
      "|    mean_step_reward   | 0.11537113  |\n",
      "|    n_updates          | 87.50 %     |\n",
      "|    policyGradLoss     | -0.0197     |\n",
      "|    value_loss         | 0.276       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 774        |\n",
      "|    iterations         | 30         |\n",
      "|    time_elapsed       | 317        |\n",
      "|    total_timesteps    | 26722304   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02543597 |\n",
      "|    entropy_loss       | -1.84      |\n",
      "|    explained_variance | 0.96       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0455    |\n",
      "|    mean_step_reward   | 0.10743547 |\n",
      "|    n_updates          | 90.62 %    |\n",
      "|    policyGradLoss     | -0.0214    |\n",
      "|    value_loss         | 0.179      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 774        |\n",
      "|    iterations         | 31         |\n",
      "|    time_elapsed       | 327        |\n",
      "|    total_timesteps    | 26730496   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02250902 |\n",
      "|    entropy_loss       | -1.76      |\n",
      "|    explained_variance | 0.966      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.000317  |\n",
      "|    mean_step_reward   | 0.13771388 |\n",
      "|    n_updates          | 93.75 %    |\n",
      "|    policyGradLoss     | -0.0157    |\n",
      "|    value_loss         | 0.289      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 774        |\n",
      "|    iterations         | 32         |\n",
      "|    time_elapsed       | 338        |\n",
      "|    total_timesteps    | 26738688   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03118423 |\n",
      "|    entropy_loss       | -1.83      |\n",
      "|    explained_variance | 0.964      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0371    |\n",
      "|    mean_step_reward   | 0.11594466 |\n",
      "|    n_updates          | 96.88 %    |\n",
      "|    policyGradLoss     | -0.0191    |\n",
      "|    value_loss         | 0.189      |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Run_101.zip\n",
      "[EVAL] Mean Return: 89.473, Best Return: 94.473\n",
      "Saved video to ./runs_smw/videos/Run/Run_101_89.47.mp4\n",
      "\n",
      "=== Round 103 | Learn 262144 steps (Total trained: 26738688) ===\n",
      "Logging to ./runs_smw/tb/Run_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1098     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 26746880 |\n",
      "---------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 905        |\n",
      "|    iterations         | 2          |\n",
      "|    time_elapsed       | 18         |\n",
      "|    total_timesteps    | 26755072   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02153026 |\n",
      "|    entropy_loss       | -1.8       |\n",
      "|    explained_variance | 0.974      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0175    |\n",
      "|    mean_step_reward   | 0.11655527 |\n",
      "|    n_updates          | 3.12 %     |\n",
      "|    policyGradLoss     | -0.0194    |\n",
      "|    value_loss         | 0.203      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 854         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 26763264    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030664796 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0629     |\n",
      "|    mean_step_reward   | 0.11257527  |\n",
      "|    n_updates          | 6.25 %      |\n",
      "|    policyGradLoss     | -0.0218     |\n",
      "|    value_loss         | 0.161       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 825         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 26771456    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028073993 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0511     |\n",
      "|    mean_step_reward   | 0.13135193  |\n",
      "|    n_updates          | 9.38 %      |\n",
      "|    policyGradLoss     | -0.0194     |\n",
      "|    value_loss         | 0.18        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 50          |\n",
      "|    total_timesteps    | 26779648    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021438356 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0484     |\n",
      "|    mean_step_reward   | 0.124874726 |\n",
      "|    n_updates          | 12.50 %     |\n",
      "|    policyGradLoss     | -0.0184     |\n",
      "|    value_loss         | 0.257       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 801         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 61          |\n",
      "|    total_timesteps    | 26787840    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028292175 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0556     |\n",
      "|    mean_step_reward   | 0.12865949  |\n",
      "|    n_updates          | 15.62 %     |\n",
      "|    policyGradLoss     | -0.0179     |\n",
      "|    value_loss         | 0.181       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 795         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 72          |\n",
      "|    total_timesteps    | 26796032    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017434537 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.038      |\n",
      "|    mean_step_reward   | 0.13873905  |\n",
      "|    n_updates          | 18.75 %     |\n",
      "|    policyGradLoss     | -0.016      |\n",
      "|    value_loss         | 0.181       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 793        |\n",
      "|    iterations         | 8          |\n",
      "|    time_elapsed       | 82         |\n",
      "|    total_timesteps    | 26804224   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02459665 |\n",
      "|    entropy_loss       | -1.82      |\n",
      "|    explained_variance | 0.949      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0476    |\n",
      "|    mean_step_reward   | 0.10266335 |\n",
      "|    n_updates          | 21.88 %    |\n",
      "|    policyGradLoss     | -0.0196    |\n",
      "|    value_loss         | 0.238      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 790         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 93          |\n",
      "|    total_timesteps    | 26812416    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028814066 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.943       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00962    |\n",
      "|    mean_step_reward   | 0.13655888  |\n",
      "|    n_updates          | 25.00 %     |\n",
      "|    policyGradLoss     | -0.0167     |\n",
      "|    value_loss         | 0.356       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 789         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 103         |\n",
      "|    total_timesteps    | 26820608    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016004786 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.958       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0264     |\n",
      "|    mean_step_reward   | 0.10734652  |\n",
      "|    n_updates          | 28.12 %     |\n",
      "|    policyGradLoss     | -0.0183     |\n",
      "|    value_loss         | 0.281       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 114         |\n",
      "|    total_timesteps    | 26828800    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.033088032 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0414     |\n",
      "|    mean_step_reward   | 0.12915957  |\n",
      "|    n_updates          | 31.25 %     |\n",
      "|    policyGradLoss     | -0.023      |\n",
      "|    value_loss         | 0.213       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 125         |\n",
      "|    total_timesteps    | 26836992    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.032921363 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0142     |\n",
      "|    mean_step_reward   | 0.13380237  |\n",
      "|    n_updates          | 34.38 %     |\n",
      "|    policyGradLoss     | -0.0241     |\n",
      "|    value_loss         | 0.122       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 136         |\n",
      "|    total_timesteps    | 26845184    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019433223 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0101      |\n",
      "|    mean_step_reward   | 0.12047252  |\n",
      "|    n_updates          | 37.50 %     |\n",
      "|    policyGradLoss     | -0.0169     |\n",
      "|    value_loss         | 0.231       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 146         |\n",
      "|    total_timesteps    | 26853376    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024353668 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0109      |\n",
      "|    mean_step_reward   | 0.12880546  |\n",
      "|    n_updates          | 40.62 %     |\n",
      "|    policyGradLoss     | -0.0185     |\n",
      "|    value_loss         | 0.208       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 157         |\n",
      "|    total_timesteps    | 26861568    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.03326323  |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0529     |\n",
      "|    mean_step_reward   | 0.119124584 |\n",
      "|    n_updates          | 43.75 %     |\n",
      "|    policyGradLoss     | -0.018      |\n",
      "|    value_loss         | 0.203       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 168         |\n",
      "|    total_timesteps    | 26869760    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029826168 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.032       |\n",
      "|    mean_step_reward   | 0.12794994  |\n",
      "|    n_updates          | 46.88 %     |\n",
      "|    policyGradLoss     | -0.0183     |\n",
      "|    value_loss         | 0.246       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 179         |\n",
      "|    total_timesteps    | 26877952    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029664837 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.958       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00221    |\n",
      "|    mean_step_reward   | 0.118444294 |\n",
      "|    n_updates          | 50.00 %     |\n",
      "|    policyGradLoss     | -0.0185     |\n",
      "|    value_loss         | 0.309       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 189         |\n",
      "|    total_timesteps    | 26886144    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028561648 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0547     |\n",
      "|    mean_step_reward   | 0.12556651  |\n",
      "|    n_updates          | 53.12 %     |\n",
      "|    policyGradLoss     | -0.0182     |\n",
      "|    value_loss         | 0.2         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 200         |\n",
      "|    total_timesteps    | 26894336    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02189125  |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.958       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0114     |\n",
      "|    mean_step_reward   | 0.123008534 |\n",
      "|    n_updates          | 56.25 %     |\n",
      "|    policyGradLoss     | -0.014      |\n",
      "|    value_loss         | 0.248       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 211         |\n",
      "|    total_timesteps    | 26902528    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029772408 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0454     |\n",
      "|    mean_step_reward   | 0.106893465 |\n",
      "|    n_updates          | 59.38 %     |\n",
      "|    policyGradLoss     | -0.0195     |\n",
      "|    value_loss         | 0.227       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 221         |\n",
      "|    total_timesteps    | 26910720    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019652832 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.935       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00259    |\n",
      "|    mean_step_reward   | 0.10674816  |\n",
      "|    n_updates          | 62.50 %     |\n",
      "|    policyGradLoss     | -0.0173     |\n",
      "|    value_loss         | 0.383       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 232         |\n",
      "|    total_timesteps    | 26918912    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023033917 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.952       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00553    |\n",
      "|    mean_step_reward   | 0.10297531  |\n",
      "|    n_updates          | 65.62 %     |\n",
      "|    policyGradLoss     | -0.0146     |\n",
      "|    value_loss         | 0.289       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 773        |\n",
      "|    iterations         | 23         |\n",
      "|    time_elapsed       | 243        |\n",
      "|    total_timesteps    | 26927104   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02588704 |\n",
      "|    entropy_loss       | -1.78      |\n",
      "|    explained_variance | 0.938      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.00315    |\n",
      "|    mean_step_reward   | 0.11974591 |\n",
      "|    n_updates          | 68.75 %    |\n",
      "|    policyGradLoss     | -0.0141    |\n",
      "|    value_loss         | 0.352      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 254         |\n",
      "|    total_timesteps    | 26935296    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028464809 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0477      |\n",
      "|    mean_step_reward   | 0.11828055  |\n",
      "|    n_updates          | 71.88 %     |\n",
      "|    policyGradLoss     | -0.0152     |\n",
      "|    value_loss         | 0.221       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 264         |\n",
      "|    total_timesteps    | 26943488    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020635411 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.957       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0198     |\n",
      "|    mean_step_reward   | 0.13902116  |\n",
      "|    n_updates          | 75.00 %     |\n",
      "|    policyGradLoss     | -0.0151     |\n",
      "|    value_loss         | 0.273       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 275         |\n",
      "|    total_timesteps    | 26951680    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024328582 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.958       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0113     |\n",
      "|    mean_step_reward   | 0.10283267  |\n",
      "|    n_updates          | 78.12 %     |\n",
      "|    policyGradLoss     | -0.0193     |\n",
      "|    value_loss         | 0.232       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 285         |\n",
      "|    total_timesteps    | 26959872    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.031743307 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0063      |\n",
      "|    mean_step_reward   | 0.1361167   |\n",
      "|    n_updates          | 81.25 %     |\n",
      "|    policyGradLoss     | -0.0192     |\n",
      "|    value_loss         | 0.258       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 296         |\n",
      "|    total_timesteps    | 26968064    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020826448 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0341     |\n",
      "|    mean_step_reward   | 0.11578349  |\n",
      "|    n_updates          | 84.38 %     |\n",
      "|    policyGradLoss     | -0.0172     |\n",
      "|    value_loss         | 0.193       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 307         |\n",
      "|    total_timesteps    | 26976256    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029605549 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.955       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0122     |\n",
      "|    mean_step_reward   | 0.12430574  |\n",
      "|    n_updates          | 87.50 %     |\n",
      "|    policyGradLoss     | -0.0162     |\n",
      "|    value_loss         | 0.326       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 317         |\n",
      "|    total_timesteps    | 26984448    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022875722 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.933       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0718      |\n",
      "|    mean_step_reward   | 0.12167795  |\n",
      "|    n_updates          | 90.62 %     |\n",
      "|    policyGradLoss     | -0.0148     |\n",
      "|    value_loss         | 0.38        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 328         |\n",
      "|    total_timesteps    | 26992640    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027014121 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0618     |\n",
      "|    mean_step_reward   | 0.12939467  |\n",
      "|    n_updates          | 93.75 %     |\n",
      "|    policyGradLoss     | -0.0208     |\n",
      "|    value_loss         | 0.2         |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 773        |\n",
      "|    iterations         | 32         |\n",
      "|    time_elapsed       | 339        |\n",
      "|    total_timesteps    | 27000832   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03322871 |\n",
      "|    entropy_loss       | -1.82      |\n",
      "|    explained_variance | 0.971      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0265    |\n",
      "|    mean_step_reward   | 0.11079016 |\n",
      "|    n_updates          | 96.88 %    |\n",
      "|    policyGradLoss     | -0.0205    |\n",
      "|    value_loss         | 0.181      |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Run_102.zip\n",
      "[EVAL] Mean Return: 95.328, Best Return: 100.328\n",
      "Saved video to ./runs_smw/videos/Run/Run_102_95.33.mp4\n",
      "\n",
      "=== Round 104 | Learn 262144 steps (Total trained: 27000832) ===\n",
      "Logging to ./runs_smw/tb/Run_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1092     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 27009024 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 899         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 27017216    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021303087 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.957       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0981      |\n",
      "|    mean_step_reward   | 0.110488474 |\n",
      "|    n_updates          | 3.12 %      |\n",
      "|    policyGradLoss     | -0.0173     |\n",
      "|    value_loss         | 0.311       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 849         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 27025408    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023749938 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00388     |\n",
      "|    mean_step_reward   | 0.120585784 |\n",
      "|    n_updates          | 6.25 %      |\n",
      "|    policyGradLoss     | -0.0165     |\n",
      "|    value_loss         | 0.327       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 829         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 27033600    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.032031834 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0542     |\n",
      "|    mean_step_reward   | 0.11924783  |\n",
      "|    n_updates          | 9.38 %      |\n",
      "|    policyGradLoss     | -0.0207     |\n",
      "|    value_loss         | 0.199       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 815         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 50          |\n",
      "|    total_timesteps    | 27041792    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023768181 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0585     |\n",
      "|    mean_step_reward   | 0.12891243  |\n",
      "|    n_updates          | 12.50 %     |\n",
      "|    policyGradLoss     | -0.0173     |\n",
      "|    value_loss         | 0.169       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 808        |\n",
      "|    iterations         | 6          |\n",
      "|    time_elapsed       | 60         |\n",
      "|    total_timesteps    | 27049984   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03069508 |\n",
      "|    entropy_loss       | -1.82      |\n",
      "|    explained_variance | 0.979      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0513    |\n",
      "|    mean_step_reward   | 0.12711945 |\n",
      "|    n_updates          | 15.62 %    |\n",
      "|    policyGradLoss     | -0.0232    |\n",
      "|    value_loss         | 0.141      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 802         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 71          |\n",
      "|    total_timesteps    | 27058176    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028975546 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0519     |\n",
      "|    mean_step_reward   | 0.1205291   |\n",
      "|    n_updates          | 18.75 %     |\n",
      "|    policyGradLoss     | -0.0181     |\n",
      "|    value_loss         | 0.28        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 795         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 82          |\n",
      "|    total_timesteps    | 27066368    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027245421 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0339     |\n",
      "|    mean_step_reward   | 0.1303139   |\n",
      "|    n_updates          | 21.88 %     |\n",
      "|    policyGradLoss     | -0.0198     |\n",
      "|    value_loss         | 0.167       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 792         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 93          |\n",
      "|    total_timesteps    | 27074560    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027700154 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0559     |\n",
      "|    mean_step_reward   | 0.12937199  |\n",
      "|    n_updates          | 25.00 %     |\n",
      "|    policyGradLoss     | -0.0185     |\n",
      "|    value_loss         | 0.204       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 103         |\n",
      "|    total_timesteps    | 27082752    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023105359 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0224     |\n",
      "|    mean_step_reward   | 0.11820458  |\n",
      "|    n_updates          | 28.12 %     |\n",
      "|    policyGradLoss     | -0.0192     |\n",
      "|    value_loss         | 0.214       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 114         |\n",
      "|    total_timesteps    | 27090944    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027231544 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0201     |\n",
      "|    mean_step_reward   | 0.122283764 |\n",
      "|    n_updates          | 31.25 %     |\n",
      "|    policyGradLoss     | -0.0173     |\n",
      "|    value_loss         | 0.234       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 125         |\n",
      "|    total_timesteps    | 27099136    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027361631 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0552     |\n",
      "|    mean_step_reward   | 0.12898529  |\n",
      "|    n_updates          | 34.38 %     |\n",
      "|    policyGradLoss     | -0.0185     |\n",
      "|    value_loss         | 0.194       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 136         |\n",
      "|    total_timesteps    | 27107328    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.031246431 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0335     |\n",
      "|    mean_step_reward   | 0.11772191  |\n",
      "|    n_updates          | 37.50 %     |\n",
      "|    policyGradLoss     | -0.019      |\n",
      "|    value_loss         | 0.175       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 146         |\n",
      "|    total_timesteps    | 27115520    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028321294 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0529     |\n",
      "|    mean_step_reward   | 0.120560646 |\n",
      "|    n_updates          | 40.62 %     |\n",
      "|    policyGradLoss     | -0.0223     |\n",
      "|    value_loss         | 0.144       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 157         |\n",
      "|    total_timesteps    | 27123712    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030028407 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0481      |\n",
      "|    mean_step_reward   | 0.13009617  |\n",
      "|    n_updates          | 43.75 %     |\n",
      "|    policyGradLoss     | -0.0175     |\n",
      "|    value_loss         | 0.233       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 167         |\n",
      "|    total_timesteps    | 27131904    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025431892 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0264     |\n",
      "|    mean_step_reward   | 0.11388087  |\n",
      "|    n_updates          | 46.88 %     |\n",
      "|    policyGradLoss     | -0.0181     |\n",
      "|    value_loss         | 0.235       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 178         |\n",
      "|    total_timesteps    | 27140096    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024412278 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0361     |\n",
      "|    mean_step_reward   | 0.12641785  |\n",
      "|    n_updates          | 50.00 %     |\n",
      "|    policyGradLoss     | -0.0196     |\n",
      "|    value_loss         | 0.278       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 779        |\n",
      "|    iterations         | 18         |\n",
      "|    time_elapsed       | 189        |\n",
      "|    total_timesteps    | 27148288   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02232655 |\n",
      "|    entropy_loss       | -1.83      |\n",
      "|    explained_variance | 0.938      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0206    |\n",
      "|    mean_step_reward   | 0.11223793 |\n",
      "|    n_updates          | 53.12 %    |\n",
      "|    policyGradLoss     | -0.0169    |\n",
      "|    value_loss         | 0.288      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 200         |\n",
      "|    total_timesteps    | 27156480    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030161127 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0615     |\n",
      "|    mean_step_reward   | 0.1346747   |\n",
      "|    n_updates          | 56.25 %     |\n",
      "|    policyGradLoss     | -0.0215     |\n",
      "|    value_loss         | 0.16        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 210         |\n",
      "|    total_timesteps    | 27164672    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026234025 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.949       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0421     |\n",
      "|    mean_step_reward   | 0.11783488  |\n",
      "|    n_updates          | 59.38 %     |\n",
      "|    policyGradLoss     | -0.0185     |\n",
      "|    value_loss         | 0.235       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 775        |\n",
      "|    iterations         | 21         |\n",
      "|    time_elapsed       | 221        |\n",
      "|    total_timesteps    | 27172864   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02870797 |\n",
      "|    entropy_loss       | -1.8       |\n",
      "|    explained_variance | 0.965      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0505    |\n",
      "|    mean_step_reward   | 0.13360956 |\n",
      "|    n_updates          | 62.50 %    |\n",
      "|    policyGradLoss     | -0.0215    |\n",
      "|    value_loss         | 0.212      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 232         |\n",
      "|    total_timesteps    | 27181056    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.032545567 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0555     |\n",
      "|    mean_step_reward   | 0.12936449  |\n",
      "|    n_updates          | 65.62 %     |\n",
      "|    policyGradLoss     | -0.0204     |\n",
      "|    value_loss         | 0.162       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 243         |\n",
      "|    total_timesteps    | 27189248    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022848522 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.048      |\n",
      "|    mean_step_reward   | 0.11435376  |\n",
      "|    n_updates          | 68.75 %     |\n",
      "|    policyGradLoss     | -0.0203     |\n",
      "|    value_loss         | 0.194       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 254         |\n",
      "|    total_timesteps    | 27197440    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025089331 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0502     |\n",
      "|    mean_step_reward   | 0.10958034  |\n",
      "|    n_updates          | 71.88 %     |\n",
      "|    policyGradLoss     | -0.0167     |\n",
      "|    value_loss         | 0.291       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 264         |\n",
      "|    total_timesteps    | 27205632    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020530397 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.949       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0135     |\n",
      "|    mean_step_reward   | 0.12747332  |\n",
      "|    n_updates          | 75.00 %     |\n",
      "|    policyGradLoss     | -0.017      |\n",
      "|    value_loss         | 0.306       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 275         |\n",
      "|    total_timesteps    | 27213824    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024608362 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.046      |\n",
      "|    mean_step_reward   | 0.11377485  |\n",
      "|    n_updates          | 78.12 %     |\n",
      "|    policyGradLoss     | -0.017      |\n",
      "|    value_loss         | 0.22        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 286         |\n",
      "|    total_timesteps    | 27222016    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028351504 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0479     |\n",
      "|    mean_step_reward   | 0.14356874  |\n",
      "|    n_updates          | 81.25 %     |\n",
      "|    policyGradLoss     | -0.0193     |\n",
      "|    value_loss         | 0.145       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 296         |\n",
      "|    total_timesteps    | 27230208    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018748164 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0255     |\n",
      "|    mean_step_reward   | 0.11799714  |\n",
      "|    n_updates          | 84.38 %     |\n",
      "|    policyGradLoss     | -0.0176     |\n",
      "|    value_loss         | 0.184       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 307         |\n",
      "|    total_timesteps    | 27238400    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026438043 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.955       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00609    |\n",
      "|    mean_step_reward   | 0.12554577  |\n",
      "|    n_updates          | 87.50 %     |\n",
      "|    policyGradLoss     | -0.0194     |\n",
      "|    value_loss         | 0.267       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 772        |\n",
      "|    iterations         | 30         |\n",
      "|    time_elapsed       | 317        |\n",
      "|    total_timesteps    | 27246592   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02319468 |\n",
      "|    entropy_loss       | -1.88      |\n",
      "|    explained_variance | 0.95       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0287    |\n",
      "|    mean_step_reward   | 0.10702883 |\n",
      "|    n_updates          | 90.62 %    |\n",
      "|    policyGradLoss     | -0.0182    |\n",
      "|    value_loss         | 0.213      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 328         |\n",
      "|    total_timesteps    | 27254784    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.057259314 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0588     |\n",
      "|    mean_step_reward   | 0.14433554  |\n",
      "|    n_updates          | 93.75 %     |\n",
      "|    policyGradLoss     | -0.0188     |\n",
      "|    value_loss         | 0.179       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 339         |\n",
      "|    total_timesteps    | 27262976    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026744872 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0481     |\n",
      "|    mean_step_reward   | 0.10133178  |\n",
      "|    n_updates          | 96.88 %     |\n",
      "|    policyGradLoss     | -0.0194     |\n",
      "|    value_loss         | 0.235       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Run_103.zip\n",
      "[EVAL] Mean Return: 154.514, Best Return: 161.180\n",
      "Saved video to ./runs_smw/videos/Run/Run_103_154.51.mp4\n",
      "\n",
      "=== Round 105 | Learn 262144 steps (Total trained: 27262976) ===\n",
      "Logging to ./runs_smw/tb/Run_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1158     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 27271168 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 919         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 27279360    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021946821 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0229     |\n",
      "|    mean_step_reward   | 0.11160222  |\n",
      "|    n_updates          | 3.12 %      |\n",
      "|    policyGradLoss     | -0.0199     |\n",
      "|    value_loss         | 0.234       |\n",
      "---------------------------------------\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    while trained < TOTAL_STEPS:\n",
    "        round_idx += 1\n",
    "        chunk = min(TRAIN_CHUNK, TOTAL_STEPS - trained)\n",
    "        # chunk = 2000\n",
    "        label = \"Run\"\n",
    "        tagged_label = f\"{label}_{int(trained/TRAIN_CHUNK)}\"\n",
    "\n",
    "        print(f\"\\n=== Round {round_idx} | Learn {chunk} steps (Total trained: {trained}) ===\")\n",
    "        \n",
    "        # --- Train ---\n",
    "        model.learn(total_timesteps=chunk, reset_num_timesteps=False, tb_log_name=label)\n",
    "        trained += chunk\n",
    "\n",
    "        # --- Save Checkpoint ---\n",
    "        ckpt_path = os.path.join(CKPT_DIR, f\"{tagged_label}.zip\")\n",
    "        model.save(ckpt_path)\n",
    "        print(f\"Saved checkpoint: {ckpt_path}\")\n",
    "\n",
    "        # --- Evaluate ---\n",
    "        mean_ret, best_ret = evaluate_policy(\n",
    "            model,\n",
    "            GAME,\n",
    "            STATE,\n",
    "            n_episodes=EVAL_EPISODES,\n",
    "            max_steps=EVAL_MAX_STEPS,\n",
    "        )\n",
    "        print(f\"[EVAL] Mean Return: {mean_ret:.3f}, Best Return: {best_ret:.3f}\")\n",
    "\n",
    "        # --- Record Video ---\n",
    "        out_path = os.path.join(VIDEO_DIR, label)\n",
    "        os.makedirs(out_path,  exist_ok=True)\n",
    "        record_video(\n",
    "            model,\n",
    "            GAME,\n",
    "            STATE,\n",
    "            VIDEO_DIR,\n",
    "            video_len=RECORD_STEPS,\n",
    "            prefix=f\"{label}/{tagged_label}_{mean_ret:.2f}\",\n",
    "        )\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nTraining interrupted manually.\")\n",
    "\n",
    "finally:\n",
    "    train_env.close()\n",
    "    print(\"Training finished. Environment closed.\")\n",
    "    \n",
    "\"\"\"\n",
    "tensorboard --logdir=./runs_smw/tb\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f088b0b3-2418-4866-b332-0312c9f6467f",
   "metadata": {},
   "source": [
    "## Display Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73191bb-e875-4939-b04c-a4670abd9612",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Video\n",
    "import glob\n",
    "# label = \"Dec22A\"\n",
    "\n",
    "# list_of_files = glob.glob(os.path.join(VIDEO_DIR, label, '*.mp4')) \n",
    "# if list_of_files:\n",
    "#     latest_file = max(list_of_files, key=os.path.getctime)\n",
    "#     print(f\"Playing: {latest_file}\")\n",
    "#     latest_file = \"runs_smw/videos/Dec22A/Dec22A_73_596.54.mp4\"\n",
    "#     print(f\"Playing: {latest_file}\")\n",
    "#     display(Video(latest_file, embed=True, width=768))\n",
    "# else:\n",
    "#     print(\"No videos found yet.\")\n",
    "    \n",
    "video = \"./runs_smw/videos/test_126.mp4\"\n",
    "display(Video(video, embed=True, width=768))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942adf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(\"runs_smw/videos/test_16.mp4\")\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    cv2.imshow(\"Frame-by-Frame\", frame)\n",
    "\n",
    "    # 關鍵：這裡等待按鍵。按 'n' 鍵跳到下一幀，按 'q' 離開\n",
    "    key = cv2.waitKey(0) \n",
    "    if key == ord('q'):\n",
    "        break\n",
    "    elif key == ord('n'):\n",
    "        continue\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1865a364",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "[070] coins: 12 | score: 3540\n",
    "[071] coins: 10 | score: 2260\n",
    "[072] coins: 11 | score: 2760\n",
    "[073] coins:  2 | score:  690\n",
    "[074] coins: 12 | score: 3450\n",
    "[075] coins: 12 | score: 3515\n",
    "[076] coins: 12 | score: 3545\n",
    "[077] coins: 12 | score: 3545\n",
    "[078] coins: 10 | score: 2460\n",
    "[079] coins: 12 | score: 3515\n",
    "[080] coins: 12 | score: 3580\n",
    "[081] coins: 11 | score: 2750\n",
    "[082] coins: 12 | score: 3545\n",
    "[083] coins: 12 | score: 3565\n",
    "[084] coins: 11 | score: 3475\n",
    "[085] coins:  0 | score:    0\n",
    "[086] coins: 12 | score: 3535\n",
    "[087] coins: 12 | score: 3560\n",
    "[088] coins:  9 | score: 1420\n",
    "[089] coins: 11 | score: 3640\n",
    "[090] coins:  1 | score:  380\n",
    "[091] coins: 10 | score: 2440\n",
    "[092] coins: 12 | score: 3570\n",
    "[093] coins: 12 | score: 3490\n",
    "[094] coins: 11 | score: 2745\n",
    "[095] coins: 12 | score: 3565\n",
    "[096] coins:  0 | score:    0\n",
    "[097] coins: 12 | score: 3490\n",
    "[098] coins: 12 | score: 3570\n",
    "[099] coins:  2 | score:  560\n",
    "[100] coins:  2 | score:  660\n",
    "[101] coins: 12 | score: 3580\n",
    "[102] coins:  9 | score: 1420\n",
    "[103] coins: 12 | score: 3575\n",
    "[104] coins: 12 | score: 3585\n",
    "[105] coins: 12 | score: 3580\n",
    "[106] coins: 12 | score: 3525\n",
    "[107] coins:  2 | score:  540\n",
    "[108] coins:  2 | score:  660\n",
    "[109] coins: 10 | score: 2420\n",
    "[110] coins:  1 | score:  140\n",
    "[111] coins: 11 | score: 2680\n",
    "[112] coins:  2 | score:  580\n",
    "[113] coins:  2 | score:  580\n",
    "[114] coins:  2 | score:  560\n",
    "[115] coins: 11 | score: 2765\n",
    "[116] coins:  2 | score:  560\n",
    "[117] coins:  0 | score:    0\n",
    "[118] coins: 12 | score: 3570\n",
    "[119] coins:  1 | score:  340\n",
    "[120] coins: 11 | score: 2735\n",
    "[121] coins: 12 | score: 3570\n",
    "[122] coins: 12 | score: 3515\n",
    "[123] coins: 12 | score: 3580\n",
    "[124] coins: 12 | score: 3585\n",
    "[125] coins: 12 | score: 3560\n",
    "[126] coins: 12 | score: 3595\n",
    "[127] coins: 12 | score: 3515\n",
    "\n",
    "所有測試結束。\n",
    "在 reward 紀錄上，紀錄前10幀的 action 是甚麼，然後檢查\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Lab8 (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
