{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dceedafe-2782-41a1-8119-50ee3d6c21fd",
   "metadata": {},
   "source": [
    "# 2025 DL Lab8: RL Assignment_Super Mario World"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fa555a-e61c-4fb3-b5d0-289b66570139",
   "metadata": {},
   "source": [
    "**Your Answer:**    \n",
    "Hi I'm XXX, XXXXXXXXXX."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5b0974-9605-488a-9fd5-00816e7832cc",
   "metadata": {},
   "source": [
    "## Overview\n",
    "This project implements a **Deep Reinforcement Learning** pipeline to train an autonomous agent for Super Mario World. Leveraging the **Proximal Policy Optimization (PPO)** algorithm, the system interacts with the **stable-retro** environment to master the YoshiIsland1 level. Key components include a custom Vision Backbone for extracting features from raw pixel data and a suite of Environment Wrappers that handle frame preprocessing, action discretization, and reward shaping to facilitate efficient learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02696447",
   "metadata": {},
   "source": [
    "Reward function implement  \n",
    "should do something in the beginning (monster attack)  \n",
    "Custom PPO implement  \n",
    "pre train weight Â∑Æ‰∏çÂ§öÔºå‰∏ªË¶ÅÊòØ reward function  \n",
    "model weight capacity 1GB  \n",
    "class name ‰∏çË¶ÅÂãï (ÂèØ‰ª•Êñ∞Â¢ûÔºå‰ΩÜÊòØÂéüÊú¨ÊúâÁöÑ‰∏çË¶ÅÂãï)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8a0ab9-f86d-4038-833d-761ec81fc4f2",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00b10def-362c-4910-9ed0-f3d0904343ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/m314834001/Lab8/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import retro\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, SubprocVecEnv\n",
    "from stable_baselines3.common.vec_env import VecNormalize\n",
    "\n",
    "from eval import evaluate_policy, record_video\n",
    "from custom_policy import VisionBackbonePolicy, CustomPPO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10361fd-f291-4d93-b50d-cc749a3af588",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b4f6a25-738c-49dd-8e66-ae164b74a45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Game Settings\n",
    "GAME = \"SuperMarioWorld-Snes\"\n",
    "STATE = \"YoshiIsland1\"\n",
    "\n",
    "# Training Settings\n",
    "TOTAL_STEPS = 0x2000000 # 33,554,432\n",
    "# TOTAL_STEPS = 0x0A00000 # 10,485,760\n",
    "# TOTAL_STEPS = 0X3200000 # 52,428,800\n",
    "TRAIN_CHUNK = 0x0040000 #    262,144\n",
    "N_ENVS = 16\n",
    "\n",
    "# Evaluation & Recording Settings\n",
    "EVAL_EPISODES = 3\n",
    "EVAL_MAX_STEPS = 18000\n",
    "RECORD_STEPS = 1200\n",
    "\n",
    "# Directories\n",
    "LOG_DIR = \"./runs_smw\"\n",
    "VIDEO_DIR       = os.path.join(LOG_DIR, \"videos\")\n",
    "CKPT_DIR        = os.path.join(LOG_DIR, \"checkpoints\")\n",
    "TENSORBOARD_LOG = os.path.join(LOG_DIR, \"tb\")\n",
    "\n",
    "os.makedirs(LOG_DIR,   exist_ok=True)\n",
    "os.makedirs(CKPT_DIR,  exist_ok=True)\n",
    "os.makedirs(VIDEO_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a34b783-0273-4835-ad2e-f9186064f76f",
   "metadata": {},
   "source": [
    "## Environment Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c34213d-2c7c-42b8-922d-bafa285d1ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wrappers import make_base_env\n",
    "def _make_env_thunk(game: str, state: str):\n",
    "    \"\"\"Return a function that creates an environment (for multiprocessing).\"\"\"\n",
    "    def _thunk():\n",
    "        return make_base_env(game, state)\n",
    "    return _thunk\n",
    "\n",
    "def make_vec_env(game: str, state: str, n_envs: int, use_subproc: bool = True):\n",
    "    \"\"\"Create a vectorized environment (multiple envs running in parallel).\"\"\"\n",
    "    env_fns = [_make_env_thunk(game, state) for _ in range(n_envs)]\n",
    "    \n",
    "    if use_subproc and n_envs > 1:\n",
    "        vec_env = SubprocVecEnv(env_fns)\n",
    "    else:\n",
    "        vec_env = DummyVecEnv(env_fns)\n",
    "\n",
    "    return vec_env"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71dff476-ea2e-4262-8780-afb32ef1b233",
   "metadata": {},
   "source": [
    "## Initialize Env & Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8c7c5fe-6421-4dbc-9bd8-822d61769c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment created: SuperMarioWorld-Snes - YoshiIsland1 with 16 parallel envs.\n",
      "[Sucess] Loaded model from runs_smw/checkpoints/S2K_33.zip\n",
      "trained: 8912896, round_index: 34\n"
     ]
    }
   ],
   "source": [
    "# 1. Create Training Environment\n",
    "train_env = make_vec_env(GAME, STATE, n_envs=N_ENVS)\n",
    "# train_env = VecNormalize(train_env, norm_obs=True, norm_reward=True, clip_obs=10., clip_reward=10.)\n",
    "print(f\"Environment created: {GAME} - {STATE} with {N_ENVS} parallel envs.\")\n",
    "\n",
    "checkpoint_path = \"None\" # 6225920 (19) ÊúâÁ†¥Â£û\n",
    "checkpoint_path = \"runs_smw/checkpoints/S2K_33.zip\"\n",
    "\n",
    "best_mean = -1e18\n",
    "trained = 0\n",
    "round_idx = 0\n",
    "\n",
    "# 2. Initialize Model\n",
    "if os.path.exists(checkpoint_path):\n",
    "    # ËÆÄÂèñÁèæÊúâÊ®°Âûã\n",
    "    model = CustomPPO.load(\n",
    "        checkpoint_path, \n",
    "        env=train_env,\n",
    "        device=\"cuda:0\" # Á¢∫‰øù‰ΩøÁî® GPU\n",
    "    )\n",
    "    trained = model.num_timesteps\n",
    "    round_idx = int(trained / TRAIN_CHUNK)\n",
    "    print(f\"[Sucess] Loaded model from {checkpoint_path}\")\n",
    "    print(f\"trained: {trained}, round_index: {round_idx}\")\n",
    "else:\n",
    "    print(f\"[Fail] Can't load {checkpoint_path}. Will use new model\")\n",
    "    model = CustomPPO(\n",
    "        VisionBackbonePolicy,\n",
    "        train_env,\n",
    "        policy_kwargs   = dict(normalize_images=False),\n",
    "        n_epochs        = 4,\n",
    "        n_steps         = 512,\n",
    "        batch_size      = 512,\n",
    "        learning_rate   = 1e-4,\n",
    "        verbose         = 1,\n",
    "        gamma           = 0.96875,\n",
    "        kl_coef         = 1,\n",
    "        clip_range      = 0.125,\n",
    "        ent_coef        = 0.0375,\n",
    "        tensorboard_log = TENSORBOARD_LOG,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1cb3d0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(\"policy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7eb7a896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from custom_policy import CustomPPO\n",
    "# from wrappers import make_base_env  # [Êñ∞Â¢û] ÂøÖÈ†àÂºïÂÖ•ÈÄôË°å‰æÜÂª∫Á´ãÁí∞Â¢É\n",
    "\n",
    "# # ================= Ë®≠ÂÆöÂçÄ =================\n",
    "# # Ë´ãÁ¢∫‰øùÈÄô‰∫õËÆäÊï∏ÊúâË¢´ÂÆöÁæ© (ÈÄôË£°Ê≤øÁî®‰Ω†ÂéüÊú¨ÁöÑËÆäÊï∏ÂêçÁ®±)\n",
    "# # GAME = \"SuperMarioWorld-Snes\"\n",
    "# # STATE = \"Level1\" \n",
    "# # CKPT_DIR = \"./\"\n",
    "# # RECORD_STEPS = 2000\n",
    "# PSVD_DIR = \"./runs_smw/preserved/\"\n",
    "\n",
    "# # target_numbers = list(range(159, 180))\n",
    "# target_numbers = [124, 137, 147, 151, 179]\n",
    "\n",
    "# # ================= Âü∑Ë°åËø¥Âúà =================\n",
    "# print(f\"Ê∫ñÂÇôÊ∏¨Ë©¶‰ª•‰∏ã Checkpoints: {target_numbers}\")\n",
    "\n",
    "# for num in target_numbers:\n",
    "#     model_path = os.path.join(PSVD_DIR, f\"Enc5_{num}.zip\")\n",
    "    \n",
    "#     # Ê™¢Êü•Ê™îÊ°àÊòØÂê¶Â≠òÂú®\n",
    "#     if not os.path.exists(model_path):\n",
    "#         print(f\"‚ö†Ô∏è Êâæ‰∏çÂà∞Ê™îÊ°à: {model_path}ÔºåË∑≥ÈÅé„ÄÇ\")\n",
    "#         continue\n",
    "    \n",
    "#     print(f\"\\n[{num}] Ê≠£Âú®ËºâÂÖ•Ê®°Âûã: {model_path} ...\")\n",
    "    \n",
    "#     env = None\n",
    "#     try:\n",
    "#         # 1. ËºâÂÖ•Ê®°Âûã\n",
    "#         model = CustomPPO.load(model_path, device=\"auto\")\n",
    "        \n",
    "#         # 2. Âª∫Á´ãÁí∞Â¢É (ÈÄôÂ∞±ÊòØÂéüÊú¨ record_video Ë£°ÂÅöÁöÑ‰∫ãÔºå‰ΩÜÊàëÂÄëÁèæÂú®Ëá™Â∑±ÂÅö)\n",
    "#         env = make_base_env(game=GAME, state=STATE)\n",
    "        \n",
    "#         print(f\"[{num}] Ê≠£Âú®Âü∑Ë°åÈÅäÊà≤ (‰∏äÈôê {RECORD_STEPS} steps)...\")\n",
    "        \n",
    "#         # 3. ÈñãÂßãË©¶Ë∑ë\n",
    "#         obs, info = env.reset()\n",
    "#         final_score = 0\n",
    "        \n",
    "#         for step in range(RECORD_STEPS):\n",
    "#             # È†êÊ∏¨Âãï‰Ωú\n",
    "#             action, _ = model.predict(obs, deterministic=True)\n",
    "            \n",
    "#             # Âü∑Ë°åÂãï‰Ωú\n",
    "#             obs, reward, terminated, truncated, info = env.step(action)\n",
    "            \n",
    "#             # Êõ¥Êñ∞Áï∂ÂâçÂàÜÊï∏ (Â¶ÇÊûúÊúâ score ÁöÑË©±)\n",
    "#             if \"score\" in info:\n",
    "#                 final_score = info[\"score\"]\n",
    "            \n",
    "#             # Âà§Êñ∑ÊòØÂê¶ÁµêÊùü\n",
    "#             if terminated or truncated:\n",
    "#                 print(f\"   -> ÈÅäÊà≤Âú® step {step} ÁµêÊùü (Terminated/Truncated)\")\n",
    "#                 break\n",
    "        \n",
    "#         # 4. Âç∞Âá∫ÁµêÊûú\n",
    "#         print(f\"üèÜ Checkpoint {num} ÊúÄÁµÇÂàÜÊï∏: {final_score}\")\n",
    "        \n",
    "#     except Exception as e:\n",
    "#         print(f\"‚ùå ÁôºÁîüÈåØË™§ (Model: {num}): {e}\")\n",
    "        \n",
    "#     finally:\n",
    "#         # Á¢∫‰øùÁí∞Â¢ÉË¢´ÈóúÈñâÔºåÈáãÊîæË≥áÊ∫ê\n",
    "#         if env is not None:\n",
    "#             env.close()\n",
    "\n",
    "# print(\"\\nÊâÄÊúâÊ∏¨Ë©¶ÁµêÊùü„ÄÇ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fdfff83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import glob\n",
    "# from custom_policy import CustomPPO\n",
    "# from eval import record_video  # Á¢∫‰øù eval.py Âú®Âêå‰∏ÄÁõÆÈåÑ‰∏ã\n",
    "# PSVD_DIR = \"./runs_smw/preserved/\"\n",
    "# # ================= Ë®≠ÂÆöÂçÄ =================\n",
    "# # target_numbers = list(range(38, 40))\n",
    "# target_numbers = [151, 179]\n",
    "\n",
    "# # ================= Âü∑Ë°åËø¥Âúà =================\n",
    "# print(f\"Ê∫ñÂÇôÊ∏¨Ë©¶‰ª•‰∏ã Checkpoints: {target_numbers}\")\n",
    "\n",
    "# for num in target_numbers:\n",
    "#     model_path = os.path.join(PSVD_DIR, f\"Enc5_{num}.zip\")\n",
    "    \n",
    "#     # Ê™¢Êü•Ê™îÊ°àÊòØÂê¶Â≠òÂú®\n",
    "#     if not os.path.exists(model_path):\n",
    "#         print(f\"‚ö†Ô∏è Êâæ‰∏çÂà∞Ê™îÊ°à: {model_path}ÔºåË∑≥ÈÅé„ÄÇ\")\n",
    "#         continue\n",
    "    \n",
    "#     print(f\"\\n[{num}] Ê≠£Âú®ËºâÂÖ•Ê®°Âûã: {model_path} ...\")\n",
    "    \n",
    "#     try:\n",
    "#         # 1. ËºâÂÖ•Ê®°Âûã (‰∏çÈúÄË¶Å env ÂèÉÊï∏‰πüËÉΩËºâÂÖ•Ê¨äÈáç)\n",
    "#         # Â¶ÇÊûú‰Ω†ÊúâÊîπÈÅé CustomPPO ÁöÑÂèÉÊï∏Ôºåload ÊúÉËá™ÂãïËÆÄÂèñ zip Ë£°ÁöÑË®≠ÂÆö\n",
    "#         model = CustomPPO.load(model_path, device=\"auto\") # device=\"auto\" ÊúÉËá™ÂãïÁî® GPU\n",
    "        \n",
    "#         # 2. ÈåÑË£ΩÂΩ±Áâá\n",
    "#         prefix_name = f\"test_{num}\"\n",
    "#         print(f\"[{num}] Ê≠£Âú®ÈåÑÂΩ± (Èï∑Â∫¶ {RECORD_STEPS} steps)...\")\n",
    "        \n",
    "#         record_video(\n",
    "#             model=model,\n",
    "#             game=GAME,\n",
    "#             state=STATE,\n",
    "#             out_dir=VIDEO_DIR,\n",
    "#             video_len=RECORD_STEPS,\n",
    "#             prefix=prefix_name\n",
    "#         )\n",
    "#         print(f\"‚úÖ ÂÆåÊàêÔºÅÂΩ±ÁâáÂ∑≤ÂÑ≤Â≠òÁÇ∫ {prefix_name}.mp4\")\n",
    "        \n",
    "#     except Exception as e:\n",
    "#         print(f\"‚ùå ÁôºÁîüÈåØË™§ (Model: {num}): {e}\")\n",
    "\n",
    "# print(\"\\nÊâÄÊúâÊ∏¨Ë©¶ÁµêÊùü„ÄÇ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f594e443-843f-42c1-9fc6-3fbc82962021",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3af4932-c531-4113-a33a-defc6fb5858e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Round 35 | Learn 262144 steps (Total trained: 8912896) ===\n",
      "Logging to ./runs_smw/tb/S2K_0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/m314834001/Lab8/.venv/lib/python3.12/site-packages/rich/live.py:256: UserWarning: install \"ipywidgets\" for \n",
       "Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/m314834001/Lab8/.venv/lib/python3.12/site-packages/rich/live.py:256: UserWarning: install \"ipywidgets\" for \n",
       "Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1132    |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 7       |\n",
      "|    total_timesteps | 8921088 |\n",
      "--------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 904         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 8929280     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013487546 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.931       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00932    |\n",
      "|    mean_step_reward   | 0.05772944  |\n",
      "|    n_updates          | 4356        |\n",
      "|    policyGradLoss     | -0.00763    |\n",
      "|    value_loss         | 0.213       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 857         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 8937472     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009466808 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.108       |\n",
      "|    mean_step_reward   | 0.08376444  |\n",
      "|    n_updates          | 4360        |\n",
      "|    policyGradLoss     | -0.00386    |\n",
      "|    value_loss         | 0.308       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 832          |\n",
      "|    iterations         | 4            |\n",
      "|    time_elapsed       | 39           |\n",
      "|    total_timesteps    | 8945664      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0072693257 |\n",
      "|    entropy_loss       | -1.85        |\n",
      "|    explained_variance | 0.944        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.179        |\n",
      "|    mean_step_reward   | 0.09904708   |\n",
      "|    n_updates          | 4364         |\n",
      "|    policyGradLoss     | -0.00101     |\n",
      "|    value_loss         | 0.593        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 818         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 50          |\n",
      "|    total_timesteps    | 8953856     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008729069 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00455     |\n",
      "|    mean_step_reward   | 0.08997855  |\n",
      "|    n_updates          | 4368        |\n",
      "|    policyGradLoss     | -0.0094     |\n",
      "|    value_loss         | 0.311       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 805         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 60          |\n",
      "|    total_timesteps    | 8962048     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008404843 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.942       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0287      |\n",
      "|    mean_step_reward   | 0.08021833  |\n",
      "|    n_updates          | 4372        |\n",
      "|    policyGradLoss     | -0.00909    |\n",
      "|    value_loss         | 0.376       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 798         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 71          |\n",
      "|    total_timesteps    | 8970240     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007859286 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0239      |\n",
      "|    mean_step_reward   | 0.0919825   |\n",
      "|    n_updates          | 4376        |\n",
      "|    policyGradLoss     | -0.00846    |\n",
      "|    value_loss         | 0.28        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 793         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 82          |\n",
      "|    total_timesteps    | 8978432     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010127597 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0228     |\n",
      "|    mean_step_reward   | 0.0692364   |\n",
      "|    n_updates          | 4380        |\n",
      "|    policyGradLoss     | -0.0109     |\n",
      "|    value_loss         | 0.196       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 789         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 93          |\n",
      "|    total_timesteps    | 8986624     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008778851 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0181      |\n",
      "|    mean_step_reward   | 0.07440798  |\n",
      "|    n_updates          | 4384        |\n",
      "|    policyGradLoss     | -0.00754    |\n",
      "|    value_loss         | 0.281       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 104         |\n",
      "|    total_timesteps    | 8994816     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011725932 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.951       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.111       |\n",
      "|    mean_step_reward   | 0.07342352  |\n",
      "|    n_updates          | 4388        |\n",
      "|    policyGradLoss     | -0.00475    |\n",
      "|    value_loss         | 0.333       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 114         |\n",
      "|    total_timesteps    | 9003008     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008627519 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.954       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0145      |\n",
      "|    mean_step_reward   | 0.08729579  |\n",
      "|    n_updates          | 4392        |\n",
      "|    policyGradLoss     | -0.00772    |\n",
      "|    value_loss         | 0.413       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 125         |\n",
      "|    total_timesteps    | 9011200     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009023723 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.146       |\n",
      "|    mean_step_reward   | 0.09928686  |\n",
      "|    n_updates          | 4396        |\n",
      "|    policyGradLoss     | -0.00568    |\n",
      "|    value_loss         | 0.584       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 136         |\n",
      "|    total_timesteps    | 9019392     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014205506 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.952       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00302    |\n",
      "|    mean_step_reward   | 0.06345355  |\n",
      "|    n_updates          | 4400        |\n",
      "|    policyGradLoss     | -0.0083     |\n",
      "|    value_loss         | 0.189       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 146         |\n",
      "|    total_timesteps    | 9027584     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008382537 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.926       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.054       |\n",
      "|    mean_step_reward   | 0.09329583  |\n",
      "|    n_updates          | 4404        |\n",
      "|    policyGradLoss     | -0.00453    |\n",
      "|    value_loss         | 0.623       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 157         |\n",
      "|    total_timesteps    | 9035776     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009299319 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0169      |\n",
      "|    mean_step_reward   | 0.103867516 |\n",
      "|    n_updates          | 4408        |\n",
      "|    policyGradLoss     | -0.0072     |\n",
      "|    value_loss         | 0.332       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 168         |\n",
      "|    total_timesteps    | 9043968     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010173306 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.929       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.154       |\n",
      "|    mean_step_reward   | 0.0851444   |\n",
      "|    n_updates          | 4412        |\n",
      "|    policyGradLoss     | -0.00653    |\n",
      "|    value_loss         | 0.49        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 178         |\n",
      "|    total_timesteps    | 9052160     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009203527 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0163     |\n",
      "|    mean_step_reward   | 0.08010878  |\n",
      "|    n_updates          | 4416        |\n",
      "|    policyGradLoss     | -0.00934    |\n",
      "|    value_loss         | 0.292       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 189         |\n",
      "|    total_timesteps    | 9060352     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009666788 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.917       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0152     |\n",
      "|    mean_step_reward   | 0.0669428   |\n",
      "|    n_updates          | 4420        |\n",
      "|    policyGradLoss     | -0.00558    |\n",
      "|    value_loss         | 0.328       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 776        |\n",
      "|    iterations         | 19         |\n",
      "|    time_elapsed       | 200        |\n",
      "|    total_timesteps    | 9068544    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.0099991  |\n",
      "|    entropy_loss       | -1.83      |\n",
      "|    explained_variance | 0.956      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.034      |\n",
      "|    mean_step_reward   | 0.10705144 |\n",
      "|    n_updates          | 4424       |\n",
      "|    policyGradLoss     | -0.00485   |\n",
      "|    value_loss         | 0.433      |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 776          |\n",
      "|    iterations         | 20           |\n",
      "|    time_elapsed       | 211          |\n",
      "|    total_timesteps    | 9076736      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0084896255 |\n",
      "|    entropy_loss       | -1.82        |\n",
      "|    explained_variance | 0.936        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.122        |\n",
      "|    mean_step_reward   | 0.100175574  |\n",
      "|    n_updates          | 4428         |\n",
      "|    policyGradLoss     | 0.00139      |\n",
      "|    value_loss         | 0.453        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 775          |\n",
      "|    iterations         | 21           |\n",
      "|    time_elapsed       | 221          |\n",
      "|    total_timesteps    | 9084928      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0074792528 |\n",
      "|    entropy_loss       | -1.82        |\n",
      "|    explained_variance | 0.951        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.17         |\n",
      "|    mean_step_reward   | 0.08858268   |\n",
      "|    n_updates          | 4432         |\n",
      "|    policyGradLoss     | -0.00707     |\n",
      "|    value_loss         | 0.537        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 232         |\n",
      "|    total_timesteps    | 9093120     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008740102 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.952       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.07        |\n",
      "|    mean_step_reward   | 0.10875668  |\n",
      "|    n_updates          | 4436        |\n",
      "|    policyGradLoss     | -0.0069     |\n",
      "|    value_loss         | 0.544       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 242         |\n",
      "|    total_timesteps    | 9101312     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009238213 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.928       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0755      |\n",
      "|    mean_step_reward   | 0.07499342  |\n",
      "|    n_updates          | 4440        |\n",
      "|    policyGradLoss     | -0.00543    |\n",
      "|    value_loss         | 0.545       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 253         |\n",
      "|    total_timesteps    | 9109504     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008172977 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.929       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.144       |\n",
      "|    mean_step_reward   | 0.12282757  |\n",
      "|    n_updates          | 4444        |\n",
      "|    policyGradLoss     | -0.003      |\n",
      "|    value_loss         | 0.753       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 264         |\n",
      "|    total_timesteps    | 9117696     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009397384 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0852      |\n",
      "|    mean_step_reward   | 0.082159914 |\n",
      "|    n_updates          | 4448        |\n",
      "|    policyGradLoss     | -0.00765    |\n",
      "|    value_loss         | 0.348       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 275         |\n",
      "|    total_timesteps    | 9125888     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009494475 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0622      |\n",
      "|    mean_step_reward   | 0.11654246  |\n",
      "|    n_updates          | 4452        |\n",
      "|    policyGradLoss     | -0.0061     |\n",
      "|    value_loss         | 0.462       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 774          |\n",
      "|    iterations         | 27           |\n",
      "|    time_elapsed       | 285          |\n",
      "|    total_timesteps    | 9134080      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0089493245 |\n",
      "|    entropy_loss       | -1.83        |\n",
      "|    explained_variance | 0.97         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0876       |\n",
      "|    mean_step_reward   | 0.088200815  |\n",
      "|    n_updates          | 4456         |\n",
      "|    policyGradLoss     | -0.00951     |\n",
      "|    value_loss         | 0.327        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 774          |\n",
      "|    iterations         | 28           |\n",
      "|    time_elapsed       | 296          |\n",
      "|    total_timesteps    | 9142272      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0146848075 |\n",
      "|    entropy_loss       | -1.84        |\n",
      "|    explained_variance | 0.979        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.00524     |\n",
      "|    mean_step_reward   | 0.08705561   |\n",
      "|    n_updates          | 4460         |\n",
      "|    policyGradLoss     | -0.012       |\n",
      "|    value_loss         | 0.216        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 306         |\n",
      "|    total_timesteps    | 9150464     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008368259 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0485      |\n",
      "|    mean_step_reward   | 0.10077212  |\n",
      "|    n_updates          | 4464        |\n",
      "|    policyGradLoss     | -0.0102     |\n",
      "|    value_loss         | 0.371       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 773          |\n",
      "|    iterations         | 30           |\n",
      "|    time_elapsed       | 317          |\n",
      "|    total_timesteps    | 9158656      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0107391365 |\n",
      "|    entropy_loss       | -1.83        |\n",
      "|    explained_variance | 0.981        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0113      |\n",
      "|    mean_step_reward   | 0.101009585  |\n",
      "|    n_updates          | 4468         |\n",
      "|    policyGradLoss     | -0.0101      |\n",
      "|    value_loss         | 0.228        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 328         |\n",
      "|    total_timesteps    | 9166848     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008991639 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00638     |\n",
      "|    mean_step_reward   | 0.10073179  |\n",
      "|    n_updates          | 4472        |\n",
      "|    policyGradLoss     | -0.01       |\n",
      "|    value_loss         | 0.218       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 338         |\n",
      "|    total_timesteps    | 9175040     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010438258 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.943       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0562      |\n",
      "|    mean_step_reward   | 0.089656614 |\n",
      "|    n_updates          | 4476        |\n",
      "|    policyGradLoss     | -0.00575    |\n",
      "|    value_loss         | 0.334       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/S2K_34.zip\n",
      "[EVAL] Mean Return: 124.114, Best Return: 128.114\n",
      "Saved video to ./runs_smw/videos/S2K/S2K_34_124.11.mp4\n",
      "\n",
      "=== Round 36 | Learn 262144 steps (Total trained: 9175040) ===\n",
      "Logging to ./runs_smw/tb/S2K_0\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1137    |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 7       |\n",
      "|    total_timesteps | 9183232 |\n",
      "--------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 921         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 9191424     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009814275 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.939       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.011      |\n",
      "|    mean_step_reward   | 0.07428531  |\n",
      "|    n_updates          | 4484        |\n",
      "|    policyGradLoss     | -0.00689    |\n",
      "|    value_loss         | 0.308       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 863         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 9199616     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011528562 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00762     |\n",
      "|    mean_step_reward   | 0.13423763  |\n",
      "|    n_updates          | 4488        |\n",
      "|    policyGradLoss     | -0.00368    |\n",
      "|    value_loss         | 0.433       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 838        |\n",
      "|    iterations         | 4          |\n",
      "|    time_elapsed       | 39         |\n",
      "|    total_timesteps    | 9207808    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01754659 |\n",
      "|    entropy_loss       | -1.84      |\n",
      "|    explained_variance | 0.976      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.00234    |\n",
      "|    mean_step_reward   | 0.06563811 |\n",
      "|    n_updates          | 4492       |\n",
      "|    policyGradLoss     | -0.00929   |\n",
      "|    value_loss         | 0.2        |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 828          |\n",
      "|    iterations         | 5            |\n",
      "|    time_elapsed       | 49           |\n",
      "|    total_timesteps    | 9216000      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0095803505 |\n",
      "|    entropy_loss       | -1.79        |\n",
      "|    explained_variance | 0.977        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0799       |\n",
      "|    mean_step_reward   | 0.14267379   |\n",
      "|    n_updates          | 4496         |\n",
      "|    policyGradLoss     | -0.00281     |\n",
      "|    value_loss         | 0.5          |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 819         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 59          |\n",
      "|    total_timesteps    | 9224192     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013109811 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00396     |\n",
      "|    mean_step_reward   | 0.09329806  |\n",
      "|    n_updates          | 4500        |\n",
      "|    policyGradLoss     | -0.00764    |\n",
      "|    value_loss         | 0.311       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 809         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 70          |\n",
      "|    total_timesteps    | 9232384     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009553537 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.943       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0557      |\n",
      "|    mean_step_reward   | 0.08928644  |\n",
      "|    n_updates          | 4504        |\n",
      "|    policyGradLoss     | -0.00618    |\n",
      "|    value_loss         | 0.439       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 804         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 81          |\n",
      "|    total_timesteps    | 9240576     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008522375 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.128       |\n",
      "|    mean_step_reward   | 0.1342921   |\n",
      "|    n_updates          | 4508        |\n",
      "|    policyGradLoss     | -0.00409    |\n",
      "|    value_loss         | 0.593       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 798         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 92          |\n",
      "|    total_timesteps    | 9248768     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011979091 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.918       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00362     |\n",
      "|    mean_step_reward   | 0.06087607  |\n",
      "|    n_updates          | 4512        |\n",
      "|    policyGradLoss     | -0.0028     |\n",
      "|    value_loss         | 0.4         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 795         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 102         |\n",
      "|    total_timesteps    | 9256960     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009125702 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00994    |\n",
      "|    mean_step_reward   | 0.0741081   |\n",
      "|    n_updates          | 4516        |\n",
      "|    policyGradLoss     | -0.00737    |\n",
      "|    value_loss         | 0.248       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 793         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 113         |\n",
      "|    total_timesteps    | 9265152     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018292308 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0406     |\n",
      "|    mean_step_reward   | 0.06305543  |\n",
      "|    n_updates          | 4520        |\n",
      "|    policyGradLoss     | -0.00943    |\n",
      "|    value_loss         | 0.128       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 792         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 123         |\n",
      "|    total_timesteps    | 9273344     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011689382 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.16        |\n",
      "|    mean_step_reward   | 0.13713929  |\n",
      "|    n_updates          | 4524        |\n",
      "|    policyGradLoss     | -0.00151    |\n",
      "|    value_loss         | 0.578       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 789         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 134         |\n",
      "|    total_timesteps    | 9281536     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014727261 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.946       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.251       |\n",
      "|    mean_step_reward   | 0.07108894  |\n",
      "|    n_updates          | 4528        |\n",
      "|    policyGradLoss     | -0.00733    |\n",
      "|    value_loss         | 0.442       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 788         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 145         |\n",
      "|    total_timesteps    | 9289728     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008857067 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.95        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.266       |\n",
      "|    mean_step_reward   | 0.1417831   |\n",
      "|    n_updates          | 4532        |\n",
      "|    policyGradLoss     | -0.00395    |\n",
      "|    value_loss         | 0.774       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 156         |\n",
      "|    total_timesteps    | 9297920     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015306381 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0215      |\n",
      "|    mean_step_reward   | 0.069977    |\n",
      "|    n_updates          | 4536        |\n",
      "|    policyGradLoss     | -0.00869    |\n",
      "|    value_loss         | 0.202       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 166         |\n",
      "|    total_timesteps    | 9306112     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009715174 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.135       |\n",
      "|    mean_step_reward   | 0.11563016  |\n",
      "|    n_updates          | 4540        |\n",
      "|    policyGradLoss     | -0.00352    |\n",
      "|    value_loss         | 0.487       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 177         |\n",
      "|    total_timesteps    | 9314304     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010649434 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.921       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00728     |\n",
      "|    mean_step_reward   | 0.060714092 |\n",
      "|    n_updates          | 4544        |\n",
      "|    policyGradLoss     | -0.004      |\n",
      "|    value_loss         | 0.323       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 188         |\n",
      "|    total_timesteps    | 9322496     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009293431 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0504      |\n",
      "|    mean_step_reward   | 0.13802658  |\n",
      "|    n_updates          | 4548        |\n",
      "|    policyGradLoss     | -0.00419    |\n",
      "|    value_loss         | 0.48        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 198         |\n",
      "|    total_timesteps    | 9330688     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009912981 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0471      |\n",
      "|    mean_step_reward   | 0.099702835 |\n",
      "|    n_updates          | 4552        |\n",
      "|    policyGradLoss     | -0.00392    |\n",
      "|    value_loss         | 0.405       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 209         |\n",
      "|    total_timesteps    | 9338880     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013670346 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0156      |\n",
      "|    mean_step_reward   | 0.079184    |\n",
      "|    n_updates          | 4556        |\n",
      "|    policyGradLoss     | -0.00988    |\n",
      "|    value_loss         | 0.27        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 220         |\n",
      "|    total_timesteps    | 9347072     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008008328 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0861      |\n",
      "|    mean_step_reward   | 0.114985965 |\n",
      "|    n_updates          | 4560        |\n",
      "|    policyGradLoss     | -0.00236    |\n",
      "|    value_loss         | 0.559       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 230         |\n",
      "|    total_timesteps    | 9355264     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011656818 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00335    |\n",
      "|    mean_step_reward   | 0.09621695  |\n",
      "|    n_updates          | 4564        |\n",
      "|    policyGradLoss     | -0.00827    |\n",
      "|    value_loss         | 0.315       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 240         |\n",
      "|    total_timesteps    | 9363456     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009784198 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00151    |\n",
      "|    mean_step_reward   | 0.08535789  |\n",
      "|    n_updates          | 4568        |\n",
      "|    policyGradLoss     | -0.00933    |\n",
      "|    value_loss         | 0.32        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 251         |\n",
      "|    total_timesteps    | 9371648     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010950241 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0964      |\n",
      "|    mean_step_reward   | 0.16053887  |\n",
      "|    n_updates          | 4572        |\n",
      "|    policyGradLoss     | -0.00136    |\n",
      "|    value_loss         | 0.562       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 262         |\n",
      "|    total_timesteps    | 9379840     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01290176  |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0917      |\n",
      "|    mean_step_reward   | 0.080641866 |\n",
      "|    n_updates          | 4576        |\n",
      "|    policyGradLoss     | -0.00786    |\n",
      "|    value_loss         | 0.259       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 272         |\n",
      "|    total_timesteps    | 9388032     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011297556 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0312      |\n",
      "|    mean_step_reward   | 0.11283266  |\n",
      "|    n_updates          | 4580        |\n",
      "|    policyGradLoss     | -0.006      |\n",
      "|    value_loss         | 0.366       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 780          |\n",
      "|    iterations         | 27           |\n",
      "|    time_elapsed       | 283          |\n",
      "|    total_timesteps    | 9396224      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0087505225 |\n",
      "|    entropy_loss       | -1.79        |\n",
      "|    explained_variance | 0.969        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0582       |\n",
      "|    mean_step_reward   | 0.09521167   |\n",
      "|    n_updates          | 4584         |\n",
      "|    policyGradLoss     | -0.0103      |\n",
      "|    value_loss         | 0.308        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 293         |\n",
      "|    total_timesteps    | 9404416     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009087292 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.958       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0147      |\n",
      "|    mean_step_reward   | 0.105170436 |\n",
      "|    n_updates          | 4588        |\n",
      "|    policyGradLoss     | -0.00809    |\n",
      "|    value_loss         | 0.428       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 304         |\n",
      "|    total_timesteps    | 9412608     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011486549 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.955       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0323      |\n",
      "|    mean_step_reward   | 0.113511585 |\n",
      "|    n_updates          | 4592        |\n",
      "|    policyGradLoss     | -0.0058     |\n",
      "|    value_loss         | 0.459       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 315         |\n",
      "|    total_timesteps    | 9420800     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016647628 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0386     |\n",
      "|    mean_step_reward   | 0.059326813 |\n",
      "|    n_updates          | 4596        |\n",
      "|    policyGradLoss     | -0.0122     |\n",
      "|    value_loss         | 0.143       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 325         |\n",
      "|    total_timesteps    | 9428992     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010501778 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0251      |\n",
      "|    mean_step_reward   | 0.12995811  |\n",
      "|    n_updates          | 4600        |\n",
      "|    policyGradLoss     | -0.00437    |\n",
      "|    value_loss         | 0.375       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 336         |\n",
      "|    total_timesteps    | 9437184     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017880235 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0193     |\n",
      "|    mean_step_reward   | 0.053717017 |\n",
      "|    n_updates          | 4604        |\n",
      "|    policyGradLoss     | -0.00665    |\n",
      "|    value_loss         | 0.162       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/S2K_35.zip\n",
      "[EVAL] Mean Return: -63.825, Best Return: -62.491\n",
      "Saved video to ./runs_smw/videos/S2K/S2K_35_-63.82.mp4\n",
      "\n",
      "=== Round 37 | Learn 262144 steps (Total trained: 9437184) ===\n",
      "Logging to ./runs_smw/tb/S2K_0\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1120    |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 7       |\n",
      "|    total_timesteps | 9445376 |\n",
      "--------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 907         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 9453568     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013729871 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0309     |\n",
      "|    mean_step_reward   | 0.06655155  |\n",
      "|    n_updates          | 4612        |\n",
      "|    policyGradLoss     | -0.00805    |\n",
      "|    value_loss         | 0.2         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 854         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 9461760     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009982994 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.936       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.151       |\n",
      "|    mean_step_reward   | 0.10778269  |\n",
      "|    n_updates          | 4616        |\n",
      "|    policyGradLoss     | -0.000938   |\n",
      "|    value_loss         | 0.772       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 833         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 9469952     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013133249 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0161      |\n",
      "|    mean_step_reward   | 0.075457744 |\n",
      "|    n_updates          | 4620        |\n",
      "|    policyGradLoss     | -0.00627    |\n",
      "|    value_loss         | 0.213       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 820        |\n",
      "|    iterations         | 5          |\n",
      "|    time_elapsed       | 49         |\n",
      "|    total_timesteps    | 9478144    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01050259 |\n",
      "|    entropy_loss       | -1.75      |\n",
      "|    explained_variance | 0.966      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.113      |\n",
      "|    mean_step_reward   | 0.14829373 |\n",
      "|    n_updates          | 4624       |\n",
      "|    policyGradLoss     | -0.000216  |\n",
      "|    value_loss         | 0.541      |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 810          |\n",
      "|    iterations         | 6            |\n",
      "|    time_elapsed       | 60           |\n",
      "|    total_timesteps    | 9486336      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0140523035 |\n",
      "|    entropy_loss       | -1.8         |\n",
      "|    explained_variance | 0.977        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0302      |\n",
      "|    mean_step_reward   | 0.08871642   |\n",
      "|    n_updates          | 4628         |\n",
      "|    policyGradLoss     | -0.0106      |\n",
      "|    value_loss         | 0.161        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 807         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 71          |\n",
      "|    total_timesteps    | 9494528     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009944977 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0326      |\n",
      "|    mean_step_reward   | 0.1004906   |\n",
      "|    n_updates          | 4632        |\n",
      "|    policyGradLoss     | -0.00359    |\n",
      "|    value_loss         | 0.336       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 804         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 81          |\n",
      "|    total_timesteps    | 9502720     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009511037 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0276      |\n",
      "|    mean_step_reward   | 0.10898704  |\n",
      "|    n_updates          | 4636        |\n",
      "|    policyGradLoss     | -0.0101     |\n",
      "|    value_loss         | 0.249       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 800         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 92          |\n",
      "|    total_timesteps    | 9510912     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008692941 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0287      |\n",
      "|    mean_step_reward   | 0.12864065  |\n",
      "|    n_updates          | 4640        |\n",
      "|    policyGradLoss     | -0.00695    |\n",
      "|    value_loss         | 0.296       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 798         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 102         |\n",
      "|    total_timesteps    | 9519104     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01153646  |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0331     |\n",
      "|    mean_step_reward   | 0.077626735 |\n",
      "|    n_updates          | 4644        |\n",
      "|    policyGradLoss     | -0.0098     |\n",
      "|    value_loss         | 0.175       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 795         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 113         |\n",
      "|    total_timesteps    | 9527296     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010798906 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0205      |\n",
      "|    mean_step_reward   | 0.11201365  |\n",
      "|    n_updates          | 4648        |\n",
      "|    policyGradLoss     | -0.0109     |\n",
      "|    value_loss         | 0.224       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 793         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 123         |\n",
      "|    total_timesteps    | 9535488     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008011678 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.937       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.138       |\n",
      "|    mean_step_reward   | 0.10154277  |\n",
      "|    n_updates          | 4652        |\n",
      "|    policyGradLoss     | -0.00412    |\n",
      "|    value_loss         | 0.594       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 789         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 134         |\n",
      "|    total_timesteps    | 9543680     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011448094 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.936       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.171       |\n",
      "|    mean_step_reward   | 0.118959345 |\n",
      "|    n_updates          | 4656        |\n",
      "|    policyGradLoss     | 0.00102     |\n",
      "|    value_loss         | 0.444       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 788          |\n",
      "|    iterations         | 14           |\n",
      "|    time_elapsed       | 145          |\n",
      "|    total_timesteps    | 9551872      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0095124245 |\n",
      "|    entropy_loss       | -1.75        |\n",
      "|    explained_variance | 0.97         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.000841     |\n",
      "|    mean_step_reward   | 0.085621476  |\n",
      "|    n_updates          | 4660         |\n",
      "|    policyGradLoss     | -0.00609     |\n",
      "|    value_loss         | 0.31         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 156         |\n",
      "|    total_timesteps    | 9560064     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008127685 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.954       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0688      |\n",
      "|    mean_step_reward   | 0.1394729   |\n",
      "|    n_updates          | 4664        |\n",
      "|    policyGradLoss     | -0.00179    |\n",
      "|    value_loss         | 0.668       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 167         |\n",
      "|    total_timesteps    | 9568256     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013031287 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0695      |\n",
      "|    mean_step_reward   | 0.07854171  |\n",
      "|    n_updates          | 4668        |\n",
      "|    policyGradLoss     | -0.00367    |\n",
      "|    value_loss         | 0.393       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 177         |\n",
      "|    total_timesteps    | 9576448     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009859862 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.168       |\n",
      "|    mean_step_reward   | 0.13258594  |\n",
      "|    n_updates          | 4672        |\n",
      "|    policyGradLoss     | -0.00412    |\n",
      "|    value_loss         | 0.537       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 188         |\n",
      "|    total_timesteps    | 9584640     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010709721 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.936       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.155       |\n",
      "|    mean_step_reward   | 0.085790515 |\n",
      "|    n_updates          | 4676        |\n",
      "|    policyGradLoss     | -0.00873    |\n",
      "|    value_loss         | 0.382       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 198         |\n",
      "|    total_timesteps    | 9592832     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011241994 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0775      |\n",
      "|    mean_step_reward   | 0.13074699  |\n",
      "|    n_updates          | 4680        |\n",
      "|    policyGradLoss     | -0.000331   |\n",
      "|    value_loss         | 0.398       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 209         |\n",
      "|    total_timesteps    | 9601024     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.006143648 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.907       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.127       |\n",
      "|    mean_step_reward   | 0.08475982  |\n",
      "|    n_updates          | 4684        |\n",
      "|    policyGradLoss     | -0.00337    |\n",
      "|    value_loss         | 0.526       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 220         |\n",
      "|    total_timesteps    | 9609216     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008082723 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.958       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.119       |\n",
      "|    mean_step_reward   | 0.11966937  |\n",
      "|    n_updates          | 4688        |\n",
      "|    policyGradLoss     | -0.00381    |\n",
      "|    value_loss         | 0.483       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 230         |\n",
      "|    total_timesteps    | 9617408     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007915905 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.933       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.146       |\n",
      "|    mean_step_reward   | 0.10871583  |\n",
      "|    n_updates          | 4692        |\n",
      "|    policyGradLoss     | -0.00345    |\n",
      "|    value_loss         | 0.687       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 781          |\n",
      "|    iterations         | 23           |\n",
      "|    time_elapsed       | 241          |\n",
      "|    total_timesteps    | 9625600      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0072164275 |\n",
      "|    entropy_loss       | -1.77        |\n",
      "|    explained_variance | 0.962        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0518       |\n",
      "|    mean_step_reward   | 0.09263456   |\n",
      "|    n_updates          | 4696         |\n",
      "|    policyGradLoss     | -0.00672     |\n",
      "|    value_loss         | 0.378        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 251         |\n",
      "|    total_timesteps    | 9633792     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008867456 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0176      |\n",
      "|    mean_step_reward   | 0.107838765 |\n",
      "|    n_updates          | 4700        |\n",
      "|    policyGradLoss     | -0.00879    |\n",
      "|    value_loss         | 0.291       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 262         |\n",
      "|    total_timesteps    | 9641984     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009506827 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00937     |\n",
      "|    mean_step_reward   | 0.10502084  |\n",
      "|    n_updates          | 4704        |\n",
      "|    policyGradLoss     | -0.00871    |\n",
      "|    value_loss         | 0.274       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 273         |\n",
      "|    total_timesteps    | 9650176     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010726122 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00163     |\n",
      "|    mean_step_reward   | 0.08170173  |\n",
      "|    n_updates          | 4708        |\n",
      "|    policyGradLoss     | -0.00811    |\n",
      "|    value_loss         | 0.21        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 780        |\n",
      "|    iterations         | 27         |\n",
      "|    time_elapsed       | 283        |\n",
      "|    total_timesteps    | 9658368    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.0116255  |\n",
      "|    entropy_loss       | -1.77      |\n",
      "|    explained_variance | 0.973      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.00326   |\n",
      "|    mean_step_reward   | 0.11636647 |\n",
      "|    n_updates          | 4712       |\n",
      "|    policyGradLoss     | -0.00253   |\n",
      "|    value_loss         | 0.3        |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 294         |\n",
      "|    total_timesteps    | 9666560     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010277422 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.944       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.136       |\n",
      "|    mean_step_reward   | 0.098007366 |\n",
      "|    n_updates          | 4716        |\n",
      "|    policyGradLoss     | -0.00379    |\n",
      "|    value_loss         | 0.661       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 779        |\n",
      "|    iterations         | 29         |\n",
      "|    time_elapsed       | 304        |\n",
      "|    total_timesteps    | 9674752    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.00783373 |\n",
      "|    entropy_loss       | -1.77      |\n",
      "|    explained_variance | 0.959      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.0265     |\n",
      "|    mean_step_reward   | 0.10812723 |\n",
      "|    n_updates          | 4720       |\n",
      "|    policyGradLoss     | -0.00427   |\n",
      "|    value_loss         | 0.373      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 315         |\n",
      "|    total_timesteps    | 9682944     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009836255 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0112      |\n",
      "|    mean_step_reward   | 0.087596074 |\n",
      "|    n_updates          | 4724        |\n",
      "|    policyGradLoss     | -0.00509    |\n",
      "|    value_loss         | 0.287       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 326         |\n",
      "|    total_timesteps    | 9691136     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013223683 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0362     |\n",
      "|    mean_step_reward   | 0.09819929  |\n",
      "|    n_updates          | 4728        |\n",
      "|    policyGradLoss     | -0.0134     |\n",
      "|    value_loss         | 0.141       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 337         |\n",
      "|    total_timesteps    | 9699328     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010291651 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.106       |\n",
      "|    mean_step_reward   | 0.1310046   |\n",
      "|    n_updates          | 4732        |\n",
      "|    policyGradLoss     | -0.00411    |\n",
      "|    value_loss         | 0.632       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/S2K_36.zip\n",
      "[EVAL] Mean Return: 129.722, Best Return: 134.389\n",
      "Saved video to ./runs_smw/videos/S2K/S2K_36_129.72.mp4\n",
      "\n",
      "=== Round 38 | Learn 262144 steps (Total trained: 9699328) ===\n",
      "Logging to ./runs_smw/tb/S2K_0\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1153    |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 7       |\n",
      "|    total_timesteps | 9707520 |\n",
      "--------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 921         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 9715712     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008516283 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.936       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.11        |\n",
      "|    mean_step_reward   | 0.092547655 |\n",
      "|    n_updates          | 4740        |\n",
      "|    policyGradLoss     | -0.000553   |\n",
      "|    value_loss         | 0.485       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 861         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 9723904     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.005805199 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.927       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.156       |\n",
      "|    mean_step_reward   | 0.123199075 |\n",
      "|    n_updates          | 4744        |\n",
      "|    policyGradLoss     | -0.00406    |\n",
      "|    value_loss         | 1.05        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 836         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 9732096     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010590276 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0102      |\n",
      "|    mean_step_reward   | 0.08729336  |\n",
      "|    n_updates          | 4748        |\n",
      "|    policyGradLoss     | -0.00582    |\n",
      "|    value_loss         | 0.259       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 822          |\n",
      "|    iterations         | 5            |\n",
      "|    time_elapsed       | 49           |\n",
      "|    total_timesteps    | 9740288      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0050414344 |\n",
      "|    entropy_loss       | -1.77        |\n",
      "|    explained_variance | 0.957        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.209        |\n",
      "|    mean_step_reward   | 0.12215096   |\n",
      "|    n_updates          | 4752         |\n",
      "|    policyGradLoss     | -0.00334     |\n",
      "|    value_loss         | 0.567        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 810         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 60          |\n",
      "|    total_timesteps    | 9748480     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010752859 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0383      |\n",
      "|    mean_step_reward   | 0.09670074  |\n",
      "|    n_updates          | 4756        |\n",
      "|    policyGradLoss     | -0.00953    |\n",
      "|    value_loss         | 0.246       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 803         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 71          |\n",
      "|    total_timesteps    | 9756672     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012565393 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0267     |\n",
      "|    mean_step_reward   | 0.11861101  |\n",
      "|    n_updates          | 4760        |\n",
      "|    policyGradLoss     | -0.00972    |\n",
      "|    value_loss         | 0.215       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 798         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 82          |\n",
      "|    total_timesteps    | 9764864     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.006958505 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.867       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.306       |\n",
      "|    mean_step_reward   | 0.1025558   |\n",
      "|    n_updates          | 4764        |\n",
      "|    policyGradLoss     | -0.000877   |\n",
      "|    value_loss         | 0.906       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 795          |\n",
      "|    iterations         | 9            |\n",
      "|    time_elapsed       | 92           |\n",
      "|    total_timesteps    | 9773056      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0073038237 |\n",
      "|    entropy_loss       | -1.77        |\n",
      "|    explained_variance | 0.937        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0744       |\n",
      "|    mean_step_reward   | 0.07214249   |\n",
      "|    n_updates          | 4768         |\n",
      "|    policyGradLoss     | 0.00082      |\n",
      "|    value_loss         | 0.35         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 793         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 103         |\n",
      "|    total_timesteps    | 9781248     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007448528 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.922       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.444       |\n",
      "|    mean_step_reward   | 0.13472599  |\n",
      "|    n_updates          | 4772        |\n",
      "|    policyGradLoss     | 0.00153     |\n",
      "|    value_loss         | 0.87        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 790         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 114         |\n",
      "|    total_timesteps    | 9789440     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010986288 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0635      |\n",
      "|    mean_step_reward   | 0.13452637  |\n",
      "|    n_updates          | 4776        |\n",
      "|    policyGradLoss     | -0.00728    |\n",
      "|    value_loss         | 0.416       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 788         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 124         |\n",
      "|    total_timesteps    | 9797632     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014348635 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0267     |\n",
      "|    mean_step_reward   | 0.084714994 |\n",
      "|    n_updates          | 4780        |\n",
      "|    policyGradLoss     | -0.0117     |\n",
      "|    value_loss         | 0.186       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 135         |\n",
      "|    total_timesteps    | 9805824     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010882167 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0205     |\n",
      "|    mean_step_reward   | 0.10324626  |\n",
      "|    n_updates          | 4784        |\n",
      "|    policyGradLoss     | -0.00718    |\n",
      "|    value_loss         | 0.229       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 145         |\n",
      "|    total_timesteps    | 9814016     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010447579 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00535     |\n",
      "|    mean_step_reward   | 0.1331309   |\n",
      "|    n_updates          | 4788        |\n",
      "|    policyGradLoss     | -0.00742    |\n",
      "|    value_loss         | 0.213       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 156         |\n",
      "|    total_timesteps    | 9822208     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.0195849   |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0113      |\n",
      "|    mean_step_reward   | 0.069191515 |\n",
      "|    n_updates          | 4792        |\n",
      "|    policyGradLoss     | -0.0107     |\n",
      "|    value_loss         | 0.172       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 167         |\n",
      "|    total_timesteps    | 9830400     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011542765 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.029       |\n",
      "|    mean_step_reward   | 0.113729    |\n",
      "|    n_updates          | 4796        |\n",
      "|    policyGradLoss     | -0.0092     |\n",
      "|    value_loss         | 0.273       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 178         |\n",
      "|    total_timesteps    | 9838592     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009113281 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0359      |\n",
      "|    mean_step_reward   | 0.09727789  |\n",
      "|    n_updates          | 4800        |\n",
      "|    policyGradLoss     | -0.0112     |\n",
      "|    value_loss         | 0.232       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 189         |\n",
      "|    total_timesteps    | 9846784     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009024683 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.942       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.118       |\n",
      "|    mean_step_reward   | 0.09261243  |\n",
      "|    n_updates          | 4804        |\n",
      "|    policyGradLoss     | -0.00451    |\n",
      "|    value_loss         | 0.537       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 199         |\n",
      "|    total_timesteps    | 9854976     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010536803 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.952       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0581      |\n",
      "|    mean_step_reward   | 0.11234239  |\n",
      "|    n_updates          | 4808        |\n",
      "|    policyGradLoss     | -0.00334    |\n",
      "|    value_loss         | 0.365       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 210         |\n",
      "|    total_timesteps    | 9863168     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011755384 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00254    |\n",
      "|    mean_step_reward   | 0.09348584  |\n",
      "|    n_updates          | 4812        |\n",
      "|    policyGradLoss     | -0.0102     |\n",
      "|    value_loss         | 0.211       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 220         |\n",
      "|    total_timesteps    | 9871360     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010839967 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.945       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.147       |\n",
      "|    mean_step_reward   | 0.07893945  |\n",
      "|    n_updates          | 4816        |\n",
      "|    policyGradLoss     | -0.0072     |\n",
      "|    value_loss         | 0.406       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 231         |\n",
      "|    total_timesteps    | 9879552     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011465747 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0215     |\n",
      "|    mean_step_reward   | 0.11912271  |\n",
      "|    n_updates          | 4820        |\n",
      "|    policyGradLoss     | -0.0106     |\n",
      "|    value_loss         | 0.196       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 242         |\n",
      "|    total_timesteps    | 9887744     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012081311 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0287     |\n",
      "|    mean_step_reward   | 0.06504937  |\n",
      "|    n_updates          | 4824        |\n",
      "|    policyGradLoss     | -0.0107     |\n",
      "|    value_loss         | 0.181       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 252         |\n",
      "|    total_timesteps    | 9895936     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010235801 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.176       |\n",
      "|    mean_step_reward   | 0.12786989  |\n",
      "|    n_updates          | 4828        |\n",
      "|    policyGradLoss     | -0.00234    |\n",
      "|    value_loss         | 0.553       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 263         |\n",
      "|    total_timesteps    | 9904128     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012382209 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0112      |\n",
      "|    mean_step_reward   | 0.11020536  |\n",
      "|    n_updates          | 4832        |\n",
      "|    policyGradLoss     | -0.00825    |\n",
      "|    value_loss         | 0.269       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 273         |\n",
      "|    total_timesteps    | 9912320     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011132639 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0466      |\n",
      "|    mean_step_reward   | 0.07748889  |\n",
      "|    n_updates          | 4836        |\n",
      "|    policyGradLoss     | -0.00506    |\n",
      "|    value_loss         | 0.281       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 778          |\n",
      "|    iterations         | 27           |\n",
      "|    time_elapsed       | 284          |\n",
      "|    total_timesteps    | 9920512      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0065747956 |\n",
      "|    entropy_loss       | -1.74        |\n",
      "|    explained_variance | 0.952        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0841       |\n",
      "|    mean_step_reward   | 0.12658632   |\n",
      "|    n_updates          | 4840         |\n",
      "|    policyGradLoss     | -0.00621     |\n",
      "|    value_loss         | 0.573        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 294         |\n",
      "|    total_timesteps    | 9928704     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.00808772  |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0161      |\n",
      "|    mean_step_reward   | 0.098829865 |\n",
      "|    n_updates          | 4844        |\n",
      "|    policyGradLoss     | -0.00712    |\n",
      "|    value_loss         | 0.289       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 305         |\n",
      "|    total_timesteps    | 9936896     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009920221 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0193      |\n",
      "|    mean_step_reward   | 0.1342313   |\n",
      "|    n_updates          | 4848        |\n",
      "|    policyGradLoss     | -0.00916    |\n",
      "|    value_loss         | 0.283       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 777          |\n",
      "|    iterations         | 30           |\n",
      "|    time_elapsed       | 315          |\n",
      "|    total_timesteps    | 9945088      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0071539525 |\n",
      "|    entropy_loss       | -1.76        |\n",
      "|    explained_variance | 0.965        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0323       |\n",
      "|    mean_step_reward   | 0.117373     |\n",
      "|    n_updates          | 4852         |\n",
      "|    policyGradLoss     | -0.00459     |\n",
      "|    value_loss         | 0.479        |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 778        |\n",
      "|    iterations         | 31         |\n",
      "|    time_elapsed       | 326        |\n",
      "|    total_timesteps    | 9953280    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.00660464 |\n",
      "|    entropy_loss       | -1.77      |\n",
      "|    explained_variance | 0.934      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.294      |\n",
      "|    mean_step_reward   | 0.10235971 |\n",
      "|    n_updates          | 4856       |\n",
      "|    policyGradLoss     | -0.00564   |\n",
      "|    value_loss         | 0.661      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 336         |\n",
      "|    total_timesteps    | 9961472     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010217914 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00685    |\n",
      "|    mean_step_reward   | 0.115328945 |\n",
      "|    n_updates          | 4860        |\n",
      "|    policyGradLoss     | -0.0109     |\n",
      "|    value_loss         | 0.231       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/S2K_37.zip\n",
      "[EVAL] Mean Return: 153.752, Best Return: 160.086\n",
      "Saved video to ./runs_smw/videos/S2K/S2K_37_153.75.mp4\n",
      "\n",
      "=== Round 39 | Learn 262144 steps (Total trained: 9961472) ===\n",
      "Logging to ./runs_smw/tb/S2K_0\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1118    |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 7       |\n",
      "|    total_timesteps | 9969664 |\n",
      "--------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 909         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 9977856     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008781334 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.07        |\n",
      "|    mean_step_reward   | 0.118036866 |\n",
      "|    n_updates          | 4868        |\n",
      "|    policyGradLoss     | -0.00578    |\n",
      "|    value_loss         | 0.47        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 859         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 9986048     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011002289 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00704     |\n",
      "|    mean_step_reward   | 0.09708107  |\n",
      "|    n_updates          | 4872        |\n",
      "|    policyGradLoss     | -0.00982    |\n",
      "|    value_loss         | 0.233       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 841         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 38          |\n",
      "|    total_timesteps    | 9994240     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009288745 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0146      |\n",
      "|    mean_step_reward   | 0.122379325 |\n",
      "|    n_updates          | 4876        |\n",
      "|    policyGradLoss     | -0.00788    |\n",
      "|    value_loss         | 0.261       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 826          |\n",
      "|    iterations         | 5            |\n",
      "|    time_elapsed       | 49           |\n",
      "|    total_timesteps    | 10002432     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0063009365 |\n",
      "|    entropy_loss       | -1.75        |\n",
      "|    explained_variance | 0.97         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0825       |\n",
      "|    mean_step_reward   | 0.13501081   |\n",
      "|    n_updates          | 4880         |\n",
      "|    policyGradLoss     | -0.00475     |\n",
      "|    value_loss         | 0.374        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 819         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 59          |\n",
      "|    total_timesteps    | 10010624    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009975325 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.939       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0133      |\n",
      "|    mean_step_reward   | 0.08014682  |\n",
      "|    n_updates          | 4884        |\n",
      "|    policyGradLoss     | -0.00507    |\n",
      "|    value_loss         | 0.421       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 813         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 70          |\n",
      "|    total_timesteps    | 10018816    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007405097 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.945       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0814      |\n",
      "|    mean_step_reward   | 0.094968006 |\n",
      "|    n_updates          | 4888        |\n",
      "|    policyGradLoss     | -0.00694    |\n",
      "|    value_loss         | 0.445       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 805         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 81          |\n",
      "|    total_timesteps    | 10027008    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012066511 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00976    |\n",
      "|    mean_step_reward   | 0.10857198  |\n",
      "|    n_updates          | 4892        |\n",
      "|    policyGradLoss     | -0.00908    |\n",
      "|    value_loss         | 0.207       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 798         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 92          |\n",
      "|    total_timesteps    | 10035200    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011776265 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0473      |\n",
      "|    mean_step_reward   | 0.09856859  |\n",
      "|    n_updates          | 4896        |\n",
      "|    policyGradLoss     | -0.00808    |\n",
      "|    value_loss         | 0.264       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 796          |\n",
      "|    iterations         | 10           |\n",
      "|    time_elapsed       | 102          |\n",
      "|    total_timesteps    | 10043392     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0068878187 |\n",
      "|    entropy_loss       | -1.79        |\n",
      "|    explained_variance | 0.938        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.185        |\n",
      "|    mean_step_reward   | 0.108654425  |\n",
      "|    n_updates          | 4900         |\n",
      "|    policyGradLoss     | -0.00143     |\n",
      "|    value_loss         | 0.66         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 794          |\n",
      "|    iterations         | 11           |\n",
      "|    time_elapsed       | 113          |\n",
      "|    total_timesteps    | 10051584     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0069650277 |\n",
      "|    entropy_loss       | -1.76        |\n",
      "|    explained_variance | 0.921        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0591       |\n",
      "|    mean_step_reward   | 0.09843066   |\n",
      "|    n_updates          | 4904         |\n",
      "|    policyGradLoss     | -0.00709     |\n",
      "|    value_loss         | 0.674        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 792         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 124         |\n",
      "|    total_timesteps    | 10059776    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009291483 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0628      |\n",
      "|    mean_step_reward   | 0.12336462  |\n",
      "|    n_updates          | 4908        |\n",
      "|    policyGradLoss     | -0.00763    |\n",
      "|    value_loss         | 0.658       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 789          |\n",
      "|    iterations         | 13           |\n",
      "|    time_elapsed       | 134          |\n",
      "|    total_timesteps    | 10067968     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0094602695 |\n",
      "|    entropy_loss       | -1.8         |\n",
      "|    explained_variance | 0.944        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0667       |\n",
      "|    mean_step_reward   | 0.091038354  |\n",
      "|    n_updates          | 4912         |\n",
      "|    policyGradLoss     | -0.00301     |\n",
      "|    value_loss         | 0.465        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 145         |\n",
      "|    total_timesteps    | 10076160    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.00964847  |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0405      |\n",
      "|    mean_step_reward   | 0.115063034 |\n",
      "|    n_updates          | 4916        |\n",
      "|    policyGradLoss     | -0.00388    |\n",
      "|    value_loss         | 0.455       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 787        |\n",
      "|    iterations         | 15         |\n",
      "|    time_elapsed       | 156        |\n",
      "|    total_timesteps    | 10084352   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01419621 |\n",
      "|    entropy_loss       | -1.81      |\n",
      "|    explained_variance | 0.984      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0154    |\n",
      "|    mean_step_reward   | 0.09298244 |\n",
      "|    n_updates          | 4920       |\n",
      "|    policyGradLoss     | -0.0116    |\n",
      "|    value_loss         | 0.159      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 166         |\n",
      "|    total_timesteps    | 10092544    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011585153 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0606      |\n",
      "|    mean_step_reward   | 0.12189132  |\n",
      "|    n_updates          | 4924        |\n",
      "|    policyGradLoss     | -0.0107     |\n",
      "|    value_loss         | 0.284       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 177         |\n",
      "|    total_timesteps    | 10100736    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017853547 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00472    |\n",
      "|    mean_step_reward   | 0.06062724  |\n",
      "|    n_updates          | 4928        |\n",
      "|    policyGradLoss     | -0.0121     |\n",
      "|    value_loss         | 0.177       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 188         |\n",
      "|    total_timesteps    | 10108928    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008722417 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.026       |\n",
      "|    mean_step_reward   | 0.09724856  |\n",
      "|    n_updates          | 4932        |\n",
      "|    policyGradLoss     | -0.00575    |\n",
      "|    value_loss         | 0.332       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 783        |\n",
      "|    iterations         | 19         |\n",
      "|    time_elapsed       | 198        |\n",
      "|    total_timesteps    | 10117120   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01265719 |\n",
      "|    entropy_loss       | -1.79      |\n",
      "|    explained_variance | 0.981      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.0438     |\n",
      "|    mean_step_reward   | 0.10610694 |\n",
      "|    n_updates          | 4936       |\n",
      "|    policyGradLoss     | -0.00823   |\n",
      "|    value_loss         | 0.236      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 209         |\n",
      "|    total_timesteps    | 10125312    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010904724 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0208      |\n",
      "|    mean_step_reward   | 0.11695951  |\n",
      "|    n_updates          | 4940        |\n",
      "|    policyGradLoss     | -0.00861    |\n",
      "|    value_loss         | 0.312       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 219         |\n",
      "|    total_timesteps    | 10133504    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010195358 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.922       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0487      |\n",
      "|    mean_step_reward   | 0.10476132  |\n",
      "|    n_updates          | 4944        |\n",
      "|    policyGradLoss     | -0.00461    |\n",
      "|    value_loss         | 0.486       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 230         |\n",
      "|    total_timesteps    | 10141696    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014657036 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.952       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0249     |\n",
      "|    mean_step_reward   | 0.05800592  |\n",
      "|    n_updates          | 4948        |\n",
      "|    policyGradLoss     | -0.0102     |\n",
      "|    value_loss         | 0.24        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 241         |\n",
      "|    total_timesteps    | 10149888    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012722813 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0355      |\n",
      "|    mean_step_reward   | 0.12423742  |\n",
      "|    n_updates          | 4952        |\n",
      "|    policyGradLoss     | -0.00515    |\n",
      "|    value_loss         | 0.275       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 251         |\n",
      "|    total_timesteps    | 10158080    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012800751 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00197     |\n",
      "|    mean_step_reward   | 0.09513813  |\n",
      "|    n_updates          | 4956        |\n",
      "|    policyGradLoss     | -0.0134     |\n",
      "|    value_loss         | 0.23        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 262         |\n",
      "|    total_timesteps    | 10166272    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020478891 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0272     |\n",
      "|    mean_step_reward   | 0.05359821  |\n",
      "|    n_updates          | 4960        |\n",
      "|    policyGradLoss     | -0.00718    |\n",
      "|    value_loss         | 0.187       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 272         |\n",
      "|    total_timesteps    | 10174464    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011150414 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.919       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.242       |\n",
      "|    mean_step_reward   | 0.11024711  |\n",
      "|    n_updates          | 4964        |\n",
      "|    policyGradLoss     | -0.000254   |\n",
      "|    value_loss         | 0.615       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 283         |\n",
      "|    total_timesteps    | 10182656    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009683038 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0212     |\n",
      "|    mean_step_reward   | 0.09856088  |\n",
      "|    n_updates          | 4968        |\n",
      "|    policyGradLoss     | -0.0101     |\n",
      "|    value_loss         | 0.106       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 294         |\n",
      "|    total_timesteps    | 10190848    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011837428 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00835    |\n",
      "|    mean_step_reward   | 0.08498227  |\n",
      "|    n_updates          | 4972        |\n",
      "|    policyGradLoss     | -0.00994    |\n",
      "|    value_loss         | 0.213       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 778          |\n",
      "|    iterations         | 29           |\n",
      "|    time_elapsed       | 305          |\n",
      "|    total_timesteps    | 10199040     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0099679995 |\n",
      "|    entropy_loss       | -1.74        |\n",
      "|    explained_variance | 0.968        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0817       |\n",
      "|    mean_step_reward   | 0.13911179   |\n",
      "|    n_updates          | 4976         |\n",
      "|    policyGradLoss     | -0.00477     |\n",
      "|    value_loss         | 0.376        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 315         |\n",
      "|    total_timesteps    | 10207232    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014350045 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0674      |\n",
      "|    mean_step_reward   | 0.10746717  |\n",
      "|    n_updates          | 4980        |\n",
      "|    policyGradLoss     | -0.00764    |\n",
      "|    value_loss         | 0.344       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 326         |\n",
      "|    total_timesteps    | 10215424    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.00804285  |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0971      |\n",
      "|    mean_step_reward   | 0.119951695 |\n",
      "|    n_updates          | 4984        |\n",
      "|    policyGradLoss     | -0.00534    |\n",
      "|    value_loss         | 0.312       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 337         |\n",
      "|    total_timesteps    | 10223616    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009621153 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.202       |\n",
      "|    mean_step_reward   | 0.08929077  |\n",
      "|    n_updates          | 4988        |\n",
      "|    policyGradLoss     | -0.00352    |\n",
      "|    value_loss         | 0.329       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/S2K_38.zip\n",
      "[EVAL] Mean Return: 134.171, Best Return: 139.837\n",
      "Saved video to ./runs_smw/videos/S2K/S2K_38_134.17.mp4\n",
      "\n",
      "=== Round 40 | Learn 262144 steps (Total trained: 10223616) ===\n",
      "Logging to ./runs_smw/tb/S2K_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1120     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 10231808 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 914         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 10240000    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014743911 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0287     |\n",
      "|    mean_step_reward   | 0.10966305  |\n",
      "|    n_updates          | 4996        |\n",
      "|    policyGradLoss     | -0.0112     |\n",
      "|    value_loss         | 0.15        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 862         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 10248192    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009965275 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00233    |\n",
      "|    mean_step_reward   | 0.103975445 |\n",
      "|    n_updates          | 5000        |\n",
      "|    policyGradLoss     | -0.00714    |\n",
      "|    value_loss         | 0.247       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 843         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 38          |\n",
      "|    total_timesteps    | 10256384    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011166652 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0334     |\n",
      "|    mean_step_reward   | 0.09998568  |\n",
      "|    n_updates          | 5004        |\n",
      "|    policyGradLoss     | -0.0117     |\n",
      "|    value_loss         | 0.191       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 827         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 49          |\n",
      "|    total_timesteps    | 10264576    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011088983 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0459      |\n",
      "|    mean_step_reward   | 0.12085576  |\n",
      "|    n_updates          | 5008        |\n",
      "|    policyGradLoss     | -0.00362    |\n",
      "|    value_loss         | 0.285       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 817        |\n",
      "|    iterations         | 6          |\n",
      "|    time_elapsed       | 60         |\n",
      "|    total_timesteps    | 10272768   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.0142514  |\n",
      "|    entropy_loss       | -1.75      |\n",
      "|    explained_variance | 0.987      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.0691     |\n",
      "|    mean_step_reward   | 0.11224367 |\n",
      "|    n_updates          | 5012       |\n",
      "|    policyGradLoss     | -0.011     |\n",
      "|    value_loss         | 0.186      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 805         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 71          |\n",
      "|    total_timesteps    | 10280960    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014855336 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0349     |\n",
      "|    mean_step_reward   | 0.109900035 |\n",
      "|    n_updates          | 5016        |\n",
      "|    policyGradLoss     | -0.0102     |\n",
      "|    value_loss         | 0.141       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 800         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 81          |\n",
      "|    total_timesteps    | 10289152    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007930436 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.109       |\n",
      "|    mean_step_reward   | 0.09430547  |\n",
      "|    n_updates          | 5020        |\n",
      "|    policyGradLoss     | -0.00598    |\n",
      "|    value_loss         | 0.342       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 796         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 92          |\n",
      "|    total_timesteps    | 10297344    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007834765 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.031       |\n",
      "|    mean_step_reward   | 0.13877863  |\n",
      "|    n_updates          | 5024        |\n",
      "|    policyGradLoss     | -0.00753    |\n",
      "|    value_loss         | 0.322       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 794          |\n",
      "|    iterations         | 10           |\n",
      "|    time_elapsed       | 103          |\n",
      "|    total_timesteps    | 10305536     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0067225005 |\n",
      "|    entropy_loss       | -1.72        |\n",
      "|    explained_variance | 0.969        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.106        |\n",
      "|    mean_step_reward   | 0.13824081   |\n",
      "|    n_updates          | 5028         |\n",
      "|    policyGradLoss     | -0.00405     |\n",
      "|    value_loss         | 0.535        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 792         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 113         |\n",
      "|    total_timesteps    | 10313728    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015014089 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00928     |\n",
      "|    mean_step_reward   | 0.08103554  |\n",
      "|    n_updates          | 5032        |\n",
      "|    policyGradLoss     | -0.00909    |\n",
      "|    value_loss         | 0.183       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 790         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 124         |\n",
      "|    total_timesteps    | 10321920    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009663608 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0124     |\n",
      "|    mean_step_reward   | 0.10779921  |\n",
      "|    n_updates          | 5036        |\n",
      "|    policyGradLoss     | -0.00568    |\n",
      "|    value_loss         | 0.312       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 788          |\n",
      "|    iterations         | 13           |\n",
      "|    time_elapsed       | 135          |\n",
      "|    total_timesteps    | 10330112     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0088542625 |\n",
      "|    entropy_loss       | -1.71        |\n",
      "|    explained_variance | 0.983        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0412       |\n",
      "|    mean_step_reward   | 0.13378415   |\n",
      "|    n_updates          | 5040         |\n",
      "|    policyGradLoss     | -0.0114      |\n",
      "|    value_loss         | 0.273        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 145         |\n",
      "|    total_timesteps    | 10338304    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012440825 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0339     |\n",
      "|    mean_step_reward   | 0.09815629  |\n",
      "|    n_updates          | 5044        |\n",
      "|    policyGradLoss     | -0.00954    |\n",
      "|    value_loss         | 0.15        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 156         |\n",
      "|    total_timesteps    | 10346496    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011055981 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0253     |\n",
      "|    mean_step_reward   | 0.122304216 |\n",
      "|    n_updates          | 5048        |\n",
      "|    policyGradLoss     | -0.00765    |\n",
      "|    value_loss         | 0.182       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 783          |\n",
      "|    iterations         | 16           |\n",
      "|    time_elapsed       | 167          |\n",
      "|    total_timesteps    | 10354688     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0066998634 |\n",
      "|    entropy_loss       | -1.74        |\n",
      "|    explained_variance | 0.961        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.138        |\n",
      "|    mean_step_reward   | 0.12511867   |\n",
      "|    n_updates          | 5052         |\n",
      "|    policyGradLoss     | -0.00449     |\n",
      "|    value_loss         | 0.532        |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 782        |\n",
      "|    iterations         | 17         |\n",
      "|    time_elapsed       | 177        |\n",
      "|    total_timesteps    | 10362880   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01517999 |\n",
      "|    entropy_loss       | -1.77      |\n",
      "|    explained_variance | 0.977      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0186    |\n",
      "|    mean_step_reward   | 0.10277945 |\n",
      "|    n_updates          | 5056       |\n",
      "|    policyGradLoss     | -0.0106    |\n",
      "|    value_loss         | 0.192      |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 782          |\n",
      "|    iterations         | 18           |\n",
      "|    time_elapsed       | 188          |\n",
      "|    total_timesteps    | 10371072     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0155888125 |\n",
      "|    entropy_loss       | -1.76        |\n",
      "|    explained_variance | 0.98         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0139      |\n",
      "|    mean_step_reward   | 0.11152251   |\n",
      "|    n_updates          | 5060         |\n",
      "|    policyGradLoss     | -0.0124      |\n",
      "|    value_loss         | 0.207        |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 781        |\n",
      "|    iterations         | 19         |\n",
      "|    time_elapsed       | 199        |\n",
      "|    total_timesteps    | 10379264   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01587138 |\n",
      "|    entropy_loss       | -1.75      |\n",
      "|    explained_variance | 0.972      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.0236     |\n",
      "|    mean_step_reward   | 0.09388752 |\n",
      "|    n_updates          | 5064       |\n",
      "|    policyGradLoss     | -0.00525   |\n",
      "|    value_loss         | 0.301      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 209         |\n",
      "|    total_timesteps    | 10387456    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013805958 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0121      |\n",
      "|    mean_step_reward   | 0.091084436 |\n",
      "|    n_updates          | 5068        |\n",
      "|    policyGradLoss     | -0.00904    |\n",
      "|    value_loss         | 0.238       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 220         |\n",
      "|    total_timesteps    | 10395648    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010378595 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.098       |\n",
      "|    mean_step_reward   | 0.12700799  |\n",
      "|    n_updates          | 5072        |\n",
      "|    policyGradLoss     | -0.00557    |\n",
      "|    value_loss         | 0.261       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 230         |\n",
      "|    total_timesteps    | 10403840    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015160194 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0413     |\n",
      "|    mean_step_reward   | 0.11258562  |\n",
      "|    n_updates          | 5076        |\n",
      "|    policyGradLoss     | -0.0134     |\n",
      "|    value_loss         | 0.155       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 779        |\n",
      "|    iterations         | 23         |\n",
      "|    time_elapsed       | 241        |\n",
      "|    total_timesteps    | 10412032   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01338367 |\n",
      "|    entropy_loss       | -1.75      |\n",
      "|    explained_variance | 0.978      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.00813   |\n",
      "|    mean_step_reward   | 0.10269666 |\n",
      "|    n_updates          | 5080       |\n",
      "|    policyGradLoss     | -0.00761   |\n",
      "|    value_loss         | 0.267      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 779        |\n",
      "|    iterations         | 24         |\n",
      "|    time_elapsed       | 252        |\n",
      "|    total_timesteps    | 10420224   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.0093209  |\n",
      "|    entropy_loss       | -1.7       |\n",
      "|    explained_variance | 0.989      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0132    |\n",
      "|    mean_step_reward   | 0.15450957 |\n",
      "|    n_updates          | 5084       |\n",
      "|    policyGradLoss     | -0.00951   |\n",
      "|    value_loss         | 0.185      |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 780          |\n",
      "|    iterations         | 25           |\n",
      "|    time_elapsed       | 262          |\n",
      "|    total_timesteps    | 10428416     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0143606225 |\n",
      "|    entropy_loss       | -1.74        |\n",
      "|    explained_variance | 0.964        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0174      |\n",
      "|    mean_step_reward   | 0.08637941   |\n",
      "|    n_updates          | 5088         |\n",
      "|    policyGradLoss     | -0.00952     |\n",
      "|    value_loss         | 0.238        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 273         |\n",
      "|    total_timesteps    | 10436608    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010996181 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0669      |\n",
      "|    mean_step_reward   | 0.12602814  |\n",
      "|    n_updates          | 5092        |\n",
      "|    policyGradLoss     | -0.00473    |\n",
      "|    value_loss         | 0.285       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 283         |\n",
      "|    total_timesteps    | 10444800    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016223589 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0213     |\n",
      "|    mean_step_reward   | 0.10416572  |\n",
      "|    n_updates          | 5096        |\n",
      "|    policyGradLoss     | -0.0131     |\n",
      "|    value_loss         | 0.122       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 293         |\n",
      "|    total_timesteps    | 10452992    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019198012 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.022      |\n",
      "|    mean_step_reward   | 0.10839522  |\n",
      "|    n_updates          | 5100        |\n",
      "|    policyGradLoss     | -0.00878    |\n",
      "|    value_loss         | 0.145       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 780        |\n",
      "|    iterations         | 29         |\n",
      "|    time_elapsed       | 304        |\n",
      "|    total_timesteps    | 10461184   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01451654 |\n",
      "|    entropy_loss       | -1.71      |\n",
      "|    explained_variance | 0.991      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.039      |\n",
      "|    mean_step_reward   | 0.13083467 |\n",
      "|    n_updates          | 5104       |\n",
      "|    policyGradLoss     | -0.0118    |\n",
      "|    value_loss         | 0.158      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 315         |\n",
      "|    total_timesteps    | 10469376    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013060344 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0015      |\n",
      "|    mean_step_reward   | 0.124137595 |\n",
      "|    n_updates          | 5108        |\n",
      "|    policyGradLoss     | -0.00995    |\n",
      "|    value_loss         | 0.184       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 325         |\n",
      "|    total_timesteps    | 10477568    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012616575 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0601      |\n",
      "|    mean_step_reward   | 0.09481895  |\n",
      "|    n_updates          | 5112        |\n",
      "|    policyGradLoss     | -0.00974    |\n",
      "|    value_loss         | 0.245       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 336         |\n",
      "|    total_timesteps    | 10485760    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010123525 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0221      |\n",
      "|    mean_step_reward   | 0.09775883  |\n",
      "|    n_updates          | 5116        |\n",
      "|    policyGradLoss     | -0.0125     |\n",
      "|    value_loss         | 0.221       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/S2K_39.zip\n",
      "[EVAL] Mean Return: 11.725, Best Return: 12.391\n",
      "Saved video to ./runs_smw/videos/S2K/S2K_39_11.72.mp4\n",
      "\n",
      "=== Round 41 | Learn 262144 steps (Total trained: 10485760) ===\n",
      "Logging to ./runs_smw/tb/S2K_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1145     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 10493952 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 921         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 10502144    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018589381 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0333     |\n",
      "|    mean_step_reward   | 0.10833956  |\n",
      "|    n_updates          | 5124        |\n",
      "|    policyGradLoss     | -0.0102     |\n",
      "|    value_loss         | 0.139       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 872         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 10510336    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012080383 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00955    |\n",
      "|    mean_step_reward   | 0.11168985  |\n",
      "|    n_updates          | 5128        |\n",
      "|    policyGradLoss     | -0.0121     |\n",
      "|    value_loss         | 0.207       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 842         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 38          |\n",
      "|    total_timesteps    | 10518528    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013573216 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0241     |\n",
      "|    mean_step_reward   | 0.12380364  |\n",
      "|    n_updates          | 5132        |\n",
      "|    policyGradLoss     | -0.00807    |\n",
      "|    value_loss         | 0.208       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 827         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 49          |\n",
      "|    total_timesteps    | 10526720    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016105209 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0397     |\n",
      "|    mean_step_reward   | 0.11567845  |\n",
      "|    n_updates          | 5136        |\n",
      "|    policyGradLoss     | -0.0116     |\n",
      "|    value_loss         | 0.114       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 824        |\n",
      "|    iterations         | 6          |\n",
      "|    time_elapsed       | 59         |\n",
      "|    total_timesteps    | 10534912   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01910702 |\n",
      "|    entropy_loss       | -1.74      |\n",
      "|    explained_variance | 0.994      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0325    |\n",
      "|    mean_step_reward   | 0.11933118 |\n",
      "|    n_updates          | 5140       |\n",
      "|    policyGradLoss     | -0.0139    |\n",
      "|    value_loss         | 0.0983     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 817         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 70          |\n",
      "|    total_timesteps    | 10543104    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012765076 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.000409   |\n",
      "|    mean_step_reward   | 0.111976996 |\n",
      "|    n_updates          | 5144        |\n",
      "|    policyGradLoss     | -0.0061     |\n",
      "|    value_loss         | 0.297       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 810         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 80          |\n",
      "|    total_timesteps    | 10551296    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014444164 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0266     |\n",
      "|    mean_step_reward   | 0.11253476  |\n",
      "|    n_updates          | 5148        |\n",
      "|    policyGradLoss     | -0.00963    |\n",
      "|    value_loss         | 0.174       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 806         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 91          |\n",
      "|    total_timesteps    | 10559488    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010800925 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0326      |\n",
      "|    mean_step_reward   | 0.11967514  |\n",
      "|    n_updates          | 5152        |\n",
      "|    policyGradLoss     | -0.000783   |\n",
      "|    value_loss         | 0.32        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 801         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 102         |\n",
      "|    total_timesteps    | 10567680    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018558472 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0403     |\n",
      "|    mean_step_reward   | 0.11335252  |\n",
      "|    n_updates          | 5156        |\n",
      "|    policyGradLoss     | -0.0109     |\n",
      "|    value_loss         | 0.119       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 796         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 113         |\n",
      "|    total_timesteps    | 10575872    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009959485 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.016      |\n",
      "|    mean_step_reward   | 0.14441587  |\n",
      "|    n_updates          | 5160        |\n",
      "|    policyGradLoss     | -0.00869    |\n",
      "|    value_loss         | 0.199       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 795         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 123         |\n",
      "|    total_timesteps    | 10584064    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017954012 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0309     |\n",
      "|    mean_step_reward   | 0.10441924  |\n",
      "|    n_updates          | 5164        |\n",
      "|    policyGradLoss     | -0.0137     |\n",
      "|    value_loss         | 0.137       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 794         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 134         |\n",
      "|    total_timesteps    | 10592256    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013788933 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00921     |\n",
      "|    mean_step_reward   | 0.11074194  |\n",
      "|    n_updates          | 5168        |\n",
      "|    policyGradLoss     | -0.00626    |\n",
      "|    value_loss         | 0.185       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 795         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 144         |\n",
      "|    total_timesteps    | 10600448    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013196635 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00752     |\n",
      "|    mean_step_reward   | 0.12612294  |\n",
      "|    n_updates          | 5172        |\n",
      "|    policyGradLoss     | -0.0116     |\n",
      "|    value_loss         | 0.203       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 795         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 154         |\n",
      "|    total_timesteps    | 10608640    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025032407 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0352     |\n",
      "|    mean_step_reward   | 0.108075045 |\n",
      "|    n_updates          | 5176        |\n",
      "|    policyGradLoss     | -0.0126     |\n",
      "|    value_loss         | 0.133       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 794         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 164         |\n",
      "|    total_timesteps    | 10616832    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015095625 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0234     |\n",
      "|    mean_step_reward   | 0.102002546 |\n",
      "|    n_updates          | 5180        |\n",
      "|    policyGradLoss     | -0.00699    |\n",
      "|    value_loss         | 0.144       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 793         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 175         |\n",
      "|    total_timesteps    | 10625024    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016305206 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0373      |\n",
      "|    mean_step_reward   | 0.11595969  |\n",
      "|    n_updates          | 5184        |\n",
      "|    policyGradLoss     | -0.00923    |\n",
      "|    value_loss         | 0.142       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 791         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 186         |\n",
      "|    total_timesteps    | 10633216    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013991661 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0289      |\n",
      "|    mean_step_reward   | 0.14319718  |\n",
      "|    n_updates          | 5188        |\n",
      "|    policyGradLoss     | -0.0088     |\n",
      "|    value_loss         | 0.316       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 790         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 196         |\n",
      "|    total_timesteps    | 10641408    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017526895 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0277     |\n",
      "|    mean_step_reward   | 0.1124739   |\n",
      "|    n_updates          | 5192        |\n",
      "|    policyGradLoss     | -0.0108     |\n",
      "|    value_loss         | 0.127       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 789         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 207         |\n",
      "|    total_timesteps    | 10649600    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015660234 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0228     |\n",
      "|    mean_step_reward   | 0.124468535 |\n",
      "|    n_updates          | 5196        |\n",
      "|    policyGradLoss     | -0.00955    |\n",
      "|    value_loss         | 0.16        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 789         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 218         |\n",
      "|    total_timesteps    | 10657792    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019611789 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0066      |\n",
      "|    mean_step_reward   | 0.10438262  |\n",
      "|    n_updates          | 5200        |\n",
      "|    policyGradLoss     | -0.0106     |\n",
      "|    value_loss         | 0.197       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 788         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 228         |\n",
      "|    total_timesteps    | 10665984    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009151196 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0274      |\n",
      "|    mean_step_reward   | 0.12492648  |\n",
      "|    n_updates          | 5204        |\n",
      "|    policyGradLoss     | -0.00082    |\n",
      "|    value_loss         | 0.254       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 239         |\n",
      "|    total_timesteps    | 10674176    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008068689 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0827      |\n",
      "|    mean_step_reward   | 0.11424805  |\n",
      "|    n_updates          | 5208        |\n",
      "|    policyGradLoss     | -0.00422    |\n",
      "|    value_loss         | 0.424       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 250         |\n",
      "|    total_timesteps    | 10682368    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014730013 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00633     |\n",
      "|    mean_step_reward   | 0.14378184  |\n",
      "|    n_updates          | 5212        |\n",
      "|    policyGradLoss     | -0.00815    |\n",
      "|    value_loss         | 0.204       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 260         |\n",
      "|    total_timesteps    | 10690560    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014300662 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00718     |\n",
      "|    mean_step_reward   | 0.10691475  |\n",
      "|    n_updates          | 5216        |\n",
      "|    policyGradLoss     | -0.00688    |\n",
      "|    value_loss         | 0.242       |\n",
      "---------------------------------------\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    while trained < TOTAL_STEPS:\n",
    "        round_idx += 1\n",
    "        chunk = min(TRAIN_CHUNK, TOTAL_STEPS - trained)\n",
    "        # chunk = 2000\n",
    "        label = \"S2K\" # smushed to killed\n",
    "        tagged_label = f\"{label}_{int(trained/TRAIN_CHUNK)}\"\n",
    "\n",
    "        print(f\"\\n=== Round {round_idx} | Learn {chunk} steps (Total trained: {trained}) ===\")\n",
    "        \n",
    "        # --- Train ---\n",
    "        model.learn(total_timesteps=chunk, reset_num_timesteps=False, tb_log_name=label)\n",
    "        trained += chunk\n",
    "\n",
    "        # --- Save Checkpoint ---\n",
    "        ckpt_path = os.path.join(CKPT_DIR, f\"{tagged_label}.zip\")\n",
    "        model.save(ckpt_path)\n",
    "        print(f\"Saved checkpoint: {ckpt_path}\")\n",
    "\n",
    "        # --- Evaluate ---\n",
    "        mean_ret, best_ret = evaluate_policy(\n",
    "            model,\n",
    "            GAME,\n",
    "            STATE,\n",
    "            n_episodes=EVAL_EPISODES,\n",
    "            max_steps=EVAL_MAX_STEPS,\n",
    "        )\n",
    "        print(f\"[EVAL] Mean Return: {mean_ret:.3f}, Best Return: {best_ret:.3f}\")\n",
    "\n",
    "        # --- Save Best Model ---\n",
    "        # if mean_ret > best_mean:\n",
    "        #     best_mean = mean_ret\n",
    "        #     best_path = os.path.join(LOG_DIR, \"best_model.zip\")\n",
    "        #     model.save(best_path)\n",
    "        #     print(f\"New best record. Saved to {best_path}\")\n",
    "\n",
    "        # --- Record Video ---\n",
    "        out_path = os.path.join(VIDEO_DIR, label)\n",
    "        os.makedirs(out_path,  exist_ok=True)\n",
    "        record_video(\n",
    "            model,\n",
    "            GAME,\n",
    "            STATE,\n",
    "            VIDEO_DIR,\n",
    "            video_len=RECORD_STEPS,\n",
    "            prefix=f\"{label}/{tagged_label}_{mean_ret:.2f}\",\n",
    "        )\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nTraining interrupted manually.\")\n",
    "\n",
    "finally:\n",
    "    train_env.close()\n",
    "    print(\"Training finished. Environment closed.\")\n",
    "    \n",
    "\"\"\"\n",
    "tensorboard --logdir=./runs_smw/tb\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f088b0b3-2418-4866-b332-0312c9f6467f",
   "metadata": {},
   "source": [
    "## Display Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73191bb-e875-4939-b04c-a4670abd9612",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Video\n",
    "import glob\n",
    "# label = \"Dec22A\"\n",
    "\n",
    "# list_of_files = glob.glob(os.path.join(VIDEO_DIR, label, '*.mp4')) \n",
    "# if list_of_files:\n",
    "#     latest_file = max(list_of_files, key=os.path.getctime)\n",
    "#     print(f\"Playing: {latest_file}\")\n",
    "#     latest_file = \"runs_smw/videos/Dec22A/Dec22A_73_596.54.mp4\"\n",
    "#     print(f\"Playing: {latest_file}\")\n",
    "#     display(Video(latest_file, embed=True, width=768))\n",
    "# else:\n",
    "#     print(\"No videos found yet.\")\n",
    "    \n",
    "video = \"./runs_smw/videos/test_151.mp4\"\n",
    "display(Video(video, embed=True, width=768))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942adf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(\"runs_smw/videos/test_16.mp4\")\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    cv2.imshow(\"Frame-by-Frame\", frame)\n",
    "\n",
    "    # ÈóúÈçµÔºöÈÄôË£°Á≠âÂæÖÊåâÈçµ„ÄÇÊåâ 'n' ÈçµË∑≥Âà∞‰∏ã‰∏ÄÂπÄÔºåÊåâ 'q' Èõ¢Èñã\n",
    "    key = cv2.waitKey(0) \n",
    "    if key == ord('q'):\n",
    "        break\n",
    "    elif key == ord('n'):\n",
    "        continue\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Lab8 (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
