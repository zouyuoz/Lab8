{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dceedafe-2782-41a1-8119-50ee3d6c21fd",
   "metadata": {},
   "source": [
    "# 2025 DL Lab8: RL Assignment_Super Mario World"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fa555a-e61c-4fb3-b5d0-289b66570139",
   "metadata": {},
   "source": [
    "**Your Answer:**    \n",
    "Hi I'm XXX, XXXXXXXXXX."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5b0974-9605-488a-9fd5-00816e7832cc",
   "metadata": {},
   "source": [
    "## Overview\n",
    "This project implements a **Deep Reinforcement Learning** pipeline to train an autonomous agent for Super Mario World. Leveraging the **Proximal Policy Optimization (PPO)** algorithm, the system interacts with the **stable-retro** environment to master the YoshiIsland1 level. Key components include a custom Vision Backbone for extracting features from raw pixel data and a suite of Environment Wrappers that handle frame preprocessing, action discretization, and reward shaping to facilitate efficient learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02696447",
   "metadata": {},
   "source": [
    "Reward function implement  \n",
    "should do something in the beginning (monster attack)  \n",
    "Custom PPO implement  \n",
    "pre train weight 差不多，主要是 reward function  \n",
    "model weight capacity 1GB  \n",
    "class name 不要動 (可以新增，但是原本有的不要動)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8a0ab9-f86d-4038-833d-761ec81fc4f2",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00b10def-362c-4910-9ed0-f3d0904343ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/m314834001/Lab8/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import retro\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, SubprocVecEnv\n",
    "from stable_baselines3.common.vec_env import VecNormalize\n",
    "\n",
    "from eval import evaluate_policy, record_video\n",
    "from custom_policy import VisionBackbonePolicy, CustomPPO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10361fd-f291-4d93-b50d-cc749a3af588",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b4f6a25-738c-49dd-8e66-ae164b74a45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Game Settings\n",
    "GAME = \"SuperMarioWorld-Snes\"\n",
    "STATE = \"YoshiIsland1\"\n",
    "\n",
    "# Training Settings\n",
    "TOTAL_STEPS = 6_553_600\n",
    "TRAIN_CHUNK =   327_680\n",
    "N_ENVS = 16\n",
    "LEARNING_RATE = 1e-4\n",
    "\n",
    "# Evaluation & Recording Settings\n",
    "EVAL_EPISODES = 3\n",
    "EVAL_MAX_STEPS = 18000\n",
    "RECORD_STEPS = 1800\n",
    "\n",
    "# Directories\n",
    "LOG_DIR = \"./runs_smw\"\n",
    "VIDEO_DIR       = os.path.join(LOG_DIR, \"videos\")\n",
    "CKPT_DIR        = os.path.join(LOG_DIR, \"checkpoints\")\n",
    "TENSORBOARD_LOG = os.path.join(LOG_DIR, \"tb\")\n",
    "\n",
    "os.makedirs(LOG_DIR,   exist_ok=True)\n",
    "os.makedirs(CKPT_DIR,  exist_ok=True)\n",
    "os.makedirs(VIDEO_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a34b783-0273-4835-ad2e-f9186064f76f",
   "metadata": {},
   "source": [
    "## Environment Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c34213d-2c7c-42b8-922d-bafa285d1ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wrappers import make_base_env\n",
    "def _make_env_thunk(game: str, state: str):\n",
    "    \"\"\"Return a function that creates an environment (for multiprocessing).\"\"\"\n",
    "    def _thunk():\n",
    "        return make_base_env(game, state)\n",
    "    return _thunk\n",
    "\n",
    "def make_vec_env(game: str, state: str, n_envs: int, use_subproc: bool = True):\n",
    "    \"\"\"Create a vectorized environment (multiple envs running in parallel).\"\"\"\n",
    "    env_fns = [_make_env_thunk(game, state) for _ in range(n_envs)]\n",
    "    \n",
    "    if use_subproc and n_envs > 1:\n",
    "        vec_env = SubprocVecEnv(env_fns)\n",
    "    else:\n",
    "        vec_env = DummyVecEnv(env_fns)\n",
    "\n",
    "    return vec_env"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71dff476-ea2e-4262-8780-afb32ef1b233",
   "metadata": {},
   "source": [
    "## Initialize Env & Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8c7c5fe-6421-4dbc-9bd8-822d61769c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment created: SuperMarioWorld-Snes - YoshiIsland1 with 16 parallel envs.\n",
      "Loading model from runs_smw/checkpoints/SF84G_5.zip...\n"
     ]
    }
   ],
   "source": [
    "# 1. Create Training Environment\n",
    "train_env = make_vec_env(GAME, STATE, n_envs=N_ENVS)\n",
    "# train_env = VecNormalize(train_env, norm_obs=True, norm_reward=True, clip_obs=10., clip_reward=10.)\n",
    "print(f\"Environment created: {GAME} - {STATE} with {N_ENVS} parallel envs.\")\n",
    "\n",
    "checkpoint_path = \"None\"\n",
    "# checkpoint_path = \"runs_smw/checkpoints/SF84_step_1600000.zip\"\n",
    "# checkpoint_path = \"runs_smw/checkpoints/SF84G_6553600.zip\"\n",
    "checkpoint_path = \"runs_smw/checkpoints/SF84G_5.zip\"\n",
    "\n",
    "# 2. Initialize Model\n",
    "if os.path.exists(checkpoint_path):\n",
    "    print(f\"Loading model from {checkpoint_path}...\")\n",
    "    # 讀取現有模型\n",
    "    model = CustomPPO.load(\n",
    "        checkpoint_path, \n",
    "        env=train_env,\n",
    "        device=\"cuda:0\" # 確保使用 GPU\n",
    "    )\n",
    "else:\n",
    "    print(f\"Fail to load {checkpoint_path}...\")\n",
    "    model = CustomPPO(\n",
    "        VisionBackbonePolicy,\n",
    "        train_env,\n",
    "        policy_kwargs   = dict(normalize_images=False),\n",
    "        n_epochs        = 4,\n",
    "        n_steps         = 512,\n",
    "        batch_size      = 512,\n",
    "        learning_rate   = LEARNING_RATE,\n",
    "        verbose         = 1,\n",
    "        gamma           = 0.99,\n",
    "        kl_coef         = 1,\n",
    "        clip_range      = 0.125,\n",
    "        tensorboard_log = TENSORBOARD_LOG,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1cb3d0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"policy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f594e443-843f-42c1-9fc6-3fbc82962021",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3af4932-c531-4113-a33a-defc6fb5858e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Round 1 | Learn 327680 steps (Total trained: 1638400) ===\n",
      "Logging to ./runs_smw/tb/tunnel_0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/m314834001/Lab8/.venv/lib/python3.12/site-packages/rich/live.py:256: UserWarning: install \"ipywidgets\" for \n",
       "Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/m314834001/Lab8/.venv/lib/python3.12/site-packages/rich/live.py:256: UserWarning: install \"ipywidgets\" for \n",
       "Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1080    |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 7       |\n",
      "|    total_timesteps | 1646592 |\n",
      "--------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 895         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 1654784     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011073049 |\n",
      "|    entropy_loss       | -2.01       |\n",
      "|    explained_variance | 0.836       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.213       |\n",
      "|    mean_step_reward   | 0.085263595 |\n",
      "|    n_updates          | 804         |\n",
      "|    policyGradLoss     | -0.00368    |\n",
      "|    value_loss         | 0.701       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 858         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 1662976     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010725081 |\n",
      "|    entropy_loss       | -2.05       |\n",
      "|    explained_variance | 0.883       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.147       |\n",
      "|    mean_step_reward   | 0.083392195 |\n",
      "|    n_updates          | 808         |\n",
      "|    policyGradLoss     | -0.00761    |\n",
      "|    value_loss         | 0.569       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 835         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 1671168     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011059588 |\n",
      "|    entropy_loss       | -2.06       |\n",
      "|    explained_variance | 0.849       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.3         |\n",
      "|    mean_step_reward   | 0.07430015  |\n",
      "|    n_updates          | 812         |\n",
      "|    policyGradLoss     | -0.00783    |\n",
      "|    value_loss         | 1.05        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 819         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 49          |\n",
      "|    total_timesteps    | 1679360     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012888858 |\n",
      "|    entropy_loss       | -2.03       |\n",
      "|    explained_variance | 0.883       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.126       |\n",
      "|    mean_step_reward   | 0.08250548  |\n",
      "|    n_updates          | 816         |\n",
      "|    policyGradLoss     | -0.00788    |\n",
      "|    value_loss         | 0.541       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 809         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 60          |\n",
      "|    total_timesteps    | 1687552     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014452414 |\n",
      "|    entropy_loss       | -2.05       |\n",
      "|    explained_variance | 0.888       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.169       |\n",
      "|    mean_step_reward   | 0.08377802  |\n",
      "|    n_updates          | 820         |\n",
      "|    policyGradLoss     | -0.00945    |\n",
      "|    value_loss         | 0.641       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 800         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 71          |\n",
      "|    total_timesteps    | 1695744     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015248722 |\n",
      "|    entropy_loss       | -2.06       |\n",
      "|    explained_variance | 0.868       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.114       |\n",
      "|    mean_step_reward   | 0.083351165 |\n",
      "|    n_updates          | 824         |\n",
      "|    policyGradLoss     | -0.0103     |\n",
      "|    value_loss         | 0.587       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 795         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 82          |\n",
      "|    total_timesteps    | 1703936     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011427581 |\n",
      "|    entropy_loss       | -2.07       |\n",
      "|    explained_variance | 0.874       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.11        |\n",
      "|    mean_step_reward   | 0.0783885   |\n",
      "|    n_updates          | 828         |\n",
      "|    policyGradLoss     | -0.00711    |\n",
      "|    value_loss         | 0.567       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 789         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 93          |\n",
      "|    total_timesteps    | 1712128     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011738017 |\n",
      "|    entropy_loss       | -2.06       |\n",
      "|    explained_variance | 0.83        |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.133       |\n",
      "|    mean_step_reward   | 0.07718454  |\n",
      "|    n_updates          | 832         |\n",
      "|    policyGradLoss     | -0.00367    |\n",
      "|    value_loss         | 0.726       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 787          |\n",
      "|    iterations         | 10           |\n",
      "|    time_elapsed       | 103          |\n",
      "|    total_timesteps    | 1720320      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0109614935 |\n",
      "|    entropy_loss       | -2.07        |\n",
      "|    explained_variance | 0.895        |\n",
      "|    learning_rate      | 0.0002       |\n",
      "|    loss               | 0.136        |\n",
      "|    mean_step_reward   | 0.07771275   |\n",
      "|    n_updates          | 836          |\n",
      "|    policyGradLoss     | -0.00866     |\n",
      "|    value_loss         | 0.719        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 114         |\n",
      "|    total_timesteps    | 1728512     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012124311 |\n",
      "|    entropy_loss       | -2.05       |\n",
      "|    explained_variance | 0.849       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.337       |\n",
      "|    mean_step_reward   | 0.08437814  |\n",
      "|    n_updates          | 840         |\n",
      "|    policyGradLoss     | -0.00906    |\n",
      "|    value_loss         | 0.803       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 125         |\n",
      "|    total_timesteps    | 1736704     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011184596 |\n",
      "|    entropy_loss       | -2.06       |\n",
      "|    explained_variance | 0.861       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.222       |\n",
      "|    mean_step_reward   | 0.076763265 |\n",
      "|    n_updates          | 844         |\n",
      "|    policyGradLoss     | -0.00721    |\n",
      "|    value_loss         | 0.896       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 136         |\n",
      "|    total_timesteps    | 1744896     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009987559 |\n",
      "|    entropy_loss       | -2.08       |\n",
      "|    explained_variance | 0.864       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.123       |\n",
      "|    mean_step_reward   | 0.073852964 |\n",
      "|    n_updates          | 848         |\n",
      "|    policyGradLoss     | -0.00618    |\n",
      "|    value_loss         | 0.795       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 147         |\n",
      "|    total_timesteps    | 1753088     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011114347 |\n",
      "|    entropy_loss       | -2.08       |\n",
      "|    explained_variance | 0.879       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.254       |\n",
      "|    mean_step_reward   | 0.07294898  |\n",
      "|    n_updates          | 852         |\n",
      "|    policyGradLoss     | -0.00962    |\n",
      "|    value_loss         | 0.853       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 157         |\n",
      "|    total_timesteps    | 1761280     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011779644 |\n",
      "|    entropy_loss       | -2.09       |\n",
      "|    explained_variance | 0.823       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.194       |\n",
      "|    mean_step_reward   | 0.07289401  |\n",
      "|    n_updates          | 856         |\n",
      "|    policyGradLoss     | -0.00754    |\n",
      "|    value_loss         | 1.05        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 168         |\n",
      "|    total_timesteps    | 1769472     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018098978 |\n",
      "|    entropy_loss       | -2.1        |\n",
      "|    explained_variance | 0.854       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0808      |\n",
      "|    mean_step_reward   | 0.07373382  |\n",
      "|    n_updates          | 860         |\n",
      "|    policyGradLoss     | -0.00883    |\n",
      "|    value_loss         | 0.794       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 179         |\n",
      "|    total_timesteps    | 1777664     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011148557 |\n",
      "|    entropy_loss       | -2.11       |\n",
      "|    explained_variance | 0.884       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.161       |\n",
      "|    mean_step_reward   | 0.06918031  |\n",
      "|    n_updates          | 864         |\n",
      "|    policyGradLoss     | -0.00853    |\n",
      "|    value_loss         | 0.799       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 189         |\n",
      "|    total_timesteps    | 1785856     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011323877 |\n",
      "|    entropy_loss       | -2.12       |\n",
      "|    explained_variance | 0.841       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.17        |\n",
      "|    mean_step_reward   | 0.06605231  |\n",
      "|    n_updates          | 868         |\n",
      "|    policyGradLoss     | -0.00771    |\n",
      "|    value_loss         | 0.946       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 200         |\n",
      "|    total_timesteps    | 1794048     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011802704 |\n",
      "|    entropy_loss       | -2.09       |\n",
      "|    explained_variance | 0.81        |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.179       |\n",
      "|    mean_step_reward   | 0.07987514  |\n",
      "|    n_updates          | 872         |\n",
      "|    policyGradLoss     | -0.00628    |\n",
      "|    value_loss         | 0.859       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 211         |\n",
      "|    total_timesteps    | 1802240     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011375647 |\n",
      "|    entropy_loss       | -2.11       |\n",
      "|    explained_variance | 0.764       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.233       |\n",
      "|    mean_step_reward   | 0.07523771  |\n",
      "|    n_updates          | 876         |\n",
      "|    policyGradLoss     | 0.00323     |\n",
      "|    value_loss         | 0.989       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 222         |\n",
      "|    total_timesteps    | 1810432     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012486271 |\n",
      "|    entropy_loss       | -2.1        |\n",
      "|    explained_variance | 0.826       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.147       |\n",
      "|    mean_step_reward   | 0.07622202  |\n",
      "|    n_updates          | 880         |\n",
      "|    policyGradLoss     | -0.00886    |\n",
      "|    value_loss         | 0.646       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 232         |\n",
      "|    total_timesteps    | 1818624     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01156863  |\n",
      "|    entropy_loss       | -2.08       |\n",
      "|    explained_variance | 0.865       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0665      |\n",
      "|    mean_step_reward   | 0.079107225 |\n",
      "|    n_updates          | 884         |\n",
      "|    policyGradLoss     | -0.0105     |\n",
      "|    value_loss         | 0.576       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 243         |\n",
      "|    total_timesteps    | 1826816     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011195738 |\n",
      "|    entropy_loss       | -2.05       |\n",
      "|    explained_variance | 0.821       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.175       |\n",
      "|    mean_step_reward   | 0.0784588   |\n",
      "|    n_updates          | 888         |\n",
      "|    policyGradLoss     | -0.00894    |\n",
      "|    value_loss         | 0.613       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 253         |\n",
      "|    total_timesteps    | 1835008     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014081231 |\n",
      "|    entropy_loss       | -2.05       |\n",
      "|    explained_variance | 0.836       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.313       |\n",
      "|    mean_step_reward   | 0.07448253  |\n",
      "|    n_updates          | 892         |\n",
      "|    policyGradLoss     | -0.00871    |\n",
      "|    value_loss         | 0.975       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 264         |\n",
      "|    total_timesteps    | 1843200     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011971284 |\n",
      "|    entropy_loss       | -2.02       |\n",
      "|    explained_variance | 0.823       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.32        |\n",
      "|    mean_step_reward   | 0.08376603  |\n",
      "|    n_updates          | 896         |\n",
      "|    policyGradLoss     | -0.00719    |\n",
      "|    value_loss         | 0.847       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 774          |\n",
      "|    iterations         | 26           |\n",
      "|    time_elapsed       | 275          |\n",
      "|    total_timesteps    | 1851392      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0115177315 |\n",
      "|    entropy_loss       | -2.06        |\n",
      "|    explained_variance | 0.88         |\n",
      "|    learning_rate      | 0.0002       |\n",
      "|    loss               | 0.225        |\n",
      "|    mean_step_reward   | 0.075376034  |\n",
      "|    n_updates          | 900          |\n",
      "|    policyGradLoss     | -0.00704     |\n",
      "|    value_loss         | 0.801        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 286         |\n",
      "|    total_timesteps    | 1859584     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010018179 |\n",
      "|    entropy_loss       | -2.06       |\n",
      "|    explained_variance | 0.858       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.213       |\n",
      "|    mean_step_reward   | 0.07498808  |\n",
      "|    n_updates          | 904         |\n",
      "|    policyGradLoss     | -0.00802    |\n",
      "|    value_loss         | 0.936       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 296         |\n",
      "|    total_timesteps    | 1867776     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010514696 |\n",
      "|    entropy_loss       | -2.06       |\n",
      "|    explained_variance | 0.853       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.165       |\n",
      "|    mean_step_reward   | 0.07472418  |\n",
      "|    n_updates          | 908         |\n",
      "|    policyGradLoss     | -0.00702    |\n",
      "|    value_loss         | 0.715       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 307         |\n",
      "|    total_timesteps    | 1875968     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011600217 |\n",
      "|    entropy_loss       | -2.06       |\n",
      "|    explained_variance | 0.829       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.118       |\n",
      "|    mean_step_reward   | 0.07698755  |\n",
      "|    n_updates          | 912         |\n",
      "|    policyGradLoss     | -0.01       |\n",
      "|    value_loss         | 0.769       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 318         |\n",
      "|    total_timesteps    | 1884160     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010980637 |\n",
      "|    entropy_loss       | -2.08       |\n",
      "|    explained_variance | 0.854       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.189       |\n",
      "|    mean_step_reward   | 0.07472348  |\n",
      "|    n_updates          | 916         |\n",
      "|    policyGradLoss     | -0.00859    |\n",
      "|    value_loss         | 0.753       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 328         |\n",
      "|    total_timesteps    | 1892352     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010560101 |\n",
      "|    entropy_loss       | -2.09       |\n",
      "|    explained_variance | 0.788       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.229       |\n",
      "|    mean_step_reward   | 0.07149902  |\n",
      "|    n_updates          | 920         |\n",
      "|    policyGradLoss     | -0.00621    |\n",
      "|    value_loss         | 1.11        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 339         |\n",
      "|    total_timesteps    | 1900544     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01368993  |\n",
      "|    entropy_loss       | -2.08       |\n",
      "|    explained_variance | 0.822       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0557      |\n",
      "|    mean_step_reward   | 0.082656324 |\n",
      "|    n_updates          | 924         |\n",
      "|    policyGradLoss     | -0.00837    |\n",
      "|    value_loss         | 0.589       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 771        |\n",
      "|    iterations         | 33         |\n",
      "|    time_elapsed       | 350        |\n",
      "|    total_timesteps    | 1908736    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01201616 |\n",
      "|    entropy_loss       | -2.1       |\n",
      "|    explained_variance | 0.876      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | 0.115      |\n",
      "|    mean_step_reward   | 0.07185868 |\n",
      "|    n_updates          | 928        |\n",
      "|    policyGradLoss     | -0.00683   |\n",
      "|    value_loss         | 0.686      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 34          |\n",
      "|    time_elapsed       | 360         |\n",
      "|    total_timesteps    | 1916928     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009284746 |\n",
      "|    entropy_loss       | -2.09       |\n",
      "|    explained_variance | 0.865       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.158       |\n",
      "|    mean_step_reward   | 0.079061344 |\n",
      "|    n_updates          | 932         |\n",
      "|    policyGradLoss     | -0.006      |\n",
      "|    value_loss         | 0.76        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 770        |\n",
      "|    iterations         | 35         |\n",
      "|    time_elapsed       | 371        |\n",
      "|    total_timesteps    | 1925120    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01101031 |\n",
      "|    entropy_loss       | -2.13      |\n",
      "|    explained_variance | 0.86       |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | 0.075      |\n",
      "|    mean_step_reward   | 0.0690469  |\n",
      "|    n_updates          | 936        |\n",
      "|    policyGradLoss     | -0.00749   |\n",
      "|    value_loss         | 0.584      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 36          |\n",
      "|    time_elapsed       | 382         |\n",
      "|    total_timesteps    | 1933312     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012061853 |\n",
      "|    entropy_loss       | -2.1        |\n",
      "|    explained_variance | 0.917       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.076       |\n",
      "|    mean_step_reward   | 0.07654202  |\n",
      "|    n_updates          | 940         |\n",
      "|    policyGradLoss     | -0.00893    |\n",
      "|    value_loss         | 0.526       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 37          |\n",
      "|    time_elapsed       | 393         |\n",
      "|    total_timesteps    | 1941504     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012579808 |\n",
      "|    entropy_loss       | -2.12       |\n",
      "|    explained_variance | 0.857       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0167      |\n",
      "|    mean_step_reward   | 0.07923861  |\n",
      "|    n_updates          | 944         |\n",
      "|    policyGradLoss     | -0.0085     |\n",
      "|    value_loss         | 0.41        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 38          |\n",
      "|    time_elapsed       | 404         |\n",
      "|    total_timesteps    | 1949696     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011718752 |\n",
      "|    entropy_loss       | -2.11       |\n",
      "|    explained_variance | 0.857       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.238       |\n",
      "|    mean_step_reward   | 0.06994817  |\n",
      "|    n_updates          | 948         |\n",
      "|    policyGradLoss     | -0.00729    |\n",
      "|    value_loss         | 0.609       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 39          |\n",
      "|    time_elapsed       | 414         |\n",
      "|    total_timesteps    | 1957888     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010943163 |\n",
      "|    entropy_loss       | -2.07       |\n",
      "|    explained_variance | 0.876       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0794      |\n",
      "|    mean_step_reward   | 0.08129606  |\n",
      "|    n_updates          | 952         |\n",
      "|    policyGradLoss     | -0.00645    |\n",
      "|    value_loss         | 0.598       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 40          |\n",
      "|    time_elapsed       | 425         |\n",
      "|    total_timesteps    | 1966080     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014097934 |\n",
      "|    entropy_loss       | -2.09       |\n",
      "|    explained_variance | 0.839       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.126       |\n",
      "|    mean_step_reward   | 0.07468188  |\n",
      "|    n_updates          | 956         |\n",
      "|    policyGradLoss     | -0.00771    |\n",
      "|    value_loss         | 0.701       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/TNL_6.zip\n",
      "[EVAL] Mean Return: -1467.902, Best Return: -1467.076\n",
      "Saved video to ./runs_smw/videos/step_1966080_mean_-1467.90.mp4\n",
      "\n",
      "=== Round 2 | Learn 327680 steps (Total trained: 1966080) ===\n",
      "Logging to ./runs_smw/tb/tunnel_0\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1131    |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 7       |\n",
      "|    total_timesteps | 1974272 |\n",
      "--------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 904         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 1982464     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011450709 |\n",
      "|    entropy_loss       | -2.08       |\n",
      "|    explained_variance | 0.862       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.147       |\n",
      "|    mean_step_reward   | 0.07587587  |\n",
      "|    n_updates          | 964         |\n",
      "|    policyGradLoss     | -0.00881    |\n",
      "|    value_loss         | 0.581       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 847         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 1990656     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010992931 |\n",
      "|    entropy_loss       | -2.09       |\n",
      "|    explained_variance | 0.893       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.128       |\n",
      "|    mean_step_reward   | 0.07354113  |\n",
      "|    n_updates          | 968         |\n",
      "|    policyGradLoss     | -0.00838    |\n",
      "|    value_loss         | 0.693       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 826         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 1998848     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011275174 |\n",
      "|    entropy_loss       | -2.09       |\n",
      "|    explained_variance | 0.87        |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.199       |\n",
      "|    mean_step_reward   | 0.07986561  |\n",
      "|    n_updates          | 972         |\n",
      "|    policyGradLoss     | -0.00745    |\n",
      "|    value_loss         | 0.73        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 817         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 50          |\n",
      "|    total_timesteps    | 2007040     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011292953 |\n",
      "|    entropy_loss       | -2.09       |\n",
      "|    explained_variance | 0.859       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.23        |\n",
      "|    mean_step_reward   | 0.07371459  |\n",
      "|    n_updates          | 976         |\n",
      "|    policyGradLoss     | -0.00802    |\n",
      "|    value_loss         | 0.846       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 808         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 60          |\n",
      "|    total_timesteps    | 2015232     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011189921 |\n",
      "|    entropy_loss       | -2.07       |\n",
      "|    explained_variance | 0.798       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.215       |\n",
      "|    mean_step_reward   | 0.07993263  |\n",
      "|    n_updates          | 980         |\n",
      "|    policyGradLoss     | -0.00572    |\n",
      "|    value_loss         | 1.16        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 800         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 71          |\n",
      "|    total_timesteps    | 2023424     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010612186 |\n",
      "|    entropy_loss       | -2.07       |\n",
      "|    explained_variance | 0.86        |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.217       |\n",
      "|    mean_step_reward   | 0.080628484 |\n",
      "|    n_updates          | 984         |\n",
      "|    policyGradLoss     | -0.00881    |\n",
      "|    value_loss         | 0.926       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 795         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 82          |\n",
      "|    total_timesteps    | 2031616     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011874155 |\n",
      "|    entropy_loss       | -2.08       |\n",
      "|    explained_variance | 0.866       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0724      |\n",
      "|    mean_step_reward   | 0.08292328  |\n",
      "|    n_updates          | 988         |\n",
      "|    policyGradLoss     | -0.00828    |\n",
      "|    value_loss         | 0.654       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 791         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 93          |\n",
      "|    total_timesteps    | 2039808     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011789057 |\n",
      "|    entropy_loss       | -2.06       |\n",
      "|    explained_variance | 0.851       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.117       |\n",
      "|    mean_step_reward   | 0.078699276 |\n",
      "|    n_updates          | 992         |\n",
      "|    policyGradLoss     | -0.00952    |\n",
      "|    value_loss         | 0.583       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 789         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 103         |\n",
      "|    total_timesteps    | 2048000     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011318985 |\n",
      "|    entropy_loss       | -2.09       |\n",
      "|    explained_variance | 0.85        |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.246       |\n",
      "|    mean_step_reward   | 0.06713942  |\n",
      "|    n_updates          | 996         |\n",
      "|    policyGradLoss     | -0.0046     |\n",
      "|    value_loss         | 0.995       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 114         |\n",
      "|    total_timesteps    | 2056192     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012022883 |\n",
      "|    entropy_loss       | -2.03       |\n",
      "|    explained_variance | 0.849       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.192       |\n",
      "|    mean_step_reward   | 0.07934117  |\n",
      "|    n_updates          | 1000        |\n",
      "|    policyGradLoss     | -0.0101     |\n",
      "|    value_loss         | 0.748       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 125         |\n",
      "|    total_timesteps    | 2064384     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013624436 |\n",
      "|    entropy_loss       | -2.05       |\n",
      "|    explained_variance | 0.844       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0868      |\n",
      "|    mean_step_reward   | 0.07741572  |\n",
      "|    n_updates          | 1004        |\n",
      "|    policyGradLoss     | -0.00915    |\n",
      "|    value_loss         | 0.705       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 135         |\n",
      "|    total_timesteps    | 2072576     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012321742 |\n",
      "|    entropy_loss       | -2.06       |\n",
      "|    explained_variance | 0.871       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.132       |\n",
      "|    mean_step_reward   | 0.08030169  |\n",
      "|    n_updates          | 1008        |\n",
      "|    policyGradLoss     | -0.00578    |\n",
      "|    value_loss         | 0.644       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 146         |\n",
      "|    total_timesteps    | 2080768     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011696679 |\n",
      "|    entropy_loss       | -2.07       |\n",
      "|    explained_variance | 0.899       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.238       |\n",
      "|    mean_step_reward   | 0.078246176 |\n",
      "|    n_updates          | 1012        |\n",
      "|    policyGradLoss     | -0.00737    |\n",
      "|    value_loss         | 0.795       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 157         |\n",
      "|    total_timesteps    | 2088960     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012960833 |\n",
      "|    entropy_loss       | -2.07       |\n",
      "|    explained_variance | 0.885       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.146       |\n",
      "|    mean_step_reward   | 0.0831061   |\n",
      "|    n_updates          | 1016        |\n",
      "|    policyGradLoss     | -0.0105     |\n",
      "|    value_loss         | 0.575       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 167         |\n",
      "|    total_timesteps    | 2097152     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013771206 |\n",
      "|    entropy_loss       | -2.1        |\n",
      "|    explained_variance | 0.897       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.119       |\n",
      "|    mean_step_reward   | 0.083813995 |\n",
      "|    n_updates          | 1020        |\n",
      "|    policyGradLoss     | -0.00826    |\n",
      "|    value_loss         | 0.563       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 178         |\n",
      "|    total_timesteps    | 2105344     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013428608 |\n",
      "|    entropy_loss       | -2.07       |\n",
      "|    explained_variance | 0.871       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.195       |\n",
      "|    mean_step_reward   | 0.07957562  |\n",
      "|    n_updates          | 1024        |\n",
      "|    policyGradLoss     | -0.00955    |\n",
      "|    value_loss         | 0.618       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 189         |\n",
      "|    total_timesteps    | 2113536     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012911458 |\n",
      "|    entropy_loss       | -2.09       |\n",
      "|    explained_variance | 0.875       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0584      |\n",
      "|    mean_step_reward   | 0.08002115  |\n",
      "|    n_updates          | 1028        |\n",
      "|    policyGradLoss     | -0.0111     |\n",
      "|    value_loss         | 0.554       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 199         |\n",
      "|    total_timesteps    | 2121728     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013190381 |\n",
      "|    entropy_loss       | -2.08       |\n",
      "|    explained_variance | 0.863       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.19        |\n",
      "|    mean_step_reward   | 0.0845895   |\n",
      "|    n_updates          | 1032        |\n",
      "|    policyGradLoss     | -0.00747    |\n",
      "|    value_loss         | 0.782       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 210         |\n",
      "|    total_timesteps    | 2129920     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014987453 |\n",
      "|    entropy_loss       | -2.09       |\n",
      "|    explained_variance | 0.858       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0621      |\n",
      "|    mean_step_reward   | 0.078158915 |\n",
      "|    n_updates          | 1036        |\n",
      "|    policyGradLoss     | -0.00746    |\n",
      "|    value_loss         | 0.546       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 221         |\n",
      "|    total_timesteps    | 2138112     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012398131 |\n",
      "|    entropy_loss       | -2.13       |\n",
      "|    explained_variance | 0.875       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.187       |\n",
      "|    mean_step_reward   | 0.073886305 |\n",
      "|    n_updates          | 1040        |\n",
      "|    policyGradLoss     | -0.00709    |\n",
      "|    value_loss         | 0.778       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 232         |\n",
      "|    total_timesteps    | 2146304     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010749797 |\n",
      "|    entropy_loss       | -2.08       |\n",
      "|    explained_variance | 0.873       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.312       |\n",
      "|    mean_step_reward   | 0.07947822  |\n",
      "|    n_updates          | 1044        |\n",
      "|    policyGradLoss     | -0.00828    |\n",
      "|    value_loss         | 0.864       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 774        |\n",
      "|    iterations         | 23         |\n",
      "|    time_elapsed       | 243        |\n",
      "|    total_timesteps    | 2154496    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01208823 |\n",
      "|    entropy_loss       | -2.09      |\n",
      "|    explained_variance | 0.885      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | 0.0132     |\n",
      "|    mean_step_reward   | 0.08212027 |\n",
      "|    n_updates          | 1048       |\n",
      "|    policyGradLoss     | -0.011     |\n",
      "|    value_loss         | 0.444      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 773        |\n",
      "|    iterations         | 24         |\n",
      "|    time_elapsed       | 254        |\n",
      "|    total_timesteps    | 2162688    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.0135183  |\n",
      "|    entropy_loss       | -2.08      |\n",
      "|    explained_variance | 0.887      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | 0.0515     |\n",
      "|    mean_step_reward   | 0.07937968 |\n",
      "|    n_updates          | 1052       |\n",
      "|    policyGradLoss     | -0.00756   |\n",
      "|    value_loss         | 0.516      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 264         |\n",
      "|    total_timesteps    | 2170880     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013515335 |\n",
      "|    entropy_loss       | -2.07       |\n",
      "|    explained_variance | 0.882       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0677      |\n",
      "|    mean_step_reward   | 0.079618245 |\n",
      "|    n_updates          | 1056        |\n",
      "|    policyGradLoss     | -0.00673    |\n",
      "|    value_loss         | 0.543       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 275         |\n",
      "|    total_timesteps    | 2179072     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011994841 |\n",
      "|    entropy_loss       | -2.06       |\n",
      "|    explained_variance | 0.91        |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.126       |\n",
      "|    mean_step_reward   | 0.08359901  |\n",
      "|    n_updates          | 1060        |\n",
      "|    policyGradLoss     | -0.00383    |\n",
      "|    value_loss         | 0.529       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 286         |\n",
      "|    total_timesteps    | 2187264     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012655495 |\n",
      "|    entropy_loss       | -2.05       |\n",
      "|    explained_variance | 0.922       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0433      |\n",
      "|    mean_step_reward   | 0.08517213  |\n",
      "|    n_updates          | 1064        |\n",
      "|    policyGradLoss     | -0.00758    |\n",
      "|    value_loss         | 0.412       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 772        |\n",
      "|    iterations         | 28         |\n",
      "|    time_elapsed       | 297        |\n",
      "|    total_timesteps    | 2195456    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01307839 |\n",
      "|    entropy_loss       | -2.05      |\n",
      "|    explained_variance | 0.895      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | 0.18       |\n",
      "|    mean_step_reward   | 0.08060696 |\n",
      "|    n_updates          | 1068       |\n",
      "|    policyGradLoss     | -0.00887   |\n",
      "|    value_loss         | 0.7        |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 307         |\n",
      "|    total_timesteps    | 2203648     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011701392 |\n",
      "|    entropy_loss       | -2.06       |\n",
      "|    explained_variance | 0.881       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.137       |\n",
      "|    mean_step_reward   | 0.08020733  |\n",
      "|    n_updates          | 1072        |\n",
      "|    policyGradLoss     | -0.0085     |\n",
      "|    value_loss         | 0.626       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 318         |\n",
      "|    total_timesteps    | 2211840     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012220138 |\n",
      "|    entropy_loss       | -2.09       |\n",
      "|    explained_variance | 0.885       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.264       |\n",
      "|    mean_step_reward   | 0.08585311  |\n",
      "|    n_updates          | 1076        |\n",
      "|    policyGradLoss     | -0.00565    |\n",
      "|    value_loss         | 0.945       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 329         |\n",
      "|    total_timesteps    | 2220032     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010568602 |\n",
      "|    entropy_loss       | -2.1        |\n",
      "|    explained_variance | 0.847       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.218       |\n",
      "|    mean_step_reward   | 0.074074045 |\n",
      "|    n_updates          | 1080        |\n",
      "|    policyGradLoss     | -0.0102     |\n",
      "|    value_loss         | 1.03        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 340         |\n",
      "|    total_timesteps    | 2228224     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011047568 |\n",
      "|    entropy_loss       | -2.08       |\n",
      "|    explained_variance | 0.888       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.209       |\n",
      "|    mean_step_reward   | 0.075880736 |\n",
      "|    n_updates          | 1084        |\n",
      "|    policyGradLoss     | -0.0125     |\n",
      "|    value_loss         | 0.812       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 33          |\n",
      "|    time_elapsed       | 350         |\n",
      "|    total_timesteps    | 2236416     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013035253 |\n",
      "|    entropy_loss       | -2.06       |\n",
      "|    explained_variance | 0.886       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0303      |\n",
      "|    mean_step_reward   | 0.08604097  |\n",
      "|    n_updates          | 1088        |\n",
      "|    policyGradLoss     | -0.01       |\n",
      "|    value_loss         | 0.523       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 34          |\n",
      "|    time_elapsed       | 361         |\n",
      "|    total_timesteps    | 2244608     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012454979 |\n",
      "|    entropy_loss       | -2.09       |\n",
      "|    explained_variance | 0.892       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.136       |\n",
      "|    mean_step_reward   | 0.075595014 |\n",
      "|    n_updates          | 1092        |\n",
      "|    policyGradLoss     | -0.00797    |\n",
      "|    value_loss         | 0.821       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 770        |\n",
      "|    iterations         | 35         |\n",
      "|    time_elapsed       | 371        |\n",
      "|    total_timesteps    | 2252800    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01007599 |\n",
      "|    entropy_loss       | -2.07      |\n",
      "|    explained_variance | 0.804      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | 0.15       |\n",
      "|    mean_step_reward   | 0.08805578 |\n",
      "|    n_updates          | 1096       |\n",
      "|    policyGradLoss     | -0.00613   |\n",
      "|    value_loss         | 1.18       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 36          |\n",
      "|    time_elapsed       | 382         |\n",
      "|    total_timesteps    | 2260992     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011409798 |\n",
      "|    entropy_loss       | -2.07       |\n",
      "|    explained_variance | 0.888       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.152       |\n",
      "|    mean_step_reward   | 0.076227725 |\n",
      "|    n_updates          | 1100        |\n",
      "|    policyGradLoss     | -0.007      |\n",
      "|    value_loss         | 0.786       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 37          |\n",
      "|    time_elapsed       | 393         |\n",
      "|    total_timesteps    | 2269184     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015710503 |\n",
      "|    entropy_loss       | -2.08       |\n",
      "|    explained_variance | 0.88        |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0232      |\n",
      "|    mean_step_reward   | 0.08618805  |\n",
      "|    n_updates          | 1104        |\n",
      "|    policyGradLoss     | -0.00844    |\n",
      "|    value_loss         | 0.437       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 38          |\n",
      "|    time_elapsed       | 404         |\n",
      "|    total_timesteps    | 2277376     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014806013 |\n",
      "|    entropy_loss       | -2.07       |\n",
      "|    explained_variance | 0.925       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.00161    |\n",
      "|    mean_step_reward   | 0.07994446  |\n",
      "|    n_updates          | 1108        |\n",
      "|    policyGradLoss     | -0.011      |\n",
      "|    value_loss         | 0.379       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 39          |\n",
      "|    time_elapsed       | 414         |\n",
      "|    total_timesteps    | 2285568     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013160173 |\n",
      "|    entropy_loss       | -2.09       |\n",
      "|    explained_variance | 0.872       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0998      |\n",
      "|    mean_step_reward   | 0.080726415 |\n",
      "|    n_updates          | 1112        |\n",
      "|    policyGradLoss     | -0.00473    |\n",
      "|    value_loss         | 0.436       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 40          |\n",
      "|    time_elapsed       | 425         |\n",
      "|    total_timesteps    | 2293760     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011264926 |\n",
      "|    entropy_loss       | -2.08       |\n",
      "|    explained_variance | 0.89        |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0198      |\n",
      "|    mean_step_reward   | 0.0796054   |\n",
      "|    n_updates          | 1116        |\n",
      "|    policyGradLoss     | -0.0102     |\n",
      "|    value_loss         | 0.5         |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/TNL_7.zip\n",
      "[EVAL] Mean Return: 17.604, Best Return: 17.717\n",
      "Saved video to ./runs_smw/videos/step_2293760_mean_17.60.mp4\n",
      "\n",
      "=== Round 3 | Learn 327680 steps (Total trained: 2293760) ===\n",
      "Logging to ./runs_smw/tb/tunnel_0\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1115    |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 7       |\n",
      "|    total_timesteps | 2301952 |\n",
      "--------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 909         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 2310144     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011228785 |\n",
      "|    entropy_loss       | -2.07       |\n",
      "|    explained_variance | 0.924       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0705      |\n",
      "|    mean_step_reward   | 0.08216121  |\n",
      "|    n_updates          | 1124        |\n",
      "|    policyGradLoss     | -0.00955    |\n",
      "|    value_loss         | 0.462       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 846         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 29          |\n",
      "|    total_timesteps    | 2318336     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011647331 |\n",
      "|    entropy_loss       | -2.03       |\n",
      "|    explained_variance | 0.889       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.168       |\n",
      "|    mean_step_reward   | 0.08499135  |\n",
      "|    n_updates          | 1128        |\n",
      "|    policyGradLoss     | -0.00769    |\n",
      "|    value_loss         | 0.679       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 822         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 2326528     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012722794 |\n",
      "|    entropy_loss       | -2.04       |\n",
      "|    explained_variance | 0.867       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.18        |\n",
      "|    mean_step_reward   | 0.07987827  |\n",
      "|    n_updates          | 1132        |\n",
      "|    policyGradLoss     | -0.00964    |\n",
      "|    value_loss         | 0.778       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 806         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 50          |\n",
      "|    total_timesteps    | 2334720     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016757855 |\n",
      "|    entropy_loss       | -2.06       |\n",
      "|    explained_variance | 0.919       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.00689     |\n",
      "|    mean_step_reward   | 0.085829474 |\n",
      "|    n_updates          | 1136        |\n",
      "|    policyGradLoss     | -0.0119     |\n",
      "|    value_loss         | 0.343       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 798         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 61          |\n",
      "|    total_timesteps    | 2342912     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012749186 |\n",
      "|    entropy_loss       | -2.05       |\n",
      "|    explained_variance | 0.924       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.194       |\n",
      "|    mean_step_reward   | 0.080836795 |\n",
      "|    n_updates          | 1140        |\n",
      "|    policyGradLoss     | -0.00723    |\n",
      "|    value_loss         | 0.771       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 792         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 72          |\n",
      "|    total_timesteps    | 2351104     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015116145 |\n",
      "|    entropy_loss       | -2.05       |\n",
      "|    explained_variance | 0.861       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.266       |\n",
      "|    mean_step_reward   | 0.08583113  |\n",
      "|    n_updates          | 1144        |\n",
      "|    policyGradLoss     | -0.00747    |\n",
      "|    value_loss         | 0.884       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 83          |\n",
      "|    total_timesteps    | 2359296     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012039768 |\n",
      "|    entropy_loss       | -2.04       |\n",
      "|    explained_variance | 0.916       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0946      |\n",
      "|    mean_step_reward   | 0.08682684  |\n",
      "|    n_updates          | 1148        |\n",
      "|    policyGradLoss     | -0.00811    |\n",
      "|    value_loss         | 0.646       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 94          |\n",
      "|    total_timesteps    | 2367488     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011104086 |\n",
      "|    entropy_loss       | -2.04       |\n",
      "|    explained_variance | 0.905       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0767      |\n",
      "|    mean_step_reward   | 0.08933501  |\n",
      "|    n_updates          | 1152        |\n",
      "|    policyGradLoss     | -0.00896    |\n",
      "|    value_loss         | 0.557       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 781        |\n",
      "|    iterations         | 10         |\n",
      "|    time_elapsed       | 104        |\n",
      "|    total_timesteps    | 2375680    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01508587 |\n",
      "|    entropy_loss       | -2.03      |\n",
      "|    explained_variance | 0.905      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | 0.104      |\n",
      "|    mean_step_reward   | 0.08861695 |\n",
      "|    n_updates          | 1156       |\n",
      "|    policyGradLoss     | -0.00906   |\n",
      "|    value_loss         | 0.583      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 780        |\n",
      "|    iterations         | 11         |\n",
      "|    time_elapsed       | 115        |\n",
      "|    total_timesteps    | 2383872    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.0152618  |\n",
      "|    entropy_loss       | -2.03      |\n",
      "|    explained_variance | 0.937      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | 0.0584     |\n",
      "|    mean_step_reward   | 0.08919065 |\n",
      "|    n_updates          | 1160       |\n",
      "|    policyGradLoss     | -0.0112    |\n",
      "|    value_loss         | 0.412      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 126         |\n",
      "|    total_timesteps    | 2392064     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016277192 |\n",
      "|    entropy_loss       | -2.06       |\n",
      "|    explained_variance | 0.918       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0125      |\n",
      "|    mean_step_reward   | 0.08044336  |\n",
      "|    n_updates          | 1164        |\n",
      "|    policyGradLoss     | -0.00993    |\n",
      "|    value_loss         | 0.438       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 136         |\n",
      "|    total_timesteps    | 2400256     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013824469 |\n",
      "|    entropy_loss       | -2.02       |\n",
      "|    explained_variance | 0.855       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0604      |\n",
      "|    mean_step_reward   | 0.08458261  |\n",
      "|    n_updates          | 1168        |\n",
      "|    policyGradLoss     | -0.0118     |\n",
      "|    value_loss         | 0.678       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 147         |\n",
      "|    total_timesteps    | 2408448     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01493025  |\n",
      "|    entropy_loss       | -2.02       |\n",
      "|    explained_variance | 0.869       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.138       |\n",
      "|    mean_step_reward   | 0.078969814 |\n",
      "|    n_updates          | 1172        |\n",
      "|    policyGradLoss     | -0.00927    |\n",
      "|    value_loss         | 0.863       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 778        |\n",
      "|    iterations         | 15         |\n",
      "|    time_elapsed       | 157        |\n",
      "|    total_timesteps    | 2416640    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.0123216  |\n",
      "|    entropy_loss       | -2.03      |\n",
      "|    explained_variance | 0.816      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | 0.041      |\n",
      "|    mean_step_reward   | 0.08116989 |\n",
      "|    n_updates          | 1176       |\n",
      "|    policyGradLoss     | -0.00868   |\n",
      "|    value_loss         | 0.79       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 168         |\n",
      "|    total_timesteps    | 2424832     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012734003 |\n",
      "|    entropy_loss       | -2.06       |\n",
      "|    explained_variance | 0.842       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0456      |\n",
      "|    mean_step_reward   | 0.07851672  |\n",
      "|    n_updates          | 1180        |\n",
      "|    policyGradLoss     | -0.0112     |\n",
      "|    value_loss         | 0.553       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 179         |\n",
      "|    total_timesteps    | 2433024     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013339057 |\n",
      "|    entropy_loss       | -2.08       |\n",
      "|    explained_variance | 0.831       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.232       |\n",
      "|    mean_step_reward   | 0.07417376  |\n",
      "|    n_updates          | 1184        |\n",
      "|    policyGradLoss     | -0.00678    |\n",
      "|    value_loss         | 0.77        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 190         |\n",
      "|    total_timesteps    | 2441216     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014053501 |\n",
      "|    entropy_loss       | -2.08       |\n",
      "|    explained_variance | 0.853       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0848      |\n",
      "|    mean_step_reward   | 0.07815846  |\n",
      "|    n_updates          | 1188        |\n",
      "|    policyGradLoss     | -0.00879    |\n",
      "|    value_loss         | 0.579       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 201         |\n",
      "|    total_timesteps    | 2449408     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011971496 |\n",
      "|    entropy_loss       | -2.1        |\n",
      "|    explained_variance | 0.826       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.00381     |\n",
      "|    mean_step_reward   | 0.08070686  |\n",
      "|    n_updates          | 1192        |\n",
      "|    policyGradLoss     | -0.00977    |\n",
      "|    value_loss         | 0.433       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 211         |\n",
      "|    total_timesteps    | 2457600     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013875734 |\n",
      "|    entropy_loss       | -2.08       |\n",
      "|    explained_variance | 0.886       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.048       |\n",
      "|    mean_step_reward   | 0.0799725   |\n",
      "|    n_updates          | 1196        |\n",
      "|    policyGradLoss     | -0.0112     |\n",
      "|    value_loss         | 0.498       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 222         |\n",
      "|    total_timesteps    | 2465792     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012419265 |\n",
      "|    entropy_loss       | -2.1        |\n",
      "|    explained_variance | 0.878       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.219       |\n",
      "|    mean_step_reward   | 0.084352896 |\n",
      "|    n_updates          | 1200        |\n",
      "|    policyGradLoss     | -0.00631    |\n",
      "|    value_loss         | 0.606       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 233         |\n",
      "|    total_timesteps    | 2473984     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016604753 |\n",
      "|    entropy_loss       | -2.05       |\n",
      "|    explained_variance | 0.934       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0793      |\n",
      "|    mean_step_reward   | 0.08428724  |\n",
      "|    n_updates          | 1204        |\n",
      "|    policyGradLoss     | -0.00951    |\n",
      "|    value_loss         | 0.355       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 243         |\n",
      "|    total_timesteps    | 2482176     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017569736 |\n",
      "|    entropy_loss       | -2.09       |\n",
      "|    explained_variance | 0.93        |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.00168     |\n",
      "|    mean_step_reward   | 0.08154057  |\n",
      "|    n_updates          | 1208        |\n",
      "|    policyGradLoss     | -0.0107     |\n",
      "|    value_loss         | 0.34        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 254         |\n",
      "|    total_timesteps    | 2490368     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014801211 |\n",
      "|    entropy_loss       | -2.07       |\n",
      "|    explained_variance | 0.933       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0128      |\n",
      "|    mean_step_reward   | 0.08356702  |\n",
      "|    n_updates          | 1212        |\n",
      "|    policyGradLoss     | -0.0103     |\n",
      "|    value_loss         | 0.239       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 265         |\n",
      "|    total_timesteps    | 2498560     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012282787 |\n",
      "|    entropy_loss       | -2.1        |\n",
      "|    explained_variance | 0.937       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.00632     |\n",
      "|    mean_step_reward   | 0.07921627  |\n",
      "|    n_updates          | 1216        |\n",
      "|    policyGradLoss     | -0.00774    |\n",
      "|    value_loss         | 0.301       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 275         |\n",
      "|    total_timesteps    | 2506752     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016728766 |\n",
      "|    entropy_loss       | -2.05       |\n",
      "|    explained_variance | 0.925       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.056       |\n",
      "|    mean_step_reward   | 0.08706932  |\n",
      "|    n_updates          | 1220        |\n",
      "|    policyGradLoss     | -0.00827    |\n",
      "|    value_loss         | 0.513       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 286         |\n",
      "|    total_timesteps    | 2514944     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011495892 |\n",
      "|    entropy_loss       | -2.07       |\n",
      "|    explained_variance | 0.893       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.377       |\n",
      "|    mean_step_reward   | 0.08296323  |\n",
      "|    n_updates          | 1224        |\n",
      "|    policyGradLoss     | -0.00579    |\n",
      "|    value_loss         | 0.899       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 297         |\n",
      "|    total_timesteps    | 2523136     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014534783 |\n",
      "|    entropy_loss       | -2.05       |\n",
      "|    explained_variance | 0.924       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0505      |\n",
      "|    mean_step_reward   | 0.08018254  |\n",
      "|    n_updates          | 1228        |\n",
      "|    policyGradLoss     | -0.00863    |\n",
      "|    value_loss         | 0.432       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 308         |\n",
      "|    total_timesteps    | 2531328     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011741159 |\n",
      "|    entropy_loss       | -2.09       |\n",
      "|    explained_variance | 0.914       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0343      |\n",
      "|    mean_step_reward   | 0.07892306  |\n",
      "|    n_updates          | 1232        |\n",
      "|    policyGradLoss     | -0.0058     |\n",
      "|    value_loss         | 0.561       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 319         |\n",
      "|    total_timesteps    | 2539520     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013942951 |\n",
      "|    entropy_loss       | -2.04       |\n",
      "|    explained_variance | 0.904       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.147       |\n",
      "|    mean_step_reward   | 0.07947484  |\n",
      "|    n_updates          | 1236        |\n",
      "|    policyGradLoss     | -0.00602    |\n",
      "|    value_loss         | 0.853       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 330         |\n",
      "|    total_timesteps    | 2547712     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013045478 |\n",
      "|    entropy_loss       | -2.06       |\n",
      "|    explained_variance | 0.916       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0544      |\n",
      "|    mean_step_reward   | 0.07481852  |\n",
      "|    n_updates          | 1240        |\n",
      "|    policyGradLoss     | -0.00954    |\n",
      "|    value_loss         | 0.533       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 341         |\n",
      "|    total_timesteps    | 2555904     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013619108 |\n",
      "|    entropy_loss       | -2.06       |\n",
      "|    explained_variance | 0.924       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.126       |\n",
      "|    mean_step_reward   | 0.08042586  |\n",
      "|    n_updates          | 1244        |\n",
      "|    policyGradLoss     | -0.00739    |\n",
      "|    value_loss         | 0.503       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 33          |\n",
      "|    time_elapsed       | 351         |\n",
      "|    total_timesteps    | 2564096     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013258221 |\n",
      "|    entropy_loss       | -2.07       |\n",
      "|    explained_variance | 0.942       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.211       |\n",
      "|    mean_step_reward   | 0.076276615 |\n",
      "|    n_updates          | 1248        |\n",
      "|    policyGradLoss     | -0.0103     |\n",
      "|    value_loss         | 0.407       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 34          |\n",
      "|    time_elapsed       | 362         |\n",
      "|    total_timesteps    | 2572288     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013813842 |\n",
      "|    entropy_loss       | -2.06       |\n",
      "|    explained_variance | 0.898       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.123       |\n",
      "|    mean_step_reward   | 0.07071116  |\n",
      "|    n_updates          | 1252        |\n",
      "|    policyGradLoss     | -0.00776    |\n",
      "|    value_loss         | 0.558       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 35          |\n",
      "|    time_elapsed       | 373         |\n",
      "|    total_timesteps    | 2580480     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012113822 |\n",
      "|    entropy_loss       | -2.07       |\n",
      "|    explained_variance | 0.918       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.00837     |\n",
      "|    mean_step_reward   | 0.0775432   |\n",
      "|    n_updates          | 1256        |\n",
      "|    policyGradLoss     | -0.0102     |\n",
      "|    value_loss         | 0.404       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 36          |\n",
      "|    time_elapsed       | 384         |\n",
      "|    total_timesteps    | 2588672     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015718967 |\n",
      "|    entropy_loss       | -2.04       |\n",
      "|    explained_variance | 0.931       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0155      |\n",
      "|    mean_step_reward   | 0.08110845  |\n",
      "|    n_updates          | 1260        |\n",
      "|    policyGradLoss     | -0.0125     |\n",
      "|    value_loss         | 0.429       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 37          |\n",
      "|    time_elapsed       | 395         |\n",
      "|    total_timesteps    | 2596864     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013019286 |\n",
      "|    entropy_loss       | -2.09       |\n",
      "|    explained_variance | 0.911       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0913      |\n",
      "|    mean_step_reward   | 0.07826854  |\n",
      "|    n_updates          | 1264        |\n",
      "|    policyGradLoss     | -0.00984    |\n",
      "|    value_loss         | 0.674       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 38          |\n",
      "|    time_elapsed       | 406         |\n",
      "|    total_timesteps    | 2605056     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012114522 |\n",
      "|    entropy_loss       | -2.04       |\n",
      "|    explained_variance | 0.914       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.158       |\n",
      "|    mean_step_reward   | 0.08252862  |\n",
      "|    n_updates          | 1268        |\n",
      "|    policyGradLoss     | -0.0065     |\n",
      "|    value_loss         | 0.745       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 39          |\n",
      "|    time_elapsed       | 417         |\n",
      "|    total_timesteps    | 2613248     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013236846 |\n",
      "|    entropy_loss       | -2.03       |\n",
      "|    explained_variance | 0.922       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.012       |\n",
      "|    mean_step_reward   | 0.08723122  |\n",
      "|    n_updates          | 1272        |\n",
      "|    policyGradLoss     | -0.00995    |\n",
      "|    value_loss         | 0.437       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 765         |\n",
      "|    iterations         | 40          |\n",
      "|    time_elapsed       | 427         |\n",
      "|    total_timesteps    | 2621440     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017962433 |\n",
      "|    entropy_loss       | -2.07       |\n",
      "|    explained_variance | 0.888       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.179       |\n",
      "|    mean_step_reward   | 0.077682786 |\n",
      "|    n_updates          | 1276        |\n",
      "|    policyGradLoss     | -0.00706    |\n",
      "|    value_loss         | 0.934       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/TNL_8.zip\n",
      "[EVAL] Mean Return: -1266.321, Best Return: -1265.443\n",
      "Saved video to ./runs_smw/videos/step_2621440_mean_-1266.32.mp4\n",
      "\n",
      "=== Round 4 | Learn 327680 steps (Total trained: 2621440) ===\n",
      "Logging to ./runs_smw/tb/tunnel_0\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1091    |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 7       |\n",
      "|    total_timesteps | 2629632 |\n",
      "--------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 910         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 2637824     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016054943 |\n",
      "|    entropy_loss       | -2.08       |\n",
      "|    explained_variance | 0.914       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.00388    |\n",
      "|    mean_step_reward   | 0.085739955 |\n",
      "|    n_updates          | 1284        |\n",
      "|    policyGradLoss     | -0.0118     |\n",
      "|    value_loss         | 0.352       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 862         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 2646016     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012220191 |\n",
      "|    entropy_loss       | -2.05       |\n",
      "|    explained_variance | 0.89        |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.275       |\n",
      "|    mean_step_reward   | 0.07856087  |\n",
      "|    n_updates          | 1288        |\n",
      "|    policyGradLoss     | -0.00674    |\n",
      "|    value_loss         | 0.865       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 832         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 2654208     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012767384 |\n",
      "|    entropy_loss       | -2.05       |\n",
      "|    explained_variance | 0.868       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.12        |\n",
      "|    mean_step_reward   | 0.088304974 |\n",
      "|    n_updates          | 1292        |\n",
      "|    policyGradLoss     | -0.00844    |\n",
      "|    value_loss         | 0.642       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 808         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 50          |\n",
      "|    total_timesteps    | 2662400     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015692925 |\n",
      "|    entropy_loss       | -2.03       |\n",
      "|    explained_variance | 0.912       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0676      |\n",
      "|    mean_step_reward   | 0.07919216  |\n",
      "|    n_updates          | 1296        |\n",
      "|    policyGradLoss     | -0.00952    |\n",
      "|    value_loss         | 0.492       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 801         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 61          |\n",
      "|    total_timesteps    | 2670592     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014845075 |\n",
      "|    entropy_loss       | -2.07       |\n",
      "|    explained_variance | 0.92        |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0519      |\n",
      "|    mean_step_reward   | 0.08207181  |\n",
      "|    n_updates          | 1300        |\n",
      "|    policyGradLoss     | -0.00987    |\n",
      "|    value_loss         | 0.417       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 792         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 72          |\n",
      "|    total_timesteps    | 2678784     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015577121 |\n",
      "|    entropy_loss       | -2.04       |\n",
      "|    explained_variance | 0.946       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0105      |\n",
      "|    mean_step_reward   | 0.08252759  |\n",
      "|    n_updates          | 1304        |\n",
      "|    policyGradLoss     | -0.00967    |\n",
      "|    value_loss         | 0.35        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 83          |\n",
      "|    total_timesteps    | 2686976     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015248688 |\n",
      "|    entropy_loss       | -2.01       |\n",
      "|    explained_variance | 0.933       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.00859    |\n",
      "|    mean_step_reward   | 0.09638546  |\n",
      "|    n_updates          | 1308        |\n",
      "|    policyGradLoss     | -0.0115     |\n",
      "|    value_loss         | 0.345       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 93          |\n",
      "|    total_timesteps    | 2695168     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014426107 |\n",
      "|    entropy_loss       | -1.98       |\n",
      "|    explained_variance | 0.922       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0627      |\n",
      "|    mean_step_reward   | 0.084893286 |\n",
      "|    n_updates          | 1312        |\n",
      "|    policyGradLoss     | -0.00717    |\n",
      "|    value_loss         | 0.602       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 104         |\n",
      "|    total_timesteps    | 2703360     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017081816 |\n",
      "|    entropy_loss       | -1.97       |\n",
      "|    explained_variance | 0.904       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0575      |\n",
      "|    mean_step_reward   | 0.09107246  |\n",
      "|    n_updates          | 1316        |\n",
      "|    policyGradLoss     | -0.00798    |\n",
      "|    value_loss         | 0.421       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 776        |\n",
      "|    iterations         | 11         |\n",
      "|    time_elapsed       | 116        |\n",
      "|    total_timesteps    | 2711552    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01400394 |\n",
      "|    entropy_loss       | -2         |\n",
      "|    explained_variance | 0.94       |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | 0.016      |\n",
      "|    mean_step_reward   | 0.08692761 |\n",
      "|    n_updates          | 1320       |\n",
      "|    policyGradLoss     | -0.0105    |\n",
      "|    value_loss         | 0.412      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 126         |\n",
      "|    total_timesteps    | 2719744     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015612956 |\n",
      "|    entropy_loss       | -1.97       |\n",
      "|    explained_variance | 0.948       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0149     |\n",
      "|    mean_step_reward   | 0.09445813  |\n",
      "|    n_updates          | 1324        |\n",
      "|    policyGradLoss     | -0.0111     |\n",
      "|    value_loss         | 0.304       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 774          |\n",
      "|    iterations         | 13           |\n",
      "|    time_elapsed       | 137          |\n",
      "|    total_timesteps    | 2727936      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0145839155 |\n",
      "|    entropy_loss       | -1.97        |\n",
      "|    explained_variance | 0.944        |\n",
      "|    learning_rate      | 0.0002       |\n",
      "|    loss               | 0.0776       |\n",
      "|    mean_step_reward   | 0.088612795  |\n",
      "|    n_updates          | 1328         |\n",
      "|    policyGradLoss     | -0.00871     |\n",
      "|    value_loss         | 0.5          |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 148         |\n",
      "|    total_timesteps    | 2736128     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014913436 |\n",
      "|    entropy_loss       | -1.97       |\n",
      "|    explained_variance | 0.93        |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0393      |\n",
      "|    mean_step_reward   | 0.08702125  |\n",
      "|    n_updates          | 1332        |\n",
      "|    policyGradLoss     | -0.00999    |\n",
      "|    value_loss         | 0.535       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 159         |\n",
      "|    total_timesteps    | 2744320     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012862394 |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.921       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.238       |\n",
      "|    mean_step_reward   | 0.08283617  |\n",
      "|    n_updates          | 1336        |\n",
      "|    policyGradLoss     | -0.00668    |\n",
      "|    value_loss         | 0.654       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 170         |\n",
      "|    total_timesteps    | 2752512     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014679831 |\n",
      "|    entropy_loss       | -1.97       |\n",
      "|    explained_variance | 0.905       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0123      |\n",
      "|    mean_step_reward   | 0.08760229  |\n",
      "|    n_updates          | 1340        |\n",
      "|    policyGradLoss     | -0.0076     |\n",
      "|    value_loss         | 0.469       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 181         |\n",
      "|    total_timesteps    | 2760704     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013198612 |\n",
      "|    entropy_loss       | -1.97       |\n",
      "|    explained_variance | 0.907       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.108       |\n",
      "|    mean_step_reward   | 0.08407998  |\n",
      "|    n_updates          | 1344        |\n",
      "|    policyGradLoss     | -0.0102     |\n",
      "|    value_loss         | 0.672       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 191         |\n",
      "|    total_timesteps    | 2768896     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012344686 |\n",
      "|    entropy_loss       | -1.99       |\n",
      "|    explained_variance | 0.885       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0567      |\n",
      "|    mean_step_reward   | 0.09528048  |\n",
      "|    n_updates          | 1348        |\n",
      "|    policyGradLoss     | -0.00647    |\n",
      "|    value_loss         | 0.692       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 202         |\n",
      "|    total_timesteps    | 2777088     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015782371 |\n",
      "|    entropy_loss       | -1.97       |\n",
      "|    explained_variance | 0.898       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0798      |\n",
      "|    mean_step_reward   | 0.082068846 |\n",
      "|    n_updates          | 1352        |\n",
      "|    policyGradLoss     | -0.0111     |\n",
      "|    value_loss         | 0.665       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 213         |\n",
      "|    total_timesteps    | 2785280     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013642513 |\n",
      "|    entropy_loss       | -1.99       |\n",
      "|    explained_variance | 0.932       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0884      |\n",
      "|    mean_step_reward   | 0.08886491  |\n",
      "|    n_updates          | 1356        |\n",
      "|    policyGradLoss     | -0.00958    |\n",
      "|    value_loss         | 0.475       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 223         |\n",
      "|    total_timesteps    | 2793472     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011322627 |\n",
      "|    entropy_loss       | -2          |\n",
      "|    explained_variance | 0.9         |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.112       |\n",
      "|    mean_step_reward   | 0.0837255   |\n",
      "|    n_updates          | 1360        |\n",
      "|    policyGradLoss     | -0.00556    |\n",
      "|    value_loss         | 0.533       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 768        |\n",
      "|    iterations         | 22         |\n",
      "|    time_elapsed       | 234        |\n",
      "|    total_timesteps    | 2801664    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01151852 |\n",
      "|    entropy_loss       | -1.99      |\n",
      "|    explained_variance | 0.882      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | 0.0819     |\n",
      "|    mean_step_reward   | 0.09689601 |\n",
      "|    n_updates          | 1364       |\n",
      "|    policyGradLoss     | -0.00546   |\n",
      "|    value_loss         | 0.668      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 245         |\n",
      "|    total_timesteps    | 2809856     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013566978 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.889       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.163       |\n",
      "|    mean_step_reward   | 0.09350015  |\n",
      "|    n_updates          | 1368        |\n",
      "|    policyGradLoss     | -0.00965    |\n",
      "|    value_loss         | 0.692       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 256         |\n",
      "|    total_timesteps    | 2818048     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011866422 |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.905       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.154       |\n",
      "|    mean_step_reward   | 0.08992981  |\n",
      "|    n_updates          | 1372        |\n",
      "|    policyGradLoss     | -0.0075     |\n",
      "|    value_loss         | 0.727       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 267         |\n",
      "|    total_timesteps    | 2826240     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012908641 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.87        |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.244       |\n",
      "|    mean_step_reward   | 0.09323782  |\n",
      "|    n_updates          | 1376        |\n",
      "|    policyGradLoss     | -0.00849    |\n",
      "|    value_loss         | 0.683       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 277         |\n",
      "|    total_timesteps    | 2834432     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012756908 |\n",
      "|    entropy_loss       | -1.98       |\n",
      "|    explained_variance | 0.933       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0219      |\n",
      "|    mean_step_reward   | 0.09401943  |\n",
      "|    n_updates          | 1380        |\n",
      "|    policyGradLoss     | -0.0113     |\n",
      "|    value_loss         | 0.444       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 288         |\n",
      "|    total_timesteps    | 2842624     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013205961 |\n",
      "|    entropy_loss       | -1.98       |\n",
      "|    explained_variance | 0.908       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0954      |\n",
      "|    mean_step_reward   | 0.09316016  |\n",
      "|    n_updates          | 1384        |\n",
      "|    policyGradLoss     | -0.0109     |\n",
      "|    value_loss         | 0.54        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 299         |\n",
      "|    total_timesteps    | 2850816     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015692241 |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.92        |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0287      |\n",
      "|    mean_step_reward   | 0.08747244  |\n",
      "|    n_updates          | 1388        |\n",
      "|    policyGradLoss     | -0.0113     |\n",
      "|    value_loss         | 0.481       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 309         |\n",
      "|    total_timesteps    | 2859008     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012989912 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.927       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0294      |\n",
      "|    mean_step_reward   | 0.09424699  |\n",
      "|    n_updates          | 1392        |\n",
      "|    policyGradLoss     | -0.0126     |\n",
      "|    value_loss         | 0.351       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 765         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 320         |\n",
      "|    total_timesteps    | 2867200     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013153813 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.932       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0846      |\n",
      "|    mean_step_reward   | 0.08986661  |\n",
      "|    n_updates          | 1396        |\n",
      "|    policyGradLoss     | -0.00771    |\n",
      "|    value_loss         | 0.536       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 765        |\n",
      "|    iterations         | 31         |\n",
      "|    time_elapsed       | 331        |\n",
      "|    total_timesteps    | 2875392    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.0131009  |\n",
      "|    entropy_loss       | -1.94      |\n",
      "|    explained_variance | 0.883      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | 0.0524     |\n",
      "|    mean_step_reward   | 0.09015304 |\n",
      "|    n_updates          | 1400       |\n",
      "|    policyGradLoss     | -0.00639   |\n",
      "|    value_loss         | 0.605      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 765         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 342         |\n",
      "|    total_timesteps    | 2883584     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013366926 |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.924       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.134       |\n",
      "|    mean_step_reward   | 0.091410965 |\n",
      "|    n_updates          | 1404        |\n",
      "|    policyGradLoss     | -0.0101     |\n",
      "|    value_loss         | 0.499       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 765         |\n",
      "|    iterations         | 33          |\n",
      "|    time_elapsed       | 353         |\n",
      "|    total_timesteps    | 2891776     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013850171 |\n",
      "|    entropy_loss       | -1.98       |\n",
      "|    explained_variance | 0.907       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0332      |\n",
      "|    mean_step_reward   | 0.09419297  |\n",
      "|    n_updates          | 1408        |\n",
      "|    policyGradLoss     | -0.00707    |\n",
      "|    value_loss         | 0.647       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 764         |\n",
      "|    iterations         | 34          |\n",
      "|    time_elapsed       | 364         |\n",
      "|    total_timesteps    | 2899968     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012350302 |\n",
      "|    entropy_loss       | -1.97       |\n",
      "|    explained_variance | 0.917       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0349      |\n",
      "|    mean_step_reward   | 0.08885953  |\n",
      "|    n_updates          | 1412        |\n",
      "|    policyGradLoss     | -0.0103     |\n",
      "|    value_loss         | 0.42        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 765         |\n",
      "|    iterations         | 35          |\n",
      "|    time_elapsed       | 374         |\n",
      "|    total_timesteps    | 2908160     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015280021 |\n",
      "|    entropy_loss       | -1.99       |\n",
      "|    explained_variance | 0.896       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.129       |\n",
      "|    mean_step_reward   | 0.08581793  |\n",
      "|    n_updates          | 1416        |\n",
      "|    policyGradLoss     | -0.0102     |\n",
      "|    value_loss         | 0.537       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 764         |\n",
      "|    iterations         | 36          |\n",
      "|    time_elapsed       | 385         |\n",
      "|    total_timesteps    | 2916352     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013260128 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.908       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.135       |\n",
      "|    mean_step_reward   | 0.09010254  |\n",
      "|    n_updates          | 1420        |\n",
      "|    policyGradLoss     | -0.00705    |\n",
      "|    value_loss         | 0.624       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 764         |\n",
      "|    iterations         | 37          |\n",
      "|    time_elapsed       | 396         |\n",
      "|    total_timesteps    | 2924544     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013317684 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.929       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.157       |\n",
      "|    mean_step_reward   | 0.09329167  |\n",
      "|    n_updates          | 1424        |\n",
      "|    policyGradLoss     | -0.00746    |\n",
      "|    value_loss         | 0.587       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 764         |\n",
      "|    iterations         | 38          |\n",
      "|    time_elapsed       | 407         |\n",
      "|    total_timesteps    | 2932736     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015517505 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.922       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.175       |\n",
      "|    mean_step_reward   | 0.09075339  |\n",
      "|    n_updates          | 1428        |\n",
      "|    policyGradLoss     | -0.00874    |\n",
      "|    value_loss         | 0.709       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 764         |\n",
      "|    iterations         | 39          |\n",
      "|    time_elapsed       | 417         |\n",
      "|    total_timesteps    | 2940928     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019067649 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.954       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.00807    |\n",
      "|    mean_step_reward   | 0.09302923  |\n",
      "|    n_updates          | 1432        |\n",
      "|    policyGradLoss     | -0.0139     |\n",
      "|    value_loss         | 0.305       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 763         |\n",
      "|    iterations         | 40          |\n",
      "|    time_elapsed       | 429         |\n",
      "|    total_timesteps    | 2949120     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018590044 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.944       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0777      |\n",
      "|    mean_step_reward   | 0.09750893  |\n",
      "|    n_updates          | 1436        |\n",
      "|    policyGradLoss     | -0.00817    |\n",
      "|    value_loss         | 0.335       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/TNL_9.zip\n",
      "[EVAL] Mean Return: -59658.954, Best Return: -59654.252\n",
      "Saved video to ./runs_smw/videos/step_2949120_mean_-59658.95.mp4\n",
      "\n",
      "=== Round 5 | Learn 327680 steps (Total trained: 2949120) ===\n",
      "Logging to ./runs_smw/tb/tunnel_0\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1073    |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 7       |\n",
      "|    total_timesteps | 2957312 |\n",
      "--------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 880         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 2965504     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015108988 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.945       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0151      |\n",
      "|    mean_step_reward   | 0.09668457  |\n",
      "|    n_updates          | 1444        |\n",
      "|    policyGradLoss     | -0.0107     |\n",
      "|    value_loss         | 0.323       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 848        |\n",
      "|    iterations         | 3          |\n",
      "|    time_elapsed       | 28         |\n",
      "|    total_timesteps    | 2973696    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01723313 |\n",
      "|    entropy_loss       | -1.85      |\n",
      "|    explained_variance | 0.934      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | -0.0133    |\n",
      "|    mean_step_reward   | 0.09505989 |\n",
      "|    n_updates          | 1448       |\n",
      "|    policyGradLoss     | -0.0109    |\n",
      "|    value_loss         | 0.27       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 823        |\n",
      "|    iterations         | 4          |\n",
      "|    time_elapsed       | 39         |\n",
      "|    total_timesteps    | 2981888    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01693618 |\n",
      "|    entropy_loss       | -1.88      |\n",
      "|    explained_variance | 0.934      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | -0.0191    |\n",
      "|    mean_step_reward   | 0.09784357 |\n",
      "|    n_updates          | 1452       |\n",
      "|    policyGradLoss     | -0.00662   |\n",
      "|    value_loss         | 0.274      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 808         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 50          |\n",
      "|    total_timesteps    | 2990080     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014912227 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.919       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.039       |\n",
      "|    mean_step_reward   | 0.099764936 |\n",
      "|    n_updates          | 1456        |\n",
      "|    policyGradLoss     | -0.00687    |\n",
      "|    value_loss         | 0.557       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 798        |\n",
      "|    iterations         | 6          |\n",
      "|    time_elapsed       | 61         |\n",
      "|    total_timesteps    | 2998272    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01569872 |\n",
      "|    entropy_loss       | -1.88      |\n",
      "|    explained_variance | 0.956      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | -0.00519   |\n",
      "|    mean_step_reward   | 0.09879704 |\n",
      "|    n_updates          | 1460       |\n",
      "|    policyGradLoss     | -0.0105    |\n",
      "|    value_loss         | 0.315      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 793        |\n",
      "|    iterations         | 7          |\n",
      "|    time_elapsed       | 72         |\n",
      "|    total_timesteps    | 3006464    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01248838 |\n",
      "|    entropy_loss       | -1.92      |\n",
      "|    explained_variance | 0.932      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | 0.121      |\n",
      "|    mean_step_reward   | 0.08976108 |\n",
      "|    n_updates          | 1464       |\n",
      "|    policyGradLoss     | -0.00767   |\n",
      "|    value_loss         | 0.529      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 788         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 83          |\n",
      "|    total_timesteps    | 3014656     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016171671 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.936       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0451      |\n",
      "|    mean_step_reward   | 0.10069117  |\n",
      "|    n_updates          | 1468        |\n",
      "|    policyGradLoss     | -0.00948    |\n",
      "|    value_loss         | 0.459       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 93          |\n",
      "|    total_timesteps    | 3022848     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014480023 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.906       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.245       |\n",
      "|    mean_step_reward   | 0.08940528  |\n",
      "|    n_updates          | 1472        |\n",
      "|    policyGradLoss     | -0.0079     |\n",
      "|    value_loss         | 0.899       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 104         |\n",
      "|    total_timesteps    | 3031040     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014544668 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.823       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.575       |\n",
      "|    mean_step_reward   | 0.10325321  |\n",
      "|    n_updates          | 1476        |\n",
      "|    policyGradLoss     | -0.00256    |\n",
      "|    value_loss         | 1.22        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 114         |\n",
      "|    total_timesteps    | 3039232     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016553978 |\n",
      "|    entropy_loss       | -1.98       |\n",
      "|    explained_variance | 0.917       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.266       |\n",
      "|    mean_step_reward   | 0.09288682  |\n",
      "|    n_updates          | 1480        |\n",
      "|    policyGradLoss     | -0.0102     |\n",
      "|    value_loss         | 0.649       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 125         |\n",
      "|    total_timesteps    | 3047424     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013800333 |\n",
      "|    entropy_loss       | -2          |\n",
      "|    explained_variance | 0.911       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.149       |\n",
      "|    mean_step_reward   | 0.08481168  |\n",
      "|    n_updates          | 1484        |\n",
      "|    policyGradLoss     | -0.00802    |\n",
      "|    value_loss         | 0.77        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 136         |\n",
      "|    total_timesteps    | 3055616     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014158277 |\n",
      "|    entropy_loss       | -2          |\n",
      "|    explained_variance | 0.907       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.132       |\n",
      "|    mean_step_reward   | 0.08776903  |\n",
      "|    n_updates          | 1488        |\n",
      "|    policyGradLoss     | -0.007      |\n",
      "|    value_loss         | 0.731       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 147         |\n",
      "|    total_timesteps    | 3063808     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012393266 |\n",
      "|    entropy_loss       | -2.02       |\n",
      "|    explained_variance | 0.9         |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.111       |\n",
      "|    mean_step_reward   | 0.080077775 |\n",
      "|    n_updates          | 1492        |\n",
      "|    policyGradLoss     | -0.00817    |\n",
      "|    value_loss         | 0.73        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 774        |\n",
      "|    iterations         | 15         |\n",
      "|    time_elapsed       | 158        |\n",
      "|    total_timesteps    | 3072000    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01148753 |\n",
      "|    entropy_loss       | -2.03      |\n",
      "|    explained_variance | 0.878      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | 0.113      |\n",
      "|    mean_step_reward   | 0.09482779 |\n",
      "|    n_updates          | 1496       |\n",
      "|    policyGradLoss     | -0.0059    |\n",
      "|    value_loss         | 0.811      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 169         |\n",
      "|    total_timesteps    | 3080192     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011427393 |\n",
      "|    entropy_loss       | -2.05       |\n",
      "|    explained_variance | 0.919       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0636      |\n",
      "|    mean_step_reward   | 0.08085246  |\n",
      "|    n_updates          | 1500        |\n",
      "|    policyGradLoss     | -0.0113     |\n",
      "|    value_loss         | 0.513       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 180         |\n",
      "|    total_timesteps    | 3088384     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014358983 |\n",
      "|    entropy_loss       | -2.02       |\n",
      "|    explained_variance | 0.861       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0953      |\n",
      "|    mean_step_reward   | 0.087592274 |\n",
      "|    n_updates          | 1504        |\n",
      "|    policyGradLoss     | -0.00738    |\n",
      "|    value_loss         | 0.683       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 190         |\n",
      "|    total_timesteps    | 3096576     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011051902 |\n",
      "|    entropy_loss       | -2.04       |\n",
      "|    explained_variance | 0.894       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.155       |\n",
      "|    mean_step_reward   | 0.0863827   |\n",
      "|    n_updates          | 1508        |\n",
      "|    policyGradLoss     | -0.00545    |\n",
      "|    value_loss         | 0.693       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 201         |\n",
      "|    total_timesteps    | 3104768     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013438247 |\n",
      "|    entropy_loss       | -2.02       |\n",
      "|    explained_variance | 0.899       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.189       |\n",
      "|    mean_step_reward   | 0.07715136  |\n",
      "|    n_updates          | 1512        |\n",
      "|    policyGradLoss     | -0.0102     |\n",
      "|    value_loss         | 0.785       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 212         |\n",
      "|    total_timesteps    | 3112960     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013675207 |\n",
      "|    entropy_loss       | -2.04       |\n",
      "|    explained_variance | 0.911       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0399      |\n",
      "|    mean_step_reward   | 0.0779321   |\n",
      "|    n_updates          | 1516        |\n",
      "|    policyGradLoss     | -0.0126     |\n",
      "|    value_loss         | 0.573       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 222         |\n",
      "|    total_timesteps    | 3121152     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014604837 |\n",
      "|    entropy_loss       | -2.06       |\n",
      "|    explained_variance | 0.865       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.169       |\n",
      "|    mean_step_reward   | 0.08031742  |\n",
      "|    n_updates          | 1520        |\n",
      "|    policyGradLoss     | -0.00757    |\n",
      "|    value_loss         | 1.08        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 772        |\n",
      "|    iterations         | 22         |\n",
      "|    time_elapsed       | 233        |\n",
      "|    total_timesteps    | 3129344    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01382437 |\n",
      "|    entropy_loss       | -2.07      |\n",
      "|    explained_variance | 0.921      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | 0.0749     |\n",
      "|    mean_step_reward   | 0.08138077 |\n",
      "|    n_updates          | 1524       |\n",
      "|    policyGradLoss     | -0.0128    |\n",
      "|    value_loss         | 0.446      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 244         |\n",
      "|    total_timesteps    | 3137536     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012030933 |\n",
      "|    entropy_loss       | -2.06       |\n",
      "|    explained_variance | 0.883       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.17        |\n",
      "|    mean_step_reward   | 0.07842214  |\n",
      "|    n_updates          | 1528        |\n",
      "|    policyGradLoss     | -0.00635    |\n",
      "|    value_loss         | 0.729       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 255         |\n",
      "|    total_timesteps    | 3145728     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012954468 |\n",
      "|    entropy_loss       | -2.04       |\n",
      "|    explained_variance | 0.891       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0291      |\n",
      "|    mean_step_reward   | 0.078507274 |\n",
      "|    n_updates          | 1532        |\n",
      "|    policyGradLoss     | -0.00953    |\n",
      "|    value_loss         | 0.584       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 266         |\n",
      "|    total_timesteps    | 3153920     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017589185 |\n",
      "|    entropy_loss       | -2.08       |\n",
      "|    explained_variance | 0.93        |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0154     |\n",
      "|    mean_step_reward   | 0.08102682  |\n",
      "|    n_updates          | 1536        |\n",
      "|    policyGradLoss     | -0.0166     |\n",
      "|    value_loss         | 0.269       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 277         |\n",
      "|    total_timesteps    | 3162112     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015452319 |\n",
      "|    entropy_loss       | -2.05       |\n",
      "|    explained_variance | 0.84        |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.284       |\n",
      "|    mean_step_reward   | 0.078296036 |\n",
      "|    n_updates          | 1540        |\n",
      "|    policyGradLoss     | -0.00744    |\n",
      "|    value_loss         | 0.809       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 767        |\n",
      "|    iterations         | 27         |\n",
      "|    time_elapsed       | 288        |\n",
      "|    total_timesteps    | 3170304    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01638512 |\n",
      "|    entropy_loss       | -2.06      |\n",
      "|    explained_variance | 0.845      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | 0.00332    |\n",
      "|    mean_step_reward   | 0.0788333  |\n",
      "|    n_updates          | 1544       |\n",
      "|    policyGradLoss     | -0.00887   |\n",
      "|    value_loss         | 0.506      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 298         |\n",
      "|    total_timesteps    | 3178496     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012731272 |\n",
      "|    entropy_loss       | -2.05       |\n",
      "|    explained_variance | 0.87        |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.104       |\n",
      "|    mean_step_reward   | 0.07884523  |\n",
      "|    n_updates          | 1548        |\n",
      "|    policyGradLoss     | -0.00794    |\n",
      "|    value_loss         | 0.625       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 309         |\n",
      "|    total_timesteps    | 3186688     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012711948 |\n",
      "|    entropy_loss       | -2.05       |\n",
      "|    explained_variance | 0.889       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.195       |\n",
      "|    mean_step_reward   | 0.08421555  |\n",
      "|    n_updates          | 1552        |\n",
      "|    policyGradLoss     | -0.009      |\n",
      "|    value_loss         | 0.705       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 320         |\n",
      "|    total_timesteps    | 3194880     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017516319 |\n",
      "|    entropy_loss       | -2.04       |\n",
      "|    explained_variance | 0.894       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.108       |\n",
      "|    mean_step_reward   | 0.08037051  |\n",
      "|    n_updates          | 1556        |\n",
      "|    policyGradLoss     | -0.0106     |\n",
      "|    value_loss         | 0.594       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 764         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 331         |\n",
      "|    total_timesteps    | 3203072     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01580982  |\n",
      "|    entropy_loss       | -2.05       |\n",
      "|    explained_variance | 0.867       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0289      |\n",
      "|    mean_step_reward   | 0.076436035 |\n",
      "|    n_updates          | 1560        |\n",
      "|    policyGradLoss     | -0.0102     |\n",
      "|    value_loss         | 0.546       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 764        |\n",
      "|    iterations         | 32         |\n",
      "|    time_elapsed       | 342        |\n",
      "|    total_timesteps    | 3211264    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01430717 |\n",
      "|    entropy_loss       | -2.03      |\n",
      "|    explained_variance | 0.898      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | 0.0579     |\n",
      "|    mean_step_reward   | 0.0915581  |\n",
      "|    n_updates          | 1564       |\n",
      "|    policyGradLoss     | -0.0103    |\n",
      "|    value_loss         | 0.482      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 763         |\n",
      "|    iterations         | 33          |\n",
      "|    time_elapsed       | 353         |\n",
      "|    total_timesteps    | 3219456     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01367851  |\n",
      "|    entropy_loss       | -2.08       |\n",
      "|    explained_variance | 0.931       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.106       |\n",
      "|    mean_step_reward   | 0.073947236 |\n",
      "|    n_updates          | 1568        |\n",
      "|    policyGradLoss     | -0.0106     |\n",
      "|    value_loss         | 0.51        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 764        |\n",
      "|    iterations         | 34         |\n",
      "|    time_elapsed       | 364        |\n",
      "|    total_timesteps    | 3227648    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01568234 |\n",
      "|    entropy_loss       | -1.99      |\n",
      "|    explained_variance | 0.931      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | 0.0751     |\n",
      "|    mean_step_reward   | 0.08793661 |\n",
      "|    n_updates          | 1572       |\n",
      "|    policyGradLoss     | -0.011     |\n",
      "|    value_loss         | 0.504      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 763         |\n",
      "|    iterations         | 35          |\n",
      "|    time_elapsed       | 375         |\n",
      "|    total_timesteps    | 3235840     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016956013 |\n",
      "|    entropy_loss       | -2.01       |\n",
      "|    explained_variance | 0.938       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.00828     |\n",
      "|    mean_step_reward   | 0.092069246 |\n",
      "|    n_updates          | 1576        |\n",
      "|    policyGradLoss     | -0.0126     |\n",
      "|    value_loss         | 0.25        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 763         |\n",
      "|    iterations         | 36          |\n",
      "|    time_elapsed       | 386         |\n",
      "|    total_timesteps    | 3244032     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014290163 |\n",
      "|    entropy_loss       | -2.03       |\n",
      "|    explained_variance | 0.911       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.145       |\n",
      "|    mean_step_reward   | 0.08211516  |\n",
      "|    n_updates          | 1580        |\n",
      "|    policyGradLoss     | -0.0117     |\n",
      "|    value_loss         | 0.657       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 763         |\n",
      "|    iterations         | 37          |\n",
      "|    time_elapsed       | 397         |\n",
      "|    total_timesteps    | 3252224     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015945561 |\n",
      "|    entropy_loss       | -2          |\n",
      "|    explained_variance | 0.906       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0872      |\n",
      "|    mean_step_reward   | 0.09073806  |\n",
      "|    n_updates          | 1584        |\n",
      "|    policyGradLoss     | -0.0108     |\n",
      "|    value_loss         | 0.531       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 763         |\n",
      "|    iterations         | 38          |\n",
      "|    time_elapsed       | 407         |\n",
      "|    total_timesteps    | 3260416     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015868058 |\n",
      "|    entropy_loss       | -2.03       |\n",
      "|    explained_variance | 0.922       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.062       |\n",
      "|    mean_step_reward   | 0.08720734  |\n",
      "|    n_updates          | 1588        |\n",
      "|    policyGradLoss     | -0.012      |\n",
      "|    value_loss         | 0.456       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 763         |\n",
      "|    iterations         | 39          |\n",
      "|    time_elapsed       | 418         |\n",
      "|    total_timesteps    | 3268608     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013552107 |\n",
      "|    entropy_loss       | -2.03       |\n",
      "|    explained_variance | 0.906       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.144       |\n",
      "|    mean_step_reward   | 0.08680512  |\n",
      "|    n_updates          | 1592        |\n",
      "|    policyGradLoss     | -0.00955    |\n",
      "|    value_loss         | 0.593       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 763        |\n",
      "|    iterations         | 40         |\n",
      "|    time_elapsed       | 429        |\n",
      "|    total_timesteps    | 3276800    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01366066 |\n",
      "|    entropy_loss       | -2.03      |\n",
      "|    explained_variance | 0.868      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | 0.188      |\n",
      "|    mean_step_reward   | 0.08943909 |\n",
      "|    n_updates          | 1596       |\n",
      "|    policyGradLoss     | -0.00555   |\n",
      "|    value_loss         | 0.98       |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/TNL_10.zip\n",
      "[EVAL] Mean Return: -1251.617, Best Return: -1250.742\n",
      "Saved video to ./runs_smw/videos/step_3276800_mean_-1251.62.mp4\n",
      "\n",
      "=== Round 6 | Learn 327680 steps (Total trained: 3276800) ===\n",
      "Logging to ./runs_smw/tb/tunnel_0\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1094    |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 7       |\n",
      "|    total_timesteps | 3284992 |\n",
      "--------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 903         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 3293184     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011255363 |\n",
      "|    entropy_loss       | -2.07       |\n",
      "|    explained_variance | 0.905       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.103       |\n",
      "|    mean_step_reward   | 0.07604368  |\n",
      "|    n_updates          | 1604        |\n",
      "|    policyGradLoss     | -0.00913    |\n",
      "|    value_loss         | 0.61        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 852         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 3301376     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011513295 |\n",
      "|    entropy_loss       | -2.05       |\n",
      "|    explained_variance | 0.903       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0334      |\n",
      "|    mean_step_reward   | 0.084289    |\n",
      "|    n_updates          | 1608        |\n",
      "|    policyGradLoss     | -0.0113     |\n",
      "|    value_loss         | 0.644       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 833         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 3309568     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010721356 |\n",
      "|    entropy_loss       | -2.07       |\n",
      "|    explained_variance | 0.89        |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0572      |\n",
      "|    mean_step_reward   | 0.07992742  |\n",
      "|    n_updates          | 1612        |\n",
      "|    policyGradLoss     | -0.011      |\n",
      "|    value_loss         | 0.637       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 820         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 49          |\n",
      "|    total_timesteps    | 3317760     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014993019 |\n",
      "|    entropy_loss       | -2.03       |\n",
      "|    explained_variance | 0.879       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.00252     |\n",
      "|    mean_step_reward   | 0.09023373  |\n",
      "|    n_updates          | 1616        |\n",
      "|    policyGradLoss     | -0.00842    |\n",
      "|    value_loss         | 0.644       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 808         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 60          |\n",
      "|    total_timesteps    | 3325952     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012725211 |\n",
      "|    entropy_loss       | -2.03       |\n",
      "|    explained_variance | 0.896       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.153       |\n",
      "|    mean_step_reward   | 0.08517278  |\n",
      "|    n_updates          | 1620        |\n",
      "|    policyGradLoss     | -0.00966    |\n",
      "|    value_loss         | 0.747       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 800          |\n",
      "|    iterations         | 7            |\n",
      "|    time_elapsed       | 71           |\n",
      "|    total_timesteps    | 3334144      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0133213345 |\n",
      "|    entropy_loss       | -2.02        |\n",
      "|    explained_variance | 0.878        |\n",
      "|    learning_rate      | 0.0002       |\n",
      "|    loss               | 0.0364       |\n",
      "|    mean_step_reward   | 0.08724496   |\n",
      "|    n_updates          | 1624         |\n",
      "|    policyGradLoss     | -0.0128      |\n",
      "|    value_loss         | 0.504        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 794         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 82          |\n",
      "|    total_timesteps    | 3342336     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014688791 |\n",
      "|    entropy_loss       | -2.04       |\n",
      "|    explained_variance | 0.91        |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0722      |\n",
      "|    mean_step_reward   | 0.081612036 |\n",
      "|    n_updates          | 1628        |\n",
      "|    policyGradLoss     | -0.0092     |\n",
      "|    value_loss         | 0.479       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 789         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 93          |\n",
      "|    total_timesteps    | 3350528     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012548113 |\n",
      "|    entropy_loss       | -2.02       |\n",
      "|    explained_variance | 0.886       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.212       |\n",
      "|    mean_step_reward   | 0.081218444 |\n",
      "|    n_updates          | 1632        |\n",
      "|    policyGradLoss     | -0.00941    |\n",
      "|    value_loss         | 0.605       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 785        |\n",
      "|    iterations         | 10         |\n",
      "|    time_elapsed       | 104        |\n",
      "|    total_timesteps    | 3358720    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01626324 |\n",
      "|    entropy_loss       | -2.05      |\n",
      "|    explained_variance | 0.906      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | 0.0072     |\n",
      "|    mean_step_reward   | 0.08288388 |\n",
      "|    n_updates          | 1636       |\n",
      "|    policyGradLoss     | -0.0138    |\n",
      "|    value_loss         | 0.414      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 115         |\n",
      "|    total_timesteps    | 3366912     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017460763 |\n",
      "|    entropy_loss       | -2.03       |\n",
      "|    explained_variance | 0.929       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0158     |\n",
      "|    mean_step_reward   | 0.07884644  |\n",
      "|    n_updates          | 1640        |\n",
      "|    policyGradLoss     | -0.0145     |\n",
      "|    value_loss         | 0.334       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 126         |\n",
      "|    total_timesteps    | 3375104     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017900791 |\n",
      "|    entropy_loss       | -2.02       |\n",
      "|    explained_variance | 0.918       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0385     |\n",
      "|    mean_step_reward   | 0.07784827  |\n",
      "|    n_updates          | 1644        |\n",
      "|    policyGradLoss     | -0.0166     |\n",
      "|    value_loss         | 0.224       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 137         |\n",
      "|    total_timesteps    | 3383296     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017182982 |\n",
      "|    entropy_loss       | -2.06       |\n",
      "|    explained_variance | 0.887       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.00479     |\n",
      "|    mean_step_reward   | 0.078644164 |\n",
      "|    n_updates          | 1648        |\n",
      "|    policyGradLoss     | -0.0115     |\n",
      "|    value_loss         | 0.419       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 147         |\n",
      "|    total_timesteps    | 3391488     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013608654 |\n",
      "|    entropy_loss       | -2.06       |\n",
      "|    explained_variance | 0.905       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0357      |\n",
      "|    mean_step_reward   | 0.06736626  |\n",
      "|    n_updates          | 1652        |\n",
      "|    policyGradLoss     | -0.00887    |\n",
      "|    value_loss         | 0.536       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 158         |\n",
      "|    total_timesteps    | 3399680     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016200405 |\n",
      "|    entropy_loss       | -2.09       |\n",
      "|    explained_variance | 0.941       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.103       |\n",
      "|    mean_step_reward   | 0.065215416 |\n",
      "|    n_updates          | 1656        |\n",
      "|    policyGradLoss     | -0.0127     |\n",
      "|    value_loss         | 0.325       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 774          |\n",
      "|    iterations         | 16           |\n",
      "|    time_elapsed       | 169          |\n",
      "|    total_timesteps    | 3407872      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0155647015 |\n",
      "|    entropy_loss       | -2.09        |\n",
      "|    explained_variance | 0.895        |\n",
      "|    learning_rate      | 0.0002       |\n",
      "|    loss               | -0.0236      |\n",
      "|    mean_step_reward   | 0.07501474   |\n",
      "|    n_updates          | 1660         |\n",
      "|    policyGradLoss     | -0.00784     |\n",
      "|    value_loss         | 0.497        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 180         |\n",
      "|    total_timesteps    | 3416064     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015119677 |\n",
      "|    entropy_loss       | -2.01       |\n",
      "|    explained_variance | 0.912       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.125       |\n",
      "|    mean_step_reward   | 0.08195983  |\n",
      "|    n_updates          | 1664        |\n",
      "|    policyGradLoss     | -0.00655    |\n",
      "|    value_loss         | 0.466       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 190         |\n",
      "|    total_timesteps    | 3424256     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017489659 |\n",
      "|    entropy_loss       | -2.03       |\n",
      "|    explained_variance | 0.884       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.111       |\n",
      "|    mean_step_reward   | 0.07857284  |\n",
      "|    n_updates          | 1668        |\n",
      "|    policyGradLoss     | -0.011      |\n",
      "|    value_loss         | 0.454       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 201         |\n",
      "|    total_timesteps    | 3432448     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013912587 |\n",
      "|    entropy_loss       | -1.99       |\n",
      "|    explained_variance | 0.933       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0735      |\n",
      "|    mean_step_reward   | 0.07830539  |\n",
      "|    n_updates          | 1672        |\n",
      "|    policyGradLoss     | -0.0103     |\n",
      "|    value_loss         | 0.434       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 771        |\n",
      "|    iterations         | 20         |\n",
      "|    time_elapsed       | 212        |\n",
      "|    total_timesteps    | 3440640    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01654573 |\n",
      "|    entropy_loss       | -2.03      |\n",
      "|    explained_variance | 0.936      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | -0.0212    |\n",
      "|    mean_step_reward   | 0.07886301 |\n",
      "|    n_updates          | 1676       |\n",
      "|    policyGradLoss     | -0.0125    |\n",
      "|    value_loss         | 0.316      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 771       |\n",
      "|    iterations         | 21        |\n",
      "|    time_elapsed       | 223       |\n",
      "|    total_timesteps    | 3448832   |\n",
      "| train/                |           |\n",
      "|    approx_kl          | 0.0148149 |\n",
      "|    entropy_loss       | -2.04     |\n",
      "|    explained_variance | 0.951     |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    loss               | -0.0318   |\n",
      "|    mean_step_reward   | 0.0691063 |\n",
      "|    n_updates          | 1680      |\n",
      "|    policyGradLoss     | -0.0123   |\n",
      "|    value_loss         | 0.279     |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 233         |\n",
      "|    total_timesteps    | 3457024     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015394865 |\n",
      "|    entropy_loss       | -2.03       |\n",
      "|    explained_variance | 0.94        |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.00806    |\n",
      "|    mean_step_reward   | 0.068056315 |\n",
      "|    n_updates          | 1684        |\n",
      "|    policyGradLoss     | -0.0132     |\n",
      "|    value_loss         | 0.409       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 244         |\n",
      "|    total_timesteps    | 3465216     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017571673 |\n",
      "|    entropy_loss       | -2.04       |\n",
      "|    explained_variance | 0.955       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0439     |\n",
      "|    mean_step_reward   | 0.07175156  |\n",
      "|    n_updates          | 1688        |\n",
      "|    policyGradLoss     | -0.0117     |\n",
      "|    value_loss         | 0.189       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 255         |\n",
      "|    total_timesteps    | 3473408     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014963582 |\n",
      "|    entropy_loss       | -2.03       |\n",
      "|    explained_variance | 0.945       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.027      |\n",
      "|    mean_step_reward   | 0.074367285 |\n",
      "|    n_updates          | 1692        |\n",
      "|    policyGradLoss     | -0.0102     |\n",
      "|    value_loss         | 0.264       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 266         |\n",
      "|    total_timesteps    | 3481600     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013497598 |\n",
      "|    entropy_loss       | -2.01       |\n",
      "|    explained_variance | 0.914       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0881      |\n",
      "|    mean_step_reward   | 0.087845646 |\n",
      "|    n_updates          | 1696        |\n",
      "|    policyGradLoss     | -0.00446    |\n",
      "|    value_loss         | 0.455       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 276         |\n",
      "|    total_timesteps    | 3489792     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018199265 |\n",
      "|    entropy_loss       | -1.98       |\n",
      "|    explained_variance | 0.93        |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0264     |\n",
      "|    mean_step_reward   | 0.083285525 |\n",
      "|    n_updates          | 1700        |\n",
      "|    policyGradLoss     | -0.0123     |\n",
      "|    value_loss         | 0.29        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 287         |\n",
      "|    total_timesteps    | 3497984     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014291409 |\n",
      "|    entropy_loss       | -2.02       |\n",
      "|    explained_variance | 0.931       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.00246    |\n",
      "|    mean_step_reward   | 0.07468934  |\n",
      "|    n_updates          | 1704        |\n",
      "|    policyGradLoss     | -0.0116     |\n",
      "|    value_loss         | 0.465       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 298         |\n",
      "|    total_timesteps    | 3506176     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016061468 |\n",
      "|    entropy_loss       | -2          |\n",
      "|    explained_variance | 0.899       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.00736     |\n",
      "|    mean_step_reward   | 0.08829291  |\n",
      "|    n_updates          | 1708        |\n",
      "|    policyGradLoss     | -0.00944    |\n",
      "|    value_loss         | 0.415       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 309         |\n",
      "|    total_timesteps    | 3514368     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014025319 |\n",
      "|    entropy_loss       | -2          |\n",
      "|    explained_variance | 0.922       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.108       |\n",
      "|    mean_step_reward   | 0.08433913  |\n",
      "|    n_updates          | 1712        |\n",
      "|    policyGradLoss     | -0.0131     |\n",
      "|    value_loss         | 0.424       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 768        |\n",
      "|    iterations         | 30         |\n",
      "|    time_elapsed       | 319        |\n",
      "|    total_timesteps    | 3522560    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01549861 |\n",
      "|    entropy_loss       | -1.99      |\n",
      "|    explained_variance | 0.876      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | 0.115      |\n",
      "|    mean_step_reward   | 0.09531316 |\n",
      "|    n_updates          | 1716       |\n",
      "|    policyGradLoss     | -0.00692   |\n",
      "|    value_loss         | 0.652      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 330         |\n",
      "|    total_timesteps    | 3530752     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013885956 |\n",
      "|    entropy_loss       | -2.01       |\n",
      "|    explained_variance | 0.887       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.113       |\n",
      "|    mean_step_reward   | 0.08089995  |\n",
      "|    n_updates          | 1720        |\n",
      "|    policyGradLoss     | -0.00784    |\n",
      "|    value_loss         | 0.814       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 341         |\n",
      "|    total_timesteps    | 3538944     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014006676 |\n",
      "|    entropy_loss       | -2.03       |\n",
      "|    explained_variance | 0.866       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.107       |\n",
      "|    mean_step_reward   | 0.08130117  |\n",
      "|    n_updates          | 1724        |\n",
      "|    policyGradLoss     | -0.00795    |\n",
      "|    value_loss         | 0.609       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 33          |\n",
      "|    time_elapsed       | 352         |\n",
      "|    total_timesteps    | 3547136     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014098275 |\n",
      "|    entropy_loss       | -2          |\n",
      "|    explained_variance | 0.884       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.125       |\n",
      "|    mean_step_reward   | 0.09618212  |\n",
      "|    n_updates          | 1728        |\n",
      "|    policyGradLoss     | -0.0079     |\n",
      "|    value_loss         | 0.528       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 34          |\n",
      "|    time_elapsed       | 363         |\n",
      "|    total_timesteps    | 3555328     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014310717 |\n",
      "|    entropy_loss       | -2.02       |\n",
      "|    explained_variance | 0.887       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0374      |\n",
      "|    mean_step_reward   | 0.087302096 |\n",
      "|    n_updates          | 1732        |\n",
      "|    policyGradLoss     | -0.0098     |\n",
      "|    value_loss         | 0.425       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 35          |\n",
      "|    time_elapsed       | 373         |\n",
      "|    total_timesteps    | 3563520     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015251326 |\n",
      "|    entropy_loss       | -2.03       |\n",
      "|    explained_variance | 0.93        |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0398      |\n",
      "|    mean_step_reward   | 0.08574913  |\n",
      "|    n_updates          | 1736        |\n",
      "|    policyGradLoss     | -0.0138     |\n",
      "|    value_loss         | 0.538       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 36          |\n",
      "|    time_elapsed       | 384         |\n",
      "|    total_timesteps    | 3571712     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012874537 |\n",
      "|    entropy_loss       | -2.01       |\n",
      "|    explained_variance | 0.903       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0855      |\n",
      "|    mean_step_reward   | 0.089295894 |\n",
      "|    n_updates          | 1740        |\n",
      "|    policyGradLoss     | -0.00629    |\n",
      "|    value_loss         | 0.727       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 37          |\n",
      "|    time_elapsed       | 395         |\n",
      "|    total_timesteps    | 3579904     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012317015 |\n",
      "|    entropy_loss       | -2.02       |\n",
      "|    explained_variance | 0.917       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0492      |\n",
      "|    mean_step_reward   | 0.08205233  |\n",
      "|    n_updates          | 1744        |\n",
      "|    policyGradLoss     | -0.0114     |\n",
      "|    value_loss         | 0.575       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 766        |\n",
      "|    iterations         | 38         |\n",
      "|    time_elapsed       | 406        |\n",
      "|    total_timesteps    | 3588096    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01306545 |\n",
      "|    entropy_loss       | -2.03      |\n",
      "|    explained_variance | 0.905      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | 0.0417     |\n",
      "|    mean_step_reward   | 0.08428974 |\n",
      "|    n_updates          | 1748       |\n",
      "|    policyGradLoss     | -0.0114    |\n",
      "|    value_loss         | 0.563      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 39          |\n",
      "|    time_elapsed       | 417         |\n",
      "|    total_timesteps    | 3596288     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01282876  |\n",
      "|    entropy_loss       | -2          |\n",
      "|    explained_variance | 0.884       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0744      |\n",
      "|    mean_step_reward   | 0.095506154 |\n",
      "|    n_updates          | 1752        |\n",
      "|    policyGradLoss     | -0.00885    |\n",
      "|    value_loss         | 0.51        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 765         |\n",
      "|    iterations         | 40          |\n",
      "|    time_elapsed       | 427         |\n",
      "|    total_timesteps    | 3604480     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013610799 |\n",
      "|    entropy_loss       | -1.99       |\n",
      "|    explained_variance | 0.919       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.14        |\n",
      "|    mean_step_reward   | 0.087947756 |\n",
      "|    n_updates          | 1756        |\n",
      "|    policyGradLoss     | -0.0114     |\n",
      "|    value_loss         | 0.536       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/TNL_11.zip\n",
      "[EVAL] Mean Return: 93.283, Best Return: 93.446\n",
      "Saved video to ./runs_smw/videos/step_3604480_mean_93.28.mp4\n",
      "\n",
      "=== Round 7 | Learn 327680 steps (Total trained: 3604480) ===\n",
      "Logging to ./runs_smw/tb/tunnel_0\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1090    |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 7       |\n",
      "|    total_timesteps | 3612672 |\n",
      "--------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 895         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 3620864     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016525116 |\n",
      "|    entropy_loss       | -1.98       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0126     |\n",
      "|    mean_step_reward   | 0.098459706 |\n",
      "|    n_updates          | 1764        |\n",
      "|    policyGradLoss     | -0.0151     |\n",
      "|    value_loss         | 0.237       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 839         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 29          |\n",
      "|    total_timesteps    | 3629056     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013788796 |\n",
      "|    entropy_loss       | -1.99       |\n",
      "|    explained_variance | 0.9         |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0339      |\n",
      "|    mean_step_reward   | 0.09144746  |\n",
      "|    n_updates          | 1768        |\n",
      "|    policyGradLoss     | -0.00767    |\n",
      "|    value_loss         | 0.588       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 814         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 40          |\n",
      "|    total_timesteps    | 3637248     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012031252 |\n",
      "|    entropy_loss       | -1.99       |\n",
      "|    explained_variance | 0.899       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.133       |\n",
      "|    mean_step_reward   | 0.0881113   |\n",
      "|    n_updates          | 1772        |\n",
      "|    policyGradLoss     | -0.00643    |\n",
      "|    value_loss         | 0.763       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 803        |\n",
      "|    iterations         | 5          |\n",
      "|    time_elapsed       | 50         |\n",
      "|    total_timesteps    | 3645440    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01209445 |\n",
      "|    entropy_loss       | -1.98      |\n",
      "|    explained_variance | 0.92       |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | 0.0876     |\n",
      "|    mean_step_reward   | 0.0933078  |\n",
      "|    n_updates          | 1776       |\n",
      "|    policyGradLoss     | -0.0103    |\n",
      "|    value_loss         | 0.523      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 797         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 61          |\n",
      "|    total_timesteps    | 3653632     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018118009 |\n",
      "|    entropy_loss       | -1.97       |\n",
      "|    explained_variance | 0.95        |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.029       |\n",
      "|    mean_step_reward   | 0.09551306  |\n",
      "|    n_updates          | 1780        |\n",
      "|    policyGradLoss     | -0.0117     |\n",
      "|    value_loss         | 0.33        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 790        |\n",
      "|    iterations         | 7          |\n",
      "|    time_elapsed       | 72         |\n",
      "|    total_timesteps    | 3661824    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01953083 |\n",
      "|    entropy_loss       | -2         |\n",
      "|    explained_variance | 0.943      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | -0.0192    |\n",
      "|    mean_step_reward   | 0.08843036 |\n",
      "|    n_updates          | 1784       |\n",
      "|    policyGradLoss     | -0.0159    |\n",
      "|    value_loss         | 0.254      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 83          |\n",
      "|    total_timesteps    | 3670016     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015413016 |\n",
      "|    entropy_loss       | -2          |\n",
      "|    explained_variance | 0.937       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.00373    |\n",
      "|    mean_step_reward   | 0.088967144 |\n",
      "|    n_updates          | 1788        |\n",
      "|    policyGradLoss     | -0.0136     |\n",
      "|    value_loss         | 0.4         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 94          |\n",
      "|    total_timesteps    | 3678208     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011851909 |\n",
      "|    entropy_loss       | -2.01       |\n",
      "|    explained_variance | 0.907       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0272      |\n",
      "|    mean_step_reward   | 0.08858506  |\n",
      "|    n_updates          | 1792        |\n",
      "|    policyGradLoss     | -0.00894    |\n",
      "|    value_loss         | 0.495       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 105         |\n",
      "|    total_timesteps    | 3686400     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013014002 |\n",
      "|    entropy_loss       | -2.01       |\n",
      "|    explained_variance | 0.891       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0881      |\n",
      "|    mean_step_reward   | 0.083116904 |\n",
      "|    n_updates          | 1796        |\n",
      "|    policyGradLoss     | -0.0118     |\n",
      "|    value_loss         | 0.608       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 116         |\n",
      "|    total_timesteps    | 3694592     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015601072 |\n",
      "|    entropy_loss       | -2.01       |\n",
      "|    explained_variance | 0.888       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.194       |\n",
      "|    mean_step_reward   | 0.090185754 |\n",
      "|    n_updates          | 1800        |\n",
      "|    policyGradLoss     | -0.00983    |\n",
      "|    value_loss         | 0.632       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 127         |\n",
      "|    total_timesteps    | 3702784     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014544053 |\n",
      "|    entropy_loss       | -2          |\n",
      "|    explained_variance | 0.782       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.127       |\n",
      "|    mean_step_reward   | 0.09803838  |\n",
      "|    n_updates          | 1804        |\n",
      "|    policyGradLoss     | -0.0046     |\n",
      "|    value_loss         | 1.02        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 137         |\n",
      "|    total_timesteps    | 3710976     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012912078 |\n",
      "|    entropy_loss       | -2.01       |\n",
      "|    explained_variance | 0.902       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.328       |\n",
      "|    mean_step_reward   | 0.09310494  |\n",
      "|    n_updates          | 1808        |\n",
      "|    policyGradLoss     | -0.0111     |\n",
      "|    value_loss         | 0.612       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 148         |\n",
      "|    total_timesteps    | 3719168     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012589663 |\n",
      "|    entropy_loss       | -2.03       |\n",
      "|    explained_variance | 0.876       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.00266    |\n",
      "|    mean_step_reward   | 0.0748478   |\n",
      "|    n_updates          | 1812        |\n",
      "|    policyGradLoss     | -0.0112     |\n",
      "|    value_loss         | 0.524       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 159         |\n",
      "|    total_timesteps    | 3727360     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012699721 |\n",
      "|    entropy_loss       | -2.01       |\n",
      "|    explained_variance | 0.83        |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.00637    |\n",
      "|    mean_step_reward   | 0.08375457  |\n",
      "|    n_updates          | 1816        |\n",
      "|    policyGradLoss     | -0.00672    |\n",
      "|    value_loss         | 0.405       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 170         |\n",
      "|    total_timesteps    | 3735552     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016505755 |\n",
      "|    entropy_loss       | -1.99       |\n",
      "|    explained_variance | 0.918       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0215      |\n",
      "|    mean_step_reward   | 0.08960167  |\n",
      "|    n_updates          | 1820        |\n",
      "|    policyGradLoss     | -0.0146     |\n",
      "|    value_loss         | 0.376       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 181         |\n",
      "|    total_timesteps    | 3743744     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015916826 |\n",
      "|    entropy_loss       | -1.98       |\n",
      "|    explained_variance | 0.884       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0328      |\n",
      "|    mean_step_reward   | 0.09689292  |\n",
      "|    n_updates          | 1824        |\n",
      "|    policyGradLoss     | -0.01       |\n",
      "|    value_loss         | 0.549       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 192         |\n",
      "|    total_timesteps    | 3751936     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015297237 |\n",
      "|    entropy_loss       | -2.01       |\n",
      "|    explained_variance | 0.885       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0396      |\n",
      "|    mean_step_reward   | 0.08532661  |\n",
      "|    n_updates          | 1828        |\n",
      "|    policyGradLoss     | -0.0077     |\n",
      "|    value_loss         | 0.503       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 202         |\n",
      "|    total_timesteps    | 3760128     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016531967 |\n",
      "|    entropy_loss       | -1.98       |\n",
      "|    explained_variance | 0.873       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0132     |\n",
      "|    mean_step_reward   | 0.090452224 |\n",
      "|    n_updates          | 1832        |\n",
      "|    policyGradLoss     | -0.0114     |\n",
      "|    value_loss         | 0.301       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 213         |\n",
      "|    total_timesteps    | 3768320     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015119137 |\n",
      "|    entropy_loss       | -2.01       |\n",
      "|    explained_variance | 0.868       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0117     |\n",
      "|    mean_step_reward   | 0.08711686  |\n",
      "|    n_updates          | 1836        |\n",
      "|    policyGradLoss     | -0.0121     |\n",
      "|    value_loss         | 0.42        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 224         |\n",
      "|    total_timesteps    | 3776512     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012809446 |\n",
      "|    entropy_loss       | -1.99       |\n",
      "|    explained_variance | 0.848       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.115       |\n",
      "|    mean_step_reward   | 0.088251546 |\n",
      "|    n_updates          | 1840        |\n",
      "|    policyGradLoss     | -0.00908    |\n",
      "|    value_loss         | 0.85        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 234         |\n",
      "|    total_timesteps    | 3784704     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015287613 |\n",
      "|    entropy_loss       | -2.01       |\n",
      "|    explained_variance | 0.885       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.00443     |\n",
      "|    mean_step_reward   | 0.09192677  |\n",
      "|    n_updates          | 1844        |\n",
      "|    policyGradLoss     | -0.014      |\n",
      "|    value_loss         | 0.492       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 245         |\n",
      "|    total_timesteps    | 3792896     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011847097 |\n",
      "|    entropy_loss       | -1.98       |\n",
      "|    explained_variance | 0.898       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.531       |\n",
      "|    mean_step_reward   | 0.09400377  |\n",
      "|    n_updates          | 1848        |\n",
      "|    policyGradLoss     | -0.0074     |\n",
      "|    value_loss         | 0.716       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 765         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 256         |\n",
      "|    total_timesteps    | 3801088     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01447114  |\n",
      "|    entropy_loss       | -2.01       |\n",
      "|    explained_variance | 0.907       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0129      |\n",
      "|    mean_step_reward   | 0.099864975 |\n",
      "|    n_updates          | 1852        |\n",
      "|    policyGradLoss     | -0.0104     |\n",
      "|    value_loss         | 0.569       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 267         |\n",
      "|    total_timesteps    | 3809280     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009996761 |\n",
      "|    entropy_loss       | -2.03       |\n",
      "|    explained_variance | 0.821       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.323       |\n",
      "|    mean_step_reward   | 0.08659574  |\n",
      "|    n_updates          | 1856        |\n",
      "|    policyGradLoss     | -0.00619    |\n",
      "|    value_loss         | 1.13        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 277         |\n",
      "|    total_timesteps    | 3817472     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010575604 |\n",
      "|    entropy_loss       | -2.04       |\n",
      "|    explained_variance | 0.817       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.213       |\n",
      "|    mean_step_reward   | 0.075518966 |\n",
      "|    n_updates          | 1860        |\n",
      "|    policyGradLoss     | -0.00645    |\n",
      "|    value_loss         | 1.14        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 288         |\n",
      "|    total_timesteps    | 3825664     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010334965 |\n",
      "|    entropy_loss       | -2.04       |\n",
      "|    explained_variance | 0.814       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.194       |\n",
      "|    mean_step_reward   | 0.08339594  |\n",
      "|    n_updates          | 1864        |\n",
      "|    policyGradLoss     | -0.00732    |\n",
      "|    value_loss         | 0.964       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 765        |\n",
      "|    iterations         | 28         |\n",
      "|    time_elapsed       | 299        |\n",
      "|    total_timesteps    | 3833856    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01079019 |\n",
      "|    entropy_loss       | -2.03      |\n",
      "|    explained_variance | 0.896      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | 0.202      |\n",
      "|    mean_step_reward   | 0.08444201 |\n",
      "|    n_updates          | 1868       |\n",
      "|    policyGradLoss     | -0.00803   |\n",
      "|    value_loss         | 0.86       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 765        |\n",
      "|    iterations         | 29         |\n",
      "|    time_elapsed       | 310        |\n",
      "|    total_timesteps    | 3842048    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01226739 |\n",
      "|    entropy_loss       | -2.02      |\n",
      "|    explained_variance | 0.814      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | 0.188      |\n",
      "|    mean_step_reward   | 0.08911989 |\n",
      "|    n_updates          | 1872       |\n",
      "|    policyGradLoss     | -0.00602   |\n",
      "|    value_loss         | 1.19       |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 765          |\n",
      "|    iterations         | 30           |\n",
      "|    time_elapsed       | 320          |\n",
      "|    total_timesteps    | 3850240      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0128607415 |\n",
      "|    entropy_loss       | -2           |\n",
      "|    explained_variance | 0.915        |\n",
      "|    learning_rate      | 0.0002       |\n",
      "|    loss               | 0.0341       |\n",
      "|    mean_step_reward   | 0.08984838   |\n",
      "|    n_updates          | 1876         |\n",
      "|    policyGradLoss     | -0.0132      |\n",
      "|    value_loss         | 0.488        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 765         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 331         |\n",
      "|    total_timesteps    | 3858432     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015227769 |\n",
      "|    entropy_loss       | -2.01       |\n",
      "|    explained_variance | 0.892       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.094       |\n",
      "|    mean_step_reward   | 0.08415492  |\n",
      "|    n_updates          | 1880        |\n",
      "|    policyGradLoss     | -0.0105     |\n",
      "|    value_loss         | 0.777       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 765         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 342         |\n",
      "|    total_timesteps    | 3866624     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009921928 |\n",
      "|    entropy_loss       | -2.02       |\n",
      "|    explained_variance | 0.772       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.233       |\n",
      "|    mean_step_reward   | 0.090455644 |\n",
      "|    n_updates          | 1884        |\n",
      "|    policyGradLoss     | -0.00427    |\n",
      "|    value_loss         | 1.06        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 765         |\n",
      "|    iterations         | 33          |\n",
      "|    time_elapsed       | 353         |\n",
      "|    total_timesteps    | 3874816     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01102591  |\n",
      "|    entropy_loss       | -2.02       |\n",
      "|    explained_variance | 0.89        |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.131       |\n",
      "|    mean_step_reward   | 0.088116795 |\n",
      "|    n_updates          | 1888        |\n",
      "|    policyGradLoss     | -0.0104     |\n",
      "|    value_loss         | 0.662       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 765        |\n",
      "|    iterations         | 34         |\n",
      "|    time_elapsed       | 363        |\n",
      "|    total_timesteps    | 3883008    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01711319 |\n",
      "|    entropy_loss       | -2         |\n",
      "|    explained_variance | 0.885      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | 0.0177     |\n",
      "|    mean_step_reward   | 0.096339   |\n",
      "|    n_updates          | 1892       |\n",
      "|    policyGradLoss     | -0.0105    |\n",
      "|    value_loss         | 0.363      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 765        |\n",
      "|    iterations         | 35         |\n",
      "|    time_elapsed       | 374        |\n",
      "|    total_timesteps    | 3891200    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.0101119  |\n",
      "|    entropy_loss       | -2.03      |\n",
      "|    explained_variance | 0.775      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | 0.0628     |\n",
      "|    mean_step_reward   | 0.09615621 |\n",
      "|    n_updates          | 1896       |\n",
      "|    policyGradLoss     | -0.00592   |\n",
      "|    value_loss         | 0.856      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 765         |\n",
      "|    iterations         | 36          |\n",
      "|    time_elapsed       | 385         |\n",
      "|    total_timesteps    | 3899392     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013857858 |\n",
      "|    entropy_loss       | -2.01       |\n",
      "|    explained_variance | 0.851       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0731      |\n",
      "|    mean_step_reward   | 0.08579984  |\n",
      "|    n_updates          | 1900        |\n",
      "|    policyGradLoss     | -0.00901    |\n",
      "|    value_loss         | 0.552       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 37          |\n",
      "|    time_elapsed       | 395         |\n",
      "|    total_timesteps    | 3907584     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013426585 |\n",
      "|    entropy_loss       | -2          |\n",
      "|    explained_variance | 0.896       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0306      |\n",
      "|    mean_step_reward   | 0.096309155 |\n",
      "|    n_updates          | 1904        |\n",
      "|    policyGradLoss     | -0.0124     |\n",
      "|    value_loss         | 0.425       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 765         |\n",
      "|    iterations         | 38          |\n",
      "|    time_elapsed       | 406         |\n",
      "|    total_timesteps    | 3915776     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012035147 |\n",
      "|    entropy_loss       | -2.01       |\n",
      "|    explained_variance | 0.869       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.155       |\n",
      "|    mean_step_reward   | 0.09362805  |\n",
      "|    n_updates          | 1908        |\n",
      "|    policyGradLoss     | -0.00731    |\n",
      "|    value_loss         | 0.704       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 765         |\n",
      "|    iterations         | 39          |\n",
      "|    time_elapsed       | 417         |\n",
      "|    total_timesteps    | 3923968     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014197457 |\n",
      "|    entropy_loss       | -2          |\n",
      "|    explained_variance | 0.869       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0697      |\n",
      "|    mean_step_reward   | 0.093360916 |\n",
      "|    n_updates          | 1912        |\n",
      "|    policyGradLoss     | -0.00903    |\n",
      "|    value_loss         | 0.704       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 765         |\n",
      "|    iterations         | 40          |\n",
      "|    time_elapsed       | 427         |\n",
      "|    total_timesteps    | 3932160     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013152963 |\n",
      "|    entropy_loss       | -2          |\n",
      "|    explained_variance | 0.874       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.13        |\n",
      "|    mean_step_reward   | 0.09059143  |\n",
      "|    n_updates          | 1916        |\n",
      "|    policyGradLoss     | -0.0112     |\n",
      "|    value_loss         | 0.821       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/TNL_12.zip\n",
      "[EVAL] Mean Return: -1265.940, Best Return: -1265.113\n",
      "Saved video to ./runs_smw/videos/step_3932160_mean_-1265.94.mp4\n",
      "\n",
      "=== Round 8 | Learn 327680 steps (Total trained: 3932160) ===\n",
      "Logging to ./runs_smw/tb/tunnel_0\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1104    |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 7       |\n",
      "|    total_timesteps | 3940352 |\n",
      "--------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 897         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 3948544     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012774943 |\n",
      "|    entropy_loss       | -2          |\n",
      "|    explained_variance | 0.865       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.142       |\n",
      "|    mean_step_reward   | 0.09457538  |\n",
      "|    n_updates          | 1924        |\n",
      "|    policyGradLoss     | -0.0105     |\n",
      "|    value_loss         | 0.569       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 851         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 3956736     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011585425 |\n",
      "|    entropy_loss       | -2.02       |\n",
      "|    explained_variance | 0.846       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.276       |\n",
      "|    mean_step_reward   | 0.092745975 |\n",
      "|    n_updates          | 1928        |\n",
      "|    policyGradLoss     | -0.00694    |\n",
      "|    value_loss         | 1.17        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 824         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 3964928     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016755952 |\n",
      "|    entropy_loss       | -2          |\n",
      "|    explained_variance | 0.909       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.164       |\n",
      "|    mean_step_reward   | 0.08643125  |\n",
      "|    n_updates          | 1932        |\n",
      "|    policyGradLoss     | -0.011      |\n",
      "|    value_loss         | 0.457       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 810         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 50          |\n",
      "|    total_timesteps    | 3973120     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014740057 |\n",
      "|    entropy_loss       | -2          |\n",
      "|    explained_variance | 0.899       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.106       |\n",
      "|    mean_step_reward   | 0.09510808  |\n",
      "|    n_updates          | 1936        |\n",
      "|    policyGradLoss     | -0.0126     |\n",
      "|    value_loss         | 0.514       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 803          |\n",
      "|    iterations         | 6            |\n",
      "|    time_elapsed       | 61           |\n",
      "|    total_timesteps    | 3981312      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0139905885 |\n",
      "|    entropy_loss       | -1.99        |\n",
      "|    explained_variance | 0.883        |\n",
      "|    learning_rate      | 0.0002       |\n",
      "|    loss               | -0.0018      |\n",
      "|    mean_step_reward   | 0.09669669   |\n",
      "|    n_updates          | 1940         |\n",
      "|    policyGradLoss     | -0.0101      |\n",
      "|    value_loss         | 0.565        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 796         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 71          |\n",
      "|    total_timesteps    | 3989504     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01245078  |\n",
      "|    entropy_loss       | -2.02       |\n",
      "|    explained_variance | 0.889       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.165       |\n",
      "|    mean_step_reward   | 0.107980505 |\n",
      "|    n_updates          | 1944        |\n",
      "|    policyGradLoss     | -0.00587    |\n",
      "|    value_loss         | 0.967       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 791         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 82          |\n",
      "|    total_timesteps    | 3997696     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01385439  |\n",
      "|    entropy_loss       | -2          |\n",
      "|    explained_variance | 0.927       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0451      |\n",
      "|    mean_step_reward   | 0.097694114 |\n",
      "|    n_updates          | 1948        |\n",
      "|    policyGradLoss     | -0.00835    |\n",
      "|    value_loss         | 0.471       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 788        |\n",
      "|    iterations         | 9          |\n",
      "|    time_elapsed       | 93         |\n",
      "|    total_timesteps    | 4005888    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01383387 |\n",
      "|    entropy_loss       | -2.02      |\n",
      "|    explained_variance | 0.93       |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | 0.0248     |\n",
      "|    mean_step_reward   | 0.09456405 |\n",
      "|    n_updates          | 1952       |\n",
      "|    policyGradLoss     | -0.00898   |\n",
      "|    value_loss         | 0.586      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 104         |\n",
      "|    total_timesteps    | 4014080     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012972338 |\n",
      "|    entropy_loss       | -2          |\n",
      "|    explained_variance | 0.881       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.166       |\n",
      "|    mean_step_reward   | 0.097198084 |\n",
      "|    n_updates          | 1956        |\n",
      "|    policyGradLoss     | -0.00771    |\n",
      "|    value_loss         | 0.741       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 781          |\n",
      "|    iterations         | 11           |\n",
      "|    time_elapsed       | 115          |\n",
      "|    total_timesteps    | 4022272      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0121633215 |\n",
      "|    entropy_loss       | -2.01        |\n",
      "|    explained_variance | 0.897        |\n",
      "|    learning_rate      | 0.0002       |\n",
      "|    loss               | 0.113        |\n",
      "|    mean_step_reward   | 0.096335694  |\n",
      "|    n_updates          | 1960         |\n",
      "|    policyGradLoss     | -0.007       |\n",
      "|    value_loss         | 0.712        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 126         |\n",
      "|    total_timesteps    | 4030464     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011789257 |\n",
      "|    entropy_loss       | -2          |\n",
      "|    explained_variance | 0.882       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.00649     |\n",
      "|    mean_step_reward   | 0.094557315 |\n",
      "|    n_updates          | 1964        |\n",
      "|    policyGradLoss     | -0.0119     |\n",
      "|    value_loss         | 0.313       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 136         |\n",
      "|    total_timesteps    | 4038656     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015199622 |\n",
      "|    entropy_loss       | -1.99       |\n",
      "|    explained_variance | 0.896       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.115       |\n",
      "|    mean_step_reward   | 0.089022145 |\n",
      "|    n_updates          | 1968        |\n",
      "|    policyGradLoss     | -0.00952    |\n",
      "|    value_loss         | 0.907       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 148         |\n",
      "|    total_timesteps    | 4046848     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014053945 |\n",
      "|    entropy_loss       | -1.97       |\n",
      "|    explained_variance | 0.891       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0206      |\n",
      "|    mean_step_reward   | 0.09547621  |\n",
      "|    n_updates          | 1972        |\n",
      "|    policyGradLoss     | -0.0112     |\n",
      "|    value_loss         | 0.589       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 774        |\n",
      "|    iterations         | 15         |\n",
      "|    time_elapsed       | 158        |\n",
      "|    total_timesteps    | 4055040    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01525441 |\n",
      "|    entropy_loss       | -1.96      |\n",
      "|    explained_variance | 0.849      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | 0.0358     |\n",
      "|    mean_step_reward   | 0.10303371 |\n",
      "|    n_updates          | 1976       |\n",
      "|    policyGradLoss     | -0.00667   |\n",
      "|    value_loss         | 0.556      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 169         |\n",
      "|    total_timesteps    | 4063232     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012445137 |\n",
      "|    entropy_loss       | -2          |\n",
      "|    explained_variance | 0.882       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.183       |\n",
      "|    mean_step_reward   | 0.09796101  |\n",
      "|    n_updates          | 1980        |\n",
      "|    policyGradLoss     | -0.00591    |\n",
      "|    value_loss         | 1.03        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 180         |\n",
      "|    total_timesteps    | 4071424     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018166985 |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.888       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.139       |\n",
      "|    mean_step_reward   | 0.09759728  |\n",
      "|    n_updates          | 1984        |\n",
      "|    policyGradLoss     | -0.011      |\n",
      "|    value_loss         | 0.492       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 774        |\n",
      "|    iterations         | 18         |\n",
      "|    time_elapsed       | 190        |\n",
      "|    total_timesteps    | 4079616    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.0170441  |\n",
      "|    entropy_loss       | -1.99      |\n",
      "|    explained_variance | 0.898      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | 0.0387     |\n",
      "|    mean_step_reward   | 0.09313324 |\n",
      "|    n_updates          | 1988       |\n",
      "|    policyGradLoss     | -0.00664   |\n",
      "|    value_loss         | 0.531      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 200         |\n",
      "|    total_timesteps    | 4087808     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012234183 |\n",
      "|    entropy_loss       | -2          |\n",
      "|    explained_variance | 0.793       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.318       |\n",
      "|    mean_step_reward   | 0.093926504 |\n",
      "|    n_updates          | 1992        |\n",
      "|    policyGradLoss     | -0.00494    |\n",
      "|    value_loss         | 1.4         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 211         |\n",
      "|    total_timesteps    | 4096000     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011245896 |\n",
      "|    entropy_loss       | -2.03       |\n",
      "|    explained_variance | 0.815       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.198       |\n",
      "|    mean_step_reward   | 0.08767875  |\n",
      "|    n_updates          | 1996        |\n",
      "|    policyGradLoss     | -0.00361    |\n",
      "|    value_loss         | 1.03        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 222         |\n",
      "|    total_timesteps    | 4104192     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013131434 |\n",
      "|    entropy_loss       | -2.01       |\n",
      "|    explained_variance | 0.876       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.143       |\n",
      "|    mean_step_reward   | 0.09240351  |\n",
      "|    n_updates          | 2000        |\n",
      "|    policyGradLoss     | -0.00906    |\n",
      "|    value_loss         | 0.915       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 233         |\n",
      "|    total_timesteps    | 4112384     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.0146398   |\n",
      "|    entropy_loss       | -2.01       |\n",
      "|    explained_variance | 0.893       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.119       |\n",
      "|    mean_step_reward   | 0.091879755 |\n",
      "|    n_updates          | 2004        |\n",
      "|    policyGradLoss     | -0.0136     |\n",
      "|    value_loss         | 0.489       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 243         |\n",
      "|    total_timesteps    | 4120576     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012744792 |\n",
      "|    entropy_loss       | -1.98       |\n",
      "|    explained_variance | 0.883       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.252       |\n",
      "|    mean_step_reward   | 0.098636165 |\n",
      "|    n_updates          | 2008        |\n",
      "|    policyGradLoss     | -0.00814    |\n",
      "|    value_loss         | 0.529       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 254         |\n",
      "|    total_timesteps    | 4128768     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012187997 |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.866       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.233       |\n",
      "|    mean_step_reward   | 0.098183975 |\n",
      "|    n_updates          | 2012        |\n",
      "|    policyGradLoss     | -0.00734    |\n",
      "|    value_loss         | 0.78        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 264         |\n",
      "|    total_timesteps    | 4136960     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013107842 |\n",
      "|    entropy_loss       | -1.98       |\n",
      "|    explained_variance | 0.867       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.205       |\n",
      "|    mean_step_reward   | 0.10442082  |\n",
      "|    n_updates          | 2016        |\n",
      "|    policyGradLoss     | -0.00759    |\n",
      "|    value_loss         | 0.851       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 275         |\n",
      "|    total_timesteps    | 4145152     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01609436  |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.849       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.145       |\n",
      "|    mean_step_reward   | 0.103129864 |\n",
      "|    n_updates          | 2020        |\n",
      "|    policyGradLoss     | -0.00812    |\n",
      "|    value_loss         | 0.814       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 286         |\n",
      "|    total_timesteps    | 4153344     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014041553 |\n",
      "|    entropy_loss       | -1.98       |\n",
      "|    explained_variance | 0.863       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.181       |\n",
      "|    mean_step_reward   | 0.10199083  |\n",
      "|    n_updates          | 2024        |\n",
      "|    policyGradLoss     | -0.00943    |\n",
      "|    value_loss         | 0.618       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 297         |\n",
      "|    total_timesteps    | 4161536     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013454912 |\n",
      "|    entropy_loss       | -2          |\n",
      "|    explained_variance | 0.812       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.169       |\n",
      "|    mean_step_reward   | 0.10191116  |\n",
      "|    n_updates          | 2028        |\n",
      "|    policyGradLoss     | -0.00196    |\n",
      "|    value_loss         | 1.25        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 308         |\n",
      "|    total_timesteps    | 4169728     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014370054 |\n",
      "|    entropy_loss       | -2.01       |\n",
      "|    explained_variance | 0.894       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.082       |\n",
      "|    mean_step_reward   | 0.09403103  |\n",
      "|    n_updates          | 2032        |\n",
      "|    policyGradLoss     | -0.0113     |\n",
      "|    value_loss         | 0.545       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 770          |\n",
      "|    iterations         | 30           |\n",
      "|    time_elapsed       | 318          |\n",
      "|    total_timesteps    | 4177920      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0108685745 |\n",
      "|    entropy_loss       | -2.04        |\n",
      "|    explained_variance | 0.838        |\n",
      "|    learning_rate      | 0.0002       |\n",
      "|    loss               | 0.0701       |\n",
      "|    mean_step_reward   | 0.0976103    |\n",
      "|    n_updates          | 2036         |\n",
      "|    policyGradLoss     | -0.0077      |\n",
      "|    value_loss         | 0.822        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 329         |\n",
      "|    total_timesteps    | 4186112     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013495636 |\n",
      "|    entropy_loss       | -2.02       |\n",
      "|    explained_variance | 0.834       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0535      |\n",
      "|    mean_step_reward   | 0.09253701  |\n",
      "|    n_updates          | 2040        |\n",
      "|    policyGradLoss     | -0.00785    |\n",
      "|    value_loss         | 0.578       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 340         |\n",
      "|    total_timesteps    | 4194304     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012791777 |\n",
      "|    entropy_loss       | -2.03       |\n",
      "|    explained_variance | 0.875       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0486      |\n",
      "|    mean_step_reward   | 0.095683    |\n",
      "|    n_updates          | 2044        |\n",
      "|    policyGradLoss     | -0.01       |\n",
      "|    value_loss         | 0.611       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 768        |\n",
      "|    iterations         | 33         |\n",
      "|    time_elapsed       | 351        |\n",
      "|    total_timesteps    | 4202496    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01674349 |\n",
      "|    entropy_loss       | -2.01      |\n",
      "|    explained_variance | 0.885      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | 0.131      |\n",
      "|    mean_step_reward   | 0.08978985 |\n",
      "|    n_updates          | 2048       |\n",
      "|    policyGradLoss     | -0.00811   |\n",
      "|    value_loss         | 0.722      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 34          |\n",
      "|    time_elapsed       | 362         |\n",
      "|    total_timesteps    | 4210688     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013334099 |\n",
      "|    entropy_loss       | -2.02       |\n",
      "|    explained_variance | 0.83        |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.141       |\n",
      "|    mean_step_reward   | 0.098006845 |\n",
      "|    n_updates          | 2052        |\n",
      "|    policyGradLoss     | -0.00691    |\n",
      "|    value_loss         | 0.711       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 35          |\n",
      "|    time_elapsed       | 373         |\n",
      "|    total_timesteps    | 4218880     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010854676 |\n",
      "|    entropy_loss       | -2.03       |\n",
      "|    explained_variance | 0.847       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.146       |\n",
      "|    mean_step_reward   | 0.100648396 |\n",
      "|    n_updates          | 2056        |\n",
      "|    policyGradLoss     | -0.00526    |\n",
      "|    value_loss         | 0.753       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 36          |\n",
      "|    time_elapsed       | 384         |\n",
      "|    total_timesteps    | 4227072     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012524083 |\n",
      "|    entropy_loss       | -2.02       |\n",
      "|    explained_variance | 0.867       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0542      |\n",
      "|    mean_step_reward   | 0.100336455 |\n",
      "|    n_updates          | 2060        |\n",
      "|    policyGradLoss     | -0.00368    |\n",
      "|    value_loss         | 0.449       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 37          |\n",
      "|    time_elapsed       | 394         |\n",
      "|    total_timesteps    | 4235264     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010395899 |\n",
      "|    entropy_loss       | -2.03       |\n",
      "|    explained_variance | 0.874       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.133       |\n",
      "|    mean_step_reward   | 0.08993149  |\n",
      "|    n_updates          | 2064        |\n",
      "|    policyGradLoss     | -0.00879    |\n",
      "|    value_loss         | 0.751       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 38          |\n",
      "|    time_elapsed       | 405         |\n",
      "|    total_timesteps    | 4243456     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010824544 |\n",
      "|    entropy_loss       | -2.02       |\n",
      "|    explained_variance | 0.898       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0745      |\n",
      "|    mean_step_reward   | 0.10896378  |\n",
      "|    n_updates          | 2068        |\n",
      "|    policyGradLoss     | -0.0079     |\n",
      "|    value_loss         | 0.652       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 39          |\n",
      "|    time_elapsed       | 416         |\n",
      "|    total_timesteps    | 4251648     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015651312 |\n",
      "|    entropy_loss       | -2.01       |\n",
      "|    explained_variance | 0.887       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.00829     |\n",
      "|    mean_step_reward   | 0.09759489  |\n",
      "|    n_updates          | 2072        |\n",
      "|    policyGradLoss     | -0.00701    |\n",
      "|    value_loss         | 0.487       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 766        |\n",
      "|    iterations         | 40         |\n",
      "|    time_elapsed       | 427        |\n",
      "|    total_timesteps    | 4259840    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01139931 |\n",
      "|    entropy_loss       | -1.99      |\n",
      "|    explained_variance | 0.828      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | 0.0775     |\n",
      "|    mean_step_reward   | 0.10097965 |\n",
      "|    n_updates          | 2076       |\n",
      "|    policyGradLoss     | -0.00655   |\n",
      "|    value_loss         | 0.65       |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/TNL_13.zip\n",
      "[EVAL] Mean Return: 104.800, Best Return: 105.013\n",
      "Saved video to ./runs_smw/videos/step_4259840_mean_104.80.mp4\n",
      "\n",
      "=== Round 9 | Learn 327680 steps (Total trained: 4259840) ===\n",
      "Logging to ./runs_smw/tb/tunnel_0\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1088    |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 7       |\n",
      "|    total_timesteps | 4268032 |\n",
      "--------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 894         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 4276224     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015124194 |\n",
      "|    entropy_loss       | -2.01       |\n",
      "|    explained_variance | 0.871       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.135       |\n",
      "|    mean_step_reward   | 0.09701364  |\n",
      "|    n_updates          | 2084        |\n",
      "|    policyGradLoss     | -0.00785    |\n",
      "|    value_loss         | 0.526       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 851         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 4284416     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009262333 |\n",
      "|    entropy_loss       | -2          |\n",
      "|    explained_variance | 0.785       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0858      |\n",
      "|    mean_step_reward   | 0.09106193  |\n",
      "|    n_updates          | 2088        |\n",
      "|    policyGradLoss     | -0.00707    |\n",
      "|    value_loss         | 0.704       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 824         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 4292608     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016259965 |\n",
      "|    entropy_loss       | -2.02       |\n",
      "|    explained_variance | 0.884       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.321       |\n",
      "|    mean_step_reward   | 0.10325302  |\n",
      "|    n_updates          | 2092        |\n",
      "|    policyGradLoss     | -0.00268    |\n",
      "|    value_loss         | 1.25        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 808         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 50          |\n",
      "|    total_timesteps    | 4300800     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014400646 |\n",
      "|    entropy_loss       | -2          |\n",
      "|    explained_variance | 0.882       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0303      |\n",
      "|    mean_step_reward   | 0.09366882  |\n",
      "|    n_updates          | 2096        |\n",
      "|    policyGradLoss     | -0.00563    |\n",
      "|    value_loss         | 0.555       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 801         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 61          |\n",
      "|    total_timesteps    | 4308992     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011238482 |\n",
      "|    entropy_loss       | -2          |\n",
      "|    explained_variance | 0.883       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.145       |\n",
      "|    mean_step_reward   | 0.102809474 |\n",
      "|    n_updates          | 2100        |\n",
      "|    policyGradLoss     | -0.00777    |\n",
      "|    value_loss         | 0.708       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 795         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 72          |\n",
      "|    total_timesteps    | 4317184     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014315626 |\n",
      "|    entropy_loss       | -1.99       |\n",
      "|    explained_variance | 0.895       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0536      |\n",
      "|    mean_step_reward   | 0.10125102  |\n",
      "|    n_updates          | 2104        |\n",
      "|    policyGradLoss     | -0.00831    |\n",
      "|    value_loss         | 0.786       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 792         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 82          |\n",
      "|    total_timesteps    | 4325376     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014485041 |\n",
      "|    entropy_loss       | -2          |\n",
      "|    explained_variance | 0.885       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.00201     |\n",
      "|    mean_step_reward   | 0.09648162  |\n",
      "|    n_updates          | 2108        |\n",
      "|    policyGradLoss     | -0.013      |\n",
      "|    value_loss         | 0.5         |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 788          |\n",
      "|    iterations         | 9            |\n",
      "|    time_elapsed       | 93           |\n",
      "|    total_timesteps    | 4333568      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0142284855 |\n",
      "|    entropy_loss       | -2.03        |\n",
      "|    explained_variance | 0.904        |\n",
      "|    learning_rate      | 0.0002       |\n",
      "|    loss               | 0.41         |\n",
      "|    mean_step_reward   | 0.10050988   |\n",
      "|    n_updates          | 2112         |\n",
      "|    policyGradLoss     | -0.00787     |\n",
      "|    value_loss         | 0.936        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 104         |\n",
      "|    total_timesteps    | 4341760     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014508954 |\n",
      "|    entropy_loss       | -2.02       |\n",
      "|    explained_variance | 0.905       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0825      |\n",
      "|    mean_step_reward   | 0.10281506  |\n",
      "|    n_updates          | 2116        |\n",
      "|    policyGradLoss     | -0.0117     |\n",
      "|    value_loss         | 0.603       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 114         |\n",
      "|    total_timesteps    | 4349952     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011407028 |\n",
      "|    entropy_loss       | -2.02       |\n",
      "|    explained_variance | 0.772       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.374       |\n",
      "|    mean_step_reward   | 0.09525661  |\n",
      "|    n_updates          | 2120        |\n",
      "|    policyGradLoss     | -0.00451    |\n",
      "|    value_loss         | 1.43        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 126         |\n",
      "|    total_timesteps    | 4358144     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010035258 |\n",
      "|    entropy_loss       | -2.02       |\n",
      "|    explained_variance | 0.808       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.239       |\n",
      "|    mean_step_reward   | 0.0932154   |\n",
      "|    n_updates          | 2124        |\n",
      "|    policyGradLoss     | -0.00673    |\n",
      "|    value_loss         | 0.91        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 136         |\n",
      "|    total_timesteps    | 4366336     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012826961 |\n",
      "|    entropy_loss       | -2.01       |\n",
      "|    explained_variance | 0.865       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0522      |\n",
      "|    mean_step_reward   | 0.093517214 |\n",
      "|    n_updates          | 2128        |\n",
      "|    policyGradLoss     | -0.0095     |\n",
      "|    value_loss         | 0.646       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 776          |\n",
      "|    iterations         | 14           |\n",
      "|    time_elapsed       | 147          |\n",
      "|    total_timesteps    | 4374528      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0146995615 |\n",
      "|    entropy_loss       | -2.02        |\n",
      "|    explained_variance | 0.918        |\n",
      "|    learning_rate      | 0.0002       |\n",
      "|    loss               | 0.0597       |\n",
      "|    mean_step_reward   | 0.10161381   |\n",
      "|    n_updates          | 2132         |\n",
      "|    policyGradLoss     | -0.00961     |\n",
      "|    value_loss         | 0.583        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 158         |\n",
      "|    total_timesteps    | 4382720     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017113931 |\n",
      "|    entropy_loss       | -2.01       |\n",
      "|    explained_variance | 0.885       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0819      |\n",
      "|    mean_step_reward   | 0.0906484   |\n",
      "|    n_updates          | 2136        |\n",
      "|    policyGradLoss     | -0.0121     |\n",
      "|    value_loss         | 0.574       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 169         |\n",
      "|    total_timesteps    | 4390912     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016375616 |\n",
      "|    entropy_loss       | -2          |\n",
      "|    explained_variance | 0.806       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.229       |\n",
      "|    mean_step_reward   | 0.08926365  |\n",
      "|    n_updates          | 2140        |\n",
      "|    policyGradLoss     | -0.00908    |\n",
      "|    value_loss         | 0.569       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 180         |\n",
      "|    total_timesteps    | 4399104     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013830055 |\n",
      "|    entropy_loss       | -2          |\n",
      "|    explained_variance | 0.843       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.057       |\n",
      "|    mean_step_reward   | 0.09818229  |\n",
      "|    n_updates          | 2144        |\n",
      "|    policyGradLoss     | -0.00444    |\n",
      "|    value_loss         | 0.676       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 190         |\n",
      "|    total_timesteps    | 4407296     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018135253 |\n",
      "|    entropy_loss       | -1.98       |\n",
      "|    explained_variance | 0.845       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0961      |\n",
      "|    mean_step_reward   | 0.093574405 |\n",
      "|    n_updates          | 2148        |\n",
      "|    policyGradLoss     | -0.00659    |\n",
      "|    value_loss         | 0.637       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 201         |\n",
      "|    total_timesteps    | 4415488     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017115701 |\n",
      "|    entropy_loss       | -1.98       |\n",
      "|    explained_variance | 0.851       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0479      |\n",
      "|    mean_step_reward   | 0.09569885  |\n",
      "|    n_updates          | 2152        |\n",
      "|    policyGradLoss     | -0.00451    |\n",
      "|    value_loss         | 0.575       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 211         |\n",
      "|    total_timesteps    | 4423680     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016130503 |\n",
      "|    entropy_loss       | -1.97       |\n",
      "|    explained_variance | 0.854       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0441      |\n",
      "|    mean_step_reward   | 0.098991334 |\n",
      "|    n_updates          | 2156        |\n",
      "|    policyGradLoss     | -0.011      |\n",
      "|    value_loss         | 0.299       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 222         |\n",
      "|    total_timesteps    | 4431872     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015804723 |\n",
      "|    entropy_loss       | -1.97       |\n",
      "|    explained_variance | 0.848       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.169       |\n",
      "|    mean_step_reward   | 0.09765313  |\n",
      "|    n_updates          | 2160        |\n",
      "|    policyGradLoss     | -0.00672    |\n",
      "|    value_loss         | 0.697       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 770        |\n",
      "|    iterations         | 22         |\n",
      "|    time_elapsed       | 233        |\n",
      "|    total_timesteps    | 4440064    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01317945 |\n",
      "|    entropy_loss       | -1.95      |\n",
      "|    explained_variance | 0.873      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | 0.0653     |\n",
      "|    mean_step_reward   | 0.09334391 |\n",
      "|    n_updates          | 2164       |\n",
      "|    policyGradLoss     | -0.0114    |\n",
      "|    value_loss         | 0.488      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 244         |\n",
      "|    total_timesteps    | 4448256     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017214395 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.883       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.012       |\n",
      "|    mean_step_reward   | 0.09933028  |\n",
      "|    n_updates          | 2168        |\n",
      "|    policyGradLoss     | -0.00868    |\n",
      "|    value_loss         | 0.472       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 255         |\n",
      "|    total_timesteps    | 4456448     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017852541 |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.903       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.118       |\n",
      "|    mean_step_reward   | 0.100015014 |\n",
      "|    n_updates          | 2172        |\n",
      "|    policyGradLoss     | -0.0118     |\n",
      "|    value_loss         | 0.533       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 266         |\n",
      "|    total_timesteps    | 4464640     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012323689 |\n",
      "|    entropy_loss       | -1.98       |\n",
      "|    explained_variance | 0.865       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0363      |\n",
      "|    mean_step_reward   | 0.106421545 |\n",
      "|    n_updates          | 2176        |\n",
      "|    policyGradLoss     | -0.00774    |\n",
      "|    value_loss         | 0.574       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 277         |\n",
      "|    total_timesteps    | 4472832     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014877589 |\n",
      "|    entropy_loss       | -1.97       |\n",
      "|    explained_variance | 0.897       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.00481    |\n",
      "|    mean_step_reward   | 0.09809328  |\n",
      "|    n_updates          | 2180        |\n",
      "|    policyGradLoss     | -0.00945    |\n",
      "|    value_loss         | 0.399       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 288         |\n",
      "|    total_timesteps    | 4481024     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014511276 |\n",
      "|    entropy_loss       | -1.98       |\n",
      "|    explained_variance | 0.831       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0927      |\n",
      "|    mean_step_reward   | 0.105247736 |\n",
      "|    n_updates          | 2184        |\n",
      "|    policyGradLoss     | -0.00684    |\n",
      "|    value_loss         | 0.731       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 299         |\n",
      "|    total_timesteps    | 4489216     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013244139 |\n",
      "|    entropy_loss       | -2.01       |\n",
      "|    explained_variance | 0.917       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0216      |\n",
      "|    mean_step_reward   | 0.11057726  |\n",
      "|    n_updates          | 2188        |\n",
      "|    policyGradLoss     | -0.00744    |\n",
      "|    value_loss         | 0.385       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 309         |\n",
      "|    total_timesteps    | 4497408     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016302224 |\n",
      "|    entropy_loss       | -1.99       |\n",
      "|    explained_variance | 0.831       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0043      |\n",
      "|    mean_step_reward   | 0.09386209  |\n",
      "|    n_updates          | 2192        |\n",
      "|    policyGradLoss     | -0.00895    |\n",
      "|    value_loss         | 0.552       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 320         |\n",
      "|    total_timesteps    | 4505600     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018157575 |\n",
      "|    entropy_loss       | -1.99       |\n",
      "|    explained_variance | 0.884       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0807      |\n",
      "|    mean_step_reward   | 0.09524064  |\n",
      "|    n_updates          | 2196        |\n",
      "|    policyGradLoss     | -0.00703    |\n",
      "|    value_loss         | 0.659       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 331         |\n",
      "|    total_timesteps    | 4513792     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014116596 |\n",
      "|    entropy_loss       | -1.99       |\n",
      "|    explained_variance | 0.858       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.00991     |\n",
      "|    mean_step_reward   | 0.096406    |\n",
      "|    n_updates          | 2200        |\n",
      "|    policyGradLoss     | -0.00985    |\n",
      "|    value_loss         | 0.402       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 765         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 342         |\n",
      "|    total_timesteps    | 4521984     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014712618 |\n",
      "|    entropy_loss       | -1.99       |\n",
      "|    explained_variance | 0.914       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0135     |\n",
      "|    mean_step_reward   | 0.09520683  |\n",
      "|    n_updates          | 2204        |\n",
      "|    policyGradLoss     | -0.0133     |\n",
      "|    value_loss         | 0.379       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 764         |\n",
      "|    iterations         | 33          |\n",
      "|    time_elapsed       | 353         |\n",
      "|    total_timesteps    | 4530176     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012200054 |\n",
      "|    entropy_loss       | -2          |\n",
      "|    explained_variance | 0.865       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0322      |\n",
      "|    mean_step_reward   | 0.097936586 |\n",
      "|    n_updates          | 2208        |\n",
      "|    policyGradLoss     | -0.00873    |\n",
      "|    value_loss         | 0.534       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 765         |\n",
      "|    iterations         | 34          |\n",
      "|    time_elapsed       | 363         |\n",
      "|    total_timesteps    | 4538368     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018427094 |\n",
      "|    entropy_loss       | -1.99       |\n",
      "|    explained_variance | 0.894       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0673      |\n",
      "|    mean_step_reward   | 0.095237285 |\n",
      "|    n_updates          | 2212        |\n",
      "|    policyGradLoss     | -0.0102     |\n",
      "|    value_loss         | 0.607       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 764         |\n",
      "|    iterations         | 35          |\n",
      "|    time_elapsed       | 375         |\n",
      "|    total_timesteps    | 4546560     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014757746 |\n",
      "|    entropy_loss       | -1.99       |\n",
      "|    explained_variance | 0.882       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.176       |\n",
      "|    mean_step_reward   | 0.09342182  |\n",
      "|    n_updates          | 2216        |\n",
      "|    policyGradLoss     | -0.00934    |\n",
      "|    value_loss         | 0.745       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 763         |\n",
      "|    iterations         | 36          |\n",
      "|    time_elapsed       | 386         |\n",
      "|    total_timesteps    | 4554752     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019672368 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.887       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.138       |\n",
      "|    mean_step_reward   | 0.101613835 |\n",
      "|    n_updates          | 2220        |\n",
      "|    policyGradLoss     | -0.00984    |\n",
      "|    value_loss         | 0.802       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 763         |\n",
      "|    iterations         | 37          |\n",
      "|    time_elapsed       | 396         |\n",
      "|    total_timesteps    | 4562944     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013738438 |\n",
      "|    entropy_loss       | -1.97       |\n",
      "|    explained_variance | 0.842       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.116       |\n",
      "|    mean_step_reward   | 0.0928497   |\n",
      "|    n_updates          | 2224        |\n",
      "|    policyGradLoss     | -0.00701    |\n",
      "|    value_loss         | 0.781       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 763        |\n",
      "|    iterations         | 38         |\n",
      "|    time_elapsed       | 407        |\n",
      "|    total_timesteps    | 4571136    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01724951 |\n",
      "|    entropy_loss       | -1.98      |\n",
      "|    explained_variance | 0.903      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | 0.0549     |\n",
      "|    mean_step_reward   | 0.10262349 |\n",
      "|    n_updates          | 2228       |\n",
      "|    policyGradLoss     | -0.014     |\n",
      "|    value_loss         | 0.429      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 763         |\n",
      "|    iterations         | 39          |\n",
      "|    time_elapsed       | 418         |\n",
      "|    total_timesteps    | 4579328     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014840484 |\n",
      "|    entropy_loss       | -1.98       |\n",
      "|    explained_variance | 0.913       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0629      |\n",
      "|    mean_step_reward   | 0.103108555 |\n",
      "|    n_updates          | 2232        |\n",
      "|    policyGradLoss     | -0.00759    |\n",
      "|    value_loss         | 0.586       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 763         |\n",
      "|    iterations         | 40          |\n",
      "|    time_elapsed       | 429         |\n",
      "|    total_timesteps    | 4587520     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015951632 |\n",
      "|    entropy_loss       | -1.98       |\n",
      "|    explained_variance | 0.915       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0228      |\n",
      "|    mean_step_reward   | 0.10397767  |\n",
      "|    n_updates          | 2236        |\n",
      "|    policyGradLoss     | -0.0103     |\n",
      "|    value_loss         | 0.425       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/TNL_14.zip\n",
      "[EVAL] Mean Return: 50.118, Best Return: 50.231\n",
      "Saved video to ./runs_smw/videos/step_4587520_mean_50.12.mp4\n",
      "\n",
      "=== Round 10 | Learn 327680 steps (Total trained: 4587520) ===\n",
      "Logging to ./runs_smw/tb/tunnel_0\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1117    |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 7       |\n",
      "|    total_timesteps | 4595712 |\n",
      "--------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 893          |\n",
      "|    iterations         | 2            |\n",
      "|    time_elapsed       | 18           |\n",
      "|    total_timesteps    | 4603904      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0141735375 |\n",
      "|    entropy_loss       | -1.98        |\n",
      "|    explained_variance | 0.863        |\n",
      "|    learning_rate      | 0.0002       |\n",
      "|    loss               | 0.096        |\n",
      "|    mean_step_reward   | 0.09792863   |\n",
      "|    n_updates          | 2244         |\n",
      "|    policyGradLoss     | -0.00778     |\n",
      "|    value_loss         | 0.651        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 846         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 29          |\n",
      "|    total_timesteps    | 4612096     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016240425 |\n",
      "|    entropy_loss       | -1.97       |\n",
      "|    explained_variance | 0.869       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0155     |\n",
      "|    mean_step_reward   | 0.09619264  |\n",
      "|    n_updates          | 2248        |\n",
      "|    policyGradLoss     | -0.0119     |\n",
      "|    value_loss         | 0.399       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 824         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 4620288     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013414254 |\n",
      "|    entropy_loss       | -2          |\n",
      "|    explained_variance | 0.815       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.163       |\n",
      "|    mean_step_reward   | 0.106042184 |\n",
      "|    n_updates          | 2252        |\n",
      "|    policyGradLoss     | -0.00127    |\n",
      "|    value_loss         | 1.08        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 809         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 50          |\n",
      "|    total_timesteps    | 4628480     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016936732 |\n",
      "|    entropy_loss       | -2.01       |\n",
      "|    explained_variance | 0.91        |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0134      |\n",
      "|    mean_step_reward   | 0.104603544 |\n",
      "|    n_updates          | 2256        |\n",
      "|    policyGradLoss     | -0.0081     |\n",
      "|    value_loss         | 0.349       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 798         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 61          |\n",
      "|    total_timesteps    | 4636672     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014258923 |\n",
      "|    entropy_loss       | -1.99       |\n",
      "|    explained_variance | 0.902       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0413      |\n",
      "|    mean_step_reward   | 0.09848633  |\n",
      "|    n_updates          | 2260        |\n",
      "|    policyGradLoss     | -0.00946    |\n",
      "|    value_loss         | 0.519       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 791         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 72          |\n",
      "|    total_timesteps    | 4644864     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013037324 |\n",
      "|    entropy_loss       | -2.01       |\n",
      "|    explained_variance | 0.873       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0631      |\n",
      "|    mean_step_reward   | 0.09907618  |\n",
      "|    n_updates          | 2264        |\n",
      "|    policyGradLoss     | -0.00706    |\n",
      "|    value_loss         | 0.686       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 790         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 82          |\n",
      "|    total_timesteps    | 4653056     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018126078 |\n",
      "|    entropy_loss       | -1.99       |\n",
      "|    explained_variance | 0.94        |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.041       |\n",
      "|    mean_step_reward   | 0.104764774 |\n",
      "|    n_updates          | 2268        |\n",
      "|    policyGradLoss     | -0.0136     |\n",
      "|    value_loss         | 0.375       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 93          |\n",
      "|    total_timesteps    | 4661248     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018069949 |\n",
      "|    entropy_loss       | -2.01       |\n",
      "|    explained_variance | 0.931       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.262       |\n",
      "|    mean_step_reward   | 0.101409644 |\n",
      "|    n_updates          | 2272        |\n",
      "|    policyGradLoss     | -0.00897    |\n",
      "|    value_loss         | 0.636       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 784        |\n",
      "|    iterations         | 10         |\n",
      "|    time_elapsed       | 104        |\n",
      "|    total_timesteps    | 4669440    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01276603 |\n",
      "|    entropy_loss       | -2         |\n",
      "|    explained_variance | 0.926      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | 0.125      |\n",
      "|    mean_step_reward   | 0.10292846 |\n",
      "|    n_updates          | 2276       |\n",
      "|    policyGradLoss     | -0.0114    |\n",
      "|    value_loss         | 0.479      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 115         |\n",
      "|    total_timesteps    | 4677632     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016917173 |\n",
      "|    entropy_loss       | -1.99       |\n",
      "|    explained_variance | 0.933       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0113      |\n",
      "|    mean_step_reward   | 0.104030654 |\n",
      "|    n_updates          | 2280        |\n",
      "|    policyGradLoss     | -0.00985    |\n",
      "|    value_loss         | 0.342       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 125         |\n",
      "|    total_timesteps    | 4685824     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013294276 |\n",
      "|    entropy_loss       | -1.99       |\n",
      "|    explained_variance | 0.881       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.118       |\n",
      "|    mean_step_reward   | 0.100410186 |\n",
      "|    n_updates          | 2284        |\n",
      "|    policyGradLoss     | -0.00765    |\n",
      "|    value_loss         | 0.844       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 136         |\n",
      "|    total_timesteps    | 4694016     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013879886 |\n",
      "|    entropy_loss       | -1.99       |\n",
      "|    explained_variance | 0.918       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0549      |\n",
      "|    mean_step_reward   | 0.10698032  |\n",
      "|    n_updates          | 2288        |\n",
      "|    policyGradLoss     | -0.0059     |\n",
      "|    value_loss         | 0.446       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 777        |\n",
      "|    iterations         | 14         |\n",
      "|    time_elapsed       | 147        |\n",
      "|    total_timesteps    | 4702208    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01642438 |\n",
      "|    entropy_loss       | -1.98      |\n",
      "|    explained_variance | 0.882      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | 0.0603     |\n",
      "|    mean_step_reward   | 0.10120408 |\n",
      "|    n_updates          | 2292       |\n",
      "|    policyGradLoss     | -0.00762   |\n",
      "|    value_loss         | 0.562      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 158         |\n",
      "|    total_timesteps    | 4710400     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012036093 |\n",
      "|    entropy_loss       | -1.99       |\n",
      "|    explained_variance | 0.923       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0356      |\n",
      "|    mean_step_reward   | 0.10738061  |\n",
      "|    n_updates          | 2296        |\n",
      "|    policyGradLoss     | -0.0117     |\n",
      "|    value_loss         | 0.461       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 169         |\n",
      "|    total_timesteps    | 4718592     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014425593 |\n",
      "|    entropy_loss       | -1.98       |\n",
      "|    explained_variance | 0.862       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.136       |\n",
      "|    mean_step_reward   | 0.09739321  |\n",
      "|    n_updates          | 2300        |\n",
      "|    policyGradLoss     | -0.00794    |\n",
      "|    value_loss         | 0.61        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 775          |\n",
      "|    iterations         | 17           |\n",
      "|    time_elapsed       | 179          |\n",
      "|    total_timesteps    | 4726784      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0142233055 |\n",
      "|    entropy_loss       | -1.97        |\n",
      "|    explained_variance | 0.867        |\n",
      "|    learning_rate      | 0.0002       |\n",
      "|    loss               | 0.0128       |\n",
      "|    mean_step_reward   | 0.10720404   |\n",
      "|    n_updates          | 2304         |\n",
      "|    policyGradLoss     | -0.00746     |\n",
      "|    value_loss         | 0.485        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 190         |\n",
      "|    total_timesteps    | 4734976     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012809504 |\n",
      "|    entropy_loss       | -1.99       |\n",
      "|    explained_variance | 0.879       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0216      |\n",
      "|    mean_step_reward   | 0.10054557  |\n",
      "|    n_updates          | 2308        |\n",
      "|    policyGradLoss     | -0.0116     |\n",
      "|    value_loss         | 0.461       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 201         |\n",
      "|    total_timesteps    | 4743168     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019312516 |\n",
      "|    entropy_loss       | -1.97       |\n",
      "|    explained_variance | 0.946       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.136       |\n",
      "|    mean_step_reward   | 0.11228639  |\n",
      "|    n_updates          | 2312        |\n",
      "|    policyGradLoss     | -0.0116     |\n",
      "|    value_loss         | 0.5         |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 772        |\n",
      "|    iterations         | 20         |\n",
      "|    time_elapsed       | 212        |\n",
      "|    total_timesteps    | 4751360    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01681466 |\n",
      "|    entropy_loss       | -1.96      |\n",
      "|    explained_variance | 0.935      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | 0.0794     |\n",
      "|    mean_step_reward   | 0.10773698 |\n",
      "|    n_updates          | 2316       |\n",
      "|    policyGradLoss     | -0.0135    |\n",
      "|    value_loss         | 0.47       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 222         |\n",
      "|    total_timesteps    | 4759552     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011914568 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.878       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0531      |\n",
      "|    mean_step_reward   | 0.10809039  |\n",
      "|    n_updates          | 2320        |\n",
      "|    policyGradLoss     | -0.0112     |\n",
      "|    value_loss         | 0.493       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 233         |\n",
      "|    total_timesteps    | 4767744     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010953948 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.861       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.176       |\n",
      "|    mean_step_reward   | 0.11191256  |\n",
      "|    n_updates          | 2324        |\n",
      "|    policyGradLoss     | -0.00335    |\n",
      "|    value_loss         | 0.818       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 244         |\n",
      "|    total_timesteps    | 4775936     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009708601 |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.897       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0882      |\n",
      "|    mean_step_reward   | 0.11578006  |\n",
      "|    n_updates          | 2328        |\n",
      "|    policyGradLoss     | -0.00855    |\n",
      "|    value_loss         | 0.704       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 254         |\n",
      "|    total_timesteps    | 4784128     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012422636 |\n",
      "|    entropy_loss       | -1.97       |\n",
      "|    explained_variance | 0.888       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.00987    |\n",
      "|    mean_step_reward   | 0.10548521  |\n",
      "|    n_updates          | 2332        |\n",
      "|    policyGradLoss     | -0.00669    |\n",
      "|    value_loss         | 0.504       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 771          |\n",
      "|    iterations         | 25           |\n",
      "|    time_elapsed       | 265          |\n",
      "|    total_timesteps    | 4792320      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0111734625 |\n",
      "|    entropy_loss       | -1.96        |\n",
      "|    explained_variance | 0.95         |\n",
      "|    learning_rate      | 0.0002       |\n",
      "|    loss               | 0.0973       |\n",
      "|    mean_step_reward   | 0.1173508    |\n",
      "|    n_updates          | 2336         |\n",
      "|    policyGradLoss     | -0.0107      |\n",
      "|    value_loss         | 0.496        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 275         |\n",
      "|    total_timesteps    | 4800512     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013537049 |\n",
      "|    entropy_loss       | -2          |\n",
      "|    explained_variance | 0.952       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0908      |\n",
      "|    mean_step_reward   | 0.12104458  |\n",
      "|    n_updates          | 2340        |\n",
      "|    policyGradLoss     | -0.0115     |\n",
      "|    value_loss         | 0.54        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 286         |\n",
      "|    total_timesteps    | 4808704     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009868318 |\n",
      "|    entropy_loss       | -2          |\n",
      "|    explained_variance | 0.895       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0588      |\n",
      "|    mean_step_reward   | 0.11407595  |\n",
      "|    n_updates          | 2344        |\n",
      "|    policyGradLoss     | -0.00535    |\n",
      "|    value_loss         | 0.498       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 771          |\n",
      "|    iterations         | 28           |\n",
      "|    time_elapsed       | 297          |\n",
      "|    total_timesteps    | 4816896      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0113475295 |\n",
      "|    entropy_loss       | -2           |\n",
      "|    explained_variance | 0.924        |\n",
      "|    learning_rate      | 0.0002       |\n",
      "|    loss               | 0.0525       |\n",
      "|    mean_step_reward   | 0.1125315    |\n",
      "|    n_updates          | 2348         |\n",
      "|    policyGradLoss     | -0.00853     |\n",
      "|    value_loss         | 0.672        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 308         |\n",
      "|    total_timesteps    | 4825088     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014405042 |\n",
      "|    entropy_loss       | -1.99       |\n",
      "|    explained_variance | 0.905       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0257      |\n",
      "|    mean_step_reward   | 0.106663704 |\n",
      "|    n_updates          | 2352        |\n",
      "|    policyGradLoss     | -0.014      |\n",
      "|    value_loss         | 0.592       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 770        |\n",
      "|    iterations         | 30         |\n",
      "|    time_elapsed       | 318        |\n",
      "|    total_timesteps    | 4833280    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01645524 |\n",
      "|    entropy_loss       | -1.97      |\n",
      "|    explained_variance | 0.913      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | 0.0854     |\n",
      "|    mean_step_reward   | 0.09615583 |\n",
      "|    n_updates          | 2356       |\n",
      "|    policyGradLoss     | -0.0149    |\n",
      "|    value_loss         | 0.548      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 329         |\n",
      "|    total_timesteps    | 4841472     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017133221 |\n",
      "|    entropy_loss       | -1.99       |\n",
      "|    explained_variance | 0.883       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0449      |\n",
      "|    mean_step_reward   | 0.10489004  |\n",
      "|    n_updates          | 2360        |\n",
      "|    policyGradLoss     | -0.00754    |\n",
      "|    value_loss         | 0.524       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 339         |\n",
      "|    total_timesteps    | 4849664     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011408661 |\n",
      "|    entropy_loss       | -1.98       |\n",
      "|    explained_variance | 0.787       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.225       |\n",
      "|    mean_step_reward   | 0.09793289  |\n",
      "|    n_updates          | 2364        |\n",
      "|    policyGradLoss     | -0.00706    |\n",
      "|    value_loss         | 0.773       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 772        |\n",
      "|    iterations         | 33         |\n",
      "|    time_elapsed       | 350        |\n",
      "|    total_timesteps    | 4857856    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01566793 |\n",
      "|    entropy_loss       | -1.97      |\n",
      "|    explained_variance | 0.927      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | 0.13       |\n",
      "|    mean_step_reward   | 0.09805125 |\n",
      "|    n_updates          | 2368       |\n",
      "|    policyGradLoss     | -0.0118    |\n",
      "|    value_loss         | 0.55       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 34          |\n",
      "|    time_elapsed       | 360         |\n",
      "|    total_timesteps    | 4866048     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016905462 |\n",
      "|    entropy_loss       | -1.99       |\n",
      "|    explained_variance | 0.936       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.019      |\n",
      "|    mean_step_reward   | 0.094449505 |\n",
      "|    n_updates          | 2372        |\n",
      "|    policyGradLoss     | -0.0167     |\n",
      "|    value_loss         | 0.301       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 35          |\n",
      "|    time_elapsed       | 371         |\n",
      "|    total_timesteps    | 4874240     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018896956 |\n",
      "|    entropy_loss       | -1.98       |\n",
      "|    explained_variance | 0.945       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.00124     |\n",
      "|    mean_step_reward   | 0.1001194   |\n",
      "|    n_updates          | 2376        |\n",
      "|    policyGradLoss     | -0.0131     |\n",
      "|    value_loss         | 0.409       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 36          |\n",
      "|    time_elapsed       | 382         |\n",
      "|    total_timesteps    | 4882432     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017903777 |\n",
      "|    entropy_loss       | -1.98       |\n",
      "|    explained_variance | 0.949       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.00108     |\n",
      "|    mean_step_reward   | 0.118170016 |\n",
      "|    n_updates          | 2380        |\n",
      "|    policyGradLoss     | -0.0131     |\n",
      "|    value_loss         | 0.355       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 37          |\n",
      "|    time_elapsed       | 393         |\n",
      "|    total_timesteps    | 4890624     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014191056 |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.879       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0845      |\n",
      "|    mean_step_reward   | 0.097018935 |\n",
      "|    n_updates          | 2384        |\n",
      "|    policyGradLoss     | -0.00949    |\n",
      "|    value_loss         | 0.538       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 38          |\n",
      "|    time_elapsed       | 404         |\n",
      "|    total_timesteps    | 4898816     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013438944 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.858       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0319      |\n",
      "|    mean_step_reward   | 0.09572766  |\n",
      "|    n_updates          | 2388        |\n",
      "|    policyGradLoss     | -0.00986    |\n",
      "|    value_loss         | 0.543       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 39          |\n",
      "|    time_elapsed       | 414         |\n",
      "|    total_timesteps    | 4907008     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018975422 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.908       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.00882     |\n",
      "|    mean_step_reward   | 0.10298744  |\n",
      "|    n_updates          | 2392        |\n",
      "|    policyGradLoss     | -0.0124     |\n",
      "|    value_loss         | 0.374       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 769        |\n",
      "|    iterations         | 40         |\n",
      "|    time_elapsed       | 425        |\n",
      "|    total_timesteps    | 4915200    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01512127 |\n",
      "|    entropy_loss       | -1.94      |\n",
      "|    explained_variance | 0.891      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | 0.0263     |\n",
      "|    mean_step_reward   | 0.10108787 |\n",
      "|    n_updates          | 2396       |\n",
      "|    policyGradLoss     | -0.0099    |\n",
      "|    value_loss         | 0.566      |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/TNL_15.zip\n",
      "[EVAL] Mean Return: 183.317, Best Return: 183.674\n",
      "Saved video to ./runs_smw/videos/step_4915200_mean_183.32.mp4\n",
      "\n",
      "=== Round 11 | Learn 327680 steps (Total trained: 4915200) ===\n",
      "Logging to ./runs_smw/tb/tunnel_0\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1103    |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 7       |\n",
      "|    total_timesteps | 4923392 |\n",
      "--------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 899         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 4931584     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016582938 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.935       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0172     |\n",
      "|    mean_step_reward   | 0.108501285 |\n",
      "|    n_updates          | 2404        |\n",
      "|    policyGradLoss     | -0.0111     |\n",
      "|    value_loss         | 0.37        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 845         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 29          |\n",
      "|    total_timesteps    | 4939776     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014884369 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.827       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.00267    |\n",
      "|    mean_step_reward   | 0.09311686  |\n",
      "|    n_updates          | 2408        |\n",
      "|    policyGradLoss     | -0.00992    |\n",
      "|    value_loss         | 0.539       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 821         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 4947968     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015187395 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.857       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0245     |\n",
      "|    mean_step_reward   | 0.10895733  |\n",
      "|    n_updates          | 2412        |\n",
      "|    policyGradLoss     | -0.0116     |\n",
      "|    value_loss         | 0.31        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 809         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 50          |\n",
      "|    total_timesteps    | 4956160     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013081333 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.845       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0492      |\n",
      "|    mean_step_reward   | 0.10201919  |\n",
      "|    n_updates          | 2416        |\n",
      "|    policyGradLoss     | -0.0054     |\n",
      "|    value_loss         | 0.571       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 801         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 61          |\n",
      "|    total_timesteps    | 4964352     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015237111 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.886       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.113       |\n",
      "|    mean_step_reward   | 0.11141993  |\n",
      "|    n_updates          | 2420        |\n",
      "|    policyGradLoss     | -0.00398    |\n",
      "|    value_loss         | 0.74        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 796         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 72          |\n",
      "|    total_timesteps    | 4972544     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015113759 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.902       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.00572     |\n",
      "|    mean_step_reward   | 0.101782    |\n",
      "|    n_updates          | 2424        |\n",
      "|    policyGradLoss     | -0.0105     |\n",
      "|    value_loss         | 0.443       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 791         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 82          |\n",
      "|    total_timesteps    | 4980736     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016246814 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.817       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.022      |\n",
      "|    mean_step_reward   | 0.10514717  |\n",
      "|    n_updates          | 2428        |\n",
      "|    policyGradLoss     | -0.00905    |\n",
      "|    value_loss         | 0.287       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 93          |\n",
      "|    total_timesteps    | 4988928     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014464544 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.839       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0742      |\n",
      "|    mean_step_reward   | 0.1048464   |\n",
      "|    n_updates          | 2432        |\n",
      "|    policyGradLoss     | -0.00456    |\n",
      "|    value_loss         | 0.589       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 104         |\n",
      "|    total_timesteps    | 4997120     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012144632 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.915       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.00329    |\n",
      "|    mean_step_reward   | 0.114730574 |\n",
      "|    n_updates          | 2436        |\n",
      "|    policyGradLoss     | -0.00891    |\n",
      "|    value_loss         | 0.352       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 784        |\n",
      "|    iterations         | 11         |\n",
      "|    time_elapsed       | 114        |\n",
      "|    total_timesteps    | 5005312    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01170636 |\n",
      "|    entropy_loss       | -1.94      |\n",
      "|    explained_variance | 0.847      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | 0.0836     |\n",
      "|    mean_step_reward   | 0.1104828  |\n",
      "|    n_updates          | 2440       |\n",
      "|    policyGradLoss     | -0.000452  |\n",
      "|    value_loss         | 1.16       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 782        |\n",
      "|    iterations         | 12         |\n",
      "|    time_elapsed       | 125        |\n",
      "|    total_timesteps    | 5013504    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01617402 |\n",
      "|    entropy_loss       | -1.93      |\n",
      "|    explained_variance | 0.919      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | -0.00578   |\n",
      "|    mean_step_reward   | 0.10932998 |\n",
      "|    n_updates          | 2444       |\n",
      "|    policyGradLoss     | -0.00851   |\n",
      "|    value_loss         | 0.314      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 136         |\n",
      "|    total_timesteps    | 5021696     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010279071 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.86        |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.194       |\n",
      "|    mean_step_reward   | 0.103462964 |\n",
      "|    n_updates          | 2448        |\n",
      "|    policyGradLoss     | -0.00625    |\n",
      "|    value_loss         | 0.998       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 147         |\n",
      "|    total_timesteps    | 5029888     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013676934 |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.897       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0664      |\n",
      "|    mean_step_reward   | 0.105377115 |\n",
      "|    n_updates          | 2452        |\n",
      "|    policyGradLoss     | -0.00724    |\n",
      "|    value_loss         | 0.565       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 158         |\n",
      "|    total_timesteps    | 5038080     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013242053 |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.893       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.031       |\n",
      "|    mean_step_reward   | 0.10904707  |\n",
      "|    n_updates          | 2456        |\n",
      "|    policyGradLoss     | -0.0118     |\n",
      "|    value_loss         | 0.47        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 168         |\n",
      "|    total_timesteps    | 5046272     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011658326 |\n",
      "|    entropy_loss       | -1.98       |\n",
      "|    explained_variance | 0.905       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0754      |\n",
      "|    mean_step_reward   | 0.1086393   |\n",
      "|    n_updates          | 2460        |\n",
      "|    policyGradLoss     | -0.00891    |\n",
      "|    value_loss         | 0.57        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 179         |\n",
      "|    total_timesteps    | 5054464     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013051838 |\n",
      "|    entropy_loss       | -1.97       |\n",
      "|    explained_variance | 0.95        |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0054     |\n",
      "|    mean_step_reward   | 0.112876296 |\n",
      "|    n_updates          | 2464        |\n",
      "|    policyGradLoss     | -0.0127     |\n",
      "|    value_loss         | 0.464       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 190         |\n",
      "|    total_timesteps    | 5062656     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016412292 |\n",
      "|    entropy_loss       | -1.97       |\n",
      "|    explained_variance | 0.95        |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0106     |\n",
      "|    mean_step_reward   | 0.10892329  |\n",
      "|    n_updates          | 2468        |\n",
      "|    policyGradLoss     | -0.0126     |\n",
      "|    value_loss         | 0.316       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 201         |\n",
      "|    total_timesteps    | 5070848     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014567878 |\n",
      "|    entropy_loss       | -2          |\n",
      "|    explained_variance | 0.937       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0558      |\n",
      "|    mean_step_reward   | 0.121849075 |\n",
      "|    n_updates          | 2472        |\n",
      "|    policyGradLoss     | -0.00907    |\n",
      "|    value_loss         | 0.524       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 211         |\n",
      "|    total_timesteps    | 5079040     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010498557 |\n",
      "|    entropy_loss       | -1.98       |\n",
      "|    explained_variance | 0.869       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0671      |\n",
      "|    mean_step_reward   | 0.110711746 |\n",
      "|    n_updates          | 2476        |\n",
      "|    policyGradLoss     | -0.00551    |\n",
      "|    value_loss         | 0.57        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 222         |\n",
      "|    total_timesteps    | 5087232     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016835425 |\n",
      "|    entropy_loss       | -1.97       |\n",
      "|    explained_variance | 0.939       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0715      |\n",
      "|    mean_step_reward   | 0.113693945 |\n",
      "|    n_updates          | 2480        |\n",
      "|    policyGradLoss     | -0.0112     |\n",
      "|    value_loss         | 0.533       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 233         |\n",
      "|    total_timesteps    | 5095424     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014817402 |\n",
      "|    entropy_loss       | -1.98       |\n",
      "|    explained_variance | 0.925       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.013       |\n",
      "|    mean_step_reward   | 0.11276804  |\n",
      "|    n_updates          | 2484        |\n",
      "|    policyGradLoss     | -0.00973    |\n",
      "|    value_loss         | 0.457       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 243         |\n",
      "|    total_timesteps    | 5103616     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012924377 |\n",
      "|    entropy_loss       | -1.98       |\n",
      "|    explained_variance | 0.902       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0286      |\n",
      "|    mean_step_reward   | 0.1058656   |\n",
      "|    n_updates          | 2488        |\n",
      "|    policyGradLoss     | -0.00911    |\n",
      "|    value_loss         | 0.599       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 254         |\n",
      "|    total_timesteps    | 5111808     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014427993 |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.927       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0118     |\n",
      "|    mean_step_reward   | 0.10392557  |\n",
      "|    n_updates          | 2492        |\n",
      "|    policyGradLoss     | -0.0131     |\n",
      "|    value_loss         | 0.32        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 265         |\n",
      "|    total_timesteps    | 5120000     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010417111 |\n",
      "|    entropy_loss       | -1.98       |\n",
      "|    explained_variance | 0.926       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0793      |\n",
      "|    mean_step_reward   | 0.11209419  |\n",
      "|    n_updates          | 2496        |\n",
      "|    policyGradLoss     | -0.00829    |\n",
      "|    value_loss         | 0.682       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 772        |\n",
      "|    iterations         | 26         |\n",
      "|    time_elapsed       | 275        |\n",
      "|    total_timesteps    | 5128192    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01511752 |\n",
      "|    entropy_loss       | -1.96      |\n",
      "|    explained_variance | 0.908      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | 0.0316     |\n",
      "|    mean_step_reward   | 0.10497476 |\n",
      "|    n_updates          | 2500       |\n",
      "|    policyGradLoss     | -0.0109    |\n",
      "|    value_loss         | 0.475      |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 772          |\n",
      "|    iterations         | 27           |\n",
      "|    time_elapsed       | 286          |\n",
      "|    total_timesteps    | 5136384      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0144968955 |\n",
      "|    entropy_loss       | -1.94        |\n",
      "|    explained_variance | 0.871        |\n",
      "|    learning_rate      | 0.0002       |\n",
      "|    loss               | 0.0479       |\n",
      "|    mean_step_reward   | 0.10357229   |\n",
      "|    n_updates          | 2504         |\n",
      "|    policyGradLoss     | -0.00695     |\n",
      "|    value_loss         | 0.507        |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 771        |\n",
      "|    iterations         | 28         |\n",
      "|    time_elapsed       | 297        |\n",
      "|    total_timesteps    | 5144576    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01502806 |\n",
      "|    entropy_loss       | -1.97      |\n",
      "|    explained_variance | 0.888      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | 0.0299     |\n",
      "|    mean_step_reward   | 0.10027349 |\n",
      "|    n_updates          | 2508       |\n",
      "|    policyGradLoss     | -0.00953   |\n",
      "|    value_loss         | 0.512      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 307         |\n",
      "|    total_timesteps    | 5152768     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020205267 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.901       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.078       |\n",
      "|    mean_step_reward   | 0.10479091  |\n",
      "|    n_updates          | 2512        |\n",
      "|    policyGradLoss     | -0.00971    |\n",
      "|    value_loss         | 0.439       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 318         |\n",
      "|    total_timesteps    | 5160960     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015525711 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.93        |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.024      |\n",
      "|    mean_step_reward   | 0.11592254  |\n",
      "|    n_updates          | 2516        |\n",
      "|    policyGradLoss     | -0.00777    |\n",
      "|    value_loss         | 0.356       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 329         |\n",
      "|    total_timesteps    | 5169152     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011924266 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.924       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0796      |\n",
      "|    mean_step_reward   | 0.113775596 |\n",
      "|    n_updates          | 2520        |\n",
      "|    policyGradLoss     | -0.00493    |\n",
      "|    value_loss         | 0.501       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 339         |\n",
      "|    total_timesteps    | 5177344     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012234867 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.896       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0472      |\n",
      "|    mean_step_reward   | 0.106886595 |\n",
      "|    n_updates          | 2524        |\n",
      "|    policyGradLoss     | -0.00452    |\n",
      "|    value_loss         | 0.539       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 33          |\n",
      "|    time_elapsed       | 350         |\n",
      "|    total_timesteps    | 5185536     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014394584 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.892       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0337      |\n",
      "|    mean_step_reward   | 0.11107236  |\n",
      "|    n_updates          | 2528        |\n",
      "|    policyGradLoss     | -0.00718    |\n",
      "|    value_loss         | 0.52        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 34          |\n",
      "|    time_elapsed       | 361         |\n",
      "|    total_timesteps    | 5193728     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015528806 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.891       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.292       |\n",
      "|    mean_step_reward   | 0.11228447  |\n",
      "|    n_updates          | 2532        |\n",
      "|    policyGradLoss     | -0.00626    |\n",
      "|    value_loss         | 0.605       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 35          |\n",
      "|    time_elapsed       | 371         |\n",
      "|    total_timesteps    | 5201920     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016501192 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.909       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0897      |\n",
      "|    mean_step_reward   | 0.1055657   |\n",
      "|    n_updates          | 2536        |\n",
      "|    policyGradLoss     | -0.00917    |\n",
      "|    value_loss         | 0.546       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 36          |\n",
      "|    time_elapsed       | 382         |\n",
      "|    total_timesteps    | 5210112     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017001934 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.929       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.206       |\n",
      "|    mean_step_reward   | 0.110605076 |\n",
      "|    n_updates          | 2540        |\n",
      "|    policyGradLoss     | -0.0123     |\n",
      "|    value_loss         | 0.636       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 37          |\n",
      "|    time_elapsed       | 393         |\n",
      "|    total_timesteps    | 5218304     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021022782 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.941       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0294     |\n",
      "|    mean_step_reward   | 0.11051433  |\n",
      "|    n_updates          | 2544        |\n",
      "|    policyGradLoss     | -0.0135     |\n",
      "|    value_loss         | 0.316       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 770        |\n",
      "|    iterations         | 38         |\n",
      "|    time_elapsed       | 404        |\n",
      "|    total_timesteps    | 5226496    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01568275 |\n",
      "|    entropy_loss       | -1.94      |\n",
      "|    explained_variance | 0.902      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | 0.427      |\n",
      "|    mean_step_reward   | 0.11363425 |\n",
      "|    n_updates          | 2548       |\n",
      "|    policyGradLoss     | -0.00591   |\n",
      "|    value_loss         | 1.06       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 39          |\n",
      "|    time_elapsed       | 415         |\n",
      "|    total_timesteps    | 5234688     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015603235 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.882       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.000493    |\n",
      "|    mean_step_reward   | 0.105805926 |\n",
      "|    n_updates          | 2552        |\n",
      "|    policyGradLoss     | -0.00963    |\n",
      "|    value_loss         | 0.594       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 40          |\n",
      "|    time_elapsed       | 425         |\n",
      "|    total_timesteps    | 5242880     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018978706 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0041     |\n",
      "|    mean_step_reward   | 0.115493566 |\n",
      "|    n_updates          | 2556        |\n",
      "|    policyGradLoss     | -0.0129     |\n",
      "|    value_loss         | 0.288       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/TNL_16.zip\n",
      "[EVAL] Mean Return: -1261.999, Best Return: -1261.121\n",
      "Saved video to ./runs_smw/videos/step_5242880_mean_-1262.00.mp4\n",
      "\n",
      "=== Round 12 | Learn 327680 steps (Total trained: 5242880) ===\n",
      "Logging to ./runs_smw/tb/tunnel_0\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1133    |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 7       |\n",
      "|    total_timesteps | 5251072 |\n",
      "--------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 909         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 5259264     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019979257 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.906       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0425      |\n",
      "|    mean_step_reward   | 0.10315264  |\n",
      "|    n_updates          | 2564        |\n",
      "|    policyGradLoss     | -0.00882    |\n",
      "|    value_loss         | 0.469       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 853         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 5267456     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016678609 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.879       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.113       |\n",
      "|    mean_step_reward   | 0.102817975 |\n",
      "|    n_updates          | 2568        |\n",
      "|    policyGradLoss     | -0.00992    |\n",
      "|    value_loss         | 0.642       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 827        |\n",
      "|    iterations         | 4          |\n",
      "|    time_elapsed       | 39         |\n",
      "|    total_timesteps    | 5275648    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01826495 |\n",
      "|    entropy_loss       | -1.93      |\n",
      "|    explained_variance | 0.934      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | -0.0023    |\n",
      "|    mean_step_reward   | 0.11107612 |\n",
      "|    n_updates          | 2572       |\n",
      "|    policyGradLoss     | -0.0136    |\n",
      "|    value_loss         | 0.373      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 809         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 50          |\n",
      "|    total_timesteps    | 5283840     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019890292 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.919       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0372      |\n",
      "|    mean_step_reward   | 0.1117035   |\n",
      "|    n_updates          | 2576        |\n",
      "|    policyGradLoss     | -0.00766    |\n",
      "|    value_loss         | 0.483       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 800         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 61          |\n",
      "|    total_timesteps    | 5292032     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011489099 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.868       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0711      |\n",
      "|    mean_step_reward   | 0.114920646 |\n",
      "|    n_updates          | 2580        |\n",
      "|    policyGradLoss     | -0.0021     |\n",
      "|    value_loss         | 0.979       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 797         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 71          |\n",
      "|    total_timesteps    | 5300224     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021041162 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.916       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.000733    |\n",
      "|    mean_step_reward   | 0.10613526  |\n",
      "|    n_updates          | 2584        |\n",
      "|    policyGradLoss     | -0.00839    |\n",
      "|    value_loss         | 0.359       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 791         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 82          |\n",
      "|    total_timesteps    | 5308416     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016384255 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.906       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0433      |\n",
      "|    mean_step_reward   | 0.10798083  |\n",
      "|    n_updates          | 2588        |\n",
      "|    policyGradLoss     | -0.0039     |\n",
      "|    value_loss         | 0.506       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 790         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 93          |\n",
      "|    total_timesteps    | 5316608     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016394623 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.901       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0309      |\n",
      "|    mean_step_reward   | 0.108025774 |\n",
      "|    n_updates          | 2592        |\n",
      "|    policyGradLoss     | -0.00466    |\n",
      "|    value_loss         | 0.588       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 104         |\n",
      "|    total_timesteps    | 5324800     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019288104 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.919       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.00905     |\n",
      "|    mean_step_reward   | 0.106708296 |\n",
      "|    n_updates          | 2596        |\n",
      "|    policyGradLoss     | -0.0103     |\n",
      "|    value_loss         | 0.347       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 115         |\n",
      "|    total_timesteps    | 5332992     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016278928 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.897       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.074       |\n",
      "|    mean_step_reward   | 0.10815692  |\n",
      "|    n_updates          | 2600        |\n",
      "|    policyGradLoss     | -0.00913    |\n",
      "|    value_loss         | 0.57        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 125         |\n",
      "|    total_timesteps    | 5341184     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016937751 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.948       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0806      |\n",
      "|    mean_step_reward   | 0.1137836   |\n",
      "|    n_updates          | 2604        |\n",
      "|    policyGradLoss     | -0.0115     |\n",
      "|    value_loss         | 0.452       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 782        |\n",
      "|    iterations         | 13         |\n",
      "|    time_elapsed       | 136        |\n",
      "|    total_timesteps    | 5349376    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01850823 |\n",
      "|    entropy_loss       | -1.94      |\n",
      "|    explained_variance | 0.957      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | -0.000567  |\n",
      "|    mean_step_reward   | 0.11338112 |\n",
      "|    n_updates          | 2608       |\n",
      "|    policyGradLoss     | -0.0126    |\n",
      "|    value_loss         | 0.343      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 146         |\n",
      "|    total_timesteps    | 5357568     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024885613 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.952       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0538     |\n",
      "|    mean_step_reward   | 0.109598696 |\n",
      "|    n_updates          | 2612        |\n",
      "|    policyGradLoss     | -0.0121     |\n",
      "|    value_loss         | 0.246       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 157         |\n",
      "|    total_timesteps    | 5365760     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014936637 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.91        |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.085       |\n",
      "|    mean_step_reward   | 0.10602521  |\n",
      "|    n_updates          | 2616        |\n",
      "|    policyGradLoss     | -0.00717    |\n",
      "|    value_loss         | 0.61        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 168         |\n",
      "|    total_timesteps    | 5373952     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017470151 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.914       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.000345   |\n",
      "|    mean_step_reward   | 0.111465275 |\n",
      "|    n_updates          | 2620        |\n",
      "|    policyGradLoss     | -0.00573    |\n",
      "|    value_loss         | 0.573       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 179         |\n",
      "|    total_timesteps    | 5382144     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01756918  |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.916       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0186      |\n",
      "|    mean_step_reward   | 0.108549446 |\n",
      "|    n_updates          | 2624        |\n",
      "|    policyGradLoss     | -0.00455    |\n",
      "|    value_loss         | 0.563       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 190         |\n",
      "|    total_timesteps    | 5390336     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020065706 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.941       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.074       |\n",
      "|    mean_step_reward   | 0.104133934 |\n",
      "|    n_updates          | 2628        |\n",
      "|    policyGradLoss     | -0.0157     |\n",
      "|    value_loss         | 0.38        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 200         |\n",
      "|    total_timesteps    | 5398528     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019489288 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.944       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0219      |\n",
      "|    mean_step_reward   | 0.10950108  |\n",
      "|    n_updates          | 2632        |\n",
      "|    policyGradLoss     | -0.00736    |\n",
      "|    value_loss         | 0.514       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 212         |\n",
      "|    total_timesteps    | 5406720     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013783924 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.867       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.134       |\n",
      "|    mean_step_reward   | 0.101593025 |\n",
      "|    n_updates          | 2636        |\n",
      "|    policyGradLoss     | -0.00489    |\n",
      "|    value_loss         | 0.814       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 771        |\n",
      "|    iterations         | 21         |\n",
      "|    time_elapsed       | 222        |\n",
      "|    total_timesteps    | 5414912    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01576871 |\n",
      "|    entropy_loss       | -1.94      |\n",
      "|    explained_variance | 0.853      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | 0.169      |\n",
      "|    mean_step_reward   | 0.09724201 |\n",
      "|    n_updates          | 2640       |\n",
      "|    policyGradLoss     | -0.00775   |\n",
      "|    value_loss         | 0.642      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 233         |\n",
      "|    total_timesteps    | 5423104     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019068781 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.921       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0455      |\n",
      "|    mean_step_reward   | 0.10222723  |\n",
      "|    n_updates          | 2644        |\n",
      "|    policyGradLoss     | -0.0106     |\n",
      "|    value_loss         | 0.457       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 244         |\n",
      "|    total_timesteps    | 5431296     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020252574 |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.955       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0013     |\n",
      "|    mean_step_reward   | 0.11530094  |\n",
      "|    n_updates          | 2648        |\n",
      "|    policyGradLoss     | -0.013      |\n",
      "|    value_loss         | 0.356       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 770        |\n",
      "|    iterations         | 24         |\n",
      "|    time_elapsed       | 255        |\n",
      "|    total_timesteps    | 5439488    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01721822 |\n",
      "|    entropy_loss       | -1.97      |\n",
      "|    explained_variance | 0.956      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | -0.00521   |\n",
      "|    mean_step_reward   | 0.11049168 |\n",
      "|    n_updates          | 2652       |\n",
      "|    policyGradLoss     | -0.0125    |\n",
      "|    value_loss         | 0.32       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 770        |\n",
      "|    iterations         | 25         |\n",
      "|    time_elapsed       | 265        |\n",
      "|    total_timesteps    | 5447680    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01642979 |\n",
      "|    entropy_loss       | -1.95      |\n",
      "|    explained_variance | 0.869      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | 0.000983   |\n",
      "|    mean_step_reward   | 0.09735796 |\n",
      "|    n_updates          | 2656       |\n",
      "|    policyGradLoss     | -0.00959   |\n",
      "|    value_loss         | 0.322      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 276         |\n",
      "|    total_timesteps    | 5455872     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016406367 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.887       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0458      |\n",
      "|    mean_step_reward   | 0.09926455  |\n",
      "|    n_updates          | 2660        |\n",
      "|    policyGradLoss     | -0.0102     |\n",
      "|    value_loss         | 0.708       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 287         |\n",
      "|    total_timesteps    | 5464064     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018937713 |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.933       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.00409     |\n",
      "|    mean_step_reward   | 0.09958305  |\n",
      "|    n_updates          | 2664        |\n",
      "|    policyGradLoss     | -0.0143     |\n",
      "|    value_loss         | 0.486       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 298         |\n",
      "|    total_timesteps    | 5472256     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017363705 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.854       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.00191    |\n",
      "|    mean_step_reward   | 0.091403246 |\n",
      "|    n_updates          | 2668        |\n",
      "|    policyGradLoss     | -0.0106     |\n",
      "|    value_loss         | 0.474       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 768        |\n",
      "|    iterations         | 29         |\n",
      "|    time_elapsed       | 309        |\n",
      "|    total_timesteps    | 5480448    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02028805 |\n",
      "|    entropy_loss       | -1.96      |\n",
      "|    explained_variance | 0.934      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | -0.0235    |\n",
      "|    mean_step_reward   | 0.11003554 |\n",
      "|    n_updates          | 2672       |\n",
      "|    policyGradLoss     | -0.0123    |\n",
      "|    value_loss         | 0.299      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 768        |\n",
      "|    iterations         | 30         |\n",
      "|    time_elapsed       | 319        |\n",
      "|    total_timesteps    | 5488640    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01635863 |\n",
      "|    entropy_loss       | -1.94      |\n",
      "|    explained_variance | 0.924      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | 0.00453    |\n",
      "|    mean_step_reward   | 0.10469718 |\n",
      "|    n_updates          | 2676       |\n",
      "|    policyGradLoss     | -0.00769   |\n",
      "|    value_loss         | 0.423      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 330         |\n",
      "|    total_timesteps    | 5496832     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017692778 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.923       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0112     |\n",
      "|    mean_step_reward   | 0.11018077  |\n",
      "|    n_updates          | 2680        |\n",
      "|    policyGradLoss     | -0.00819    |\n",
      "|    value_loss         | 0.389       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 341         |\n",
      "|    total_timesteps    | 5505024     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019141875 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.916       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0051     |\n",
      "|    mean_step_reward   | 0.108129025 |\n",
      "|    n_updates          | 2684        |\n",
      "|    policyGradLoss     | -0.0144     |\n",
      "|    value_loss         | 0.349       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 33          |\n",
      "|    time_elapsed       | 351         |\n",
      "|    total_timesteps    | 5513216     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013704509 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.9         |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.00848    |\n",
      "|    mean_step_reward   | 0.10758899  |\n",
      "|    n_updates          | 2688        |\n",
      "|    policyGradLoss     | -0.0105     |\n",
      "|    value_loss         | 0.334       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 34          |\n",
      "|    time_elapsed       | 362         |\n",
      "|    total_timesteps    | 5521408     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018826801 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.905       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.00945    |\n",
      "|    mean_step_reward   | 0.11387464  |\n",
      "|    n_updates          | 2692        |\n",
      "|    policyGradLoss     | -0.013      |\n",
      "|    value_loss         | 0.388       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 35          |\n",
      "|    time_elapsed       | 373         |\n",
      "|    total_timesteps    | 5529600     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012762055 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.913       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.127       |\n",
      "|    mean_step_reward   | 0.113599576 |\n",
      "|    n_updates          | 2696        |\n",
      "|    policyGradLoss     | -0.00837    |\n",
      "|    value_loss         | 0.958       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 36          |\n",
      "|    time_elapsed       | 384         |\n",
      "|    total_timesteps    | 5537792     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015538778 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.928       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0632      |\n",
      "|    mean_step_reward   | 0.11737325  |\n",
      "|    n_updates          | 2700        |\n",
      "|    policyGradLoss     | -0.00879    |\n",
      "|    value_loss         | 0.739       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 37          |\n",
      "|    time_elapsed       | 395         |\n",
      "|    total_timesteps    | 5545984     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013873958 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.938       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.000319    |\n",
      "|    mean_step_reward   | 0.10808235  |\n",
      "|    n_updates          | 2704        |\n",
      "|    policyGradLoss     | -0.0126     |\n",
      "|    value_loss         | 0.362       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 38          |\n",
      "|    time_elapsed       | 406         |\n",
      "|    total_timesteps    | 5554176     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01676396  |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.91        |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0367      |\n",
      "|    mean_step_reward   | 0.124010555 |\n",
      "|    n_updates          | 2708        |\n",
      "|    policyGradLoss     | -0.00274    |\n",
      "|    value_loss         | 0.744       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 39          |\n",
      "|    time_elapsed       | 416         |\n",
      "|    total_timesteps    | 5562368     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018710885 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.902       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.11        |\n",
      "|    mean_step_reward   | 0.10886571  |\n",
      "|    n_updates          | 2712        |\n",
      "|    policyGradLoss     | -0.00668    |\n",
      "|    value_loss         | 0.679       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 40          |\n",
      "|    time_elapsed       | 427         |\n",
      "|    total_timesteps    | 5570560     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014317668 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.922       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0198      |\n",
      "|    mean_step_reward   | 0.12149947  |\n",
      "|    n_updates          | 2716        |\n",
      "|    policyGradLoss     | -0.00813    |\n",
      "|    value_loss         | 0.42        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/TNL_17.zip\n",
      "[EVAL] Mean Return: -1265.712, Best Return: -1264.834\n",
      "Saved video to ./runs_smw/videos/step_5570560_mean_-1265.71.mp4\n",
      "\n",
      "=== Round 13 | Learn 327680 steps (Total trained: 5570560) ===\n",
      "Logging to ./runs_smw/tb/tunnel_0\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1083    |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 7       |\n",
      "|    total_timesteps | 5578752 |\n",
      "--------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 881         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 5586944     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019700333 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.936       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.115       |\n",
      "|    mean_step_reward   | 0.116772026 |\n",
      "|    n_updates          | 2724        |\n",
      "|    policyGradLoss     | -0.00578    |\n",
      "|    value_loss         | 0.419       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 837         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 29          |\n",
      "|    total_timesteps    | 5595136     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01599526  |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.952       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.00981    |\n",
      "|    mean_step_reward   | 0.122980066 |\n",
      "|    n_updates          | 2728        |\n",
      "|    policyGradLoss     | -0.0111     |\n",
      "|    value_loss         | 0.435       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 820        |\n",
      "|    iterations         | 4          |\n",
      "|    time_elapsed       | 39         |\n",
      "|    total_timesteps    | 5603328    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01444087 |\n",
      "|    entropy_loss       | -1.94      |\n",
      "|    explained_variance | 0.916      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | 0.0772     |\n",
      "|    mean_step_reward   | 0.1308845  |\n",
      "|    n_updates          | 2732       |\n",
      "|    policyGradLoss     | -0.00195   |\n",
      "|    value_loss         | 0.607      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 805        |\n",
      "|    iterations         | 5          |\n",
      "|    time_elapsed       | 50         |\n",
      "|    total_timesteps    | 5611520    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02145333 |\n",
      "|    entropy_loss       | -1.89      |\n",
      "|    explained_variance | 0.957      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | -0.0409    |\n",
      "|    mean_step_reward   | 0.11496294 |\n",
      "|    n_updates          | 2736       |\n",
      "|    policyGradLoss     | -0.014     |\n",
      "|    value_loss         | 0.245      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 801        |\n",
      "|    iterations         | 6          |\n",
      "|    time_elapsed       | 61         |\n",
      "|    total_timesteps    | 5619712    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01953312 |\n",
      "|    entropy_loss       | -1.91      |\n",
      "|    explained_variance | 0.944      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | 0.153      |\n",
      "|    mean_step_reward   | 0.11838859 |\n",
      "|    n_updates          | 2740       |\n",
      "|    policyGradLoss     | -0.00641   |\n",
      "|    value_loss         | 0.844      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 796         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 72          |\n",
      "|    total_timesteps    | 5627904     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01849854  |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.924       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0126     |\n",
      "|    mean_step_reward   | 0.116197586 |\n",
      "|    n_updates          | 2744        |\n",
      "|    policyGradLoss     | -0.00833    |\n",
      "|    value_loss         | 0.268       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 792        |\n",
      "|    iterations         | 8          |\n",
      "|    time_elapsed       | 82         |\n",
      "|    total_timesteps    | 5636096    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01471619 |\n",
      "|    entropy_loss       | -1.86      |\n",
      "|    explained_variance | 0.916      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | 0.0344     |\n",
      "|    mean_step_reward   | 0.13127568 |\n",
      "|    n_updates          | 2748       |\n",
      "|    policyGradLoss     | -0.00501   |\n",
      "|    value_loss         | 0.761      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 788        |\n",
      "|    iterations         | 9          |\n",
      "|    time_elapsed       | 93         |\n",
      "|    total_timesteps    | 5644288    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01391275 |\n",
      "|    entropy_loss       | -1.93      |\n",
      "|    explained_variance | 0.943      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | 0.0988     |\n",
      "|    mean_step_reward   | 0.11463052 |\n",
      "|    n_updates          | 2752       |\n",
      "|    policyGradLoss     | -0.0111    |\n",
      "|    value_loss         | 0.729      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 103         |\n",
      "|    total_timesteps    | 5652480     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018087642 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.936       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0084      |\n",
      "|    mean_step_reward   | 0.10998348  |\n",
      "|    n_updates          | 2756        |\n",
      "|    policyGradLoss     | -0.013      |\n",
      "|    value_loss         | 0.394       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 114         |\n",
      "|    total_timesteps    | 5660672     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016791567 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.947       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.00886    |\n",
      "|    mean_step_reward   | 0.12156826  |\n",
      "|    n_updates          | 2760        |\n",
      "|    policyGradLoss     | -0.00709    |\n",
      "|    value_loss         | 0.384       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 125         |\n",
      "|    total_timesteps    | 5668864     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016123068 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.933       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.246       |\n",
      "|    mean_step_reward   | 0.110174954 |\n",
      "|    n_updates          | 2764        |\n",
      "|    policyGradLoss     | -0.0104     |\n",
      "|    value_loss         | 0.652       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 136         |\n",
      "|    total_timesteps    | 5677056     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009751374 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.871       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.368       |\n",
      "|    mean_step_reward   | 0.11239463  |\n",
      "|    n_updates          | 2768        |\n",
      "|    policyGradLoss     | -0.00406    |\n",
      "|    value_loss         | 0.887       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 147         |\n",
      "|    total_timesteps    | 5685248     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017399192 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.954       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0162      |\n",
      "|    mean_step_reward   | 0.12470269  |\n",
      "|    n_updates          | 2772        |\n",
      "|    policyGradLoss     | -0.0102     |\n",
      "|    value_loss         | 0.447       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 778          |\n",
      "|    iterations         | 15           |\n",
      "|    time_elapsed       | 157          |\n",
      "|    total_timesteps    | 5693440      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0142317945 |\n",
      "|    entropy_loss       | -1.93        |\n",
      "|    explained_variance | 0.906        |\n",
      "|    learning_rate      | 0.0002       |\n",
      "|    loss               | 0.0181       |\n",
      "|    mean_step_reward   | 0.10583107   |\n",
      "|    n_updates          | 2776         |\n",
      "|    policyGradLoss     | -0.00913     |\n",
      "|    value_loss         | 0.44         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 168         |\n",
      "|    total_timesteps    | 5701632     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014058622 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.933       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0223      |\n",
      "|    mean_step_reward   | 0.11696371  |\n",
      "|    n_updates          | 2780        |\n",
      "|    policyGradLoss     | -0.00852    |\n",
      "|    value_loss         | 0.403       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 179         |\n",
      "|    total_timesteps    | 5709824     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019227378 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.931       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0403     |\n",
      "|    mean_step_reward   | 0.11112104  |\n",
      "|    n_updates          | 2784        |\n",
      "|    policyGradLoss     | -0.014      |\n",
      "|    value_loss         | 0.247       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 190         |\n",
      "|    total_timesteps    | 5718016     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014788369 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.951       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0214      |\n",
      "|    mean_step_reward   | 0.12702107  |\n",
      "|    n_updates          | 2788        |\n",
      "|    policyGradLoss     | -0.00917    |\n",
      "|    value_loss         | 0.491       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 200         |\n",
      "|    total_timesteps    | 5726208     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011956318 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.928       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0387      |\n",
      "|    mean_step_reward   | 0.13009621  |\n",
      "|    n_updates          | 2792        |\n",
      "|    policyGradLoss     | -0.00689    |\n",
      "|    value_loss         | 0.516       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 211         |\n",
      "|    total_timesteps    | 5734400     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016035382 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.883       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0801      |\n",
      "|    mean_step_reward   | 0.10653052  |\n",
      "|    n_updates          | 2796        |\n",
      "|    policyGradLoss     | -0.00384    |\n",
      "|    value_loss         | 0.695       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 222         |\n",
      "|    total_timesteps    | 5742592     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014193747 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.868       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.00685     |\n",
      "|    mean_step_reward   | 0.104681894 |\n",
      "|    n_updates          | 2800        |\n",
      "|    policyGradLoss     | -0.00912    |\n",
      "|    value_loss         | 0.512       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 772        |\n",
      "|    iterations         | 22         |\n",
      "|    time_elapsed       | 233        |\n",
      "|    total_timesteps    | 5750784    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01329419 |\n",
      "|    entropy_loss       | -1.96      |\n",
      "|    explained_variance | 0.879      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | 0.0566     |\n",
      "|    mean_step_reward   | 0.11921743 |\n",
      "|    n_updates          | 2804       |\n",
      "|    policyGradLoss     | -0.00834   |\n",
      "|    value_loss         | 0.695      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 244         |\n",
      "|    total_timesteps    | 5758976     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013656554 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.886       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.209       |\n",
      "|    mean_step_reward   | 0.117553234 |\n",
      "|    n_updates          | 2808        |\n",
      "|    policyGradLoss     | -0.00619    |\n",
      "|    value_loss         | 0.779       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 254         |\n",
      "|    total_timesteps    | 5767168     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013860361 |\n",
      "|    entropy_loss       | -1.98       |\n",
      "|    explained_variance | 0.927       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0739      |\n",
      "|    mean_step_reward   | 0.11328183  |\n",
      "|    n_updates          | 2812        |\n",
      "|    policyGradLoss     | -0.0113     |\n",
      "|    value_loss         | 0.723       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 265         |\n",
      "|    total_timesteps    | 5775360     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016723542 |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.93        |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0145      |\n",
      "|    mean_step_reward   | 0.11275227  |\n",
      "|    n_updates          | 2816        |\n",
      "|    policyGradLoss     | -0.0101     |\n",
      "|    value_loss         | 0.394       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 275         |\n",
      "|    total_timesteps    | 5783552     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011133075 |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.846       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.159       |\n",
      "|    mean_step_reward   | 0.10477831  |\n",
      "|    n_updates          | 2820        |\n",
      "|    policyGradLoss     | -0.00756    |\n",
      "|    value_loss         | 0.744       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 286         |\n",
      "|    total_timesteps    | 5791744     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012860464 |\n",
      "|    entropy_loss       | -2          |\n",
      "|    explained_variance | 0.942       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0534      |\n",
      "|    mean_step_reward   | 0.12087123  |\n",
      "|    n_updates          | 2824        |\n",
      "|    policyGradLoss     | -0.00775    |\n",
      "|    value_loss         | 0.522       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 297         |\n",
      "|    total_timesteps    | 5799936     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013608839 |\n",
      "|    entropy_loss       | -1.97       |\n",
      "|    explained_variance | 0.854       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.00824     |\n",
      "|    mean_step_reward   | 0.10550603  |\n",
      "|    n_updates          | 2828        |\n",
      "|    policyGradLoss     | -0.00707    |\n",
      "|    value_loss         | 0.613       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 308         |\n",
      "|    total_timesteps    | 5808128     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014036069 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.868       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.00775    |\n",
      "|    mean_step_reward   | 0.10102001  |\n",
      "|    n_updates          | 2832        |\n",
      "|    policyGradLoss     | -0.00967    |\n",
      "|    value_loss         | 0.452       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 318         |\n",
      "|    total_timesteps    | 5816320     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017290913 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.928       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0365     |\n",
      "|    mean_step_reward   | 0.10833474  |\n",
      "|    n_updates          | 2836        |\n",
      "|    policyGradLoss     | -0.0135     |\n",
      "|    value_loss         | 0.322       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 329         |\n",
      "|    total_timesteps    | 5824512     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013011034 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.922       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0627      |\n",
      "|    mean_step_reward   | 0.12048207  |\n",
      "|    n_updates          | 2840        |\n",
      "|    policyGradLoss     | -0.00553    |\n",
      "|    value_loss         | 0.95        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 340         |\n",
      "|    total_timesteps    | 5832704     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017770711 |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.926       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0133      |\n",
      "|    mean_step_reward   | 0.10914244  |\n",
      "|    n_updates          | 2844        |\n",
      "|    policyGradLoss     | -0.0105     |\n",
      "|    value_loss         | 0.397       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 33          |\n",
      "|    time_elapsed       | 350         |\n",
      "|    total_timesteps    | 5840896     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016070189 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.896       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0232      |\n",
      "|    mean_step_reward   | 0.10672952  |\n",
      "|    n_updates          | 2848        |\n",
      "|    policyGradLoss     | -0.00645    |\n",
      "|    value_loss         | 0.53        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 34          |\n",
      "|    time_elapsed       | 361         |\n",
      "|    total_timesteps    | 5849088     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014555085 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.886       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0127      |\n",
      "|    mean_step_reward   | 0.10906453  |\n",
      "|    n_updates          | 2852        |\n",
      "|    policyGradLoss     | -0.00778    |\n",
      "|    value_loss         | 0.58        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 769        |\n",
      "|    iterations         | 35         |\n",
      "|    time_elapsed       | 372        |\n",
      "|    total_timesteps    | 5857280    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01589904 |\n",
      "|    entropy_loss       | -1.93      |\n",
      "|    explained_variance | 0.861      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | 0.0209     |\n",
      "|    mean_step_reward   | 0.10552198 |\n",
      "|    n_updates          | 2856       |\n",
      "|    policyGradLoss     | -0.00494   |\n",
      "|    value_loss         | 0.465      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 36          |\n",
      "|    time_elapsed       | 383         |\n",
      "|    total_timesteps    | 5865472     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014838001 |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.879       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0117      |\n",
      "|    mean_step_reward   | 0.12084713  |\n",
      "|    n_updates          | 2860        |\n",
      "|    policyGradLoss     | -0.00254    |\n",
      "|    value_loss         | 0.811       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 37          |\n",
      "|    time_elapsed       | 393         |\n",
      "|    total_timesteps    | 5873664     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014630312 |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.86        |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0736      |\n",
      "|    mean_step_reward   | 0.113553666 |\n",
      "|    n_updates          | 2864        |\n",
      "|    policyGradLoss     | -0.0026     |\n",
      "|    value_loss         | 0.85        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 38          |\n",
      "|    time_elapsed       | 404         |\n",
      "|    total_timesteps    | 5881856     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015197618 |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.922       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.034       |\n",
      "|    mean_step_reward   | 0.108440414 |\n",
      "|    n_updates          | 2868        |\n",
      "|    policyGradLoss     | -0.011      |\n",
      "|    value_loss         | 0.598       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 39          |\n",
      "|    time_elapsed       | 415         |\n",
      "|    total_timesteps    | 5890048     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012302746 |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.874       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.138       |\n",
      "|    mean_step_reward   | 0.11194475  |\n",
      "|    n_updates          | 2872        |\n",
      "|    policyGradLoss     | -0.0097     |\n",
      "|    value_loss         | 0.926       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 40          |\n",
      "|    time_elapsed       | 426         |\n",
      "|    total_timesteps    | 5898240     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014099453 |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.914       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0424      |\n",
      "|    mean_step_reward   | 0.1105576   |\n",
      "|    n_updates          | 2876        |\n",
      "|    policyGradLoss     | -0.00918    |\n",
      "|    value_loss         | 0.628       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/TNL_18.zip\n",
      "[EVAL] Mean Return: 160.551, Best Return: 160.858\n",
      "Saved video to ./runs_smw/videos/step_5898240_mean_160.55.mp4\n",
      "\n",
      "=== Round 14 | Learn 327680 steps (Total trained: 5898240) ===\n",
      "Logging to ./runs_smw/tb/tunnel_0\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1086    |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 7       |\n",
      "|    total_timesteps | 5906432 |\n",
      "--------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 895         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 5914624     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012466939 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.925       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.012      |\n",
      "|    mean_step_reward   | 0.11563295  |\n",
      "|    n_updates          | 2884        |\n",
      "|    policyGradLoss     | -0.0136     |\n",
      "|    value_loss         | 0.487       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 840         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 29          |\n",
      "|    total_timesteps    | 5922816     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019707758 |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.921       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.161       |\n",
      "|    mean_step_reward   | 0.110612206 |\n",
      "|    n_updates          | 2888        |\n",
      "|    policyGradLoss     | -0.00888    |\n",
      "|    value_loss         | 0.73        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 821         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 5931008     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012662895 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.9         |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0406      |\n",
      "|    mean_step_reward   | 0.11420509  |\n",
      "|    n_updates          | 2892        |\n",
      "|    policyGradLoss     | -0.00805    |\n",
      "|    value_loss         | 0.811       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 808         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 50          |\n",
      "|    total_timesteps    | 5939200     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015740063 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.851       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0453      |\n",
      "|    mean_step_reward   | 0.10763259  |\n",
      "|    n_updates          | 2896        |\n",
      "|    policyGradLoss     | -0.00823    |\n",
      "|    value_loss         | 0.625       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 798         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 61          |\n",
      "|    total_timesteps    | 5947392     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013521045 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.865       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0891      |\n",
      "|    mean_step_reward   | 0.11078146  |\n",
      "|    n_updates          | 2900        |\n",
      "|    policyGradLoss     | -0.00789    |\n",
      "|    value_loss         | 0.81        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 790         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 72          |\n",
      "|    total_timesteps    | 5955584     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01972522  |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.874       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0885      |\n",
      "|    mean_step_reward   | 0.100921795 |\n",
      "|    n_updates          | 2904        |\n",
      "|    policyGradLoss     | -0.0105     |\n",
      "|    value_loss         | 0.758       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 788        |\n",
      "|    iterations         | 8          |\n",
      "|    time_elapsed       | 83         |\n",
      "|    total_timesteps    | 5963776    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01694791 |\n",
      "|    entropy_loss       | -1.91      |\n",
      "|    explained_variance | 0.886      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | 0.0311     |\n",
      "|    mean_step_reward   | 0.10247592 |\n",
      "|    n_updates          | 2908       |\n",
      "|    policyGradLoss     | -0.00971   |\n",
      "|    value_loss         | 0.625      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 787        |\n",
      "|    iterations         | 9          |\n",
      "|    time_elapsed       | 93         |\n",
      "|    total_timesteps    | 5971968    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.0206516  |\n",
      "|    entropy_loss       | -1.92      |\n",
      "|    explained_variance | 0.909      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | -0.0035    |\n",
      "|    mean_step_reward   | 0.11328368 |\n",
      "|    n_updates          | 2912       |\n",
      "|    policyGradLoss     | -0.011     |\n",
      "|    value_loss         | 0.409      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 104         |\n",
      "|    total_timesteps    | 5980160     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012993219 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.903       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.144       |\n",
      "|    mean_step_reward   | 0.11682929  |\n",
      "|    n_updates          | 2916        |\n",
      "|    policyGradLoss     | -0.00755    |\n",
      "|    value_loss         | 0.689       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 781        |\n",
      "|    iterations         | 11         |\n",
      "|    time_elapsed       | 115        |\n",
      "|    total_timesteps    | 5988352    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01862448 |\n",
      "|    entropy_loss       | -1.92      |\n",
      "|    explained_variance | 0.909      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | 0.105      |\n",
      "|    mean_step_reward   | 0.10463473 |\n",
      "|    n_updates          | 2920       |\n",
      "|    policyGradLoss     | -0.0074    |\n",
      "|    value_loss         | 0.72       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 125         |\n",
      "|    total_timesteps    | 5996544     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017632732 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.924       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0244     |\n",
      "|    mean_step_reward   | 0.109831646 |\n",
      "|    n_updates          | 2924        |\n",
      "|    policyGradLoss     | -0.0105     |\n",
      "|    value_loss         | 0.433       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 136         |\n",
      "|    total_timesteps    | 6004736     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015217481 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.917       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.00619     |\n",
      "|    mean_step_reward   | 0.11529404  |\n",
      "|    n_updates          | 2928        |\n",
      "|    policyGradLoss     | -0.011      |\n",
      "|    value_loss         | 0.524       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 147         |\n",
      "|    total_timesteps    | 6012928     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014645923 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.887       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0851      |\n",
      "|    mean_step_reward   | 0.113240786 |\n",
      "|    n_updates          | 2932        |\n",
      "|    policyGradLoss     | -0.00789    |\n",
      "|    value_loss         | 0.679       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 158         |\n",
      "|    total_timesteps    | 6021120     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015322307 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.913       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.00914     |\n",
      "|    mean_step_reward   | 0.10951021  |\n",
      "|    n_updates          | 2936        |\n",
      "|    policyGradLoss     | -0.012      |\n",
      "|    value_loss         | 0.532       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 168         |\n",
      "|    total_timesteps    | 6029312     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021613063 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.873       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.00409     |\n",
      "|    mean_step_reward   | 0.10608187  |\n",
      "|    n_updates          | 2940        |\n",
      "|    policyGradLoss     | -0.00594    |\n",
      "|    value_loss         | 0.528       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 179         |\n",
      "|    total_timesteps    | 6037504     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014828742 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.792       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0418      |\n",
      "|    mean_step_reward   | 0.103027    |\n",
      "|    n_updates          | 2944        |\n",
      "|    policyGradLoss     | -0.00757    |\n",
      "|    value_loss         | 0.741       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 190         |\n",
      "|    total_timesteps    | 6045696     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016916469 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.903       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0207     |\n",
      "|    mean_step_reward   | 0.11168172  |\n",
      "|    n_updates          | 2948        |\n",
      "|    policyGradLoss     | -0.0118     |\n",
      "|    value_loss         | 0.335       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 200         |\n",
      "|    total_timesteps    | 6053888     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015324853 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.832       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.119       |\n",
      "|    mean_step_reward   | 0.11187315  |\n",
      "|    n_updates          | 2952        |\n",
      "|    policyGradLoss     | -0.000276   |\n",
      "|    value_loss         | 0.763       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 211         |\n",
      "|    total_timesteps    | 6062080     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014617907 |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.949       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0591      |\n",
      "|    mean_step_reward   | 0.12688138  |\n",
      "|    n_updates          | 2956        |\n",
      "|    policyGradLoss     | -0.0125     |\n",
      "|    value_loss         | 0.491       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 222         |\n",
      "|    total_timesteps    | 6070272     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017604556 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.922       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0212      |\n",
      "|    mean_step_reward   | 0.11424456  |\n",
      "|    n_updates          | 2960        |\n",
      "|    policyGradLoss     | -0.0129     |\n",
      "|    value_loss         | 0.424       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 232         |\n",
      "|    total_timesteps    | 6078464     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015672283 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.919       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.29        |\n",
      "|    mean_step_reward   | 0.10379341  |\n",
      "|    n_updates          | 2964        |\n",
      "|    policyGradLoss     | -0.01       |\n",
      "|    value_loss         | 0.933       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 243         |\n",
      "|    total_timesteps    | 6086656     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018804267 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.91        |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0345     |\n",
      "|    mean_step_reward   | 0.10847041  |\n",
      "|    n_updates          | 2968        |\n",
      "|    policyGradLoss     | -0.0129     |\n",
      "|    value_loss         | 0.263       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 254         |\n",
      "|    total_timesteps    | 6094848     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013981925 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.899       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0371      |\n",
      "|    mean_step_reward   | 0.11369248  |\n",
      "|    n_updates          | 2972        |\n",
      "|    policyGradLoss     | -0.00641    |\n",
      "|    value_loss         | 0.551       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 265         |\n",
      "|    total_timesteps    | 6103040     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014737218 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.87        |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0455      |\n",
      "|    mean_step_reward   | 0.116947986 |\n",
      "|    n_updates          | 2976        |\n",
      "|    policyGradLoss     | -0.00317    |\n",
      "|    value_loss         | 0.929       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 276         |\n",
      "|    total_timesteps    | 6111232     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016548341 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.893       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.101       |\n",
      "|    mean_step_reward   | 0.108640194 |\n",
      "|    n_updates          | 2980        |\n",
      "|    policyGradLoss     | -0.00986    |\n",
      "|    value_loss         | 0.523       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 287         |\n",
      "|    total_timesteps    | 6119424     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016735822 |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.893       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.227       |\n",
      "|    mean_step_reward   | 0.11192265  |\n",
      "|    n_updates          | 2984        |\n",
      "|    policyGradLoss     | -0.00389    |\n",
      "|    value_loss         | 1.05        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 298         |\n",
      "|    total_timesteps    | 6127616     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013907997 |\n",
      "|    entropy_loss       | -1.97       |\n",
      "|    explained_variance | 0.921       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.084       |\n",
      "|    mean_step_reward   | 0.1149353   |\n",
      "|    n_updates          | 2988        |\n",
      "|    policyGradLoss     | -0.00837    |\n",
      "|    value_loss         | 0.588       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 308         |\n",
      "|    total_timesteps    | 6135808     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019297898 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.928       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0576      |\n",
      "|    mean_step_reward   | 0.10750311  |\n",
      "|    n_updates          | 2992        |\n",
      "|    policyGradLoss     | -0.0138     |\n",
      "|    value_loss         | 0.454       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 319         |\n",
      "|    total_timesteps    | 6144000     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017609011 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.911       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.00746    |\n",
      "|    mean_step_reward   | 0.10211173  |\n",
      "|    n_updates          | 2996        |\n",
      "|    policyGradLoss     | -0.00885    |\n",
      "|    value_loss         | 0.53        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 330         |\n",
      "|    total_timesteps    | 6152192     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015466407 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.879       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.123       |\n",
      "|    mean_step_reward   | 0.10500492  |\n",
      "|    n_updates          | 3000        |\n",
      "|    policyGradLoss     | -0.00912    |\n",
      "|    value_loss         | 0.877       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 341         |\n",
      "|    total_timesteps    | 6160384     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01613615  |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.901       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0561      |\n",
      "|    mean_step_reward   | 0.107317254 |\n",
      "|    n_updates          | 3004        |\n",
      "|    policyGradLoss     | -0.00345    |\n",
      "|    value_loss         | 0.662       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 33          |\n",
      "|    time_elapsed       | 352         |\n",
      "|    total_timesteps    | 6168576     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015061045 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.84        |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0502      |\n",
      "|    mean_step_reward   | 0.10080308  |\n",
      "|    n_updates          | 3008        |\n",
      "|    policyGradLoss     | -0.00978    |\n",
      "|    value_loss         | 0.624       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 34          |\n",
      "|    time_elapsed       | 362         |\n",
      "|    total_timesteps    | 6176768     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013568031 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.918       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0106      |\n",
      "|    mean_step_reward   | 0.1156736   |\n",
      "|    n_updates          | 3012        |\n",
      "|    policyGradLoss     | -0.00815    |\n",
      "|    value_loss         | 0.459       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 35          |\n",
      "|    time_elapsed       | 373         |\n",
      "|    total_timesteps    | 6184960     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012567984 |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.938       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0314      |\n",
      "|    mean_step_reward   | 0.11216599  |\n",
      "|    n_updates          | 3016        |\n",
      "|    policyGradLoss     | -0.0145     |\n",
      "|    value_loss         | 0.449       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 36          |\n",
      "|    time_elapsed       | 384         |\n",
      "|    total_timesteps    | 6193152     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013805815 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.871       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0599      |\n",
      "|    mean_step_reward   | 0.11707977  |\n",
      "|    n_updates          | 3020        |\n",
      "|    policyGradLoss     | -0.00749    |\n",
      "|    value_loss         | 0.725       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 37          |\n",
      "|    time_elapsed       | 395         |\n",
      "|    total_timesteps    | 6201344     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014218707 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.919       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.00793    |\n",
      "|    mean_step_reward   | 0.11483678  |\n",
      "|    n_updates          | 3024        |\n",
      "|    policyGradLoss     | -0.00827    |\n",
      "|    value_loss         | 0.467       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 38          |\n",
      "|    time_elapsed       | 405         |\n",
      "|    total_timesteps    | 6209536     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016285196 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.914       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0153      |\n",
      "|    mean_step_reward   | 0.112346314 |\n",
      "|    n_updates          | 3028        |\n",
      "|    policyGradLoss     | -0.0109     |\n",
      "|    value_loss         | 0.495       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 767          |\n",
      "|    iterations         | 39           |\n",
      "|    time_elapsed       | 416          |\n",
      "|    total_timesteps    | 6217728      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0153632695 |\n",
      "|    entropy_loss       | -1.91        |\n",
      "|    explained_variance | 0.933        |\n",
      "|    learning_rate      | 0.0002       |\n",
      "|    loss               | 0.0442       |\n",
      "|    mean_step_reward   | 0.11987516   |\n",
      "|    n_updates          | 3032         |\n",
      "|    policyGradLoss     | -0.0128      |\n",
      "|    value_loss         | 0.473        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 40          |\n",
      "|    time_elapsed       | 427         |\n",
      "|    total_timesteps    | 6225920     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013841211 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.848       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0952      |\n",
      "|    mean_step_reward   | 0.09750053  |\n",
      "|    n_updates          | 3036        |\n",
      "|    policyGradLoss     | -0.00791    |\n",
      "|    value_loss         | 0.825       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/TNL_19.zip\n",
      "[EVAL] Mean Return: 102.878, Best Return: 103.041\n",
      "Saved video to ./runs_smw/videos/step_6225920_mean_102.88.mp4\n",
      "\n",
      "=== Round 15 | Learn 327680 steps (Total trained: 6225920) ===\n",
      "Logging to ./runs_smw/tb/tunnel_0\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1124    |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 7       |\n",
      "|    total_timesteps | 6234112 |\n",
      "--------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 898       |\n",
      "|    iterations         | 2         |\n",
      "|    time_elapsed       | 18        |\n",
      "|    total_timesteps    | 6242304   |\n",
      "| train/                |           |\n",
      "|    approx_kl          | 0.0169594 |\n",
      "|    entropy_loss       | -1.93     |\n",
      "|    explained_variance | 0.937     |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    loss               | 0.134     |\n",
      "|    mean_step_reward   | 0.1155926 |\n",
      "|    n_updates          | 3044      |\n",
      "|    policyGradLoss     | -0.0111   |\n",
      "|    value_loss         | 0.749     |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 847         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 6250496     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015714142 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.938       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0612      |\n",
      "|    mean_step_reward   | 0.11798565  |\n",
      "|    n_updates          | 3048        |\n",
      "|    policyGradLoss     | -0.00991    |\n",
      "|    value_loss         | 0.662       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 824         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 6258688     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019753456 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.949       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0147      |\n",
      "|    mean_step_reward   | 0.121911116 |\n",
      "|    n_updates          | 3052        |\n",
      "|    policyGradLoss     | -0.0133     |\n",
      "|    value_loss         | 0.478       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 809         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 50          |\n",
      "|    total_timesteps    | 6266880     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017195642 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.863       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.112       |\n",
      "|    mean_step_reward   | 0.118604474 |\n",
      "|    n_updates          | 3056        |\n",
      "|    policyGradLoss     | -0.000169   |\n",
      "|    value_loss         | 0.912       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 801         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 61          |\n",
      "|    total_timesteps    | 6275072     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014449872 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.918       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0436      |\n",
      "|    mean_step_reward   | 0.12090696  |\n",
      "|    n_updates          | 3060        |\n",
      "|    policyGradLoss     | -0.00607    |\n",
      "|    value_loss         | 0.643       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 797         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 71          |\n",
      "|    total_timesteps    | 6283264     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011533622 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.909       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0213      |\n",
      "|    mean_step_reward   | 0.119989306 |\n",
      "|    n_updates          | 3064        |\n",
      "|    policyGradLoss     | -0.00763    |\n",
      "|    value_loss         | 0.606       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 791         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 82          |\n",
      "|    total_timesteps    | 6291456     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016281249 |\n",
      "|    entropy_loss       | -1.97       |\n",
      "|    explained_variance | 0.938       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0523      |\n",
      "|    mean_step_reward   | 0.11332995  |\n",
      "|    n_updates          | 3068        |\n",
      "|    policyGradLoss     | -0.00904    |\n",
      "|    value_loss         | 0.639       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 788         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 93          |\n",
      "|    total_timesteps    | 6299648     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017009357 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.946       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0421      |\n",
      "|    mean_step_reward   | 0.10528244  |\n",
      "|    n_updates          | 3072        |\n",
      "|    policyGradLoss     | -0.0125     |\n",
      "|    value_loss         | 0.59        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 788         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 103         |\n",
      "|    total_timesteps    | 6307840     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01630768  |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0589      |\n",
      "|    mean_step_reward   | 0.117925666 |\n",
      "|    n_updates          | 3076        |\n",
      "|    policyGradLoss     | -0.0103     |\n",
      "|    value_loss         | 0.601       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 114         |\n",
      "|    total_timesteps    | 6316032     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019950679 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.936       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0314      |\n",
      "|    mean_step_reward   | 0.116647236 |\n",
      "|    n_updates          | 3080        |\n",
      "|    policyGradLoss     | -0.011      |\n",
      "|    value_loss         | 0.501       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 125         |\n",
      "|    total_timesteps    | 6324224     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018045409 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.017       |\n",
      "|    mean_step_reward   | 0.117645904 |\n",
      "|    n_updates          | 3084        |\n",
      "|    policyGradLoss     | -0.0135     |\n",
      "|    value_loss         | 0.347       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 136         |\n",
      "|    total_timesteps    | 6332416     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016845986 |\n",
      "|    entropy_loss       | -1.99       |\n",
      "|    explained_variance | 0.919       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.117       |\n",
      "|    mean_step_reward   | 0.10240561  |\n",
      "|    n_updates          | 3088        |\n",
      "|    policyGradLoss     | -0.00787    |\n",
      "|    value_loss         | 0.863       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 147         |\n",
      "|    total_timesteps    | 6340608     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017395657 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.916       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.112       |\n",
      "|    mean_step_reward   | 0.104585215 |\n",
      "|    n_updates          | 3092        |\n",
      "|    policyGradLoss     | -0.00995    |\n",
      "|    value_loss         | 0.519       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 157         |\n",
      "|    total_timesteps    | 6348800     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012830514 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.859       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0748      |\n",
      "|    mean_step_reward   | 0.110329956 |\n",
      "|    n_updates          | 3096        |\n",
      "|    policyGradLoss     | -0.00677    |\n",
      "|    value_loss         | 0.778       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 168         |\n",
      "|    total_timesteps    | 6356992     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017617019 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.926       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.203       |\n",
      "|    mean_step_reward   | 0.121056505 |\n",
      "|    n_updates          | 3100        |\n",
      "|    policyGradLoss     | -0.0076     |\n",
      "|    value_loss         | 0.908       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 776        |\n",
      "|    iterations         | 17         |\n",
      "|    time_elapsed       | 179        |\n",
      "|    total_timesteps    | 6365184    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01667772 |\n",
      "|    entropy_loss       | -1.93      |\n",
      "|    explained_variance | 0.898      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | 0.124      |\n",
      "|    mean_step_reward   | 0.10460684 |\n",
      "|    n_updates          | 3104       |\n",
      "|    policyGradLoss     | -0.00566   |\n",
      "|    value_loss         | 0.623      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 190         |\n",
      "|    total_timesteps    | 6373376     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017455142 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.947       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0152     |\n",
      "|    mean_step_reward   | 0.11911983  |\n",
      "|    n_updates          | 3108        |\n",
      "|    policyGradLoss     | -0.0127     |\n",
      "|    value_loss         | 0.435       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 201         |\n",
      "|    total_timesteps    | 6381568     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016754579 |\n",
      "|    entropy_loss       | -1.97       |\n",
      "|    explained_variance | 0.937       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.14        |\n",
      "|    mean_step_reward   | 0.11298667  |\n",
      "|    n_updates          | 3112        |\n",
      "|    policyGradLoss     | -0.00767    |\n",
      "|    value_loss         | 0.657       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 211         |\n",
      "|    total_timesteps    | 6389760     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016697923 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.86        |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0182      |\n",
      "|    mean_step_reward   | 0.10507995  |\n",
      "|    n_updates          | 3116        |\n",
      "|    policyGradLoss     | -0.00835    |\n",
      "|    value_loss         | 0.492       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 222         |\n",
      "|    total_timesteps    | 6397952     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012718517 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.847       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0451      |\n",
      "|    mean_step_reward   | 0.1093736   |\n",
      "|    n_updates          | 3120        |\n",
      "|    policyGradLoss     | -0.00652    |\n",
      "|    value_loss         | 0.62        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 233         |\n",
      "|    total_timesteps    | 6406144     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016966157 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.895       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.108       |\n",
      "|    mean_step_reward   | 0.11711011  |\n",
      "|    n_updates          | 3124        |\n",
      "|    policyGradLoss     | -0.0052     |\n",
      "|    value_loss         | 0.778       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 244         |\n",
      "|    total_timesteps    | 6414336     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013316521 |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.854       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0317      |\n",
      "|    mean_step_reward   | 0.12224999  |\n",
      "|    n_updates          | 3128        |\n",
      "|    policyGradLoss     | -0.00239    |\n",
      "|    value_loss         | 0.864       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 769        |\n",
      "|    iterations         | 24         |\n",
      "|    time_elapsed       | 255        |\n",
      "|    total_timesteps    | 6422528    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01791517 |\n",
      "|    entropy_loss       | -1.98      |\n",
      "|    explained_variance | 0.951      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | 0.00106    |\n",
      "|    mean_step_reward   | 0.11878373 |\n",
      "|    n_updates          | 3132       |\n",
      "|    policyGradLoss     | -0.0125    |\n",
      "|    value_loss         | 0.264      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 265         |\n",
      "|    total_timesteps    | 6430720     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014241417 |\n",
      "|    entropy_loss       | -1.97       |\n",
      "|    explained_variance | 0.938       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.027       |\n",
      "|    mean_step_reward   | 0.11827227  |\n",
      "|    n_updates          | 3136        |\n",
      "|    policyGradLoss     | -0.0102     |\n",
      "|    value_loss         | 0.447       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 276         |\n",
      "|    total_timesteps    | 6438912     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011713162 |\n",
      "|    entropy_loss       | -1.97       |\n",
      "|    explained_variance | 0.899       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0446      |\n",
      "|    mean_step_reward   | 0.115984984 |\n",
      "|    n_updates          | 3140        |\n",
      "|    policyGradLoss     | -0.00759    |\n",
      "|    value_loss         | 0.728       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 286         |\n",
      "|    total_timesteps    | 6447104     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013677442 |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.887       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0969      |\n",
      "|    mean_step_reward   | 0.10913761  |\n",
      "|    n_updates          | 3144        |\n",
      "|    policyGradLoss     | -0.00606    |\n",
      "|    value_loss         | 0.764       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 297         |\n",
      "|    total_timesteps    | 6455296     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016324528 |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.939       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.023       |\n",
      "|    mean_step_reward   | 0.11447756  |\n",
      "|    n_updates          | 3148        |\n",
      "|    policyGradLoss     | -0.0122     |\n",
      "|    value_loss         | 0.341       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 308         |\n",
      "|    total_timesteps    | 6463488     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013994267 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.915       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0499      |\n",
      "|    mean_step_reward   | 0.112034045 |\n",
      "|    n_updates          | 3152        |\n",
      "|    policyGradLoss     | -0.0113     |\n",
      "|    value_loss         | 0.524       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 319         |\n",
      "|    total_timesteps    | 6471680     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01694466  |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0782      |\n",
      "|    mean_step_reward   | 0.122519106 |\n",
      "|    n_updates          | 3156        |\n",
      "|    policyGradLoss     | -0.00997    |\n",
      "|    value_loss         | 0.393       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 330         |\n",
      "|    total_timesteps    | 6479872     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017299216 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.941       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.156       |\n",
      "|    mean_step_reward   | 0.13266903  |\n",
      "|    n_updates          | 3160        |\n",
      "|    policyGradLoss     | -0.00869    |\n",
      "|    value_loss         | 0.862       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 340         |\n",
      "|    total_timesteps    | 6488064     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015964977 |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.903       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.157       |\n",
      "|    mean_step_reward   | 0.11092135  |\n",
      "|    n_updates          | 3164        |\n",
      "|    policyGradLoss     | -0.00636    |\n",
      "|    value_loss         | 0.889       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 33          |\n",
      "|    time_elapsed       | 351         |\n",
      "|    total_timesteps    | 6496256     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015413223 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.939       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0313      |\n",
      "|    mean_step_reward   | 0.11616506  |\n",
      "|    n_updates          | 3168        |\n",
      "|    policyGradLoss     | -0.0159     |\n",
      "|    value_loss         | 0.501       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 34          |\n",
      "|    time_elapsed       | 361         |\n",
      "|    total_timesteps    | 6504448     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020557545 |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.931       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.121       |\n",
      "|    mean_step_reward   | 0.11443493  |\n",
      "|    n_updates          | 3172        |\n",
      "|    policyGradLoss     | -0.00703    |\n",
      "|    value_loss         | 0.751       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 35          |\n",
      "|    time_elapsed       | 372         |\n",
      "|    total_timesteps    | 6512640     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013880587 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.932       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.015       |\n",
      "|    mean_step_reward   | 0.1172065   |\n",
      "|    n_updates          | 3176        |\n",
      "|    policyGradLoss     | -0.0116     |\n",
      "|    value_loss         | 0.412       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 36          |\n",
      "|    time_elapsed       | 383         |\n",
      "|    total_timesteps    | 6520832     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012708986 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.949       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.137       |\n",
      "|    mean_step_reward   | 0.12546265  |\n",
      "|    n_updates          | 3180        |\n",
      "|    policyGradLoss     | -0.00596    |\n",
      "|    value_loss         | 0.535       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 37          |\n",
      "|    time_elapsed       | 394         |\n",
      "|    total_timesteps    | 6529024     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013331732 |\n",
      "|    entropy_loss       | -1.97       |\n",
      "|    explained_variance | 0.933       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.154       |\n",
      "|    mean_step_reward   | 0.117776565 |\n",
      "|    n_updates          | 3184        |\n",
      "|    policyGradLoss     | -0.00838    |\n",
      "|    value_loss         | 0.92        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 38          |\n",
      "|    time_elapsed       | 404         |\n",
      "|    total_timesteps    | 6537216     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015733691 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.865       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.166       |\n",
      "|    mean_step_reward   | 0.10289222  |\n",
      "|    n_updates          | 3188        |\n",
      "|    policyGradLoss     | -0.00392    |\n",
      "|    value_loss         | 1.03        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 39          |\n",
      "|    time_elapsed       | 415         |\n",
      "|    total_timesteps    | 6545408     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016449887 |\n",
      "|    entropy_loss       | -2          |\n",
      "|    explained_variance | 0.922       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0571      |\n",
      "|    mean_step_reward   | 0.117353775 |\n",
      "|    n_updates          | 3192        |\n",
      "|    policyGradLoss     | -0.00968    |\n",
      "|    value_loss         | 0.558       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 40          |\n",
      "|    time_elapsed       | 426         |\n",
      "|    total_timesteps    | 6553600     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017090896 |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.948       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0235      |\n",
      "|    mean_step_reward   | 0.11583345  |\n",
      "|    n_updates          | 3196        |\n",
      "|    policyGradLoss     | -0.0119     |\n",
      "|    value_loss         | 0.399       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/TNL_20.zip\n",
      "[EVAL] Mean Return: -0.563, Best Return: -0.500\n",
      "Saved video to ./runs_smw/videos/step_6553600_mean_-0.56.mp4\n",
      "Training finished. Environment closed.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\ntensorboard --logdir=./runs_smw/tb\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_mean = -1e18\n",
    "trained = 1638400\n",
    "round_idx = 0\n",
    "\n",
    "try:\n",
    "    while trained < TOTAL_STEPS:\n",
    "        round_idx += 1\n",
    "        chunk = min(TRAIN_CHUNK, TOTAL_STEPS - trained)\n",
    "        # chunk = 2000\n",
    "\n",
    "        print(f\"\\n=== Round {round_idx} | Learn {chunk} steps (Total trained: {trained}) ===\")\n",
    "        \n",
    "        # --- Train ---\n",
    "        model.learn(total_timesteps=chunk, reset_num_timesteps=False, tb_log_name='tunnel')\n",
    "        trained += chunk\n",
    "        \n",
    "        label = \"TNL\"\n",
    "        tagged_label = f\"{label}_{int(trained/TRAIN_CHUNK)}\"\n",
    "\n",
    "        # --- Save Checkpoint ---\n",
    "        ckpt_path = os.path.join(CKPT_DIR, f\"{tagged_label}.zip\")\n",
    "        model.save(ckpt_path)\n",
    "        print(f\"Saved checkpoint: {ckpt_path}\")\n",
    "\n",
    "        # --- Evaluate ---\n",
    "        mean_ret, best_ret = evaluate_policy(\n",
    "            model,\n",
    "            GAME,\n",
    "            STATE,\n",
    "            n_episodes=EVAL_EPISODES,\n",
    "            max_steps=EVAL_MAX_STEPS,\n",
    "        )\n",
    "        print(f\"[EVAL] Mean Return: {mean_ret:.3f}, Best Return: {best_ret:.3f}\")\n",
    "\n",
    "        # --- Save Best Model ---\n",
    "        # if mean_ret > best_mean:\n",
    "        #     best_mean = mean_ret\n",
    "        #     best_path = os.path.join(LOG_DIR, \"best_model.zip\")\n",
    "        #     model.save(best_path)\n",
    "        #     print(f\"New best record. Saved to {best_path}\")\n",
    "\n",
    "        # --- Record Video ---\n",
    "        record_video(\n",
    "            model,\n",
    "            GAME,\n",
    "            STATE,\n",
    "            VIDEO_DIR,\n",
    "            video_len=RECORD_STEPS,\n",
    "            prefix=f\"{label}/{tagged_label}_{mean_ret:.2f}\",\n",
    "        )\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nTraining interrupted manually.\")\n",
    "\n",
    "finally:\n",
    "    train_env.close()\n",
    "    print(\"Training finished. Environment closed.\")\n",
    "    \n",
    "\"\"\"\n",
    "tensorboard --logdir=./runs_smw/tb\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f088b0b3-2418-4866-b332-0312c9f6467f",
   "metadata": {},
   "source": [
    "## Display Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a73191bb-e875-4939-b04c-a4670abd9612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import Video\n",
    "# import glob\n",
    "\n",
    "# list_of_files = glob.glob(os.path.join(VIDEO_DIR, '*.mp4')) \n",
    "# if list_of_files:\n",
    "#     latest_file = max(list_of_files, key=os.path.getctime)\n",
    "#     print(f\"Playing: {latest_file}\")\n",
    "#     display(Video(latest_file, embed=True, width=600))\n",
    "# else:\n",
    "#     print(\"No videos found yet.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Lab8 (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
