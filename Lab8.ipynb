{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dceedafe-2782-41a1-8119-50ee3d6c21fd",
   "metadata": {},
   "source": [
    "# 2025 DL Lab8: RL Assignment_Super Mario World"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fa555a-e61c-4fb3-b5d0-289b66570139",
   "metadata": {},
   "source": [
    "**Your Answer:**    \n",
    "Hi I'm XXX, XXXXXXXXXX."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5b0974-9605-488a-9fd5-00816e7832cc",
   "metadata": {},
   "source": [
    "## Overview\n",
    "This project implements a **Deep Reinforcement Learning** pipeline to train an autonomous agent for Super Mario World. Leveraging the **Proximal Policy Optimization (PPO)** algorithm, the system interacts with the **stable-retro** environment to master the YoshiIsland1 level. Key components include a custom Vision Backbone for extracting features from raw pixel data and a suite of Environment Wrappers that handle frame preprocessing, action discretization, and reward shaping to facilitate efficient learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02696447",
   "metadata": {},
   "source": [
    "Reward function implement  \n",
    "should do something in the beginning (monster attack)  \n",
    "Custom PPO implement  \n",
    "pre train weight 差不多，主要是 reward function  \n",
    "model weight capacity 1GB  \n",
    "class name 不要動 (可以新增，但是原本有的不要動)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8a0ab9-f86d-4038-833d-761ec81fc4f2",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00b10def-362c-4910-9ed0-f3d0904343ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/m314834001/Lab8/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import retro\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, SubprocVecEnv\n",
    "from stable_baselines3.common.vec_env import VecNormalize\n",
    "\n",
    "from eval import evaluate_policy, record_video\n",
    "from custom_policy import VisionBackbonePolicy, CustomPPO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10361fd-f291-4d93-b50d-cc749a3af588",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b4f6a25-738c-49dd-8e66-ae164b74a45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Game Settings\n",
    "GAME = \"SuperMarioWorld-Snes\"\n",
    "STATE = \"YoshiIsland1\"\n",
    "\n",
    "# Training Settings\n",
    "TOTAL_STEPS = 13_107_200\n",
    "TRAIN_CHUNK =    327_680\n",
    "N_ENVS = 16\n",
    "LEARNING_RATE = 1e-4\n",
    "\n",
    "# Evaluation & Recording Settings\n",
    "EVAL_EPISODES = 3\n",
    "EVAL_MAX_STEPS = 18000\n",
    "RECORD_STEPS = 1800\n",
    "\n",
    "# Directories\n",
    "LOG_DIR = \"./runs_smw\"\n",
    "VIDEO_DIR       = os.path.join(LOG_DIR, \"videos\")\n",
    "CKPT_DIR        = os.path.join(LOG_DIR, \"checkpoints\")\n",
    "TENSORBOARD_LOG = os.path.join(LOG_DIR, \"tb\")\n",
    "\n",
    "os.makedirs(LOG_DIR,   exist_ok=True)\n",
    "os.makedirs(CKPT_DIR,  exist_ok=True)\n",
    "os.makedirs(VIDEO_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a34b783-0273-4835-ad2e-f9186064f76f",
   "metadata": {},
   "source": [
    "## Environment Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c34213d-2c7c-42b8-922d-bafa285d1ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wrappers import make_base_env\n",
    "def _make_env_thunk(game: str, state: str):\n",
    "    \"\"\"Return a function that creates an environment (for multiprocessing).\"\"\"\n",
    "    def _thunk():\n",
    "        return make_base_env(game, state)\n",
    "    return _thunk\n",
    "\n",
    "def make_vec_env(game: str, state: str, n_envs: int, use_subproc: bool = True):\n",
    "    \"\"\"Create a vectorized environment (multiple envs running in parallel).\"\"\"\n",
    "    env_fns = [_make_env_thunk(game, state) for _ in range(n_envs)]\n",
    "    \n",
    "    if use_subproc and n_envs > 1:\n",
    "        vec_env = SubprocVecEnv(env_fns)\n",
    "    else:\n",
    "        vec_env = DummyVecEnv(env_fns)\n",
    "\n",
    "    return vec_env"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71dff476-ea2e-4262-8780-afb32ef1b233",
   "metadata": {},
   "source": [
    "## Initialize Env & Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8c7c5fe-6421-4dbc-9bd8-822d61769c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment created: SuperMarioWorld-Snes - YoshiIsland1 with 16 parallel envs.\n",
      "Loading model from runs_smw/checkpoints/SF84G_PT_29.zip...\n"
     ]
    }
   ],
   "source": [
    "# 1. Create Training Environment\n",
    "train_env = make_vec_env(GAME, STATE, n_envs=N_ENVS)\n",
    "# train_env = VecNormalize(train_env, norm_obs=True, norm_reward=True, clip_obs=10., clip_reward=10.)\n",
    "print(f\"Environment created: {GAME} - {STATE} with {N_ENVS} parallel envs.\")\n",
    "\n",
    "checkpoint_path = \"None\"\n",
    "# checkpoint_path = \"runs_smw/checkpoints/SF84_step_1600000.zip\"\n",
    "# checkpoint_path = \"runs_smw/checkpoints/SF84G_6553600.zip\"\n",
    "checkpoint_path = \"runs_smw/checkpoints/SF84G_PT_29.zip\"\n",
    "\n",
    "# 2. Initialize Model\n",
    "if os.path.exists(checkpoint_path):\n",
    "    print(f\"Loading model from {checkpoint_path}...\")\n",
    "    # 讀取現有模型\n",
    "    model = CustomPPO.load(\n",
    "        checkpoint_path, \n",
    "        env=train_env,\n",
    "        device=\"cuda:0\" # 確保使用 GPU\n",
    "    )\n",
    "else:\n",
    "    print(f\"Fail to load {checkpoint_path}...\")\n",
    "    model = CustomPPO(\n",
    "        VisionBackbonePolicy,\n",
    "        train_env,\n",
    "        policy_kwargs   = dict(normalize_images=False),\n",
    "        n_epochs        = 4,\n",
    "        n_steps         = 512,\n",
    "        batch_size      = 512,\n",
    "        learning_rate   = LEARNING_RATE,\n",
    "        verbose         = 1,\n",
    "        gamma           = 0.99,\n",
    "        kl_coef         = 1,\n",
    "        clip_range      = 0.125,\n",
    "        tensorboard_log = TENSORBOARD_LOG,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1cb3d0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"policy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f594e443-843f-42c1-9fc6-3fbc82962021",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3af4932-c531-4113-a33a-defc6fb5858e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Round 1 | Learn 327680 steps (Total trained: 9502720) ===\n",
      "Logging to ./runs_smw/tb/SF84G_1220_20_0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/m314834001/Lab8/.venv/lib/python3.12/site-packages/rich/live.py:256: UserWarning: install \"ipywidgets\" for \n",
       "Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/m314834001/Lab8/.venv/lib/python3.12/site-packages/rich/live.py:256: UserWarning: install \"ipywidgets\" for \n",
       "Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 740     |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 11      |\n",
      "|    total_timesteps | 9510912 |\n",
      "--------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 628         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 26          |\n",
      "|    total_timesteps    | 9519104     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027881095 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.838       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.127       |\n",
      "|    mean_step_reward   | 0.10536369  |\n",
      "|    n_updates          | 4644        |\n",
      "|    policyGradLoss     | -0.00657    |\n",
      "|    value_loss         | 0.527       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 601         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 40          |\n",
      "|    total_timesteps    | 9527296     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015729934 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0118     |\n",
      "|    mean_step_reward   | 0.13369122  |\n",
      "|    n_updates          | 4648        |\n",
      "|    policyGradLoss     | -0.0114     |\n",
      "|    value_loss         | 0.514       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 585         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 55          |\n",
      "|    total_timesteps    | 9535488     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026182747 |\n",
      "|    entropy_loss       | -1.99       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0869      |\n",
      "|    mean_step_reward   | 0.13638052  |\n",
      "|    n_updates          | 4652        |\n",
      "|    policyGradLoss     | -0.0051     |\n",
      "|    value_loss         | 0.438       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 598         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 68          |\n",
      "|    total_timesteps    | 9543680     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020963572 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.916       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.287       |\n",
      "|    mean_step_reward   | 0.11055109  |\n",
      "|    n_updates          | 4656        |\n",
      "|    policyGradLoss     | -0.0074     |\n",
      "|    value_loss         | 0.818       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 599         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 82          |\n",
      "|    total_timesteps    | 9551872     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022019528 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0956      |\n",
      "|    mean_step_reward   | 0.13385592  |\n",
      "|    n_updates          | 4660        |\n",
      "|    policyGradLoss     | -0.0083     |\n",
      "|    value_loss         | 0.549       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 600         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 95          |\n",
      "|    total_timesteps    | 9560064     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023196321 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.947       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0246      |\n",
      "|    mean_step_reward   | 0.11929722  |\n",
      "|    n_updates          | 4664        |\n",
      "|    policyGradLoss     | -0.00978    |\n",
      "|    value_loss         | 0.359       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 602         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 108         |\n",
      "|    total_timesteps    | 9568256     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018709464 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.00439    |\n",
      "|    mean_step_reward   | 0.1297109   |\n",
      "|    n_updates          | 4668        |\n",
      "|    policyGradLoss     | -0.015      |\n",
      "|    value_loss         | 0.367       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 604         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 122         |\n",
      "|    total_timesteps    | 9576448     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016672324 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0204     |\n",
      "|    mean_step_reward   | 0.13050938  |\n",
      "|    n_updates          | 4672        |\n",
      "|    policyGradLoss     | -0.0157     |\n",
      "|    value_loss         | 0.216       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 616         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 132         |\n",
      "|    total_timesteps    | 9584640     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012895397 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.945       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0305      |\n",
      "|    mean_step_reward   | 0.1257672   |\n",
      "|    n_updates          | 4676        |\n",
      "|    policyGradLoss     | -0.00877    |\n",
      "|    value_loss         | 0.628       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 632         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 142         |\n",
      "|    total_timesteps    | 9592832     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013067415 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.873       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.339       |\n",
      "|    mean_step_reward   | 0.110374376 |\n",
      "|    n_updates          | 4680        |\n",
      "|    policyGradLoss     | -0.00389    |\n",
      "|    value_loss         | 1.09        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 624         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 157         |\n",
      "|    total_timesteps    | 9601024     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017760726 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.00187     |\n",
      "|    mean_step_reward   | 0.12433214  |\n",
      "|    n_updates          | 4684        |\n",
      "|    policyGradLoss     | -0.0151     |\n",
      "|    value_loss         | 0.259       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 617         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 172         |\n",
      "|    total_timesteps    | 9609216     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012042112 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.886       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.348       |\n",
      "|    mean_step_reward   | 0.11616729  |\n",
      "|    n_updates          | 4688        |\n",
      "|    policyGradLoss     | -0.00379    |\n",
      "|    value_loss         | 1.63        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 611         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 187         |\n",
      "|    total_timesteps    | 9617408     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015815593 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.938       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0289      |\n",
      "|    mean_step_reward   | 0.12789713  |\n",
      "|    n_updates          | 4692        |\n",
      "|    policyGradLoss     | -0.00728    |\n",
      "|    value_loss         | 0.52        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 607         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 202         |\n",
      "|    total_timesteps    | 9625600     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016144527 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.949       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0187      |\n",
      "|    mean_step_reward   | 0.12014561  |\n",
      "|    n_updates          | 4696        |\n",
      "|    policyGradLoss     | -0.0118     |\n",
      "|    value_loss         | 0.454       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 603        |\n",
      "|    iterations         | 16         |\n",
      "|    time_elapsed       | 217        |\n",
      "|    total_timesteps    | 9633792    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01597637 |\n",
      "|    entropy_loss       | -1.97      |\n",
      "|    explained_variance | 0.943      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | 0.00926    |\n",
      "|    mean_step_reward   | 0.12967384 |\n",
      "|    n_updates          | 4700       |\n",
      "|    policyGradLoss     | -0.00535   |\n",
      "|    value_loss         | 0.553      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 599         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 232         |\n",
      "|    total_timesteps    | 9641984     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016800892 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.922       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0446      |\n",
      "|    mean_step_reward   | 0.104531065 |\n",
      "|    n_updates          | 4704        |\n",
      "|    policyGradLoss     | -0.00682    |\n",
      "|    value_loss         | 0.545       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 595        |\n",
      "|    iterations         | 18         |\n",
      "|    time_elapsed       | 247        |\n",
      "|    total_timesteps    | 9650176    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01511652 |\n",
      "|    entropy_loss       | -1.96      |\n",
      "|    explained_variance | 0.892      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | 0.144      |\n",
      "|    mean_step_reward   | 0.11408721 |\n",
      "|    n_updates          | 4708       |\n",
      "|    policyGradLoss     | -0.00581   |\n",
      "|    value_loss         | 1.15       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 592         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 262         |\n",
      "|    total_timesteps    | 9658368     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017902456 |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.00663     |\n",
      "|    mean_step_reward   | 0.12978071  |\n",
      "|    n_updates          | 4712        |\n",
      "|    policyGradLoss     | -0.0112     |\n",
      "|    value_loss         | 0.355       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 590         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 277         |\n",
      "|    total_timesteps    | 9666560     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022190902 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0251     |\n",
      "|    mean_step_reward   | 0.124910414 |\n",
      "|    n_updates          | 4716        |\n",
      "|    policyGradLoss     | -0.0192     |\n",
      "|    value_loss         | 0.217       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 588        |\n",
      "|    iterations         | 21         |\n",
      "|    time_elapsed       | 292        |\n",
      "|    total_timesteps    | 9674752    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01526682 |\n",
      "|    entropy_loss       | -1.94      |\n",
      "|    explained_variance | 0.953      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | 0.027      |\n",
      "|    mean_step_reward   | 0.12354552 |\n",
      "|    n_updates          | 4720       |\n",
      "|    policyGradLoss     | -0.00412   |\n",
      "|    value_loss         | 0.62       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 586        |\n",
      "|    iterations         | 22         |\n",
      "|    time_elapsed       | 307        |\n",
      "|    total_timesteps    | 9682944    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.016863   |\n",
      "|    entropy_loss       | -1.9       |\n",
      "|    explained_variance | 0.943      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | 0.0423     |\n",
      "|    mean_step_reward   | 0.11067711 |\n",
      "|    n_updates          | 4724       |\n",
      "|    policyGradLoss     | -0.0093    |\n",
      "|    value_loss         | 0.479      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 584         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 322         |\n",
      "|    total_timesteps    | 9691136     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016465306 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.106       |\n",
      "|    mean_step_reward   | 0.13765314  |\n",
      "|    n_updates          | 4728        |\n",
      "|    policyGradLoss     | -0.00865    |\n",
      "|    value_loss         | 0.558       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 583        |\n",
      "|    iterations         | 24         |\n",
      "|    time_elapsed       | 336        |\n",
      "|    total_timesteps    | 9699328    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02567669 |\n",
      "|    entropy_loss       | -1.89      |\n",
      "|    explained_variance | 0.976      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | -0.00892   |\n",
      "|    mean_step_reward   | 0.12008746 |\n",
      "|    n_updates          | 4732       |\n",
      "|    policyGradLoss     | -0.0147    |\n",
      "|    value_loss         | 0.311      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 581        |\n",
      "|    iterations         | 25         |\n",
      "|    time_elapsed       | 351        |\n",
      "|    total_timesteps    | 9707520    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01587466 |\n",
      "|    entropy_loss       | -1.9       |\n",
      "|    explained_variance | 0.972      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | -0.00383   |\n",
      "|    mean_step_reward   | 0.12724498 |\n",
      "|    n_updates          | 4736       |\n",
      "|    policyGradLoss     | -0.00875   |\n",
      "|    value_loss         | 0.362      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 580         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 366         |\n",
      "|    total_timesteps    | 9715712     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016578939 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0812      |\n",
      "|    mean_step_reward   | 0.1280592   |\n",
      "|    n_updates          | 4740        |\n",
      "|    policyGradLoss     | -0.0106     |\n",
      "|    value_loss         | 0.548       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 579         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 381         |\n",
      "|    total_timesteps    | 9723904     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017161861 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0302      |\n",
      "|    mean_step_reward   | 0.12702794  |\n",
      "|    n_updates          | 4744        |\n",
      "|    policyGradLoss     | -0.0106     |\n",
      "|    value_loss         | 0.454       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 578        |\n",
      "|    iterations         | 28         |\n",
      "|    time_elapsed       | 396        |\n",
      "|    total_timesteps    | 9732096    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01797721 |\n",
      "|    entropy_loss       | -1.87      |\n",
      "|    explained_variance | 0.982      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | -0.0149    |\n",
      "|    mean_step_reward   | 0.13580714 |\n",
      "|    n_updates          | 4748       |\n",
      "|    policyGradLoss     | -0.0135    |\n",
      "|    value_loss         | 0.288      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 577         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 411         |\n",
      "|    total_timesteps    | 9740288     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023228496 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0119     |\n",
      "|    mean_step_reward   | 0.13140997  |\n",
      "|    n_updates          | 4752        |\n",
      "|    policyGradLoss     | -0.0144     |\n",
      "|    value_loss         | 0.374       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 576         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 426         |\n",
      "|    total_timesteps    | 9748480     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019410204 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0549      |\n",
      "|    mean_step_reward   | 0.13005821  |\n",
      "|    n_updates          | 4756        |\n",
      "|    policyGradLoss     | -0.0155     |\n",
      "|    value_loss         | 0.375       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 575         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 441         |\n",
      "|    total_timesteps    | 9756672     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013643723 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0269      |\n",
      "|    mean_step_reward   | 0.14245129  |\n",
      "|    n_updates          | 4760        |\n",
      "|    policyGradLoss     | -0.0136     |\n",
      "|    value_loss         | 0.373       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 574         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 456         |\n",
      "|    total_timesteps    | 9764864     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017765505 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.00393    |\n",
      "|    mean_step_reward   | 0.12724425  |\n",
      "|    n_updates          | 4764        |\n",
      "|    policyGradLoss     | -0.0129     |\n",
      "|    value_loss         | 0.296       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 574         |\n",
      "|    iterations         | 33          |\n",
      "|    time_elapsed       | 470         |\n",
      "|    total_timesteps    | 9773056     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016723715 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.957       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0126     |\n",
      "|    mean_step_reward   | 0.12140719  |\n",
      "|    n_updates          | 4768        |\n",
      "|    policyGradLoss     | -0.0151     |\n",
      "|    value_loss         | 0.468       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 573         |\n",
      "|    iterations         | 34          |\n",
      "|    time_elapsed       | 485         |\n",
      "|    total_timesteps    | 9781248     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015754834 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0444      |\n",
      "|    mean_step_reward   | 0.13865373  |\n",
      "|    n_updates          | 4772        |\n",
      "|    policyGradLoss     | -0.013      |\n",
      "|    value_loss         | 0.395       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 572         |\n",
      "|    iterations         | 35          |\n",
      "|    time_elapsed       | 500         |\n",
      "|    total_timesteps    | 9789440     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014954963 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0031      |\n",
      "|    mean_step_reward   | 0.12990904  |\n",
      "|    n_updates          | 4776        |\n",
      "|    policyGradLoss     | -0.0117     |\n",
      "|    value_loss         | 0.449       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 572         |\n",
      "|    iterations         | 36          |\n",
      "|    time_elapsed       | 515         |\n",
      "|    total_timesteps    | 9797632     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020923533 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0472      |\n",
      "|    mean_step_reward   | 0.12275524  |\n",
      "|    n_updates          | 4780        |\n",
      "|    policyGradLoss     | -0.0142     |\n",
      "|    value_loss         | 0.445       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 571         |\n",
      "|    iterations         | 37          |\n",
      "|    time_elapsed       | 530         |\n",
      "|    total_timesteps    | 9805824     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017529625 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.00771     |\n",
      "|    mean_step_reward   | 0.14160597  |\n",
      "|    n_updates          | 4784        |\n",
      "|    policyGradLoss     | -0.0148     |\n",
      "|    value_loss         | 0.27        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 573         |\n",
      "|    iterations         | 38          |\n",
      "|    time_elapsed       | 542         |\n",
      "|    total_timesteps    | 9814016     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016262025 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0483      |\n",
      "|    mean_step_reward   | 0.13730705  |\n",
      "|    n_updates          | 4788        |\n",
      "|    policyGradLoss     | -0.014      |\n",
      "|    value_loss         | 0.413       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 574         |\n",
      "|    iterations         | 39          |\n",
      "|    time_elapsed       | 555         |\n",
      "|    total_timesteps    | 9822208     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015038797 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 8.24e-05    |\n",
      "|    mean_step_reward   | 0.13353494  |\n",
      "|    n_updates          | 4792        |\n",
      "|    policyGradLoss     | -0.0103     |\n",
      "|    value_loss         | 0.36        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 575        |\n",
      "|    iterations         | 40         |\n",
      "|    time_elapsed       | 569        |\n",
      "|    total_timesteps    | 9830400    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02292069 |\n",
      "|    entropy_loss       | -1.85      |\n",
      "|    explained_variance | 0.981      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | -0.00887   |\n",
      "|    mean_step_reward   | 0.12686822 |\n",
      "|    n_updates          | 4796       |\n",
      "|    policyGradLoss     | -0.0166    |\n",
      "|    value_loss         | 0.187      |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/SF84G_PT_30.zip\n",
      "[EVAL] Mean Return: 182.850, Best Return: 182.858\n",
      "New best record. Saved to ./runs_smw/best_model_A.zip\n",
      "Saved video to ./runs_smw/videos/step_9830400_mean_182.85.mp4\n",
      "\n",
      "=== Round 2 | Learn 327680 steps (Total trained: 9830400) ===\n",
      "Logging to ./runs_smw/tb/SF84G_1220_20_0\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 735     |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 11      |\n",
      "|    total_timesteps | 9838592 |\n",
      "--------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 622         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 26          |\n",
      "|    total_timesteps    | 9846784     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021215059 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0149      |\n",
      "|    mean_step_reward   | 0.1322881   |\n",
      "|    n_updates          | 4804        |\n",
      "|    policyGradLoss     | -0.0158     |\n",
      "|    value_loss         | 0.351       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 592         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 41          |\n",
      "|    total_timesteps    | 9854976     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020897195 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0576      |\n",
      "|    mean_step_reward   | 0.14279078  |\n",
      "|    n_updates          | 4808        |\n",
      "|    policyGradLoss     | -0.00536    |\n",
      "|    value_loss         | 0.444       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 583         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 56          |\n",
      "|    total_timesteps    | 9863168     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024472645 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.00554    |\n",
      "|    mean_step_reward   | 0.1315672   |\n",
      "|    n_updates          | 4812        |\n",
      "|    policyGradLoss     | -0.00867    |\n",
      "|    value_loss         | 0.262       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 577        |\n",
      "|    iterations         | 5          |\n",
      "|    time_elapsed       | 70         |\n",
      "|    total_timesteps    | 9871360    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01831644 |\n",
      "|    entropy_loss       | -1.86      |\n",
      "|    explained_variance | 0.969      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | 0.101      |\n",
      "|    mean_step_reward   | 0.12567443 |\n",
      "|    n_updates          | 4816       |\n",
      "|    policyGradLoss     | -0.00822   |\n",
      "|    value_loss         | 0.604      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 571        |\n",
      "|    iterations         | 6          |\n",
      "|    time_elapsed       | 86         |\n",
      "|    total_timesteps    | 9879552    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01800672 |\n",
      "|    entropy_loss       | -1.89      |\n",
      "|    explained_variance | 0.984      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | -0.0125    |\n",
      "|    mean_step_reward   | 0.13942456 |\n",
      "|    n_updates          | 4820       |\n",
      "|    policyGradLoss     | -0.012     |\n",
      "|    value_loss         | 0.223      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 568         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 100         |\n",
      "|    total_timesteps    | 9887744     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026732313 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0279     |\n",
      "|    mean_step_reward   | 0.13999455  |\n",
      "|    n_updates          | 4824        |\n",
      "|    policyGradLoss     | -0.0202     |\n",
      "|    value_loss         | 0.154       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 567         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 115         |\n",
      "|    total_timesteps    | 9895936     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024058629 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0017     |\n",
      "|    mean_step_reward   | 0.14491667  |\n",
      "|    n_updates          | 4828        |\n",
      "|    policyGradLoss     | -0.0107     |\n",
      "|    value_loss         | 0.225       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 564        |\n",
      "|    iterations         | 9          |\n",
      "|    time_elapsed       | 130        |\n",
      "|    total_timesteps    | 9904128    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01833221 |\n",
      "|    entropy_loss       | -1.89      |\n",
      "|    explained_variance | 0.939      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | 0.0162     |\n",
      "|    mean_step_reward   | 0.11399391 |\n",
      "|    n_updates          | 4832       |\n",
      "|    policyGradLoss     | -0.00819   |\n",
      "|    value_loss         | 0.641      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 563         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 145         |\n",
      "|    total_timesteps    | 9912320     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016298767 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.00372    |\n",
      "|    mean_step_reward   | 0.13208814  |\n",
      "|    n_updates          | 4836        |\n",
      "|    policyGradLoss     | -0.0153     |\n",
      "|    value_loss         | 0.437       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 561         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 160         |\n",
      "|    total_timesteps    | 9920512     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021720538 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0335     |\n",
      "|    mean_step_reward   | 0.14157534  |\n",
      "|    n_updates          | 4840        |\n",
      "|    policyGradLoss     | -0.0175     |\n",
      "|    value_loss         | 0.156       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 560         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 175         |\n",
      "|    total_timesteps    | 9928704     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018900897 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.00259     |\n",
      "|    mean_step_reward   | 0.13660762  |\n",
      "|    n_updates          | 4844        |\n",
      "|    policyGradLoss     | -0.0184     |\n",
      "|    value_loss         | 0.278       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 560         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 190         |\n",
      "|    total_timesteps    | 9936896     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029650524 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0394     |\n",
      "|    mean_step_reward   | 0.13918501  |\n",
      "|    n_updates          | 4848        |\n",
      "|    policyGradLoss     | -0.0183     |\n",
      "|    value_loss         | 0.153       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 558         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 205         |\n",
      "|    total_timesteps    | 9945088     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020189438 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.958       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0234      |\n",
      "|    mean_step_reward   | 0.12095465  |\n",
      "|    n_updates          | 4852        |\n",
      "|    policyGradLoss     | -0.00833    |\n",
      "|    value_loss         | 0.632       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 559         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 219         |\n",
      "|    total_timesteps    | 9953280     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018547844 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0162      |\n",
      "|    mean_step_reward   | 0.13896139  |\n",
      "|    n_updates          | 4856        |\n",
      "|    policyGradLoss     | -0.00889    |\n",
      "|    value_loss         | 0.414       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 558         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 234         |\n",
      "|    total_timesteps    | 9961472     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026981935 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.00706     |\n",
      "|    mean_step_reward   | 0.12693028  |\n",
      "|    n_updates          | 4860        |\n",
      "|    policyGradLoss     | -0.0107     |\n",
      "|    value_loss         | 0.387       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 557        |\n",
      "|    iterations         | 17         |\n",
      "|    time_elapsed       | 249        |\n",
      "|    total_timesteps    | 9969664    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01973214 |\n",
      "|    entropy_loss       | -1.86      |\n",
      "|    explained_variance | 0.97       |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | -0.00893   |\n",
      "|    mean_step_reward   | 0.13025264 |\n",
      "|    n_updates          | 4864       |\n",
      "|    policyGradLoss     | -0.0156    |\n",
      "|    value_loss         | 0.344      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 556        |\n",
      "|    iterations         | 18         |\n",
      "|    time_elapsed       | 264        |\n",
      "|    total_timesteps    | 9977856    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03026715 |\n",
      "|    entropy_loss       | -1.86      |\n",
      "|    explained_variance | 0.991      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | -0.025     |\n",
      "|    mean_step_reward   | 0.1456461  |\n",
      "|    n_updates          | 4868       |\n",
      "|    policyGradLoss     | -0.0175    |\n",
      "|    value_loss         | 0.158      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 556         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 279         |\n",
      "|    total_timesteps    | 9986048     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025993716 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0272     |\n",
      "|    mean_step_reward   | 0.14786321  |\n",
      "|    n_updates          | 4872        |\n",
      "|    policyGradLoss     | -0.0156     |\n",
      "|    value_loss         | 0.195       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 555         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 294         |\n",
      "|    total_timesteps    | 9994240     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024209443 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0447     |\n",
      "|    mean_step_reward   | 0.12829015  |\n",
      "|    n_updates          | 4876        |\n",
      "|    policyGradLoss     | -0.0179     |\n",
      "|    value_loss         | 0.16        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 555         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 309         |\n",
      "|    total_timesteps    | 10002432    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021676388 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0351     |\n",
      "|    mean_step_reward   | 0.14129162  |\n",
      "|    n_updates          | 4880        |\n",
      "|    policyGradLoss     | -0.0167     |\n",
      "|    value_loss         | 0.181       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 555         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 324         |\n",
      "|    total_timesteps    | 10010624    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016383357 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0375      |\n",
      "|    mean_step_reward   | 0.14409113  |\n",
      "|    n_updates          | 4884        |\n",
      "|    policyGradLoss     | -0.0137     |\n",
      "|    value_loss         | 0.358       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 555         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 339         |\n",
      "|    total_timesteps    | 10018816    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021023806 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0284      |\n",
      "|    mean_step_reward   | 0.12907457  |\n",
      "|    n_updates          | 4888        |\n",
      "|    policyGradLoss     | -0.00962    |\n",
      "|    value_loss         | 0.285       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 556         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 353         |\n",
      "|    total_timesteps    | 10027008    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020956133 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.00355     |\n",
      "|    mean_step_reward   | 0.15049186  |\n",
      "|    n_updates          | 4892        |\n",
      "|    policyGradLoss     | -0.0113     |\n",
      "|    value_loss         | 0.274       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 558         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 366         |\n",
      "|    total_timesteps    | 10035200    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023214974 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.00348    |\n",
      "|    mean_step_reward   | 0.12136374  |\n",
      "|    n_updates          | 4896        |\n",
      "|    policyGradLoss     | -0.00785    |\n",
      "|    value_loss         | 0.398       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 560        |\n",
      "|    iterations         | 26         |\n",
      "|    time_elapsed       | 380        |\n",
      "|    total_timesteps    | 10043392   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01832666 |\n",
      "|    entropy_loss       | -1.85      |\n",
      "|    explained_variance | 0.939      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | 0.0136     |\n",
      "|    mean_step_reward   | 0.13335963 |\n",
      "|    n_updates          | 4900       |\n",
      "|    policyGradLoss     | -0.00915   |\n",
      "|    value_loss         | 0.418      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 561         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 394         |\n",
      "|    total_timesteps    | 10051584    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012986558 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.933       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0622      |\n",
      "|    mean_step_reward   | 0.12799966  |\n",
      "|    n_updates          | 4904        |\n",
      "|    policyGradLoss     | -0.00652    |\n",
      "|    value_loss         | 0.537       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 560         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 409         |\n",
      "|    total_timesteps    | 10059776    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019902514 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0225     |\n",
      "|    mean_step_reward   | 0.12709424  |\n",
      "|    n_updates          | 4908        |\n",
      "|    policyGradLoss     | -0.00935    |\n",
      "|    value_loss         | 0.334       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 560         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 424         |\n",
      "|    total_timesteps    | 10067968    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029733745 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.00593    |\n",
      "|    mean_step_reward   | 0.13601685  |\n",
      "|    n_updates          | 4912        |\n",
      "|    policyGradLoss     | -0.0155     |\n",
      "|    value_loss         | 0.184       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 559         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 438         |\n",
      "|    total_timesteps    | 10076160    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024670605 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.141       |\n",
      "|    mean_step_reward   | 0.14317086  |\n",
      "|    n_updates          | 4916        |\n",
      "|    policyGradLoss     | -0.0101     |\n",
      "|    value_loss         | 0.387       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 558         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 454         |\n",
      "|    total_timesteps    | 10084352    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019262537 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.00923    |\n",
      "|    mean_step_reward   | 0.13367115  |\n",
      "|    n_updates          | 4920        |\n",
      "|    policyGradLoss     | -0.0158     |\n",
      "|    value_loss         | 0.256       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 558         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 469         |\n",
      "|    total_timesteps    | 10092544    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021934563 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.039      |\n",
      "|    mean_step_reward   | 0.14192511  |\n",
      "|    n_updates          | 4924        |\n",
      "|    policyGradLoss     | -0.0162     |\n",
      "|    value_loss         | 0.178       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 558         |\n",
      "|    iterations         | 33          |\n",
      "|    time_elapsed       | 483         |\n",
      "|    total_timesteps    | 10100736    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024290826 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0404     |\n",
      "|    mean_step_reward   | 0.1392647   |\n",
      "|    n_updates          | 4928        |\n",
      "|    policyGradLoss     | -0.018      |\n",
      "|    value_loss         | 0.159       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 558         |\n",
      "|    iterations         | 34          |\n",
      "|    time_elapsed       | 498         |\n",
      "|    total_timesteps    | 10108928    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019481031 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0275     |\n",
      "|    mean_step_reward   | 0.13824186  |\n",
      "|    n_updates          | 4932        |\n",
      "|    policyGradLoss     | -0.0138     |\n",
      "|    value_loss         | 0.273       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 558         |\n",
      "|    iterations         | 35          |\n",
      "|    time_elapsed       | 513         |\n",
      "|    total_timesteps    | 10117120    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022969078 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0127     |\n",
      "|    mean_step_reward   | 0.13786194  |\n",
      "|    n_updates          | 4936        |\n",
      "|    policyGradLoss     | -0.0136     |\n",
      "|    value_loss         | 0.301       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 558         |\n",
      "|    iterations         | 36          |\n",
      "|    time_elapsed       | 528         |\n",
      "|    total_timesteps    | 10125312    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016593566 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0803      |\n",
      "|    mean_step_reward   | 0.14330748  |\n",
      "|    n_updates          | 4940        |\n",
      "|    policyGradLoss     | -0.0125     |\n",
      "|    value_loss         | 0.509       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 557        |\n",
      "|    iterations         | 37         |\n",
      "|    time_elapsed       | 543        |\n",
      "|    total_timesteps    | 10133504   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01868045 |\n",
      "|    entropy_loss       | -1.84      |\n",
      "|    explained_variance | 0.969      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | 0.0975     |\n",
      "|    mean_step_reward   | 0.13048615 |\n",
      "|    n_updates          | 4944       |\n",
      "|    policyGradLoss     | -0.0121    |\n",
      "|    value_loss         | 0.388      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 557         |\n",
      "|    iterations         | 38          |\n",
      "|    time_elapsed       | 558         |\n",
      "|    total_timesteps    | 10141696    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017758645 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0252      |\n",
      "|    mean_step_reward   | 0.14488855  |\n",
      "|    n_updates          | 4948        |\n",
      "|    policyGradLoss     | -0.00267    |\n",
      "|    value_loss         | 0.31        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 557        |\n",
      "|    iterations         | 39         |\n",
      "|    time_elapsed       | 573        |\n",
      "|    total_timesteps    | 10149888   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.0220965  |\n",
      "|    entropy_loss       | -1.9       |\n",
      "|    explained_variance | 0.985      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | 0.0805     |\n",
      "|    mean_step_reward   | 0.13826716 |\n",
      "|    n_updates          | 4952       |\n",
      "|    policyGradLoss     | -0.0151    |\n",
      "|    value_loss         | 0.317      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 557        |\n",
      "|    iterations         | 40         |\n",
      "|    time_elapsed       | 588        |\n",
      "|    total_timesteps    | 10158080   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02195586 |\n",
      "|    entropy_loss       | -1.88      |\n",
      "|    explained_variance | 0.972      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | -0.023     |\n",
      "|    mean_step_reward   | 0.13164517 |\n",
      "|    n_updates          | 4956       |\n",
      "|    policyGradLoss     | -0.0139    |\n",
      "|    value_loss         | 0.281      |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/SF84G_PT_31.zip\n",
      "[EVAL] Mean Return: 180.600, Best Return: 180.608\n",
      "Saved video to ./runs_smw/videos/step_10158080_mean_180.60.mp4\n",
      "\n",
      "=== Round 3 | Learn 327680 steps (Total trained: 10158080) ===\n",
      "Logging to ./runs_smw/tb/SF84G_1220_20_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 731      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 11       |\n",
      "|    total_timesteps | 10166272 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 634         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 25          |\n",
      "|    total_timesteps    | 10174464    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022227086 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0215      |\n",
      "|    mean_step_reward   | 0.12181686  |\n",
      "|    n_updates          | 4964        |\n",
      "|    policyGradLoss     | -0.0151     |\n",
      "|    value_loss         | 0.281       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 599         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 40          |\n",
      "|    total_timesteps    | 10182656    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021035738 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0392     |\n",
      "|    mean_step_reward   | 0.1411125   |\n",
      "|    n_updates          | 4968        |\n",
      "|    policyGradLoss     | -0.016      |\n",
      "|    value_loss         | 0.175       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 584         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 56          |\n",
      "|    total_timesteps    | 10190848    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017317066 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.124       |\n",
      "|    mean_step_reward   | 0.1371277   |\n",
      "|    n_updates          | 4972        |\n",
      "|    policyGradLoss     | -0.0109     |\n",
      "|    value_loss         | 0.326       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 575         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 71          |\n",
      "|    total_timesteps    | 10199040    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016753374 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.00379    |\n",
      "|    mean_step_reward   | 0.12630899  |\n",
      "|    n_updates          | 4976        |\n",
      "|    policyGradLoss     | -0.0154     |\n",
      "|    value_loss         | 0.283       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 571          |\n",
      "|    iterations         | 6            |\n",
      "|    time_elapsed       | 86           |\n",
      "|    total_timesteps    | 10207232     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0137472795 |\n",
      "|    entropy_loss       | -1.85        |\n",
      "|    explained_variance | 0.952        |\n",
      "|    learning_rate      | 0.0002       |\n",
      "|    loss               | -0.00529     |\n",
      "|    mean_step_reward   | 0.13902642   |\n",
      "|    n_updates          | 4980         |\n",
      "|    policyGradLoss     | -0.00777     |\n",
      "|    value_loss         | 0.506        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 568         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 100         |\n",
      "|    total_timesteps    | 10215424    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019759126 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.013      |\n",
      "|    mean_step_reward   | 0.1317429   |\n",
      "|    n_updates          | 4984        |\n",
      "|    policyGradLoss     | -0.0151     |\n",
      "|    value_loss         | 0.226       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 567        |\n",
      "|    iterations         | 8          |\n",
      "|    time_elapsed       | 115        |\n",
      "|    total_timesteps    | 10223616   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01916849 |\n",
      "|    entropy_loss       | -1.91      |\n",
      "|    explained_variance | 0.978      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | -0.0156    |\n",
      "|    mean_step_reward   | 0.12589487 |\n",
      "|    n_updates          | 4988       |\n",
      "|    policyGradLoss     | -0.0166    |\n",
      "|    value_loss         | 0.284      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 564         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 130         |\n",
      "|    total_timesteps    | 10231808    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.032049973 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0249      |\n",
      "|    mean_step_reward   | 0.1260483   |\n",
      "|    n_updates          | 4992        |\n",
      "|    policyGradLoss     | -0.0125     |\n",
      "|    value_loss         | 0.225       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 563         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 145         |\n",
      "|    total_timesteps    | 10240000    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015307535 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0905      |\n",
      "|    mean_step_reward   | 0.15707457  |\n",
      "|    n_updates          | 4996        |\n",
      "|    policyGradLoss     | -0.00558    |\n",
      "|    value_loss         | 0.532       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 571        |\n",
      "|    iterations         | 11         |\n",
      "|    time_elapsed       | 157        |\n",
      "|    total_timesteps    | 10248192   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02830229 |\n",
      "|    entropy_loss       | -1.83      |\n",
      "|    explained_variance | 0.989      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | -0.0536    |\n",
      "|    mean_step_reward   | 0.13434605 |\n",
      "|    n_updates          | 5000       |\n",
      "|    policyGradLoss     | -0.018     |\n",
      "|    value_loss         | 0.101      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 573         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 171         |\n",
      "|    total_timesteps    | 10256384    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017972114 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.00677     |\n",
      "|    mean_step_reward   | 0.15340406  |\n",
      "|    n_updates          | 5004        |\n",
      "|    policyGradLoss     | -0.0086     |\n",
      "|    value_loss         | 0.479       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 576         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 184         |\n",
      "|    total_timesteps    | 10264576    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020937134 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0156      |\n",
      "|    mean_step_reward   | 0.122692734 |\n",
      "|    n_updates          | 5008        |\n",
      "|    policyGradLoss     | -0.00976    |\n",
      "|    value_loss         | 0.452       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 578         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 198         |\n",
      "|    total_timesteps    | 10272768    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019440867 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0897      |\n",
      "|    mean_step_reward   | 0.1338921   |\n",
      "|    n_updates          | 5012        |\n",
      "|    policyGradLoss     | -0.0118     |\n",
      "|    value_loss         | 0.479       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 573         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 214         |\n",
      "|    total_timesteps    | 10280960    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019585457 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.103       |\n",
      "|    mean_step_reward   | 0.13428757  |\n",
      "|    n_updates          | 5016        |\n",
      "|    policyGradLoss     | -0.00817    |\n",
      "|    value_loss         | 0.563       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 571         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 229         |\n",
      "|    total_timesteps    | 10289152    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014351112 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.106       |\n",
      "|    mean_step_reward   | 0.13643229  |\n",
      "|    n_updates          | 5020        |\n",
      "|    policyGradLoss     | -0.0106     |\n",
      "|    value_loss         | 0.542       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 570         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 244         |\n",
      "|    total_timesteps    | 10297344    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015947456 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0113     |\n",
      "|    mean_step_reward   | 0.14620915  |\n",
      "|    n_updates          | 5024        |\n",
      "|    policyGradLoss     | -0.0137     |\n",
      "|    value_loss         | 0.243       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 568         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 259         |\n",
      "|    total_timesteps    | 10305536    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014178975 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.941       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.201       |\n",
      "|    mean_step_reward   | 0.12685104  |\n",
      "|    n_updates          | 5028        |\n",
      "|    policyGradLoss     | -0.00543    |\n",
      "|    value_loss         | 0.566       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 567         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 274         |\n",
      "|    total_timesteps    | 10313728    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016388262 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0571      |\n",
      "|    mean_step_reward   | 0.12777525  |\n",
      "|    n_updates          | 5032        |\n",
      "|    policyGradLoss     | -0.0134     |\n",
      "|    value_loss         | 0.411       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 566         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 289         |\n",
      "|    total_timesteps    | 10321920    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021452501 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0946      |\n",
      "|    mean_step_reward   | 0.12753028  |\n",
      "|    n_updates          | 5036        |\n",
      "|    policyGradLoss     | -0.0103     |\n",
      "|    value_loss         | 0.438       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 566         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 303         |\n",
      "|    total_timesteps    | 10330112    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015025765 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0137      |\n",
      "|    mean_step_reward   | 0.13636199  |\n",
      "|    n_updates          | 5040        |\n",
      "|    policyGradLoss     | -0.00972    |\n",
      "|    value_loss         | 0.418       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 565         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 318         |\n",
      "|    total_timesteps    | 10338304    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019397471 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0213     |\n",
      "|    mean_step_reward   | 0.1475873   |\n",
      "|    n_updates          | 5044        |\n",
      "|    policyGradLoss     | -0.0152     |\n",
      "|    value_loss         | 0.15        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 564         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 333         |\n",
      "|    total_timesteps    | 10346496    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017253313 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.016      |\n",
      "|    mean_step_reward   | 0.13263077  |\n",
      "|    n_updates          | 5048        |\n",
      "|    policyGradLoss     | -0.00938    |\n",
      "|    value_loss         | 0.26        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 563         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 348         |\n",
      "|    total_timesteps    | 10354688    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018484423 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0136      |\n",
      "|    mean_step_reward   | 0.14076993  |\n",
      "|    n_updates          | 5052        |\n",
      "|    policyGradLoss     | -0.0105     |\n",
      "|    value_loss         | 0.424       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 563         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 363         |\n",
      "|    total_timesteps    | 10362880    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015116724 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0776      |\n",
      "|    mean_step_reward   | 0.13523374  |\n",
      "|    n_updates          | 5056        |\n",
      "|    policyGradLoss     | -0.00962    |\n",
      "|    value_loss         | 0.433       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 562         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 378         |\n",
      "|    total_timesteps    | 10371072    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021998078 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0215     |\n",
      "|    mean_step_reward   | 0.14355719  |\n",
      "|    n_updates          | 5060        |\n",
      "|    policyGradLoss     | -0.014      |\n",
      "|    value_loss         | 0.131       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 562         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 393         |\n",
      "|    total_timesteps    | 10379264    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022631621 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0317     |\n",
      "|    mean_step_reward   | 0.14706568  |\n",
      "|    n_updates          | 5064        |\n",
      "|    policyGradLoss     | -0.0162     |\n",
      "|    value_loss         | 0.162       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 561         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 408         |\n",
      "|    total_timesteps    | 10387456    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021119785 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0069     |\n",
      "|    mean_step_reward   | 0.13457888  |\n",
      "|    n_updates          | 5068        |\n",
      "|    policyGradLoss     | -0.0119     |\n",
      "|    value_loss         | 0.344       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 561         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 423         |\n",
      "|    total_timesteps    | 10395648    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019798364 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0126     |\n",
      "|    mean_step_reward   | 0.14854743  |\n",
      "|    n_updates          | 5072        |\n",
      "|    policyGradLoss     | -0.0142     |\n",
      "|    value_loss         | 0.236       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 560         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 438         |\n",
      "|    total_timesteps    | 10403840    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019218072 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.00393     |\n",
      "|    mean_step_reward   | 0.14132866  |\n",
      "|    n_updates          | 5076        |\n",
      "|    policyGradLoss     | -0.0131     |\n",
      "|    value_loss         | 0.332       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 561        |\n",
      "|    iterations         | 31         |\n",
      "|    time_elapsed       | 452        |\n",
      "|    total_timesteps    | 10412032   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01706823 |\n",
      "|    entropy_loss       | -1.77      |\n",
      "|    explained_variance | 0.964      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | 0.0156     |\n",
      "|    mean_step_reward   | 0.13391113 |\n",
      "|    n_updates          | 5080       |\n",
      "|    policyGradLoss     | -0.00756   |\n",
      "|    value_loss         | 0.2        |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 560         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 467         |\n",
      "|    total_timesteps    | 10420224    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012661448 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.948       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0965      |\n",
      "|    mean_step_reward   | 0.1461209   |\n",
      "|    n_updates          | 5084        |\n",
      "|    policyGradLoss     | -0.00521    |\n",
      "|    value_loss         | 0.826       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 560        |\n",
      "|    iterations         | 33         |\n",
      "|    time_elapsed       | 482        |\n",
      "|    total_timesteps    | 10428416   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02250877 |\n",
      "|    entropy_loss       | -1.8       |\n",
      "|    explained_variance | 0.973      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | 0.00194    |\n",
      "|    mean_step_reward   | 0.12609014 |\n",
      "|    n_updates          | 5088       |\n",
      "|    policyGradLoss     | -0.014     |\n",
      "|    value_loss         | 0.21       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 559         |\n",
      "|    iterations         | 34          |\n",
      "|    time_elapsed       | 497         |\n",
      "|    total_timesteps    | 10436608    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014918303 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0186     |\n",
      "|    mean_step_reward   | 0.1440136   |\n",
      "|    n_updates          | 5092        |\n",
      "|    policyGradLoss     | -0.00932    |\n",
      "|    value_loss         | 0.22        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 559         |\n",
      "|    iterations         | 35          |\n",
      "|    time_elapsed       | 512         |\n",
      "|    total_timesteps    | 10444800    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017415477 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.00994    |\n",
      "|    mean_step_reward   | 0.1448502   |\n",
      "|    n_updates          | 5096        |\n",
      "|    policyGradLoss     | -0.00944    |\n",
      "|    value_loss         | 0.32        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 559         |\n",
      "|    iterations         | 36          |\n",
      "|    time_elapsed       | 527         |\n",
      "|    total_timesteps    | 10452992    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016936067 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.954       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0765      |\n",
      "|    mean_step_reward   | 0.12782799  |\n",
      "|    n_updates          | 5100        |\n",
      "|    policyGradLoss     | -0.0112     |\n",
      "|    value_loss         | 0.51        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 559         |\n",
      "|    iterations         | 37          |\n",
      "|    time_elapsed       | 541         |\n",
      "|    total_timesteps    | 10461184    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021484323 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0226     |\n",
      "|    mean_step_reward   | 0.13495484  |\n",
      "|    n_updates          | 5104        |\n",
      "|    policyGradLoss     | -0.0161     |\n",
      "|    value_loss         | 0.221       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 559         |\n",
      "|    iterations         | 38          |\n",
      "|    time_elapsed       | 556         |\n",
      "|    total_timesteps    | 10469376    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024089986 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0329     |\n",
      "|    mean_step_reward   | 0.14635849  |\n",
      "|    n_updates          | 5108        |\n",
      "|    policyGradLoss     | -0.0167     |\n",
      "|    value_loss         | 0.163       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 558         |\n",
      "|    iterations         | 39          |\n",
      "|    time_elapsed       | 571         |\n",
      "|    total_timesteps    | 10477568    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016074661 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.038      |\n",
      "|    mean_step_reward   | 0.14484113  |\n",
      "|    n_updates          | 5112        |\n",
      "|    policyGradLoss     | -0.0131     |\n",
      "|    value_loss         | 0.139       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 558         |\n",
      "|    iterations         | 40          |\n",
      "|    time_elapsed       | 586         |\n",
      "|    total_timesteps    | 10485760    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022464387 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.00861    |\n",
      "|    mean_step_reward   | 0.13685763  |\n",
      "|    n_updates          | 5116        |\n",
      "|    policyGradLoss     | -0.0127     |\n",
      "|    value_loss         | 0.204       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/SF84G_PT_32.zip\n",
      "[EVAL] Mean Return: 185.040, Best Return: 185.048\n",
      "New best record. Saved to ./runs_smw/best_model_A.zip\n",
      "Saved video to ./runs_smw/videos/step_10485760_mean_185.04.mp4\n",
      "\n",
      "=== Round 4 | Learn 327680 steps (Total trained: 10485760) ===\n",
      "Logging to ./runs_smw/tb/SF84G_1220_20_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 721      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 11       |\n",
      "|    total_timesteps | 10493952 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 627         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 26          |\n",
      "|    total_timesteps    | 10502144    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018910073 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0235     |\n",
      "|    mean_step_reward   | 0.14320734  |\n",
      "|    n_updates          | 5124        |\n",
      "|    policyGradLoss     | -0.0128     |\n",
      "|    value_loss         | 0.17        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 600         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 40          |\n",
      "|    total_timesteps    | 10510336    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015979731 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.00728     |\n",
      "|    mean_step_reward   | 0.14993191  |\n",
      "|    n_updates          | 5128        |\n",
      "|    policyGradLoss     | -0.0133     |\n",
      "|    value_loss         | 0.192       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 583         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 56          |\n",
      "|    total_timesteps    | 10518528    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018736497 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0101      |\n",
      "|    mean_step_reward   | 0.13828576  |\n",
      "|    n_updates          | 5132        |\n",
      "|    policyGradLoss     | -0.0101     |\n",
      "|    value_loss         | 0.386       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 578         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 70          |\n",
      "|    total_timesteps    | 10526720    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015646182 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0828      |\n",
      "|    mean_step_reward   | 0.13929194  |\n",
      "|    n_updates          | 5136        |\n",
      "|    policyGradLoss     | -0.00865    |\n",
      "|    value_loss         | 0.428       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 572         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 85          |\n",
      "|    total_timesteps    | 10534912    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023552548 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.019      |\n",
      "|    mean_step_reward   | 0.13601202  |\n",
      "|    n_updates          | 5140        |\n",
      "|    policyGradLoss     | -0.0141     |\n",
      "|    value_loss         | 0.277       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 570        |\n",
      "|    iterations         | 7          |\n",
      "|    time_elapsed       | 100        |\n",
      "|    total_timesteps    | 10543104   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.0233959  |\n",
      "|    entropy_loss       | -1.86      |\n",
      "|    explained_variance | 0.996      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | -0.0426    |\n",
      "|    mean_step_reward   | 0.15562013 |\n",
      "|    n_updates          | 5144       |\n",
      "|    policyGradLoss     | -0.0181    |\n",
      "|    value_loss         | 0.121      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 566         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 115         |\n",
      "|    total_timesteps    | 10551296    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020812828 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.00569    |\n",
      "|    mean_step_reward   | 0.14690962  |\n",
      "|    n_updates          | 5148        |\n",
      "|    policyGradLoss     | -0.00904    |\n",
      "|    value_loss         | 0.327       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 565         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 130         |\n",
      "|    total_timesteps    | 10559488    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019147329 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0213     |\n",
      "|    mean_step_reward   | 0.14672218  |\n",
      "|    n_updates          | 5152        |\n",
      "|    policyGradLoss     | -0.0155     |\n",
      "|    value_loss         | 0.213       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 564         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 145         |\n",
      "|    total_timesteps    | 10567680    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020419106 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.958       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0426      |\n",
      "|    mean_step_reward   | 0.12493493  |\n",
      "|    n_updates          | 5156        |\n",
      "|    policyGradLoss     | -0.0106     |\n",
      "|    value_loss         | 0.443       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 563         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 160         |\n",
      "|    total_timesteps    | 10575872    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020808972 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.00447     |\n",
      "|    mean_step_reward   | 0.13821578  |\n",
      "|    n_updates          | 5160        |\n",
      "|    policyGradLoss     | -0.0126     |\n",
      "|    value_loss         | 0.268       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 562        |\n",
      "|    iterations         | 12         |\n",
      "|    time_elapsed       | 174        |\n",
      "|    total_timesteps    | 10584064   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01604402 |\n",
      "|    entropy_loss       | -1.83      |\n",
      "|    explained_variance | 0.972      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | 0.00797    |\n",
      "|    mean_step_reward   | 0.1419594  |\n",
      "|    n_updates          | 5164       |\n",
      "|    policyGradLoss     | -0.00964   |\n",
      "|    value_loss         | 0.391      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 561         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 189         |\n",
      "|    total_timesteps    | 10592256    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019579373 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.00696    |\n",
      "|    mean_step_reward   | 0.13755056  |\n",
      "|    n_updates          | 5168        |\n",
      "|    policyGradLoss     | -0.0115     |\n",
      "|    value_loss         | 0.207       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 560         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 204         |\n",
      "|    total_timesteps    | 10600448    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022353187 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.116       |\n",
      "|    mean_step_reward   | 0.14228791  |\n",
      "|    n_updates          | 5172        |\n",
      "|    policyGradLoss     | -0.00768    |\n",
      "|    value_loss         | 0.626       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 559         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 219         |\n",
      "|    total_timesteps    | 10608640    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017577088 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0281     |\n",
      "|    mean_step_reward   | 0.1388168   |\n",
      "|    n_updates          | 5176        |\n",
      "|    policyGradLoss     | -0.0118     |\n",
      "|    value_loss         | 0.288       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 558         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 234         |\n",
      "|    total_timesteps    | 10616832    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018624421 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.00528    |\n",
      "|    mean_step_reward   | 0.1506751   |\n",
      "|    n_updates          | 5180        |\n",
      "|    policyGradLoss     | -0.0122     |\n",
      "|    value_loss         | 0.315       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 557         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 249         |\n",
      "|    total_timesteps    | 10625024    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021026336 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0457      |\n",
      "|    mean_step_reward   | 0.13910304  |\n",
      "|    n_updates          | 5184        |\n",
      "|    policyGradLoss     | -0.0103     |\n",
      "|    value_loss         | 0.366       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 557         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 264         |\n",
      "|    total_timesteps    | 10633216    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019983117 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.097       |\n",
      "|    mean_step_reward   | 0.14284205  |\n",
      "|    n_updates          | 5188        |\n",
      "|    policyGradLoss     | -0.00908    |\n",
      "|    value_loss         | 0.461       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 556        |\n",
      "|    iterations         | 19         |\n",
      "|    time_elapsed       | 279        |\n",
      "|    total_timesteps    | 10641408   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01890288 |\n",
      "|    entropy_loss       | -1.85      |\n",
      "|    explained_variance | 0.971      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | 0.126      |\n",
      "|    mean_step_reward   | 0.14347672 |\n",
      "|    n_updates          | 5192       |\n",
      "|    policyGradLoss     | -0.00694   |\n",
      "|    value_loss         | 0.581      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 556         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 294         |\n",
      "|    total_timesteps    | 10649600    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024054576 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.958       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0167     |\n",
      "|    mean_step_reward   | 0.12475812  |\n",
      "|    n_updates          | 5196        |\n",
      "|    policyGradLoss     | -0.00763    |\n",
      "|    value_loss         | 0.325       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 555         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 309         |\n",
      "|    total_timesteps    | 10657792    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020742778 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.993       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0276     |\n",
      "|    mean_step_reward   | 0.15522642  |\n",
      "|    n_updates          | 5200        |\n",
      "|    policyGradLoss     | -0.013      |\n",
      "|    value_loss         | 0.153       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 554         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 324         |\n",
      "|    total_timesteps    | 10665984    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023742627 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0115      |\n",
      "|    mean_step_reward   | 0.1327613   |\n",
      "|    n_updates          | 5204        |\n",
      "|    policyGradLoss     | -0.0122     |\n",
      "|    value_loss         | 0.259       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 554         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 339         |\n",
      "|    total_timesteps    | 10674176    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017346408 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.00584     |\n",
      "|    mean_step_reward   | 0.1408281   |\n",
      "|    n_updates          | 5208        |\n",
      "|    policyGradLoss     | -0.00856    |\n",
      "|    value_loss         | 0.444       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 553        |\n",
      "|    iterations         | 24         |\n",
      "|    time_elapsed       | 354        |\n",
      "|    total_timesteps    | 10682368   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01833816 |\n",
      "|    entropy_loss       | -1.87      |\n",
      "|    explained_variance | 0.969      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | 0.19       |\n",
      "|    mean_step_reward   | 0.14149499 |\n",
      "|    n_updates          | 5212       |\n",
      "|    policyGradLoss     | -0.0073    |\n",
      "|    value_loss         | 0.799      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 553         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 370         |\n",
      "|    total_timesteps    | 10690560    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023709044 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.214       |\n",
      "|    mean_step_reward   | 0.13042638  |\n",
      "|    n_updates          | 5216        |\n",
      "|    policyGradLoss     | -0.0057     |\n",
      "|    value_loss         | 0.584       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 553        |\n",
      "|    iterations         | 26         |\n",
      "|    time_elapsed       | 384        |\n",
      "|    total_timesteps    | 10698752   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02498025 |\n",
      "|    entropy_loss       | -1.83      |\n",
      "|    explained_variance | 0.986      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | 0.113      |\n",
      "|    mean_step_reward   | 0.14850378 |\n",
      "|    n_updates          | 5220       |\n",
      "|    policyGradLoss     | -0.0119    |\n",
      "|    value_loss         | 0.31       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 555         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 398         |\n",
      "|    total_timesteps    | 10706944    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017863233 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0192      |\n",
      "|    mean_step_reward   | 0.1308673   |\n",
      "|    n_updates          | 5224        |\n",
      "|    policyGradLoss     | -0.0143     |\n",
      "|    value_loss         | 0.294       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 557        |\n",
      "|    iterations         | 28         |\n",
      "|    time_elapsed       | 411        |\n",
      "|    total_timesteps    | 10715136   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01796889 |\n",
      "|    entropy_loss       | -1.82      |\n",
      "|    explained_variance | 0.985      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | 0.0396     |\n",
      "|    mean_step_reward   | 0.13718551 |\n",
      "|    n_updates          | 5228       |\n",
      "|    policyGradLoss     | -0.0155    |\n",
      "|    value_loss         | 0.306      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 558        |\n",
      "|    iterations         | 29         |\n",
      "|    time_elapsed       | 425        |\n",
      "|    total_timesteps    | 10723328   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01763276 |\n",
      "|    entropy_loss       | -1.88      |\n",
      "|    explained_variance | 0.987      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | 0.0914     |\n",
      "|    mean_step_reward   | 0.14637658 |\n",
      "|    n_updates          | 5232       |\n",
      "|    policyGradLoss     | -0.0124    |\n",
      "|    value_loss         | 0.298      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 558         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 439         |\n",
      "|    total_timesteps    | 10731520    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022250578 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0232     |\n",
      "|    mean_step_reward   | 0.1289713   |\n",
      "|    n_updates          | 5236        |\n",
      "|    policyGradLoss     | -0.0107     |\n",
      "|    value_loss         | 0.22        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 558         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 454         |\n",
      "|    total_timesteps    | 10739712    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014235302 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.000407    |\n",
      "|    mean_step_reward   | 0.1517172   |\n",
      "|    n_updates          | 5240        |\n",
      "|    policyGradLoss     | -0.00635    |\n",
      "|    value_loss         | 0.291       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 557         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 469         |\n",
      "|    total_timesteps    | 10747904    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017237112 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0271     |\n",
      "|    mean_step_reward   | 0.12655553  |\n",
      "|    n_updates          | 5244        |\n",
      "|    policyGradLoss     | -0.0136     |\n",
      "|    value_loss         | 0.213       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 557         |\n",
      "|    iterations         | 33          |\n",
      "|    time_elapsed       | 485         |\n",
      "|    total_timesteps    | 10756096    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017964508 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.00865    |\n",
      "|    mean_step_reward   | 0.14128746  |\n",
      "|    n_updates          | 5248        |\n",
      "|    policyGradLoss     | -0.0116     |\n",
      "|    value_loss         | 0.237       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 556         |\n",
      "|    iterations         | 34          |\n",
      "|    time_elapsed       | 500         |\n",
      "|    total_timesteps    | 10764288    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027358536 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0405     |\n",
      "|    mean_step_reward   | 0.14784238  |\n",
      "|    n_updates          | 5252        |\n",
      "|    policyGradLoss     | -0.0127     |\n",
      "|    value_loss         | 0.141       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 556         |\n",
      "|    iterations         | 35          |\n",
      "|    time_elapsed       | 515         |\n",
      "|    total_timesteps    | 10772480    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.033736385 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0982      |\n",
      "|    mean_step_reward   | 0.14219259  |\n",
      "|    n_updates          | 5256        |\n",
      "|    policyGradLoss     | -0.0155     |\n",
      "|    value_loss         | 0.239       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 556         |\n",
      "|    iterations         | 36          |\n",
      "|    time_elapsed       | 530         |\n",
      "|    total_timesteps    | 10780672    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020507626 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.994       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0243     |\n",
      "|    mean_step_reward   | 0.1601487   |\n",
      "|    n_updates          | 5260        |\n",
      "|    policyGradLoss     | -0.0137     |\n",
      "|    value_loss         | 0.147       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 555         |\n",
      "|    iterations         | 37          |\n",
      "|    time_elapsed       | 545         |\n",
      "|    total_timesteps    | 10788864    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025416547 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0209     |\n",
      "|    mean_step_reward   | 0.13375899  |\n",
      "|    n_updates          | 5264        |\n",
      "|    policyGradLoss     | -0.00908    |\n",
      "|    value_loss         | 0.346       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 555         |\n",
      "|    iterations         | 38          |\n",
      "|    time_elapsed       | 560         |\n",
      "|    total_timesteps    | 10797056    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018056322 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.000327    |\n",
      "|    mean_step_reward   | 0.15345055  |\n",
      "|    n_updates          | 5268        |\n",
      "|    policyGradLoss     | -0.01       |\n",
      "|    value_loss         | 0.259       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 555         |\n",
      "|    iterations         | 39          |\n",
      "|    time_elapsed       | 575         |\n",
      "|    total_timesteps    | 10805248    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026230603 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0671      |\n",
      "|    mean_step_reward   | 0.13683741  |\n",
      "|    n_updates          | 5272        |\n",
      "|    policyGradLoss     | -0.0124     |\n",
      "|    value_loss         | 0.279       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 555        |\n",
      "|    iterations         | 40         |\n",
      "|    time_elapsed       | 589        |\n",
      "|    total_timesteps    | 10813440   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02830189 |\n",
      "|    entropy_loss       | -1.76      |\n",
      "|    explained_variance | 0.981      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | -0.0216    |\n",
      "|    mean_step_reward   | 0.13654923 |\n",
      "|    n_updates          | 5276       |\n",
      "|    policyGradLoss     | -0.0112    |\n",
      "|    value_loss         | 0.237      |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/SF84G_PT_33.zip\n",
      "[EVAL] Mean Return: 184.820, Best Return: 184.828\n",
      "Saved video to ./runs_smw/videos/step_10813440_mean_184.82.mp4\n",
      "\n",
      "=== Round 5 | Learn 327680 steps (Total trained: 10813440) ===\n",
      "Logging to ./runs_smw/tb/SF84G_1220_20_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 731      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 11       |\n",
      "|    total_timesteps | 10821632 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 632         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 25          |\n",
      "|    total_timesteps    | 10829824    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016876098 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0947      |\n",
      "|    mean_step_reward   | 0.13686031  |\n",
      "|    n_updates          | 5284        |\n",
      "|    policyGradLoss     | -0.00912    |\n",
      "|    value_loss         | 0.464       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 602         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 40          |\n",
      "|    total_timesteps    | 10838016    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024511546 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0441     |\n",
      "|    mean_step_reward   | 0.13834259  |\n",
      "|    n_updates          | 5288        |\n",
      "|    policyGradLoss     | -0.0149     |\n",
      "|    value_loss         | 0.126       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 590         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 55          |\n",
      "|    total_timesteps    | 10846208    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017079279 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0384      |\n",
      "|    mean_step_reward   | 0.13926564  |\n",
      "|    n_updates          | 5292        |\n",
      "|    policyGradLoss     | -0.00826    |\n",
      "|    value_loss         | 0.325       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 583         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 70          |\n",
      "|    total_timesteps    | 10854400    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017471153 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.00938    |\n",
      "|    mean_step_reward   | 0.13499019  |\n",
      "|    n_updates          | 5296        |\n",
      "|    policyGradLoss     | -0.0116     |\n",
      "|    value_loss         | 0.276       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 574         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 85          |\n",
      "|    total_timesteps    | 10862592    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017679725 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0377     |\n",
      "|    mean_step_reward   | 0.14514434  |\n",
      "|    n_updates          | 5300        |\n",
      "|    policyGradLoss     | -0.0124     |\n",
      "|    value_loss         | 0.202       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 568         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 100         |\n",
      "|    total_timesteps    | 10870784    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016498975 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0342     |\n",
      "|    mean_step_reward   | 0.14299811  |\n",
      "|    n_updates          | 5304        |\n",
      "|    policyGradLoss     | -0.0104     |\n",
      "|    value_loss         | 0.222       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 565        |\n",
      "|    iterations         | 8          |\n",
      "|    time_elapsed       | 115        |\n",
      "|    total_timesteps    | 10878976   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02368116 |\n",
      "|    entropy_loss       | -1.79      |\n",
      "|    explained_variance | 0.984      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | -0.00865   |\n",
      "|    mean_step_reward   | 0.15086609 |\n",
      "|    n_updates          | 5308       |\n",
      "|    policyGradLoss     | -0.013     |\n",
      "|    value_loss         | 0.3        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 562        |\n",
      "|    iterations         | 9          |\n",
      "|    time_elapsed       | 130        |\n",
      "|    total_timesteps    | 10887168   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01105411 |\n",
      "|    entropy_loss       | -1.82      |\n",
      "|    explained_variance | 0.946      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | 0.06       |\n",
      "|    mean_step_reward   | 0.13787007 |\n",
      "|    n_updates          | 5312       |\n",
      "|    policyGradLoss     | -0.00588   |\n",
      "|    value_loss         | 0.546      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 561         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 145         |\n",
      "|    total_timesteps    | 10895360    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017170448 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0257     |\n",
      "|    mean_step_reward   | 0.13558438  |\n",
      "|    n_updates          | 5316        |\n",
      "|    policyGradLoss     | -0.0145     |\n",
      "|    value_loss         | 0.174       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 558         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 161         |\n",
      "|    total_timesteps    | 10903552    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024421081 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0207     |\n",
      "|    mean_step_reward   | 0.15543766  |\n",
      "|    n_updates          | 5320        |\n",
      "|    policyGradLoss     | -0.00875    |\n",
      "|    value_loss         | 0.311       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 557         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 176         |\n",
      "|    total_timesteps    | 10911744    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026881844 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0734      |\n",
      "|    mean_step_reward   | 0.14336222  |\n",
      "|    n_updates          | 5324        |\n",
      "|    policyGradLoss     | -0.0135     |\n",
      "|    value_loss         | 0.371       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 565         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 188         |\n",
      "|    total_timesteps    | 10919936    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027463077 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0175     |\n",
      "|    mean_step_reward   | 0.1480674   |\n",
      "|    n_updates          | 5328        |\n",
      "|    policyGradLoss     | -0.0142     |\n",
      "|    value_loss         | 0.152       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 568        |\n",
      "|    iterations         | 14         |\n",
      "|    time_elapsed       | 201        |\n",
      "|    total_timesteps    | 10928128   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02934093 |\n",
      "|    entropy_loss       | -1.79      |\n",
      "|    explained_variance | 0.977      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | -0.0132    |\n",
      "|    mean_step_reward   | 0.1349279  |\n",
      "|    n_updates          | 5332       |\n",
      "|    policyGradLoss     | -0.0122    |\n",
      "|    value_loss         | 0.243      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 570         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 215         |\n",
      "|    total_timesteps    | 10936320    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018786479 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.12        |\n",
      "|    mean_step_reward   | 0.14683428  |\n",
      "|    n_updates          | 5336        |\n",
      "|    policyGradLoss     | -0.00813    |\n",
      "|    value_loss         | 0.466       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 572         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 229         |\n",
      "|    total_timesteps    | 10944512    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018682875 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0107      |\n",
      "|    mean_step_reward   | 0.13510494  |\n",
      "|    n_updates          | 5340        |\n",
      "|    policyGradLoss     | -0.00766    |\n",
      "|    value_loss         | 0.448       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 569         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 244         |\n",
      "|    total_timesteps    | 10952704    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022519026 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0116      |\n",
      "|    mean_step_reward   | 0.13374493  |\n",
      "|    n_updates          | 5344        |\n",
      "|    policyGradLoss     | -0.0121     |\n",
      "|    value_loss         | 0.357       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 568         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 259         |\n",
      "|    total_timesteps    | 10960896    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021064814 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.046       |\n",
      "|    mean_step_reward   | 0.15442696  |\n",
      "|    n_updates          | 5348        |\n",
      "|    policyGradLoss     | -0.00876    |\n",
      "|    value_loss         | 0.435       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 568        |\n",
      "|    iterations         | 19         |\n",
      "|    time_elapsed       | 273        |\n",
      "|    total_timesteps    | 10969088   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01868838 |\n",
      "|    entropy_loss       | -1.77      |\n",
      "|    explained_variance | 0.983      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | 0.0333     |\n",
      "|    mean_step_reward   | 0.13978614 |\n",
      "|    n_updates          | 5352       |\n",
      "|    policyGradLoss     | -0.0102    |\n",
      "|    value_loss         | 0.316      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 567        |\n",
      "|    iterations         | 20         |\n",
      "|    time_elapsed       | 288        |\n",
      "|    total_timesteps    | 10977280   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01584297 |\n",
      "|    entropy_loss       | -1.82      |\n",
      "|    explained_variance | 0.991      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | -0.0241    |\n",
      "|    mean_step_reward   | 0.154059   |\n",
      "|    n_updates          | 5356       |\n",
      "|    policyGradLoss     | -0.0112    |\n",
      "|    value_loss         | 0.168      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 565         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 304         |\n",
      "|    total_timesteps    | 10985472    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021845499 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0053     |\n",
      "|    mean_step_reward   | 0.13820484  |\n",
      "|    n_updates          | 5360        |\n",
      "|    policyGradLoss     | -0.0117     |\n",
      "|    value_loss         | 0.214       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 565        |\n",
      "|    iterations         | 22         |\n",
      "|    time_elapsed       | 318        |\n",
      "|    total_timesteps    | 10993664   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01710655 |\n",
      "|    entropy_loss       | -1.8       |\n",
      "|    explained_variance | 0.973      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | 0.00779    |\n",
      "|    mean_step_reward   | 0.13237277 |\n",
      "|    n_updates          | 5364       |\n",
      "|    policyGradLoss     | -0.00842   |\n",
      "|    value_loss         | 0.339      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 564         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 333         |\n",
      "|    total_timesteps    | 11001856    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021020077 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.00912     |\n",
      "|    mean_step_reward   | 0.13980508  |\n",
      "|    n_updates          | 5368        |\n",
      "|    policyGradLoss     | -0.00786    |\n",
      "|    value_loss         | 0.363       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 564         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 348         |\n",
      "|    total_timesteps    | 11010048    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026902769 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0116      |\n",
      "|    mean_step_reward   | 0.13495979  |\n",
      "|    n_updates          | 5372        |\n",
      "|    policyGradLoss     | -0.0118     |\n",
      "|    value_loss         | 0.289       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 563         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 363         |\n",
      "|    total_timesteps    | 11018240    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015824137 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0666      |\n",
      "|    mean_step_reward   | 0.13212237  |\n",
      "|    n_updates          | 5376        |\n",
      "|    policyGradLoss     | -0.0121     |\n",
      "|    value_loss         | 0.632       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 562        |\n",
      "|    iterations         | 26         |\n",
      "|    time_elapsed       | 378        |\n",
      "|    total_timesteps    | 11026432   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.0162553  |\n",
      "|    entropy_loss       | -1.84      |\n",
      "|    explained_variance | 0.968      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | -0.0231    |\n",
      "|    mean_step_reward   | 0.12877482 |\n",
      "|    n_updates          | 5380       |\n",
      "|    policyGradLoss     | -0.0131    |\n",
      "|    value_loss         | 0.283      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 562        |\n",
      "|    iterations         | 27         |\n",
      "|    time_elapsed       | 393        |\n",
      "|    total_timesteps    | 11034624   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01831134 |\n",
      "|    entropy_loss       | -1.88      |\n",
      "|    explained_variance | 0.977      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | 0.0396     |\n",
      "|    mean_step_reward   | 0.1355918  |\n",
      "|    n_updates          | 5384       |\n",
      "|    policyGradLoss     | -0.0122    |\n",
      "|    value_loss         | 0.41       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 561        |\n",
      "|    iterations         | 28         |\n",
      "|    time_elapsed       | 408        |\n",
      "|    total_timesteps    | 11042816   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02164672 |\n",
      "|    entropy_loss       | -1.87      |\n",
      "|    explained_variance | 0.973      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | 0.0501     |\n",
      "|    mean_step_reward   | 0.13185026 |\n",
      "|    n_updates          | 5388       |\n",
      "|    policyGradLoss     | -0.0129    |\n",
      "|    value_loss         | 0.325      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 561         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 423         |\n",
      "|    total_timesteps    | 11051008    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025547192 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.00129     |\n",
      "|    mean_step_reward   | 0.13624758  |\n",
      "|    n_updates          | 5392        |\n",
      "|    policyGradLoss     | -0.0158     |\n",
      "|    value_loss         | 0.288       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 561        |\n",
      "|    iterations         | 30         |\n",
      "|    time_elapsed       | 437        |\n",
      "|    total_timesteps    | 11059200   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02665237 |\n",
      "|    entropy_loss       | -1.85      |\n",
      "|    explained_variance | 0.985      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | -0.019     |\n",
      "|    mean_step_reward   | 0.1393925  |\n",
      "|    n_updates          | 5396       |\n",
      "|    policyGradLoss     | -0.0144    |\n",
      "|    value_loss         | 0.246      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 561        |\n",
      "|    iterations         | 31         |\n",
      "|    time_elapsed       | 452        |\n",
      "|    total_timesteps    | 11067392   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02207174 |\n",
      "|    entropy_loss       | -1.82      |\n",
      "|    explained_variance | 0.982      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | 0.0971     |\n",
      "|    mean_step_reward   | 0.13585821 |\n",
      "|    n_updates          | 5400       |\n",
      "|    policyGradLoss     | -0.0149    |\n",
      "|    value_loss         | 0.289      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 560         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 467         |\n",
      "|    total_timesteps    | 11075584    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016693728 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.00193     |\n",
      "|    mean_step_reward   | 0.14665776  |\n",
      "|    n_updates          | 5404        |\n",
      "|    policyGradLoss     | -0.0123     |\n",
      "|    value_loss         | 0.207       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 560         |\n",
      "|    iterations         | 33          |\n",
      "|    time_elapsed       | 482         |\n",
      "|    total_timesteps    | 11083776    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020522311 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.202       |\n",
      "|    mean_step_reward   | 0.14788038  |\n",
      "|    n_updates          | 5408        |\n",
      "|    policyGradLoss     | -0.0085     |\n",
      "|    value_loss         | 0.394       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 560        |\n",
      "|    iterations         | 34         |\n",
      "|    time_elapsed       | 497        |\n",
      "|    total_timesteps    | 11091968   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02004152 |\n",
      "|    entropy_loss       | -1.82      |\n",
      "|    explained_variance | 0.974      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | 0.00266    |\n",
      "|    mean_step_reward   | 0.14018653 |\n",
      "|    n_updates          | 5412       |\n",
      "|    policyGradLoss     | -0.0111    |\n",
      "|    value_loss         | 0.421      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 560         |\n",
      "|    iterations         | 35          |\n",
      "|    time_elapsed       | 511         |\n",
      "|    total_timesteps    | 11100160    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020074043 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0126     |\n",
      "|    mean_step_reward   | 0.15016109  |\n",
      "|    n_updates          | 5416        |\n",
      "|    policyGradLoss     | -0.00706    |\n",
      "|    value_loss         | 0.189       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 559         |\n",
      "|    iterations         | 36          |\n",
      "|    time_elapsed       | 526         |\n",
      "|    total_timesteps    | 11108352    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018894482 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0133     |\n",
      "|    mean_step_reward   | 0.13743821  |\n",
      "|    n_updates          | 5420        |\n",
      "|    policyGradLoss     | -0.0123     |\n",
      "|    value_loss         | 0.259       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 559         |\n",
      "|    iterations         | 37          |\n",
      "|    time_elapsed       | 541         |\n",
      "|    total_timesteps    | 11116544    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018923324 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.941       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0346      |\n",
      "|    mean_step_reward   | 0.12960128  |\n",
      "|    n_updates          | 5424        |\n",
      "|    policyGradLoss     | -0.00404    |\n",
      "|    value_loss         | 0.6         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 559         |\n",
      "|    iterations         | 38          |\n",
      "|    time_elapsed       | 556         |\n",
      "|    total_timesteps    | 11124736    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020648409 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.114       |\n",
      "|    mean_step_reward   | 0.13538483  |\n",
      "|    n_updates          | 5428        |\n",
      "|    policyGradLoss     | -0.0142     |\n",
      "|    value_loss         | 0.414       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 559         |\n",
      "|    iterations         | 39          |\n",
      "|    time_elapsed       | 570         |\n",
      "|    total_timesteps    | 11132928    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019210532 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.016       |\n",
      "|    mean_step_reward   | 0.15320694  |\n",
      "|    n_updates          | 5432        |\n",
      "|    policyGradLoss     | -0.0127     |\n",
      "|    value_loss         | 0.32        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 559         |\n",
      "|    iterations         | 40          |\n",
      "|    time_elapsed       | 585         |\n",
      "|    total_timesteps    | 11141120    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024910899 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.00949     |\n",
      "|    mean_step_reward   | 0.12853302  |\n",
      "|    n_updates          | 5436        |\n",
      "|    policyGradLoss     | -0.0111     |\n",
      "|    value_loss         | 0.354       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/SF84G_PT_34.zip\n",
      "[EVAL] Mean Return: 185.590, Best Return: 185.598\n",
      "New best record. Saved to ./runs_smw/best_model_A.zip\n",
      "Saved video to ./runs_smw/videos/step_11141120_mean_185.59.mp4\n",
      "\n",
      "=== Round 6 | Learn 327680 steps (Total trained: 11141120) ===\n",
      "Logging to ./runs_smw/tb/SF84G_1220_20_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1003     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 8        |\n",
      "|    total_timesteps | 11149312 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 750         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 21          |\n",
      "|    total_timesteps    | 11157504    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026751881 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0443     |\n",
      "|    mean_step_reward   | 0.13484591  |\n",
      "|    n_updates          | 5444        |\n",
      "|    policyGradLoss     | -0.0186     |\n",
      "|    value_loss         | 0.198       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 692         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 35          |\n",
      "|    total_timesteps    | 11165696    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018960588 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0294     |\n",
      "|    mean_step_reward   | 0.13385084  |\n",
      "|    n_updates          | 5448        |\n",
      "|    policyGradLoss     | -0.0123     |\n",
      "|    value_loss         | 0.233       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 683         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 47          |\n",
      "|    total_timesteps    | 11173888    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015845595 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.119       |\n",
      "|    mean_step_reward   | 0.12730187  |\n",
      "|    n_updates          | 5452        |\n",
      "|    policyGradLoss     | -0.0125     |\n",
      "|    value_loss         | 0.482       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 688         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 59          |\n",
      "|    total_timesteps    | 11182080    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016181326 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.955       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0429      |\n",
      "|    mean_step_reward   | 0.12793702  |\n",
      "|    n_updates          | 5456        |\n",
      "|    policyGradLoss     | -0.0119     |\n",
      "|    value_loss         | 0.563       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 692         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 70          |\n",
      "|    total_timesteps    | 11190272    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017822033 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.85        |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0696      |\n",
      "|    mean_step_reward   | 0.106317244 |\n",
      "|    n_updates          | 5460        |\n",
      "|    policyGradLoss     | -0.00362    |\n",
      "|    value_loss         | 0.774       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 670         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 85          |\n",
      "|    total_timesteps    | 11198464    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018216264 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.00444    |\n",
      "|    mean_step_reward   | 0.13913038  |\n",
      "|    n_updates          | 5464        |\n",
      "|    policyGradLoss     | -0.009      |\n",
      "|    value_loss         | 0.493       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 651         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 100         |\n",
      "|    total_timesteps    | 11206656    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021441132 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0226     |\n",
      "|    mean_step_reward   | 0.13433018  |\n",
      "|    n_updates          | 5468        |\n",
      "|    policyGradLoss     | -0.0116     |\n",
      "|    value_loss         | 0.273       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 636         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 115         |\n",
      "|    total_timesteps    | 11214848    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019011552 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0214     |\n",
      "|    mean_step_reward   | 0.13651803  |\n",
      "|    n_updates          | 5472        |\n",
      "|    policyGradLoss     | -0.0159     |\n",
      "|    value_loss         | 0.253       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 627         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 130         |\n",
      "|    total_timesteps    | 11223040    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024257265 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0231     |\n",
      "|    mean_step_reward   | 0.14639713  |\n",
      "|    n_updates          | 5476        |\n",
      "|    policyGradLoss     | -0.012      |\n",
      "|    value_loss         | 0.406       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 619         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 145         |\n",
      "|    total_timesteps    | 11231232    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022737622 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0411     |\n",
      "|    mean_step_reward   | 0.13172692  |\n",
      "|    n_updates          | 5480        |\n",
      "|    policyGradLoss     | -0.0119     |\n",
      "|    value_loss         | 0.22        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 612         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 160         |\n",
      "|    total_timesteps    | 11239424    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015211627 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.00664    |\n",
      "|    mean_step_reward   | 0.16351475  |\n",
      "|    n_updates          | 5484        |\n",
      "|    policyGradLoss     | -0.00528    |\n",
      "|    value_loss         | 0.185       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 606         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 175         |\n",
      "|    total_timesteps    | 11247616    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023436762 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0671      |\n",
      "|    mean_step_reward   | 0.1299738   |\n",
      "|    n_updates          | 5488        |\n",
      "|    policyGradLoss     | -0.0138     |\n",
      "|    value_loss         | 0.44        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 602         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 190         |\n",
      "|    total_timesteps    | 11255808    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017460223 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0208     |\n",
      "|    mean_step_reward   | 0.14455533  |\n",
      "|    n_updates          | 5492        |\n",
      "|    policyGradLoss     | -0.0167     |\n",
      "|    value_loss         | 0.256       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 597         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 205         |\n",
      "|    total_timesteps    | 11264000    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018763125 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0155     |\n",
      "|    mean_step_reward   | 0.13570167  |\n",
      "|    n_updates          | 5496        |\n",
      "|    policyGradLoss     | -0.0129     |\n",
      "|    value_loss         | 0.206       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 594        |\n",
      "|    iterations         | 16         |\n",
      "|    time_elapsed       | 220        |\n",
      "|    total_timesteps    | 11272192   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02648951 |\n",
      "|    entropy_loss       | -1.83      |\n",
      "|    explained_variance | 0.983      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | -0.0208    |\n",
      "|    mean_step_reward   | 0.13744268 |\n",
      "|    n_updates          | 5500       |\n",
      "|    policyGradLoss     | -0.0136    |\n",
      "|    value_loss         | 0.301      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 592         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 235         |\n",
      "|    total_timesteps    | 11280384    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020392768 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0763      |\n",
      "|    mean_step_reward   | 0.14794683  |\n",
      "|    n_updates          | 5504        |\n",
      "|    policyGradLoss     | -0.0135     |\n",
      "|    value_loss         | 0.265       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 589        |\n",
      "|    iterations         | 18         |\n",
      "|    time_elapsed       | 250        |\n",
      "|    total_timesteps    | 11288576   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01765915 |\n",
      "|    entropy_loss       | -1.83      |\n",
      "|    explained_variance | 0.954      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | 0.0526     |\n",
      "|    mean_step_reward   | 0.12464674 |\n",
      "|    n_updates          | 5508       |\n",
      "|    policyGradLoss     | -0.0128    |\n",
      "|    value_loss         | 0.382      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 587         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 264         |\n",
      "|    total_timesteps    | 11296768    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018009637 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0351     |\n",
      "|    mean_step_reward   | 0.14130247  |\n",
      "|    n_updates          | 5512        |\n",
      "|    policyGradLoss     | -0.0185     |\n",
      "|    value_loss         | 0.135       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 585        |\n",
      "|    iterations         | 20         |\n",
      "|    time_elapsed       | 279        |\n",
      "|    total_timesteps    | 11304960   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01396253 |\n",
      "|    entropy_loss       | -1.84      |\n",
      "|    explained_variance | 0.957      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | 0.000359   |\n",
      "|    mean_step_reward   | 0.14582154 |\n",
      "|    n_updates          | 5516       |\n",
      "|    policyGradLoss     | -0.00727   |\n",
      "|    value_loss         | 0.337      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 583         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 294         |\n",
      "|    total_timesteps    | 11313152    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020731613 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0236     |\n",
      "|    mean_step_reward   | 0.14909889  |\n",
      "|    n_updates          | 5520        |\n",
      "|    policyGradLoss     | -0.0121     |\n",
      "|    value_loss         | 0.192       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 582         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 309         |\n",
      "|    total_timesteps    | 11321344    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022138622 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.000431    |\n",
      "|    mean_step_reward   | 0.1279925   |\n",
      "|    n_updates          | 5524        |\n",
      "|    policyGradLoss     | -0.00931    |\n",
      "|    value_loss         | 0.318       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 580         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 324         |\n",
      "|    total_timesteps    | 11329536    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018107105 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0189      |\n",
      "|    mean_step_reward   | 0.13641384  |\n",
      "|    n_updates          | 5528        |\n",
      "|    policyGradLoss     | -0.0117     |\n",
      "|    value_loss         | 0.483       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 579        |\n",
      "|    iterations         | 24         |\n",
      "|    time_elapsed       | 339        |\n",
      "|    total_timesteps    | 11337728   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02162905 |\n",
      "|    entropy_loss       | -1.85      |\n",
      "|    explained_variance | 0.979      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | 0.088      |\n",
      "|    mean_step_reward   | 0.13927652 |\n",
      "|    n_updates          | 5532       |\n",
      "|    policyGradLoss     | -0.0094    |\n",
      "|    value_loss         | 0.366      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 578         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 354         |\n",
      "|    total_timesteps    | 11345920    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021138836 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0188      |\n",
      "|    mean_step_reward   | 0.14848898  |\n",
      "|    n_updates          | 5536        |\n",
      "|    policyGradLoss     | -0.0146     |\n",
      "|    value_loss         | 0.264       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 576         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 369         |\n",
      "|    total_timesteps    | 11354112    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020546958 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.021      |\n",
      "|    mean_step_reward   | 0.13518918  |\n",
      "|    n_updates          | 5540        |\n",
      "|    policyGradLoss     | -0.00868    |\n",
      "|    value_loss         | 0.389       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 576         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 383         |\n",
      "|    total_timesteps    | 11362304    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021252278 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0742      |\n",
      "|    mean_step_reward   | 0.13648604  |\n",
      "|    n_updates          | 5544        |\n",
      "|    policyGradLoss     | -0.011      |\n",
      "|    value_loss         | 0.33        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 574         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 399         |\n",
      "|    total_timesteps    | 11370496    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023345338 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0336     |\n",
      "|    mean_step_reward   | 0.1510613   |\n",
      "|    n_updates          | 5548        |\n",
      "|    policyGradLoss     | -0.0166     |\n",
      "|    value_loss         | 0.136       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 574         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 413         |\n",
      "|    total_timesteps    | 11378688    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024570636 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.111       |\n",
      "|    mean_step_reward   | 0.1409854   |\n",
      "|    n_updates          | 5552        |\n",
      "|    policyGradLoss     | -0.00964    |\n",
      "|    value_loss         | 0.509       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 572         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 429         |\n",
      "|    total_timesteps    | 11386880    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017763864 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.917       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.025       |\n",
      "|    mean_step_reward   | 0.122873984 |\n",
      "|    n_updates          | 5556        |\n",
      "|    policyGradLoss     | -0.00387    |\n",
      "|    value_loss         | 0.611       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 572         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 443         |\n",
      "|    total_timesteps    | 11395072    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021388717 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0289     |\n",
      "|    mean_step_reward   | 0.14557877  |\n",
      "|    n_updates          | 5560        |\n",
      "|    policyGradLoss     | -0.0101     |\n",
      "|    value_loss         | 0.206       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 571         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 459         |\n",
      "|    total_timesteps    | 11403264    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010780662 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0864      |\n",
      "|    mean_step_reward   | 0.13743234  |\n",
      "|    n_updates          | 5564        |\n",
      "|    policyGradLoss     | 0.00103     |\n",
      "|    value_loss         | 0.405       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 573         |\n",
      "|    iterations         | 33          |\n",
      "|    time_elapsed       | 471         |\n",
      "|    total_timesteps    | 11411456    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022865407 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.036      |\n",
      "|    mean_step_reward   | 0.13103469  |\n",
      "|    n_updates          | 5568        |\n",
      "|    policyGradLoss     | -0.0119     |\n",
      "|    value_loss         | 0.213       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 574         |\n",
      "|    iterations         | 34          |\n",
      "|    time_elapsed       | 484         |\n",
      "|    total_timesteps    | 11419648    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017669318 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.153       |\n",
      "|    mean_step_reward   | 0.13637853  |\n",
      "|    n_updates          | 5572        |\n",
      "|    policyGradLoss     | -0.00812    |\n",
      "|    value_loss         | 0.404       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 575        |\n",
      "|    iterations         | 35         |\n",
      "|    time_elapsed       | 498        |\n",
      "|    total_timesteps    | 11427840   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01962959 |\n",
      "|    entropy_loss       | -1.85      |\n",
      "|    explained_variance | 0.986      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | -0.0364    |\n",
      "|    mean_step_reward   | 0.1449357  |\n",
      "|    n_updates          | 5576       |\n",
      "|    policyGradLoss     | -0.0157    |\n",
      "|    value_loss         | 0.162      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 575         |\n",
      "|    iterations         | 36          |\n",
      "|    time_elapsed       | 512         |\n",
      "|    total_timesteps    | 11436032    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021419901 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0182     |\n",
      "|    mean_step_reward   | 0.13850465  |\n",
      "|    n_updates          | 5580        |\n",
      "|    policyGradLoss     | -0.014      |\n",
      "|    value_loss         | 0.242       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 573         |\n",
      "|    iterations         | 37          |\n",
      "|    time_elapsed       | 528         |\n",
      "|    total_timesteps    | 11444224    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025090698 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0366     |\n",
      "|    mean_step_reward   | 0.13432476  |\n",
      "|    n_updates          | 5584        |\n",
      "|    policyGradLoss     | -0.0154     |\n",
      "|    value_loss         | 0.161       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 572         |\n",
      "|    iterations         | 38          |\n",
      "|    time_elapsed       | 543         |\n",
      "|    total_timesteps    | 11452416    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023504052 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -6.68e-05   |\n",
      "|    mean_step_reward   | 0.14788297  |\n",
      "|    n_updates          | 5588        |\n",
      "|    policyGradLoss     | -0.0139     |\n",
      "|    value_loss         | 0.305       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 572         |\n",
      "|    iterations         | 39          |\n",
      "|    time_elapsed       | 558         |\n",
      "|    total_timesteps    | 11460608    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018099017 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0631      |\n",
      "|    mean_step_reward   | 0.15182233  |\n",
      "|    n_updates          | 5592        |\n",
      "|    policyGradLoss     | -0.00869    |\n",
      "|    value_loss         | 0.32        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 571         |\n",
      "|    iterations         | 40          |\n",
      "|    time_elapsed       | 573         |\n",
      "|    total_timesteps    | 11468800    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023194853 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.029      |\n",
      "|    mean_step_reward   | 0.14379533  |\n",
      "|    n_updates          | 5596        |\n",
      "|    policyGradLoss     | -0.0124     |\n",
      "|    value_loss         | 0.152       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/SF84G_PT_35.zip\n",
      "[EVAL] Mean Return: 182.230, Best Return: 182.238\n",
      "Saved video to ./runs_smw/videos/step_11468800_mean_182.23.mp4\n",
      "\n",
      "=== Round 7 | Learn 327680 steps (Total trained: 11468800) ===\n",
      "Logging to ./runs_smw/tb/SF84G_1220_20_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 743      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 11       |\n",
      "|    total_timesteps | 11476992 |\n",
      "---------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 634        |\n",
      "|    iterations         | 2          |\n",
      "|    time_elapsed       | 25         |\n",
      "|    total_timesteps    | 11485184   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02070201 |\n",
      "|    entropy_loss       | -1.79      |\n",
      "|    explained_variance | 0.99       |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | 0.0166     |\n",
      "|    mean_step_reward   | 0.14090098 |\n",
      "|    n_updates          | 5604       |\n",
      "|    policyGradLoss     | -0.0145    |\n",
      "|    value_loss         | 0.238      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 599        |\n",
      "|    iterations         | 3          |\n",
      "|    time_elapsed       | 40         |\n",
      "|    total_timesteps    | 11493376   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02118026 |\n",
      "|    entropy_loss       | -1.83      |\n",
      "|    explained_variance | 0.979      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | 0.0656     |\n",
      "|    mean_step_reward   | 0.14229591 |\n",
      "|    n_updates          | 5608       |\n",
      "|    policyGradLoss     | -0.00946   |\n",
      "|    value_loss         | 0.537      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 585         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 55          |\n",
      "|    total_timesteps    | 11501568    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024910308 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0159     |\n",
      "|    mean_step_reward   | 0.13999122  |\n",
      "|    n_updates          | 5612        |\n",
      "|    policyGradLoss     | -0.0075     |\n",
      "|    value_loss         | 0.163       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 578         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 70          |\n",
      "|    total_timesteps    | 11509760    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021080948 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.996       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0384     |\n",
      "|    mean_step_reward   | 0.15362872  |\n",
      "|    n_updates          | 5616        |\n",
      "|    policyGradLoss     | -0.014      |\n",
      "|    value_loss         | 0.108       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 573         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 85          |\n",
      "|    total_timesteps    | 11517952    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018949218 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0316      |\n",
      "|    mean_step_reward   | 0.14475553  |\n",
      "|    n_updates          | 5620        |\n",
      "|    policyGradLoss     | -0.00858    |\n",
      "|    value_loss         | 0.334       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 567         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 100         |\n",
      "|    total_timesteps    | 11526144    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028994735 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.993       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0483     |\n",
      "|    mean_step_reward   | 0.14213127  |\n",
      "|    n_updates          | 5624        |\n",
      "|    policyGradLoss     | -0.0174     |\n",
      "|    value_loss         | 0.117       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 565         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 115         |\n",
      "|    total_timesteps    | 11534336    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021408487 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0149      |\n",
      "|    mean_step_reward   | 0.14230797  |\n",
      "|    n_updates          | 5628        |\n",
      "|    policyGradLoss     | -0.00923    |\n",
      "|    value_loss         | 0.491       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 564         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 130         |\n",
      "|    total_timesteps    | 11542528    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015782233 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0396      |\n",
      "|    mean_step_reward   | 0.13585538  |\n",
      "|    n_updates          | 5632        |\n",
      "|    policyGradLoss     | -0.0121     |\n",
      "|    value_loss         | 0.336       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 563         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 145         |\n",
      "|    total_timesteps    | 11550720    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020733742 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0111      |\n",
      "|    mean_step_reward   | 0.14948586  |\n",
      "|    n_updates          | 5636        |\n",
      "|    policyGradLoss     | -0.0103     |\n",
      "|    value_loss         | 0.264       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 562         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 160         |\n",
      "|    total_timesteps    | 11558912    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019895148 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.141       |\n",
      "|    mean_step_reward   | 0.13488996  |\n",
      "|    n_updates          | 5640        |\n",
      "|    policyGradLoss     | -0.00972    |\n",
      "|    value_loss         | 0.607       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 560         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 175         |\n",
      "|    total_timesteps    | 11567104    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013663815 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.109       |\n",
      "|    mean_step_reward   | 0.12724963  |\n",
      "|    n_updates          | 5644        |\n",
      "|    policyGradLoss     | -0.00908    |\n",
      "|    value_loss         | 0.521       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 559         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 190         |\n",
      "|    total_timesteps    | 11575296    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019957244 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0376      |\n",
      "|    mean_step_reward   | 0.14785783  |\n",
      "|    n_updates          | 5648        |\n",
      "|    policyGradLoss     | -0.0115     |\n",
      "|    value_loss         | 0.369       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 558         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 205         |\n",
      "|    total_timesteps    | 11583488    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026312066 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0421     |\n",
      "|    mean_step_reward   | 0.13200656  |\n",
      "|    n_updates          | 5652        |\n",
      "|    policyGradLoss     | -0.018      |\n",
      "|    value_loss         | 0.115       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 558         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 220         |\n",
      "|    total_timesteps    | 11591680    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016695237 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0196     |\n",
      "|    mean_step_reward   | 0.14194772  |\n",
      "|    n_updates          | 5656        |\n",
      "|    policyGradLoss     | -0.00816    |\n",
      "|    value_loss         | 0.25        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 557         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 235         |\n",
      "|    total_timesteps    | 11599872    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021903683 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0825      |\n",
      "|    mean_step_reward   | 0.13247243  |\n",
      "|    n_updates          | 5660        |\n",
      "|    policyGradLoss     | -0.00859    |\n",
      "|    value_loss         | 0.49        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 556         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 250         |\n",
      "|    total_timesteps    | 11608064    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023307886 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0615     |\n",
      "|    mean_step_reward   | 0.1424633   |\n",
      "|    n_updates          | 5664        |\n",
      "|    policyGradLoss     | -0.0176     |\n",
      "|    value_loss         | 0.122       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 556         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 264         |\n",
      "|    total_timesteps    | 11616256    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015636228 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0612      |\n",
      "|    mean_step_reward   | 0.15235338  |\n",
      "|    n_updates          | 5668        |\n",
      "|    policyGradLoss     | -0.00963    |\n",
      "|    value_loss         | 0.325       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 557         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 279         |\n",
      "|    total_timesteps    | 11624448    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027422253 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0199     |\n",
      "|    mean_step_reward   | 0.13404036  |\n",
      "|    n_updates          | 5672        |\n",
      "|    policyGradLoss     | -0.0111     |\n",
      "|    value_loss         | 0.222       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 559         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 292         |\n",
      "|    total_timesteps    | 11632640    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014008955 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0104      |\n",
      "|    mean_step_reward   | 0.15712628  |\n",
      "|    n_updates          | 5676        |\n",
      "|    policyGradLoss     | -0.0105     |\n",
      "|    value_loss         | 0.313       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 561         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 306         |\n",
      "|    total_timesteps    | 11640832    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022051714 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.00956    |\n",
      "|    mean_step_reward   | 0.14394502  |\n",
      "|    n_updates          | 5680        |\n",
      "|    policyGradLoss     | -0.00284    |\n",
      "|    value_loss         | 0.245       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 563         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 320         |\n",
      "|    total_timesteps    | 11649024    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015965648 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0348      |\n",
      "|    mean_step_reward   | 0.13173926  |\n",
      "|    n_updates          | 5684        |\n",
      "|    policyGradLoss     | -0.00812    |\n",
      "|    value_loss         | 0.553       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 562         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 334         |\n",
      "|    total_timesteps    | 11657216    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020199236 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.00966    |\n",
      "|    mean_step_reward   | 0.14602116  |\n",
      "|    n_updates          | 5688        |\n",
      "|    policyGradLoss     | -0.0134     |\n",
      "|    value_loss         | 0.31        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 562         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 349         |\n",
      "|    total_timesteps    | 11665408    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013598377 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.00522    |\n",
      "|    mean_step_reward   | 0.14022155  |\n",
      "|    n_updates          | 5692        |\n",
      "|    policyGradLoss     | -0.0119     |\n",
      "|    value_loss         | 0.394       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 561         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 364         |\n",
      "|    total_timesteps    | 11673600    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012732538 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0382     |\n",
      "|    mean_step_reward   | 0.13657331  |\n",
      "|    n_updates          | 5696        |\n",
      "|    policyGradLoss     | -0.0121     |\n",
      "|    value_loss         | 0.276       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 560        |\n",
      "|    iterations         | 26         |\n",
      "|    time_elapsed       | 379        |\n",
      "|    total_timesteps    | 11681792   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02432194 |\n",
      "|    entropy_loss       | -1.82      |\n",
      "|    explained_variance | 0.987      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | -0.0251    |\n",
      "|    mean_step_reward   | 0.14501339 |\n",
      "|    n_updates          | 5700       |\n",
      "|    policyGradLoss     | -0.0177    |\n",
      "|    value_loss         | 0.175      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 560        |\n",
      "|    iterations         | 27         |\n",
      "|    time_elapsed       | 394        |\n",
      "|    total_timesteps    | 11689984   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01848253 |\n",
      "|    entropy_loss       | -1.85      |\n",
      "|    explained_variance | 0.987      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | 0.0354     |\n",
      "|    mean_step_reward   | 0.14606701 |\n",
      "|    n_updates          | 5704       |\n",
      "|    policyGradLoss     | -0.0153    |\n",
      "|    value_loss         | 0.259      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 559         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 409         |\n",
      "|    total_timesteps    | 11698176    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017894823 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0466      |\n",
      "|    mean_step_reward   | 0.14632721  |\n",
      "|    n_updates          | 5708        |\n",
      "|    policyGradLoss     | -0.0116     |\n",
      "|    value_loss         | 0.467       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 559         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 424         |\n",
      "|    total_timesteps    | 11706368    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017254591 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0308     |\n",
      "|    mean_step_reward   | 0.14512286  |\n",
      "|    n_updates          | 5712        |\n",
      "|    policyGradLoss     | -0.0131     |\n",
      "|    value_loss         | 0.319       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 559         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 439         |\n",
      "|    total_timesteps    | 11714560    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017105913 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0314     |\n",
      "|    mean_step_reward   | 0.14935817  |\n",
      "|    n_updates          | 5716        |\n",
      "|    policyGradLoss     | -0.011      |\n",
      "|    value_loss         | 0.122       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 558         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 454         |\n",
      "|    total_timesteps    | 11722752    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022888528 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0317     |\n",
      "|    mean_step_reward   | 0.14652476  |\n",
      "|    n_updates          | 5720        |\n",
      "|    policyGradLoss     | -0.0117     |\n",
      "|    value_loss         | 0.159       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 557         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 469         |\n",
      "|    total_timesteps    | 11730944    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022709887 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0205     |\n",
      "|    mean_step_reward   | 0.14349084  |\n",
      "|    n_updates          | 5724        |\n",
      "|    policyGradLoss     | -0.0109     |\n",
      "|    value_loss         | 0.273       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 557        |\n",
      "|    iterations         | 33         |\n",
      "|    time_elapsed       | 484        |\n",
      "|    total_timesteps    | 11739136   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01939945 |\n",
      "|    entropy_loss       | -1.82      |\n",
      "|    explained_variance | 0.986      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | -0.0185    |\n",
      "|    mean_step_reward   | 0.15093872 |\n",
      "|    n_updates          | 5728       |\n",
      "|    policyGradLoss     | -0.0117    |\n",
      "|    value_loss         | 0.221      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 557         |\n",
      "|    iterations         | 34          |\n",
      "|    time_elapsed       | 499         |\n",
      "|    total_timesteps    | 11747328    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021642946 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0134      |\n",
      "|    mean_step_reward   | 0.14072037  |\n",
      "|    n_updates          | 5732        |\n",
      "|    policyGradLoss     | -0.00871    |\n",
      "|    value_loss         | 0.265       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 557        |\n",
      "|    iterations         | 35         |\n",
      "|    time_elapsed       | 514        |\n",
      "|    total_timesteps    | 11755520   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02017176 |\n",
      "|    entropy_loss       | -1.8       |\n",
      "|    explained_variance | 0.982      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | -0.0162    |\n",
      "|    mean_step_reward   | 0.13897312 |\n",
      "|    n_updates          | 5736       |\n",
      "|    policyGradLoss     | -0.0131    |\n",
      "|    value_loss         | 0.386      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 557         |\n",
      "|    iterations         | 36          |\n",
      "|    time_elapsed       | 529         |\n",
      "|    total_timesteps    | 11763712    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020837598 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0854      |\n",
      "|    mean_step_reward   | 0.13631149  |\n",
      "|    n_updates          | 5740        |\n",
      "|    policyGradLoss     | -0.00919    |\n",
      "|    value_loss         | 0.531       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 557        |\n",
      "|    iterations         | 37         |\n",
      "|    time_elapsed       | 544        |\n",
      "|    total_timesteps    | 11771904   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02199496 |\n",
      "|    entropy_loss       | -1.79      |\n",
      "|    explained_variance | 0.98       |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | -0.018     |\n",
      "|    mean_step_reward   | 0.1410237  |\n",
      "|    n_updates          | 5744       |\n",
      "|    policyGradLoss     | -0.0152    |\n",
      "|    value_loss         | 0.313      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 557        |\n",
      "|    iterations         | 38         |\n",
      "|    time_elapsed       | 558        |\n",
      "|    total_timesteps    | 11780096   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02790152 |\n",
      "|    entropy_loss       | -1.79      |\n",
      "|    explained_variance | 0.987      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | 0.018      |\n",
      "|    mean_step_reward   | 0.14400133 |\n",
      "|    n_updates          | 5748       |\n",
      "|    policyGradLoss     | -0.0156    |\n",
      "|    value_loss         | 0.248      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 556         |\n",
      "|    iterations         | 39          |\n",
      "|    time_elapsed       | 573         |\n",
      "|    total_timesteps    | 11788288    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023070812 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.052       |\n",
      "|    mean_step_reward   | 0.15359831  |\n",
      "|    n_updates          | 5752        |\n",
      "|    policyGradLoss     | -0.0104     |\n",
      "|    value_loss         | 0.398       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 556         |\n",
      "|    iterations         | 40          |\n",
      "|    time_elapsed       | 588         |\n",
      "|    total_timesteps    | 11796480    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023827957 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0393     |\n",
      "|    mean_step_reward   | 0.13882266  |\n",
      "|    n_updates          | 5756        |\n",
      "|    policyGradLoss     | -0.0115     |\n",
      "|    value_loss         | 0.132       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/SF84G_PT_36.zip\n",
      "[EVAL] Mean Return: 185.400, Best Return: 185.408\n",
      "Saved video to ./runs_smw/videos/step_11796480_mean_185.40.mp4\n",
      "\n",
      "=== Round 8 | Learn 327680 steps (Total trained: 11796480) ===\n",
      "Logging to ./runs_smw/tb/SF84G_1220_20_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 719      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 11       |\n",
      "|    total_timesteps | 11804672 |\n",
      "---------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 620        |\n",
      "|    iterations         | 2          |\n",
      "|    time_elapsed       | 26         |\n",
      "|    total_timesteps    | 11812864   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01675863 |\n",
      "|    entropy_loss       | -1.79      |\n",
      "|    explained_variance | 0.984      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | -0.0197    |\n",
      "|    mean_step_reward   | 0.13922535 |\n",
      "|    n_updates          | 5764       |\n",
      "|    policyGradLoss     | -0.0108    |\n",
      "|    value_loss         | 0.336      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 589         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 41          |\n",
      "|    total_timesteps    | 11821056    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022268591 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.025      |\n",
      "|    mean_step_reward   | 0.13794136  |\n",
      "|    n_updates          | 5768        |\n",
      "|    policyGradLoss     | -0.0161     |\n",
      "|    value_loss         | 0.219       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 579         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 56          |\n",
      "|    total_timesteps    | 11829248    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028997893 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0249     |\n",
      "|    mean_step_reward   | 0.14964834  |\n",
      "|    n_updates          | 5772        |\n",
      "|    policyGradLoss     | -0.0112     |\n",
      "|    value_loss         | 0.223       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 572         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 71          |\n",
      "|    total_timesteps    | 11837440    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026911505 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.993       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0489     |\n",
      "|    mean_step_reward   | 0.14439708  |\n",
      "|    n_updates          | 5776        |\n",
      "|    policyGradLoss     | -0.0191     |\n",
      "|    value_loss         | 0.109       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 590         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 83          |\n",
      "|    total_timesteps    | 11845632    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023745215 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.022      |\n",
      "|    mean_step_reward   | 0.14703497  |\n",
      "|    n_updates          | 5780        |\n",
      "|    policyGradLoss     | -0.0147     |\n",
      "|    value_loss         | 0.184       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 592         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 96          |\n",
      "|    total_timesteps    | 11853824    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016845493 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0171      |\n",
      "|    mean_step_reward   | 0.1367193   |\n",
      "|    n_updates          | 5784        |\n",
      "|    policyGradLoss     | -0.00448    |\n",
      "|    value_loss         | 0.344       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 593         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 110         |\n",
      "|    total_timesteps    | 11862016    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030476786 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0397     |\n",
      "|    mean_step_reward   | 0.1386605   |\n",
      "|    n_updates          | 5788        |\n",
      "|    policyGradLoss     | -0.013      |\n",
      "|    value_loss         | 0.145       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 594         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 123         |\n",
      "|    total_timesteps    | 11870208    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017594922 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0181     |\n",
      "|    mean_step_reward   | 0.15772697  |\n",
      "|    n_updates          | 5792        |\n",
      "|    policyGradLoss     | -0.0103     |\n",
      "|    value_loss         | 0.231       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 587         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 139         |\n",
      "|    total_timesteps    | 11878400    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028016873 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.993       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0497     |\n",
      "|    mean_step_reward   | 0.1345674   |\n",
      "|    n_updates          | 5796        |\n",
      "|    policyGradLoss     | -0.0176     |\n",
      "|    value_loss         | 0.0926      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 583         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 154         |\n",
      "|    total_timesteps    | 11886592    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024411285 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.994       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0216     |\n",
      "|    mean_step_reward   | 0.16019253  |\n",
      "|    n_updates          | 5800        |\n",
      "|    policyGradLoss     | -0.0132     |\n",
      "|    value_loss         | 0.137       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 581         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 169         |\n",
      "|    total_timesteps    | 11894784    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025129158 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.996       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0349     |\n",
      "|    mean_step_reward   | 0.14727165  |\n",
      "|    n_updates          | 5804        |\n",
      "|    policyGradLoss     | -0.0159     |\n",
      "|    value_loss         | 0.086       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 579         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 183         |\n",
      "|    total_timesteps    | 11902976    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017377824 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0164     |\n",
      "|    mean_step_reward   | 0.14739302  |\n",
      "|    n_updates          | 5808        |\n",
      "|    policyGradLoss     | -0.0121     |\n",
      "|    value_loss         | 0.181       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 577        |\n",
      "|    iterations         | 14         |\n",
      "|    time_elapsed       | 198        |\n",
      "|    total_timesteps    | 11911168   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02822591 |\n",
      "|    entropy_loss       | -1.81      |\n",
      "|    explained_variance | 0.991      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | 0.0118     |\n",
      "|    mean_step_reward   | 0.14242822 |\n",
      "|    n_updates          | 5812       |\n",
      "|    policyGradLoss     | -0.0124    |\n",
      "|    value_loss         | 0.226      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 575         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 213         |\n",
      "|    total_timesteps    | 11919360    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026122306 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0372     |\n",
      "|    mean_step_reward   | 0.14519718  |\n",
      "|    n_updates          | 5816        |\n",
      "|    policyGradLoss     | -0.0153     |\n",
      "|    value_loss         | 0.0999      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 573         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 228         |\n",
      "|    total_timesteps    | 11927552    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019806344 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0789      |\n",
      "|    mean_step_reward   | 0.15562129  |\n",
      "|    n_updates          | 5820        |\n",
      "|    policyGradLoss     | -0.00953    |\n",
      "|    value_loss         | 0.478       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 571         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 243         |\n",
      "|    total_timesteps    | 11935744    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019056516 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.00627     |\n",
      "|    mean_step_reward   | 0.12338892  |\n",
      "|    n_updates          | 5824        |\n",
      "|    policyGradLoss     | -0.0103     |\n",
      "|    value_loss         | 0.429       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 570         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 258         |\n",
      "|    total_timesteps    | 11943936    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020077115 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0227     |\n",
      "|    mean_step_reward   | 0.1446756   |\n",
      "|    n_updates          | 5828        |\n",
      "|    policyGradLoss     | -0.018      |\n",
      "|    value_loss         | 0.192       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 569        |\n",
      "|    iterations         | 19         |\n",
      "|    time_elapsed       | 273        |\n",
      "|    total_timesteps    | 11952128   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01808314 |\n",
      "|    entropy_loss       | -1.83      |\n",
      "|    explained_variance | 0.98       |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | 0.0962     |\n",
      "|    mean_step_reward   | 0.14404376 |\n",
      "|    n_updates          | 5832       |\n",
      "|    policyGradLoss     | -0.00593   |\n",
      "|    value_loss         | 0.387      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 568         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 288         |\n",
      "|    total_timesteps    | 11960320    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025588846 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0348     |\n",
      "|    mean_step_reward   | 0.13617145  |\n",
      "|    n_updates          | 5836        |\n",
      "|    policyGradLoss     | -0.0157     |\n",
      "|    value_loss         | 0.17        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 567        |\n",
      "|    iterations         | 21         |\n",
      "|    time_elapsed       | 303        |\n",
      "|    total_timesteps    | 11968512   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.0219635  |\n",
      "|    entropy_loss       | -1.82      |\n",
      "|    explained_variance | 0.996      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | -0.033     |\n",
      "|    mean_step_reward   | 0.15735605 |\n",
      "|    n_updates          | 5840       |\n",
      "|    policyGradLoss     | -0.017     |\n",
      "|    value_loss         | 0.126      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 566         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 318         |\n",
      "|    total_timesteps    | 11976704    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022801537 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.278       |\n",
      "|    mean_step_reward   | 0.13357784  |\n",
      "|    n_updates          | 5844        |\n",
      "|    policyGradLoss     | -0.00932    |\n",
      "|    value_loss         | 0.578       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 565         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 333         |\n",
      "|    total_timesteps    | 11984896    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021425951 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.995       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.059      |\n",
      "|    mean_step_reward   | 0.15009123  |\n",
      "|    n_updates          | 5848        |\n",
      "|    policyGradLoss     | -0.0186     |\n",
      "|    value_loss         | 0.0979      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 564         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 348         |\n",
      "|    total_timesteps    | 11993088    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016455492 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0587      |\n",
      "|    mean_step_reward   | 0.1478422   |\n",
      "|    n_updates          | 5852        |\n",
      "|    policyGradLoss     | -0.00838    |\n",
      "|    value_loss         | 0.481       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 563         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 363         |\n",
      "|    total_timesteps    | 12001280    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022763984 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0193     |\n",
      "|    mean_step_reward   | 0.13149177  |\n",
      "|    n_updates          | 5856        |\n",
      "|    policyGradLoss     | -0.013      |\n",
      "|    value_loss         | 0.183       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 563         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 378         |\n",
      "|    total_timesteps    | 12009472    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020977914 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.995       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0323     |\n",
      "|    mean_step_reward   | 0.15609859  |\n",
      "|    n_updates          | 5860        |\n",
      "|    policyGradLoss     | -0.0142     |\n",
      "|    value_loss         | 0.142       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 562         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 393         |\n",
      "|    total_timesteps    | 12017664    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030932369 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.995       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0444     |\n",
      "|    mean_step_reward   | 0.14229411  |\n",
      "|    n_updates          | 5864        |\n",
      "|    policyGradLoss     | -0.0164     |\n",
      "|    value_loss         | 0.0905      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 561         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 408         |\n",
      "|    total_timesteps    | 12025856    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028706893 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.000326    |\n",
      "|    mean_step_reward   | 0.14537618  |\n",
      "|    n_updates          | 5868        |\n",
      "|    policyGradLoss     | -0.0149     |\n",
      "|    value_loss         | 0.191       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 560         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 423         |\n",
      "|    total_timesteps    | 12034048    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019077806 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.00548    |\n",
      "|    mean_step_reward   | 0.14947203  |\n",
      "|    n_updates          | 5872        |\n",
      "|    policyGradLoss     | -0.0138     |\n",
      "|    value_loss         | 0.257       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 559         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 439         |\n",
      "|    total_timesteps    | 12042240    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.041179284 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0434     |\n",
      "|    mean_step_reward   | 0.14577638  |\n",
      "|    n_updates          | 5876        |\n",
      "|    policyGradLoss     | 0.00487     |\n",
      "|    value_loss         | 0.179       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 559         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 453         |\n",
      "|    total_timesteps    | 12050432    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018613447 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0304     |\n",
      "|    mean_step_reward   | 0.15087365  |\n",
      "|    n_updates          | 5880        |\n",
      "|    policyGradLoss     | -0.0028     |\n",
      "|    value_loss         | 0.198       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 559        |\n",
      "|    iterations         | 32         |\n",
      "|    time_elapsed       | 468        |\n",
      "|    total_timesteps    | 12058624   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03592373 |\n",
      "|    entropy_loss       | -1.78      |\n",
      "|    explained_variance | 0.993      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | -0.0207    |\n",
      "|    mean_step_reward   | 0.14705037 |\n",
      "|    n_updates          | 5884       |\n",
      "|    policyGradLoss     | -0.0164    |\n",
      "|    value_loss         | 0.115      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 558         |\n",
      "|    iterations         | 33          |\n",
      "|    time_elapsed       | 483         |\n",
      "|    total_timesteps    | 12066816    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029530644 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.993       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0152     |\n",
      "|    mean_step_reward   | 0.15462404  |\n",
      "|    n_updates          | 5888        |\n",
      "|    policyGradLoss     | -0.0121     |\n",
      "|    value_loss         | 0.154       |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 558       |\n",
      "|    iterations         | 34        |\n",
      "|    time_elapsed       | 498       |\n",
      "|    total_timesteps    | 12075008  |\n",
      "| train/                |           |\n",
      "|    approx_kl          | 0.0196172 |\n",
      "|    entropy_loss       | -1.79     |\n",
      "|    explained_variance | 0.976     |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    loss               | 0.115     |\n",
      "|    mean_step_reward   | 0.1314775 |\n",
      "|    n_updates          | 5892      |\n",
      "|    policyGradLoss     | -0.00216  |\n",
      "|    value_loss         | 0.355     |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 557         |\n",
      "|    iterations         | 35          |\n",
      "|    time_elapsed       | 513         |\n",
      "|    total_timesteps    | 12083200    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029386688 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.994       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0495     |\n",
      "|    mean_step_reward   | 0.14793059  |\n",
      "|    n_updates          | 5896        |\n",
      "|    policyGradLoss     | -0.0172     |\n",
      "|    value_loss         | 0.107       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 560         |\n",
      "|    iterations         | 36          |\n",
      "|    time_elapsed       | 525         |\n",
      "|    total_timesteps    | 12091392    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021113887 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.994       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0227     |\n",
      "|    mean_step_reward   | 0.15119943  |\n",
      "|    n_updates          | 5900        |\n",
      "|    policyGradLoss     | -0.0159     |\n",
      "|    value_loss         | 0.145       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 561         |\n",
      "|    iterations         | 37          |\n",
      "|    time_elapsed       | 539         |\n",
      "|    total_timesteps    | 12099584    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019316947 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0104     |\n",
      "|    mean_step_reward   | 0.14376345  |\n",
      "|    n_updates          | 5904        |\n",
      "|    policyGradLoss     | -0.00984    |\n",
      "|    value_loss         | 0.194       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 562         |\n",
      "|    iterations         | 38          |\n",
      "|    time_elapsed       | 552         |\n",
      "|    total_timesteps    | 12107776    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022839492 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.997       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0522     |\n",
      "|    mean_step_reward   | 0.15999737  |\n",
      "|    n_updates          | 5908        |\n",
      "|    policyGradLoss     | -0.0153     |\n",
      "|    value_loss         | 0.1         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 563         |\n",
      "|    iterations         | 39          |\n",
      "|    time_elapsed       | 566         |\n",
      "|    total_timesteps    | 12115968    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014282305 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0752      |\n",
      "|    mean_step_reward   | 0.1359611   |\n",
      "|    n_updates          | 5912        |\n",
      "|    policyGradLoss     | -0.00723    |\n",
      "|    value_loss         | 0.334       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 563         |\n",
      "|    iterations         | 40          |\n",
      "|    time_elapsed       | 581         |\n",
      "|    total_timesteps    | 12124160    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015302589 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.023       |\n",
      "|    mean_step_reward   | 0.14336553  |\n",
      "|    n_updates          | 5916        |\n",
      "|    policyGradLoss     | -0.00751    |\n",
      "|    value_loss         | 0.354       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/SF84G_PT_37.zip\n",
      "[EVAL] Mean Return: 184.840, Best Return: 184.848\n",
      "Saved video to ./runs_smw/videos/step_12124160_mean_184.84.mp4\n",
      "\n",
      "=== Round 9 | Learn 327680 steps (Total trained: 12124160) ===\n",
      "Logging to ./runs_smw/tb/SF84G_1220_20_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 741      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 11       |\n",
      "|    total_timesteps | 12132352 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 630         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 26          |\n",
      "|    total_timesteps    | 12140544    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020190623 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.993       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0265     |\n",
      "|    mean_step_reward   | 0.15696149  |\n",
      "|    n_updates          | 5924        |\n",
      "|    policyGradLoss     | -0.0132     |\n",
      "|    value_loss         | 0.162       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 598        |\n",
      "|    iterations         | 3          |\n",
      "|    time_elapsed       | 41         |\n",
      "|    total_timesteps    | 12148736   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02850354 |\n",
      "|    entropy_loss       | -1.8       |\n",
      "|    explained_variance | 0.991      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | -0.0412    |\n",
      "|    mean_step_reward   | 0.14077619 |\n",
      "|    n_updates          | 5928       |\n",
      "|    policyGradLoss     | -0.0129    |\n",
      "|    value_loss         | 0.141      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 583         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 56          |\n",
      "|    total_timesteps    | 12156928    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023970641 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0297     |\n",
      "|    mean_step_reward   | 0.15080866  |\n",
      "|    n_updates          | 5932        |\n",
      "|    policyGradLoss     | -0.0112     |\n",
      "|    value_loss         | 0.245       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 575        |\n",
      "|    iterations         | 5          |\n",
      "|    time_elapsed       | 71         |\n",
      "|    total_timesteps    | 12165120   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.0234043  |\n",
      "|    entropy_loss       | -1.84      |\n",
      "|    explained_variance | 0.996      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | -0.0401    |\n",
      "|    mean_step_reward   | 0.14986524 |\n",
      "|    n_updates          | 5936       |\n",
      "|    policyGradLoss     | -0.0176    |\n",
      "|    value_loss         | 0.0955     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 571         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 85          |\n",
      "|    total_timesteps    | 12173312    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021101441 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0271     |\n",
      "|    mean_step_reward   | 0.14797042  |\n",
      "|    n_updates          | 5940        |\n",
      "|    policyGradLoss     | -0.00974    |\n",
      "|    value_loss         | 0.195       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 566         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 101         |\n",
      "|    total_timesteps    | 12181504    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020738792 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0415      |\n",
      "|    mean_step_reward   | 0.148832    |\n",
      "|    n_updates          | 5944        |\n",
      "|    policyGradLoss     | -0.00907    |\n",
      "|    value_loss         | 0.332       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 564         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 116         |\n",
      "|    total_timesteps    | 12189696    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020370232 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0165     |\n",
      "|    mean_step_reward   | 0.12639356  |\n",
      "|    n_updates          | 5948        |\n",
      "|    policyGradLoss     | -0.00894    |\n",
      "|    value_loss         | 0.253       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 564        |\n",
      "|    iterations         | 9          |\n",
      "|    time_elapsed       | 130        |\n",
      "|    total_timesteps    | 12197888   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01995305 |\n",
      "|    entropy_loss       | -1.83      |\n",
      "|    explained_variance | 0.984      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | 0.00718    |\n",
      "|    mean_step_reward   | 0.15275963 |\n",
      "|    n_updates          | 5952       |\n",
      "|    policyGradLoss     | 0.00586    |\n",
      "|    value_loss         | 0.31       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 562         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 145         |\n",
      "|    total_timesteps    | 12206080    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021493204 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.189       |\n",
      "|    mean_step_reward   | 0.14843333  |\n",
      "|    n_updates          | 5956        |\n",
      "|    policyGradLoss     | -0.00832    |\n",
      "|    value_loss         | 0.329       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 561         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 160         |\n",
      "|    total_timesteps    | 12214272    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019283477 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.00534    |\n",
      "|    mean_step_reward   | 0.14301652  |\n",
      "|    n_updates          | 5960        |\n",
      "|    policyGradLoss     | -0.012      |\n",
      "|    value_loss         | 0.266       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 559         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 175         |\n",
      "|    total_timesteps    | 12222464    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014982666 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.00595    |\n",
      "|    mean_step_reward   | 0.14568853  |\n",
      "|    n_updates          | 5964        |\n",
      "|    policyGradLoss     | -0.0102     |\n",
      "|    value_loss         | 0.228       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 560        |\n",
      "|    iterations         | 13         |\n",
      "|    time_elapsed       | 190        |\n",
      "|    total_timesteps    | 12230656   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01747382 |\n",
      "|    entropy_loss       | -1.79      |\n",
      "|    explained_variance | 0.966      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | 0.029      |\n",
      "|    mean_step_reward   | 0.14042355 |\n",
      "|    n_updates          | 5968       |\n",
      "|    policyGradLoss     | -0.0109    |\n",
      "|    value_loss         | 0.37       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 559         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 205         |\n",
      "|    total_timesteps    | 12238848    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018842138 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0462      |\n",
      "|    mean_step_reward   | 0.14861251  |\n",
      "|    n_updates          | 5972        |\n",
      "|    policyGradLoss     | -0.00788    |\n",
      "|    value_loss         | 0.563       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 558         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 220         |\n",
      "|    total_timesteps    | 12247040    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023701452 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0566     |\n",
      "|    mean_step_reward   | 0.14272492  |\n",
      "|    n_updates          | 5976        |\n",
      "|    policyGradLoss     | -0.015      |\n",
      "|    value_loss         | 0.114       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 558         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 234         |\n",
      "|    total_timesteps    | 12255232    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015325408 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0381      |\n",
      "|    mean_step_reward   | 0.14843863  |\n",
      "|    n_updates          | 5980        |\n",
      "|    policyGradLoss     | -0.0105     |\n",
      "|    value_loss         | 0.425       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 557         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 249         |\n",
      "|    total_timesteps    | 12263424    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015330589 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.125       |\n",
      "|    mean_step_reward   | 0.13871802  |\n",
      "|    n_updates          | 5984        |\n",
      "|    policyGradLoss     | -0.00806    |\n",
      "|    value_loss         | 0.653       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 557         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 264         |\n",
      "|    total_timesteps    | 12271616    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019905927 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0214     |\n",
      "|    mean_step_reward   | 0.1524275   |\n",
      "|    n_updates          | 5988        |\n",
      "|    policyGradLoss     | -0.0134     |\n",
      "|    value_loss         | 0.204       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 557         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 279         |\n",
      "|    total_timesteps    | 12279808    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019781642 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.188       |\n",
      "|    mean_step_reward   | 0.1381467   |\n",
      "|    n_updates          | 5992        |\n",
      "|    policyGradLoss     | -0.0112     |\n",
      "|    value_loss         | 0.544       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 556         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 294         |\n",
      "|    total_timesteps    | 12288000    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013192636 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.899       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.2         |\n",
      "|    mean_step_reward   | 0.13976184  |\n",
      "|    n_updates          | 5996        |\n",
      "|    policyGradLoss     | -0.00355    |\n",
      "|    value_loss         | 0.689       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 556        |\n",
      "|    iterations         | 21         |\n",
      "|    time_elapsed       | 309        |\n",
      "|    total_timesteps    | 12296192   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01877274 |\n",
      "|    entropy_loss       | -1.87      |\n",
      "|    explained_variance | 0.984      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | 4.62e-05   |\n",
      "|    mean_step_reward   | 0.15404162 |\n",
      "|    n_updates          | 6000       |\n",
      "|    policyGradLoss     | -0.00981   |\n",
      "|    value_loss         | 0.331      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 559         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 322         |\n",
      "|    total_timesteps    | 12304384    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021831032 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0863      |\n",
      "|    mean_step_reward   | 0.13935563  |\n",
      "|    n_updates          | 6004        |\n",
      "|    policyGradLoss     | -0.0153     |\n",
      "|    value_loss         | 0.23        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 560         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 335         |\n",
      "|    total_timesteps    | 12312576    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021063779 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0458     |\n",
      "|    mean_step_reward   | 0.14170954  |\n",
      "|    n_updates          | 6008        |\n",
      "|    policyGradLoss     | -0.0181     |\n",
      "|    value_loss         | 0.14        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 562        |\n",
      "|    iterations         | 24         |\n",
      "|    time_elapsed       | 349        |\n",
      "|    total_timesteps    | 12320768   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01867478 |\n",
      "|    entropy_loss       | -1.87      |\n",
      "|    explained_variance | 0.987      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | 0.0171     |\n",
      "|    mean_step_reward   | 0.14315069 |\n",
      "|    n_updates          | 6012       |\n",
      "|    policyGradLoss     | -0.0092    |\n",
      "|    value_loss         | 0.161      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 563         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 363         |\n",
      "|    total_timesteps    | 12328960    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018711787 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0415     |\n",
      "|    mean_step_reward   | 0.13512497  |\n",
      "|    n_updates          | 6016        |\n",
      "|    policyGradLoss     | -0.0104     |\n",
      "|    value_loss         | 0.16        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 561         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 379         |\n",
      "|    total_timesteps    | 12337152    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027334161 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.994       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.00168     |\n",
      "|    mean_step_reward   | 0.1644367   |\n",
      "|    n_updates          | 6020        |\n",
      "|    policyGradLoss     | -0.0131     |\n",
      "|    value_loss         | 0.167       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 561         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 394         |\n",
      "|    total_timesteps    | 12345344    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025375841 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0155      |\n",
      "|    mean_step_reward   | 0.12622726  |\n",
      "|    n_updates          | 6024        |\n",
      "|    policyGradLoss     | -0.0103     |\n",
      "|    value_loss         | 0.355       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 560         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 409         |\n",
      "|    total_timesteps    | 12353536    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020090561 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0069     |\n",
      "|    mean_step_reward   | 0.14690202  |\n",
      "|    n_updates          | 6028        |\n",
      "|    policyGradLoss     | -0.012      |\n",
      "|    value_loss         | 0.195       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 560         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 424         |\n",
      "|    total_timesteps    | 12361728    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020352714 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.146       |\n",
      "|    mean_step_reward   | 0.14966993  |\n",
      "|    n_updates          | 6032        |\n",
      "|    policyGradLoss     | -0.0109     |\n",
      "|    value_loss         | 0.468       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 559         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 438         |\n",
      "|    total_timesteps    | 12369920    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020773951 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0417     |\n",
      "|    mean_step_reward   | 0.13787657  |\n",
      "|    n_updates          | 6036        |\n",
      "|    policyGradLoss     | -0.0142     |\n",
      "|    value_loss         | 0.16        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 559         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 453         |\n",
      "|    total_timesteps    | 12378112    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024033353 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.039      |\n",
      "|    mean_step_reward   | 0.15287794  |\n",
      "|    n_updates          | 6040        |\n",
      "|    policyGradLoss     | -0.0151     |\n",
      "|    value_loss         | 0.178       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 559        |\n",
      "|    iterations         | 32         |\n",
      "|    time_elapsed       | 468        |\n",
      "|    total_timesteps    | 12386304   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.0218895  |\n",
      "|    entropy_loss       | -1.84      |\n",
      "|    explained_variance | 0.98       |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | 0.0433     |\n",
      "|    mean_step_reward   | 0.14044772 |\n",
      "|    n_updates          | 6044       |\n",
      "|    policyGradLoss     | -0.0125    |\n",
      "|    value_loss         | 0.386      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 558        |\n",
      "|    iterations         | 33         |\n",
      "|    time_elapsed       | 483        |\n",
      "|    total_timesteps    | 12394496   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.0211897  |\n",
      "|    entropy_loss       | -1.86      |\n",
      "|    explained_variance | 0.989      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | -0.00661   |\n",
      "|    mean_step_reward   | 0.14936572 |\n",
      "|    n_updates          | 6048       |\n",
      "|    policyGradLoss     | -0.0122    |\n",
      "|    value_loss         | 0.243      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 558         |\n",
      "|    iterations         | 34          |\n",
      "|    time_elapsed       | 498         |\n",
      "|    total_timesteps    | 12402688    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019933298 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.046       |\n",
      "|    mean_step_reward   | 0.14472593  |\n",
      "|    n_updates          | 6052        |\n",
      "|    policyGradLoss     | -0.00913    |\n",
      "|    value_loss         | 0.396       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 558         |\n",
      "|    iterations         | 35          |\n",
      "|    time_elapsed       | 513         |\n",
      "|    total_timesteps    | 12410880    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020554928 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.00846     |\n",
      "|    mean_step_reward   | 0.14052941  |\n",
      "|    n_updates          | 6056        |\n",
      "|    policyGradLoss     | -0.0147     |\n",
      "|    value_loss         | 0.22        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 558         |\n",
      "|    iterations         | 36          |\n",
      "|    time_elapsed       | 528         |\n",
      "|    total_timesteps    | 12419072    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020678842 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.00837     |\n",
      "|    mean_step_reward   | 0.15334938  |\n",
      "|    n_updates          | 6060        |\n",
      "|    policyGradLoss     | -0.0134     |\n",
      "|    value_loss         | 0.317       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 557         |\n",
      "|    iterations         | 37          |\n",
      "|    time_elapsed       | 543         |\n",
      "|    total_timesteps    | 12427264    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026235307 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0468     |\n",
      "|    mean_step_reward   | 0.13169537  |\n",
      "|    n_updates          | 6064        |\n",
      "|    policyGradLoss     | -0.0168     |\n",
      "|    value_loss         | 0.122       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 557         |\n",
      "|    iterations         | 38          |\n",
      "|    time_elapsed       | 558         |\n",
      "|    total_timesteps    | 12435456    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024111116 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0205     |\n",
      "|    mean_step_reward   | 0.14464644  |\n",
      "|    n_updates          | 6068        |\n",
      "|    policyGradLoss     | -0.0119     |\n",
      "|    value_loss         | 0.231       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 557        |\n",
      "|    iterations         | 39         |\n",
      "|    time_elapsed       | 573        |\n",
      "|    total_timesteps    | 12443648   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02289654 |\n",
      "|    entropy_loss       | -1.84      |\n",
      "|    explained_variance | 0.986      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | -0.0213    |\n",
      "|    mean_step_reward   | 0.13805161 |\n",
      "|    n_updates          | 6072       |\n",
      "|    policyGradLoss     | -0.0137    |\n",
      "|    value_loss         | 0.209      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 557        |\n",
      "|    iterations         | 40         |\n",
      "|    time_elapsed       | 588        |\n",
      "|    total_timesteps    | 12451840   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03154411 |\n",
      "|    entropy_loss       | -1.85      |\n",
      "|    explained_variance | 0.994      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | -0.0376    |\n",
      "|    mean_step_reward   | 0.14792979 |\n",
      "|    n_updates          | 6076       |\n",
      "|    policyGradLoss     | -0.0189    |\n",
      "|    value_loss         | 0.112      |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/SF84G_PT_38.zip\n",
      "[EVAL] Mean Return: 186.300, Best Return: 186.308\n",
      "New best record. Saved to ./runs_smw/best_model_A.zip\n",
      "Saved video to ./runs_smw/videos/step_12451840_mean_186.30.mp4\n",
      "\n",
      "=== Round 10 | Learn 327680 steps (Total trained: 12451840) ===\n",
      "Logging to ./runs_smw/tb/SF84G_1220_20_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 745      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 10       |\n",
      "|    total_timesteps | 12460032 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 634         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 25          |\n",
      "|    total_timesteps    | 12468224    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027178876 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0312      |\n",
      "|    mean_step_reward   | 0.13844112  |\n",
      "|    n_updates          | 6084        |\n",
      "|    policyGradLoss     | -0.0115     |\n",
      "|    value_loss         | 0.399       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 603         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 40          |\n",
      "|    total_timesteps    | 12476416    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020419562 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0442      |\n",
      "|    mean_step_reward   | 0.14794567  |\n",
      "|    n_updates          | 6088        |\n",
      "|    policyGradLoss     | -0.0148     |\n",
      "|    value_loss         | 0.304       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 589        |\n",
      "|    iterations         | 4          |\n",
      "|    time_elapsed       | 55         |\n",
      "|    total_timesteps    | 12484608   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02587737 |\n",
      "|    entropy_loss       | -1.8       |\n",
      "|    explained_variance | 0.994      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | -0.0498    |\n",
      "|    mean_step_reward   | 0.14108145 |\n",
      "|    n_updates          | 6092       |\n",
      "|    policyGradLoss     | -0.0193    |\n",
      "|    value_loss         | 0.107      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 579        |\n",
      "|    iterations         | 5          |\n",
      "|    time_elapsed       | 70         |\n",
      "|    total_timesteps    | 12492800   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02191246 |\n",
      "|    entropy_loss       | -1.81      |\n",
      "|    explained_variance | 0.992      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | -0.0221    |\n",
      "|    mean_step_reward   | 0.1538376  |\n",
      "|    n_updates          | 6096       |\n",
      "|    policyGradLoss     | -0.0147    |\n",
      "|    value_loss         | 0.16       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 573         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 85          |\n",
      "|    total_timesteps    | 12500992    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027730525 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.996       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0487     |\n",
      "|    mean_step_reward   | 0.14527677  |\n",
      "|    n_updates          | 6100        |\n",
      "|    policyGradLoss     | -0.0218     |\n",
      "|    value_loss         | 0.0713      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 569        |\n",
      "|    iterations         | 7          |\n",
      "|    time_elapsed       | 100        |\n",
      "|    total_timesteps    | 12509184   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.0218641  |\n",
      "|    entropy_loss       | -1.8       |\n",
      "|    explained_variance | 0.984      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | 0.204      |\n",
      "|    mean_step_reward   | 0.14676651 |\n",
      "|    n_updates          | 6104       |\n",
      "|    policyGradLoss     | -0.011     |\n",
      "|    value_loss         | 0.325      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 565         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 115         |\n",
      "|    total_timesteps    | 12517376    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026197407 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.994       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0407     |\n",
      "|    mean_step_reward   | 0.14931184  |\n",
      "|    n_updates          | 6108        |\n",
      "|    policyGradLoss     | -0.0173     |\n",
      "|    value_loss         | 0.0901      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 578         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 127         |\n",
      "|    total_timesteps    | 12525568    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026757035 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.994       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0514     |\n",
      "|    mean_step_reward   | 0.14630152  |\n",
      "|    n_updates          | 6112        |\n",
      "|    policyGradLoss     | -0.0191     |\n",
      "|    value_loss         | 0.114       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 580         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 141         |\n",
      "|    total_timesteps    | 12533760    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024841547 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.995       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0474     |\n",
      "|    mean_step_reward   | 0.148086    |\n",
      "|    n_updates          | 6116        |\n",
      "|    policyGradLoss     | -0.0168     |\n",
      "|    value_loss         | 0.123       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 582         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 154         |\n",
      "|    total_timesteps    | 12541952    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019806104 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0333      |\n",
      "|    mean_step_reward   | 0.14015128  |\n",
      "|    n_updates          | 6120        |\n",
      "|    policyGradLoss     | -0.0101     |\n",
      "|    value_loss         | 0.314       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 583         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 168         |\n",
      "|    total_timesteps    | 12550144    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018596303 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0534      |\n",
      "|    mean_step_reward   | 0.1478108   |\n",
      "|    n_updates          | 6124        |\n",
      "|    policyGradLoss     | -0.00603    |\n",
      "|    value_loss         | 0.209       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 578         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 184         |\n",
      "|    total_timesteps    | 12558336    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027491352 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.994       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0352     |\n",
      "|    mean_step_reward   | 0.14670289  |\n",
      "|    n_updates          | 6128        |\n",
      "|    policyGradLoss     | -0.0111     |\n",
      "|    value_loss         | 0.108       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 576        |\n",
      "|    iterations         | 14         |\n",
      "|    time_elapsed       | 199        |\n",
      "|    total_timesteps    | 12566528   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01988313 |\n",
      "|    entropy_loss       | -1.85      |\n",
      "|    explained_variance | 0.996      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | -0.0375    |\n",
      "|    mean_step_reward   | 0.1592509  |\n",
      "|    n_updates          | 6132       |\n",
      "|    policyGradLoss     | -0.0133    |\n",
      "|    value_loss         | 0.0992     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 574        |\n",
      "|    iterations         | 15         |\n",
      "|    time_elapsed       | 214        |\n",
      "|    total_timesteps    | 12574720   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02294756 |\n",
      "|    entropy_loss       | -1.79      |\n",
      "|    explained_variance | 0.988      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | -0.00294   |\n",
      "|    mean_step_reward   | 0.13137892 |\n",
      "|    n_updates          | 6136       |\n",
      "|    policyGradLoss     | -0.0132    |\n",
      "|    value_loss         | 0.204      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 572         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 229         |\n",
      "|    total_timesteps    | 12582912    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025511365 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.997       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0406     |\n",
      "|    mean_step_reward   | 0.16439952  |\n",
      "|    n_updates          | 6140        |\n",
      "|    policyGradLoss     | -0.0178     |\n",
      "|    value_loss         | 0.104       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 570         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 244         |\n",
      "|    total_timesteps    | 12591104    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015589267 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0119      |\n",
      "|    mean_step_reward   | 0.14002654  |\n",
      "|    n_updates          | 6144        |\n",
      "|    policyGradLoss     | -0.0106     |\n",
      "|    value_loss         | 0.41        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 569         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 258         |\n",
      "|    total_timesteps    | 12599296    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021605885 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0306     |\n",
      "|    mean_step_reward   | 0.14087018  |\n",
      "|    n_updates          | 6148        |\n",
      "|    policyGradLoss     | -0.0119     |\n",
      "|    value_loss         | 0.115       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 567        |\n",
      "|    iterations         | 19         |\n",
      "|    time_elapsed       | 274        |\n",
      "|    total_timesteps    | 12607488   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02242551 |\n",
      "|    entropy_loss       | -1.81      |\n",
      "|    explained_variance | 0.986      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | 0.0944     |\n",
      "|    mean_step_reward   | 0.15569112 |\n",
      "|    n_updates          | 6152       |\n",
      "|    policyGradLoss     | -0.00994   |\n",
      "|    value_loss         | 0.451      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 567         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 288         |\n",
      "|    total_timesteps    | 12615680    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027350694 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.995       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0656     |\n",
      "|    mean_step_reward   | 0.1385991   |\n",
      "|    n_updates          | 6156        |\n",
      "|    policyGradLoss     | -0.0206     |\n",
      "|    value_loss         | 0.0608      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 565         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 304         |\n",
      "|    total_timesteps    | 12623872    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014748876 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.00429    |\n",
      "|    mean_step_reward   | 0.16529019  |\n",
      "|    n_updates          | 6160        |\n",
      "|    policyGradLoss     | -0.00816    |\n",
      "|    value_loss         | 0.202       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 564         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 319         |\n",
      "|    total_timesteps    | 12632064    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022757133 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.993       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0221     |\n",
      "|    mean_step_reward   | 0.13729952  |\n",
      "|    n_updates          | 6164        |\n",
      "|    policyGradLoss     | -0.0172     |\n",
      "|    value_loss         | 0.132       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 563         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 334         |\n",
      "|    total_timesteps    | 12640256    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017183369 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0918      |\n",
      "|    mean_step_reward   | 0.154548    |\n",
      "|    n_updates          | 6168        |\n",
      "|    policyGradLoss     | -0.00585    |\n",
      "|    value_loss         | 0.331       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 562         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 349         |\n",
      "|    total_timesteps    | 12648448    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019021388 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.997       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0313     |\n",
      "|    mean_step_reward   | 0.15395856  |\n",
      "|    n_updates          | 6172        |\n",
      "|    policyGradLoss     | -0.016      |\n",
      "|    value_loss         | 0.0853      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 562         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 364         |\n",
      "|    total_timesteps    | 12656640    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022786207 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0398     |\n",
      "|    mean_step_reward   | 0.14631812  |\n",
      "|    n_updates          | 6176        |\n",
      "|    policyGradLoss     | -0.0108     |\n",
      "|    value_loss         | 0.235       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 561         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 379         |\n",
      "|    total_timesteps    | 12664832    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019245451 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.124       |\n",
      "|    mean_step_reward   | 0.15700802  |\n",
      "|    n_updates          | 6180        |\n",
      "|    policyGradLoss     | -0.00863    |\n",
      "|    value_loss         | 0.619       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 560        |\n",
      "|    iterations         | 27         |\n",
      "|    time_elapsed       | 394        |\n",
      "|    total_timesteps    | 12673024   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01825481 |\n",
      "|    entropy_loss       | -1.75      |\n",
      "|    explained_variance | 0.968      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | 0.00137    |\n",
      "|    mean_step_reward   | 0.13127339 |\n",
      "|    n_updates          | 6184       |\n",
      "|    policyGradLoss     | -0.0091    |\n",
      "|    value_loss         | 0.398      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 560         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 409         |\n",
      "|    total_timesteps    | 12681216    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016690113 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0678      |\n",
      "|    mean_step_reward   | 0.15183097  |\n",
      "|    n_updates          | 6188        |\n",
      "|    policyGradLoss     | -0.0112     |\n",
      "|    value_loss         | 0.305       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 560         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 424         |\n",
      "|    total_timesteps    | 12689408    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018333199 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0221     |\n",
      "|    mean_step_reward   | 0.14964953  |\n",
      "|    n_updates          | 6192        |\n",
      "|    policyGradLoss     | -0.0104     |\n",
      "|    value_loss         | 0.253       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 559         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 438         |\n",
      "|    total_timesteps    | 12697600    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018013686 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.00336    |\n",
      "|    mean_step_reward   | 0.14541262  |\n",
      "|    n_updates          | 6196        |\n",
      "|    policyGradLoss     | -0.0102     |\n",
      "|    value_loss         | 0.523       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 559         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 453         |\n",
      "|    total_timesteps    | 12705792    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023589943 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.995       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0479     |\n",
      "|    mean_step_reward   | 0.14682662  |\n",
      "|    n_updates          | 6200        |\n",
      "|    policyGradLoss     | -0.02       |\n",
      "|    value_loss         | 0.0778      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 558         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 469         |\n",
      "|    total_timesteps    | 12713984    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024486247 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.995       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0218     |\n",
      "|    mean_step_reward   | 0.16310064  |\n",
      "|    n_updates          | 6204        |\n",
      "|    policyGradLoss     | -0.0141     |\n",
      "|    value_loss         | 0.147       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 557         |\n",
      "|    iterations         | 33          |\n",
      "|    time_elapsed       | 484         |\n",
      "|    total_timesteps    | 12722176    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017152283 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.00765    |\n",
      "|    mean_step_reward   | 0.1455863   |\n",
      "|    n_updates          | 6208        |\n",
      "|    policyGradLoss     | -0.00979    |\n",
      "|    value_loss         | 0.307       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 557         |\n",
      "|    iterations         | 34          |\n",
      "|    time_elapsed       | 499         |\n",
      "|    total_timesteps    | 12730368    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012229652 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0165      |\n",
      "|    mean_step_reward   | 0.14286041  |\n",
      "|    n_updates          | 6212        |\n",
      "|    policyGradLoss     | -0.00858    |\n",
      "|    value_loss         | 0.37        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 556         |\n",
      "|    iterations         | 35          |\n",
      "|    time_elapsed       | 514         |\n",
      "|    total_timesteps    | 12738560    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018271867 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0107      |\n",
      "|    mean_step_reward   | 0.14277959  |\n",
      "|    n_updates          | 6216        |\n",
      "|    policyGradLoss     | -0.0113     |\n",
      "|    value_loss         | 0.249       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 556         |\n",
      "|    iterations         | 36          |\n",
      "|    time_elapsed       | 529         |\n",
      "|    total_timesteps    | 12746752    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018194053 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0453      |\n",
      "|    mean_step_reward   | 0.15392667  |\n",
      "|    n_updates          | 6220        |\n",
      "|    policyGradLoss     | -0.0117     |\n",
      "|    value_loss         | 0.352       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 556         |\n",
      "|    iterations         | 37          |\n",
      "|    time_elapsed       | 544         |\n",
      "|    total_timesteps    | 12754944    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020697383 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0157     |\n",
      "|    mean_step_reward   | 0.15226206  |\n",
      "|    n_updates          | 6224        |\n",
      "|    policyGradLoss     | -0.0101     |\n",
      "|    value_loss         | 0.183       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 555         |\n",
      "|    iterations         | 38          |\n",
      "|    time_elapsed       | 559         |\n",
      "|    total_timesteps    | 12763136    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013221763 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0172     |\n",
      "|    mean_step_reward   | 0.14534727  |\n",
      "|    n_updates          | 6228        |\n",
      "|    policyGradLoss     | -0.00829    |\n",
      "|    value_loss         | 0.21        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 557         |\n",
      "|    iterations         | 39          |\n",
      "|    time_elapsed       | 572         |\n",
      "|    total_timesteps    | 12771328    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017682815 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0272     |\n",
      "|    mean_step_reward   | 0.1568208   |\n",
      "|    n_updates          | 6232        |\n",
      "|    policyGradLoss     | -0.012      |\n",
      "|    value_loss         | 0.226       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 558         |\n",
      "|    iterations         | 40          |\n",
      "|    time_elapsed       | 586         |\n",
      "|    total_timesteps    | 12779520    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025051195 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.996       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0421     |\n",
      "|    mean_step_reward   | 0.15351847  |\n",
      "|    n_updates          | 6236        |\n",
      "|    policyGradLoss     | -0.0166     |\n",
      "|    value_loss         | 0.0778      |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/SF84G_PT_39.zip\n",
      "[EVAL] Mean Return: 29.276, Best Return: 29.289\n",
      "Saved video to ./runs_smw/videos/step_12779520_mean_29.28.mp4\n",
      "\n",
      "=== Round 11 | Learn 327680 steps (Total trained: 12779520) ===\n",
      "Logging to ./runs_smw/tb/SF84G_1220_20_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1081     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 12787712 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 852         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 19          |\n",
      "|    total_timesteps    | 12795904    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018827666 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0611      |\n",
      "|    mean_step_reward   | 0.1478585   |\n",
      "|    n_updates          | 6244        |\n",
      "|    policyGradLoss     | -0.00637    |\n",
      "|    value_loss         | 0.429       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 718         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 34          |\n",
      "|    total_timesteps    | 12804096    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020489847 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.107       |\n",
      "|    mean_step_reward   | 0.13446403  |\n",
      "|    n_updates          | 6248        |\n",
      "|    policyGradLoss     | -0.0126     |\n",
      "|    value_loss         | 0.259       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 667         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 49          |\n",
      "|    total_timesteps    | 12812288    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018916108 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.109       |\n",
      "|    mean_step_reward   | 0.13687173  |\n",
      "|    n_updates          | 6252        |\n",
      "|    policyGradLoss     | -0.00709    |\n",
      "|    value_loss         | 0.47        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 640         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 63          |\n",
      "|    total_timesteps    | 12820480    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021499317 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.033      |\n",
      "|    mean_step_reward   | 0.13433799  |\n",
      "|    n_updates          | 6256        |\n",
      "|    policyGradLoss     | -0.0123     |\n",
      "|    value_loss         | 0.26        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 622         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 78          |\n",
      "|    total_timesteps    | 12828672    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013211152 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.03        |\n",
      "|    mean_step_reward   | 0.14966914  |\n",
      "|    n_updates          | 6260        |\n",
      "|    policyGradLoss     | -0.00716    |\n",
      "|    value_loss         | 0.395       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 612         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 93          |\n",
      "|    total_timesteps    | 12836864    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020430569 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0219     |\n",
      "|    mean_step_reward   | 0.1303314   |\n",
      "|    n_updates          | 6264        |\n",
      "|    policyGradLoss     | -0.0109     |\n",
      "|    value_loss         | 0.257       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 602         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 108         |\n",
      "|    total_timesteps    | 12845056    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014655908 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0052      |\n",
      "|    mean_step_reward   | 0.15711686  |\n",
      "|    n_updates          | 6268        |\n",
      "|    policyGradLoss     | -0.00574    |\n",
      "|    value_loss         | 0.386       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 595        |\n",
      "|    iterations         | 9          |\n",
      "|    time_elapsed       | 123        |\n",
      "|    total_timesteps    | 12853248   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02497945 |\n",
      "|    entropy_loss       | -1.8       |\n",
      "|    explained_variance | 0.989      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | -0.0371    |\n",
      "|    mean_step_reward   | 0.14739093 |\n",
      "|    n_updates          | 6272       |\n",
      "|    policyGradLoss     | -0.0141    |\n",
      "|    value_loss         | 0.216      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 591         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 138         |\n",
      "|    total_timesteps    | 12861440    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022372738 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0304     |\n",
      "|    mean_step_reward   | 0.15304884  |\n",
      "|    n_updates          | 6276        |\n",
      "|    policyGradLoss     | -0.0141     |\n",
      "|    value_loss         | 0.171       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 587         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 153         |\n",
      "|    total_timesteps    | 12869632    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021029143 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0288     |\n",
      "|    mean_step_reward   | 0.14357209  |\n",
      "|    n_updates          | 6280        |\n",
      "|    policyGradLoss     | -0.0125     |\n",
      "|    value_loss         | 0.168       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 583        |\n",
      "|    iterations         | 12         |\n",
      "|    time_elapsed       | 168        |\n",
      "|    total_timesteps    | 12877824   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02926113 |\n",
      "|    entropy_loss       | -1.78      |\n",
      "|    explained_variance | 0.985      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | -0.016     |\n",
      "|    mean_step_reward   | 0.14075363 |\n",
      "|    n_updates          | 6284       |\n",
      "|    policyGradLoss     | -0.0172    |\n",
      "|    value_loss         | 0.171      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 581         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 183         |\n",
      "|    total_timesteps    | 12886016    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013435602 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.996       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0113     |\n",
      "|    mean_step_reward   | 0.17330705  |\n",
      "|    n_updates          | 6288        |\n",
      "|    policyGradLoss     | -0.0122     |\n",
      "|    value_loss         | 0.135       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 578         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 198         |\n",
      "|    total_timesteps    | 12894208    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026718464 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0173     |\n",
      "|    mean_step_reward   | 0.13121773  |\n",
      "|    n_updates          | 6292        |\n",
      "|    policyGradLoss     | -0.0128     |\n",
      "|    value_loss         | 0.185       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 575         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 213         |\n",
      "|    total_timesteps    | 12902400    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024264641 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0319     |\n",
      "|    mean_step_reward   | 0.159538    |\n",
      "|    n_updates          | 6296        |\n",
      "|    policyGradLoss     | -0.0128     |\n",
      "|    value_loss         | 0.216       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 573         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 228         |\n",
      "|    total_timesteps    | 12910592    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020050067 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0275     |\n",
      "|    mean_step_reward   | 0.14062384  |\n",
      "|    n_updates          | 6300        |\n",
      "|    policyGradLoss     | -0.0184     |\n",
      "|    value_loss         | 0.15        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 571         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 243         |\n",
      "|    total_timesteps    | 12918784    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024985848 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.024      |\n",
      "|    mean_step_reward   | 0.15144172  |\n",
      "|    n_updates          | 6304        |\n",
      "|    policyGradLoss     | -0.0132     |\n",
      "|    value_loss         | 0.192       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 570         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 258         |\n",
      "|    total_timesteps    | 12926976    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025896378 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.996       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.00713    |\n",
      "|    mean_step_reward   | 0.14734957  |\n",
      "|    n_updates          | 6308        |\n",
      "|    policyGradLoss     | -0.018      |\n",
      "|    value_loss         | 0.103       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 569          |\n",
      "|    iterations         | 19           |\n",
      "|    time_elapsed       | 273          |\n",
      "|    total_timesteps    | 12935168     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0144593995 |\n",
      "|    entropy_loss       | -1.76        |\n",
      "|    explained_variance | 0.98         |\n",
      "|    learning_rate      | 0.0002       |\n",
      "|    loss               | 0.0731       |\n",
      "|    mean_step_reward   | 0.1451843    |\n",
      "|    n_updates          | 6312         |\n",
      "|    policyGradLoss     | -0.00933     |\n",
      "|    value_loss         | 0.246        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 568          |\n",
      "|    iterations         | 20           |\n",
      "|    time_elapsed       | 288          |\n",
      "|    total_timesteps    | 12943360     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0139491195 |\n",
      "|    entropy_loss       | -1.84        |\n",
      "|    explained_variance | 0.969        |\n",
      "|    learning_rate      | 0.0002       |\n",
      "|    loss               | 0.075        |\n",
      "|    mean_step_reward   | 0.15393952   |\n",
      "|    n_updates          | 6316         |\n",
      "|    policyGradLoss     | -0.0054      |\n",
      "|    value_loss         | 0.294        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 567         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 302         |\n",
      "|    total_timesteps    | 12951552    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011537661 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0205     |\n",
      "|    mean_step_reward   | 0.13840564  |\n",
      "|    n_updates          | 6320        |\n",
      "|    policyGradLoss     | -0.00595    |\n",
      "|    value_loss         | 0.215       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 567         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 317         |\n",
      "|    total_timesteps    | 12959744    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022111908 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.996       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0542     |\n",
      "|    mean_step_reward   | 0.16250354  |\n",
      "|    n_updates          | 6324        |\n",
      "|    policyGradLoss     | -0.0171     |\n",
      "|    value_loss         | 0.0887      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 566         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 332         |\n",
      "|    total_timesteps    | 12967936    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015575023 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0365      |\n",
      "|    mean_step_reward   | 0.15014625  |\n",
      "|    n_updates          | 6328        |\n",
      "|    policyGradLoss     | -0.0106     |\n",
      "|    value_loss         | 0.37        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 565         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 347         |\n",
      "|    total_timesteps    | 12976128    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026969988 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.993       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0527     |\n",
      "|    mean_step_reward   | 0.14792112  |\n",
      "|    n_updates          | 6332        |\n",
      "|    policyGradLoss     | -0.0153     |\n",
      "|    value_loss         | 0.113       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 565         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 362         |\n",
      "|    total_timesteps    | 12984320    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025528707 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.997       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0352     |\n",
      "|    mean_step_reward   | 0.15609768  |\n",
      "|    n_updates          | 6336        |\n",
      "|    policyGradLoss     | -0.0145     |\n",
      "|    value_loss         | 0.105       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 564        |\n",
      "|    iterations         | 26         |\n",
      "|    time_elapsed       | 377        |\n",
      "|    total_timesteps    | 12992512   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02197932 |\n",
      "|    entropy_loss       | -1.74      |\n",
      "|    explained_variance | 0.991      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | -0.0247    |\n",
      "|    mean_step_reward   | 0.15472469 |\n",
      "|    n_updates          | 6340       |\n",
      "|    policyGradLoss     | -0.0129    |\n",
      "|    value_loss         | 0.15       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 563         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 392         |\n",
      "|    total_timesteps    | 13000704    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018591333 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0376      |\n",
      "|    mean_step_reward   | 0.16181788  |\n",
      "|    n_updates          | 6344        |\n",
      "|    policyGradLoss     | -0.0107     |\n",
      "|    value_loss         | 0.239       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 562         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 407         |\n",
      "|    total_timesteps    | 13008896    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022705944 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0276     |\n",
      "|    mean_step_reward   | 0.1429048   |\n",
      "|    n_updates          | 6348        |\n",
      "|    policyGradLoss     | -0.0153     |\n",
      "|    value_loss         | 0.138       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 564         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 420         |\n",
      "|    total_timesteps    | 13017088    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017698668 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.995       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.036      |\n",
      "|    mean_step_reward   | 0.16633448  |\n",
      "|    n_updates          | 6352        |\n",
      "|    policyGradLoss     | -0.017      |\n",
      "|    value_loss         | 0.128       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 565         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 434         |\n",
      "|    total_timesteps    | 13025280    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014413909 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0115      |\n",
      "|    mean_step_reward   | 0.1499613   |\n",
      "|    n_updates          | 6356        |\n",
      "|    policyGradLoss     | -0.0118     |\n",
      "|    value_loss         | 0.266       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 566        |\n",
      "|    iterations         | 31         |\n",
      "|    time_elapsed       | 448        |\n",
      "|    total_timesteps    | 13033472   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01962526 |\n",
      "|    entropy_loss       | -1.77      |\n",
      "|    explained_variance | 0.993      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | -0.0369    |\n",
      "|    mean_step_reward   | 0.15030031 |\n",
      "|    n_updates          | 6360       |\n",
      "|    policyGradLoss     | -0.0119    |\n",
      "|    value_loss         | 0.105      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 566         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 462         |\n",
      "|    total_timesteps    | 13041664    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016570002 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0701      |\n",
      "|    mean_step_reward   | 0.15900144  |\n",
      "|    n_updates          | 6364        |\n",
      "|    policyGradLoss     | -0.00901    |\n",
      "|    value_loss         | 0.34        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 565         |\n",
      "|    iterations         | 33          |\n",
      "|    time_elapsed       | 477         |\n",
      "|    total_timesteps    | 13049856    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019627731 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0188     |\n",
      "|    mean_step_reward   | 0.14124465  |\n",
      "|    n_updates          | 6368        |\n",
      "|    policyGradLoss     | -0.0125     |\n",
      "|    value_loss         | 0.265       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 565         |\n",
      "|    iterations         | 34          |\n",
      "|    time_elapsed       | 492         |\n",
      "|    total_timesteps    | 13058048    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021679953 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0205     |\n",
      "|    mean_step_reward   | 0.148765    |\n",
      "|    n_updates          | 6372        |\n",
      "|    policyGradLoss     | -0.00541    |\n",
      "|    value_loss         | 0.248       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 565         |\n",
      "|    iterations         | 35          |\n",
      "|    time_elapsed       | 507         |\n",
      "|    total_timesteps    | 13066240    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018984552 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.193       |\n",
      "|    mean_step_reward   | 0.13585694  |\n",
      "|    n_updates          | 6376        |\n",
      "|    policyGradLoss     | -0.0122     |\n",
      "|    value_loss         | 0.401       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 564         |\n",
      "|    iterations         | 36          |\n",
      "|    time_elapsed       | 522         |\n",
      "|    total_timesteps    | 13074432    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019665178 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.00171     |\n",
      "|    mean_step_reward   | 0.15067306  |\n",
      "|    n_updates          | 6380        |\n",
      "|    policyGradLoss     | -0.0119     |\n",
      "|    value_loss         | 0.355       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 564         |\n",
      "|    iterations         | 37          |\n",
      "|    time_elapsed       | 536         |\n",
      "|    total_timesteps    | 13082624    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023876231 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.993       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0419     |\n",
      "|    mean_step_reward   | 0.140538    |\n",
      "|    n_updates          | 6384        |\n",
      "|    policyGradLoss     | -0.0162     |\n",
      "|    value_loss         | 0.11        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 564        |\n",
      "|    iterations         | 38         |\n",
      "|    time_elapsed       | 551        |\n",
      "|    total_timesteps    | 13090816   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02136974 |\n",
      "|    entropy_loss       | -1.74      |\n",
      "|    explained_variance | 0.981      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | -0.0147    |\n",
      "|    mean_step_reward   | 0.14565752 |\n",
      "|    n_updates          | 6388       |\n",
      "|    policyGradLoss     | -0.0151    |\n",
      "|    value_loss         | 0.296      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 563         |\n",
      "|    iterations         | 39          |\n",
      "|    time_elapsed       | 566         |\n",
      "|    total_timesteps    | 13099008    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023529815 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0122     |\n",
      "|    mean_step_reward   | 0.1434523   |\n",
      "|    n_updates          | 6392        |\n",
      "|    policyGradLoss     | -0.0127     |\n",
      "|    value_loss         | 0.276       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 563        |\n",
      "|    iterations         | 40         |\n",
      "|    time_elapsed       | 581        |\n",
      "|    total_timesteps    | 13107200   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01987165 |\n",
      "|    entropy_loss       | -1.78      |\n",
      "|    explained_variance | 0.983      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | -0.00112   |\n",
      "|    mean_step_reward   | 0.14375143 |\n",
      "|    n_updates          | 6396       |\n",
      "|    policyGradLoss     | -0.0133    |\n",
      "|    value_loss         | 0.275      |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/SF84G_PT_40.zip\n",
      "[EVAL] Mean Return: 184.600, Best Return: 184.608\n",
      "Saved video to ./runs_smw/videos/step_13107200_mean_184.60.mp4\n",
      "Training finished. Environment closed.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\ntensorboard --logdir=./runs_smw/tb\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_mean = -1e18\n",
    "trained = 9502720\n",
    "round_idx = 0\n",
    "\n",
    "try:\n",
    "    while trained < TOTAL_STEPS:\n",
    "        round_idx += 1\n",
    "        chunk = min(TRAIN_CHUNK, TOTAL_STEPS - trained)\n",
    "        # chunk = 2000\n",
    "\n",
    "        print(f\"\\n=== Round {round_idx} | Learn {chunk} steps (Total trained: {trained}) ===\")\n",
    "        \n",
    "        # --- Train ---\n",
    "        model.learn(total_timesteps=chunk, reset_num_timesteps=False, tb_log_name='SF84G_1220_20')\n",
    "        trained += chunk\n",
    "\n",
    "        # --- Save Checkpoint ---\n",
    "        ckpt_path = os.path.join(CKPT_DIR, f\"SF84G_PT_{int(trained/TRAIN_CHUNK)}.zip\")\n",
    "        model.save(ckpt_path)\n",
    "        print(f\"Saved checkpoint: {ckpt_path}\")\n",
    "\n",
    "        # --- Evaluate ---\n",
    "        mean_ret, best_ret = evaluate_policy(\n",
    "            model,\n",
    "            GAME,\n",
    "            STATE,\n",
    "            n_episodes=EVAL_EPISODES,\n",
    "            max_steps=EVAL_MAX_STEPS,\n",
    "        )\n",
    "        print(f\"[EVAL] Mean Return: {mean_ret:.3f}, Best Return: {best_ret:.3f}\")\n",
    "\n",
    "        # --- Save Best Model ---\n",
    "        if mean_ret > best_mean:\n",
    "            best_mean = mean_ret\n",
    "            best_path = os.path.join(LOG_DIR, \"best_model_A.zip\")\n",
    "            model.save(best_path)\n",
    "            print(f\"New best record. Saved to {best_path}\")\n",
    "\n",
    "        # --- Record Video ---\n",
    "        record_video(\n",
    "            model,\n",
    "            GAME,\n",
    "            STATE,\n",
    "            VIDEO_DIR,\n",
    "            video_len=RECORD_STEPS,\n",
    "            prefix=f\"step_{trained}_mean_{mean_ret:.2f}\",\n",
    "        )\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nTraining interrupted manually.\")\n",
    "\n",
    "finally:\n",
    "    train_env.close()\n",
    "    print(\"Training finished. Environment closed.\")\n",
    "    \n",
    "\"\"\"\n",
    "tensorboard --logdir=./runs_smw/tb\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f088b0b3-2418-4866-b332-0312c9f6467f",
   "metadata": {},
   "source": [
    "## Display Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73191bb-e875-4939-b04c-a4670abd9612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import Video\n",
    "# import glob\n",
    "\n",
    "# list_of_files = glob.glob(os.path.join(VIDEO_DIR, '*.mp4')) \n",
    "# if list_of_files:\n",
    "#     latest_file = max(list_of_files, key=os.path.getctime)\n",
    "#     print(f\"Playing: {latest_file}\")\n",
    "#     display(Video(latest_file, embed=True, width=600))\n",
    "# else:\n",
    "#     print(\"No videos found yet.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Lab8 (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
