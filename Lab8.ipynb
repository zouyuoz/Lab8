{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dceedafe-2782-41a1-8119-50ee3d6c21fd",
   "metadata": {},
   "source": [
    "# 2025 DL Lab8: RL Assignment_Super Mario World"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fa555a-e61c-4fb3-b5d0-289b66570139",
   "metadata": {},
   "source": [
    "**Your Answer:**    \n",
    "Hi I'm XXX, XXXXXXXXXX."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5b0974-9605-488a-9fd5-00816e7832cc",
   "metadata": {},
   "source": [
    "## Overview\n",
    "This project implements a **Deep Reinforcement Learning** pipeline to train an autonomous agent for Super Mario World. Leveraging the **Proximal Policy Optimization (PPO)** algorithm, the system interacts with the **stable-retro** environment to master the YoshiIsland1 level. Key components include a custom Vision Backbone for extracting features from raw pixel data and a suite of Environment Wrappers that handle frame preprocessing, action discretization, and reward shaping to facilitate efficient learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02696447",
   "metadata": {},
   "source": [
    "Reward function implement  \n",
    "should do something in the beginning (monster attack)  \n",
    "Custom PPO implement  \n",
    "pre train weight 差不多，主要是 reward function  \n",
    "model weight capacity 1GB  \n",
    "class name 不要動 (可以新增，但是原本有的不要動)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8a0ab9-f86d-4038-833d-761ec81fc4f2",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00b10def-362c-4910-9ed0-f3d0904343ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/m314834001/Lab8/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import retro\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, SubprocVecEnv\n",
    "from stable_baselines3.common.vec_env import VecNormalize\n",
    "\n",
    "from eval import evaluate_policy, record_video\n",
    "from custom_policy import VisionBackbonePolicy, CustomPPO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10361fd-f291-4d93-b50d-cc749a3af588",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b4f6a25-738c-49dd-8e66-ae164b74a45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Game Settings\n",
    "GAME = \"SuperMarioWorld-Snes\"\n",
    "STATE = \"YoshiIsland1\"\n",
    "\n",
    "# Training Settings\n",
    "TOTAL_STEPS = 13_107_200\n",
    "TRAIN_CHUNK =    327_680\n",
    "N_ENVS = 16\n",
    "LEARNING_RATE = 1e-4\n",
    "\n",
    "# Evaluation & Recording Settings\n",
    "EVAL_EPISODES = 3\n",
    "EVAL_MAX_STEPS = 18000\n",
    "RECORD_STEPS = 1200\n",
    "\n",
    "# Directories\n",
    "LOG_DIR = \"./runs_smw\"\n",
    "VIDEO_DIR       = os.path.join(LOG_DIR, \"videos\")\n",
    "CKPT_DIR        = os.path.join(LOG_DIR, \"checkpoints\")\n",
    "TENSORBOARD_LOG = os.path.join(LOG_DIR, \"tb\")\n",
    "\n",
    "os.makedirs(LOG_DIR,   exist_ok=True)\n",
    "os.makedirs(CKPT_DIR,  exist_ok=True)\n",
    "os.makedirs(VIDEO_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a34b783-0273-4835-ad2e-f9186064f76f",
   "metadata": {},
   "source": [
    "## Environment Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c34213d-2c7c-42b8-922d-bafa285d1ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wrappers import make_base_env\n",
    "def _make_env_thunk(game: str, state: str):\n",
    "    \"\"\"Return a function that creates an environment (for multiprocessing).\"\"\"\n",
    "    def _thunk():\n",
    "        return make_base_env(game, state)\n",
    "    return _thunk\n",
    "\n",
    "def make_vec_env(game: str, state: str, n_envs: int, use_subproc: bool = True):\n",
    "    \"\"\"Create a vectorized environment (multiple envs running in parallel).\"\"\"\n",
    "    env_fns = [_make_env_thunk(game, state) for _ in range(n_envs)]\n",
    "    \n",
    "    if use_subproc and n_envs > 1:\n",
    "        vec_env = SubprocVecEnv(env_fns)\n",
    "    else:\n",
    "        vec_env = DummyVecEnv(env_fns)\n",
    "\n",
    "    return vec_env"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71dff476-ea2e-4262-8780-afb32ef1b233",
   "metadata": {},
   "source": [
    "## Initialize Env & Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8c7c5fe-6421-4dbc-9bd8-822d61769c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment created: SuperMarioWorld-Snes - YoshiIsland1 with 16 parallel envs.\n",
      "[Sucess] Loaded model from runs_smw/checkpoints/P_RWD_18.zip\n",
      "trained: 6225920, round_index: 19\n"
     ]
    }
   ],
   "source": [
    "# 1. Create Training Environment\n",
    "train_env = make_vec_env(GAME, STATE, n_envs=N_ENVS)\n",
    "# train_env = VecNormalize(train_env, norm_obs=True, norm_reward=True, clip_obs=10., clip_reward=10.)\n",
    "print(f\"Environment created: {GAME} - {STATE} with {N_ENVS} parallel envs.\")\n",
    "\n",
    "checkpoint_path = \"None\" # 6225920 (19) 有破壞\n",
    "checkpoint_path = \"runs_smw/checkpoints/P_RWD_18.zip\"\n",
    "\n",
    "best_mean = -1e18\n",
    "trained = 0\n",
    "round_idx = 0\n",
    "\n",
    "# 2. Initialize Model\n",
    "if os.path.exists(checkpoint_path):\n",
    "    # 讀取現有模型\n",
    "    model = CustomPPO.load(\n",
    "        checkpoint_path, \n",
    "        env=train_env,\n",
    "        device=\"cuda:0\" # 確保使用 GPU\n",
    "    )\n",
    "    trained = model.num_timesteps\n",
    "    round_idx = int(trained / TRAIN_CHUNK)\n",
    "    print(f\"[Sucess] Loaded model from {checkpoint_path}\")\n",
    "    print(f\"trained: {trained}, round_index: {round_idx}\")\n",
    "else:\n",
    "    print(f\"[Fail] Can't load {checkpoint_path}. Will use new model\")\n",
    "    model = CustomPPO(\n",
    "        VisionBackbonePolicy,\n",
    "        train_env,\n",
    "        policy_kwargs   = dict(normalize_images=False),\n",
    "        n_epochs        = 4,\n",
    "        n_steps         = 512,\n",
    "        batch_size      = 512,\n",
    "        learning_rate   = LEARNING_RATE,\n",
    "        verbose         = 1,\n",
    "        gamma           = 0.99,\n",
    "        kl_coef         = 1,\n",
    "        clip_range      = 0.125,\n",
    "        tensorboard_log = TENSORBOARD_LOG,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1cb3d0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(\"policy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7eb7a896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import glob\n",
    "# from custom_policy import CustomPPO\n",
    "# from eval import record_video  # 確保 eval.py 在同一目錄下\n",
    "\n",
    "# # ================= 設定區 =================\n",
    "# # 遊戲設定 (請確保跟訓練時一致)\n",
    "# # target_numbers = [3932160, 6225920, 12451840] \n",
    "\n",
    "# # 方法 B: 自動搜尋資料夾下所有 PIPE_{number}.zip (如果你想全部測的話，把下面解註解)\n",
    "# files = glob.glob(os.path.join(CKPT_DIR, \"SF84G_*.zip\"))\n",
    "# target_numbers = list(range(35, 40))\n",
    "\n",
    "# # ================= 執行迴圈 =================\n",
    "# print(f\"準備測試以下 Checkpoints: {target_numbers}\")\n",
    "\n",
    "# for num in target_numbers:\n",
    "#     model_path = os.path.join(CKPT_DIR, f\"PIPE_{num}.zip\")\n",
    "    \n",
    "#     # 檢查檔案是否存在\n",
    "#     if not os.path.exists(model_path):\n",
    "#         print(f\"⚠️ 找不到檔案: {model_path}，跳過。\")\n",
    "#         continue\n",
    "    \n",
    "#     print(f\"\\n[{num}] 正在載入模型: {model_path} ...\")\n",
    "    \n",
    "#     try:\n",
    "#         # 1. 載入模型 (不需要 env 參數也能載入權重)\n",
    "#         # 如果你有改過 CustomPPO 的參數，load 會自動讀取 zip 裡的設定\n",
    "#         model = CustomPPO.load(model_path, device=\"auto\") # device=\"auto\" 會自動用 GPU\n",
    "        \n",
    "#         # 2. 錄製影片\n",
    "#         prefix_name = f\"test_{num}\"\n",
    "#         print(f\"[{num}] 正在錄影 (長度 {RECORD_STEPS} steps)...\")\n",
    "        \n",
    "#         record_video(\n",
    "#             model=model,\n",
    "#             game=GAME,\n",
    "#             state=STATE,\n",
    "#             out_dir=VIDEO_DIR,\n",
    "#             video_len=RECORD_STEPS,\n",
    "#             prefix=prefix_name\n",
    "#         )\n",
    "#         print(f\"✅ 完成！影片已儲存為 {prefix_name}.mp4\")\n",
    "        \n",
    "#     except Exception as e:\n",
    "#         print(f\"❌ 發生錯誤 (Model: {num}): {e}\")\n",
    "\n",
    "# print(\"\\n所有測試結束。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f594e443-843f-42c1-9fc6-3fbc82962021",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3af4932-c531-4113-a33a-defc6fb5858e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Round 20 | Learn 327680 steps (Total trained: 6225920) ===\n",
      "Logging to ./runs_smw/tb/P_RWD18_0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/m314834001/Lab8/.venv/lib/python3.12/site-packages/rich/live.py:256: UserWarning: install \"ipywidgets\" for \n",
       "Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/m314834001/Lab8/.venv/lib/python3.12/site-packages/rich/live.py:256: UserWarning: install \"ipywidgets\" for \n",
       "Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 928     |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 8       |\n",
      "|    total_timesteps | 6234112 |\n",
      "--------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 823          |\n",
      "|    iterations         | 2            |\n",
      "|    time_elapsed       | 19           |\n",
      "|    total_timesteps    | 6242304      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0046068337 |\n",
      "|    entropy_loss       | -2.33        |\n",
      "|    explained_variance | 0.944        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.135        |\n",
      "|    mean_step_reward   | 0.0104382355 |\n",
      "|    n_updates          | 3044         |\n",
      "|    policyGradLoss     | -0.002       |\n",
      "|    value_loss         | 0.683        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 764          |\n",
      "|    iterations         | 3            |\n",
      "|    time_elapsed       | 32           |\n",
      "|    total_timesteps    | 6250496      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0023845863 |\n",
      "|    entropy_loss       | -2.32        |\n",
      "|    explained_variance | 0.928        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.729        |\n",
      "|    mean_step_reward   | 0.019126218  |\n",
      "|    n_updates          | 3048         |\n",
      "|    policyGradLoss     | 0.000508     |\n",
      "|    value_loss         | 5.42         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 762          |\n",
      "|    iterations         | 4            |\n",
      "|    time_elapsed       | 42           |\n",
      "|    total_timesteps    | 6258688      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0035063038 |\n",
      "|    entropy_loss       | -2.26        |\n",
      "|    explained_variance | 0.898        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 5.03         |\n",
      "|    mean_step_reward   | 0.09619921   |\n",
      "|    n_updates          | 3052         |\n",
      "|    policyGradLoss     | 0.000285     |\n",
      "|    value_loss         | 18.2         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 738         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 55          |\n",
      "|    total_timesteps    | 6266880     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.006966048 |\n",
      "|    entropy_loss       | -2.27       |\n",
      "|    explained_variance | 0.876       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.19        |\n",
      "|    mean_step_reward   | 0.07206438  |\n",
      "|    n_updates          | 3056        |\n",
      "|    policyGradLoss     | -6.54e-05   |\n",
      "|    value_loss         | 16.1        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 728         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 67          |\n",
      "|    total_timesteps    | 6275072     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.006505988 |\n",
      "|    entropy_loss       | -2.19       |\n",
      "|    explained_variance | 0.934       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 56.6        |\n",
      "|    mean_step_reward   | 0.21749333  |\n",
      "|    n_updates          | 3060        |\n",
      "|    policyGradLoss     | 0.00319     |\n",
      "|    value_loss         | 125         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 725         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 79          |\n",
      "|    total_timesteps    | 6283264     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.004418902 |\n",
      "|    entropy_loss       | -2.17       |\n",
      "|    explained_variance | 0.943       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 46.7        |\n",
      "|    mean_step_reward   | 0.18216589  |\n",
      "|    n_updates          | 3064        |\n",
      "|    policyGradLoss     | 0.000805    |\n",
      "|    value_loss         | 105         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 718         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 91          |\n",
      "|    total_timesteps    | 6291456     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013284041 |\n",
      "|    entropy_loss       | -2.19       |\n",
      "|    explained_variance | 0.937       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 83.9        |\n",
      "|    mean_step_reward   | 0.40072572  |\n",
      "|    n_updates          | 3068        |\n",
      "|    policyGradLoss     | 0.00264     |\n",
      "|    value_loss         | 213         |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 724          |\n",
      "|    iterations         | 9            |\n",
      "|    time_elapsed       | 101          |\n",
      "|    total_timesteps    | 6299648      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0028769863 |\n",
      "|    entropy_loss       | -2.16        |\n",
      "|    explained_variance | 0.951        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 120          |\n",
      "|    mean_step_reward   | 0.4899049    |\n",
      "|    n_updates          | 3072         |\n",
      "|    policyGradLoss     | 0.000797     |\n",
      "|    value_loss         | 268          |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 717          |\n",
      "|    iterations         | 10           |\n",
      "|    time_elapsed       | 114          |\n",
      "|    total_timesteps    | 6307840      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0009926339 |\n",
      "|    entropy_loss       | -2.12        |\n",
      "|    explained_variance | 0.955        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 140          |\n",
      "|    mean_step_reward   | 0.614131     |\n",
      "|    n_updates          | 3076         |\n",
      "|    policyGradLoss     | -0.000181    |\n",
      "|    value_loss         | 313          |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 720          |\n",
      "|    iterations         | 11           |\n",
      "|    time_elapsed       | 125          |\n",
      "|    total_timesteps    | 6316032      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0075729457 |\n",
      "|    entropy_loss       | -2.32        |\n",
      "|    explained_variance | 0.945        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 30.3         |\n",
      "|    mean_step_reward   | 0.12819214   |\n",
      "|    n_updates          | 3080         |\n",
      "|    policyGradLoss     | 0.00101      |\n",
      "|    value_loss         | 63.9         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 715          |\n",
      "|    iterations         | 12           |\n",
      "|    time_elapsed       | 137          |\n",
      "|    total_timesteps    | 6324224      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0023974292 |\n",
      "|    entropy_loss       | -2.29        |\n",
      "|    explained_variance | 0.947        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 58           |\n",
      "|    mean_step_reward   | 0.24173513   |\n",
      "|    n_updates          | 3084         |\n",
      "|    policyGradLoss     | 0.00136      |\n",
      "|    value_loss         | 134          |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 711         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 149         |\n",
      "|    total_timesteps    | 6332416     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.004716322 |\n",
      "|    entropy_loss       | -2.29       |\n",
      "|    explained_variance | 0.947       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 63.8        |\n",
      "|    mean_step_reward   | 0.26290137  |\n",
      "|    n_updates          | 3088        |\n",
      "|    policyGradLoss     | 0.00383     |\n",
      "|    value_loss         | 147         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 713         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 160         |\n",
      "|    total_timesteps    | 6340608     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.005032728 |\n",
      "|    entropy_loss       | -2.36       |\n",
      "|    explained_variance | 0.95        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 11.9        |\n",
      "|    mean_step_reward   | 0.098170854 |\n",
      "|    n_updates          | 3092        |\n",
      "|    policyGradLoss     | 0.00253     |\n",
      "|    value_loss         | 45.7        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 710          |\n",
      "|    iterations         | 15           |\n",
      "|    time_elapsed       | 173          |\n",
      "|    total_timesteps    | 6348800      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.003838804  |\n",
      "|    entropy_loss       | -2.41        |\n",
      "|    explained_variance | 0.623        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0467      |\n",
      "|    mean_step_reward   | -0.009356917 |\n",
      "|    n_updates          | 3096         |\n",
      "|    policyGradLoss     | -0.00256     |\n",
      "|    value_loss         | 0.116        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 714          |\n",
      "|    iterations         | 16           |\n",
      "|    time_elapsed       | 183          |\n",
      "|    total_timesteps    | 6356992      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0037904808 |\n",
      "|    entropy_loss       | -2.41        |\n",
      "|    explained_variance | 0.943        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0493      |\n",
      "|    mean_step_reward   | -0.008197289 |\n",
      "|    n_updates          | 3100         |\n",
      "|    policyGradLoss     | -0.0025      |\n",
      "|    value_loss         | 0.0822       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 711           |\n",
      "|    iterations         | 17            |\n",
      "|    time_elapsed       | 195           |\n",
      "|    total_timesteps    | 6365184       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0044809133  |\n",
      "|    entropy_loss       | -2.4          |\n",
      "|    explained_variance | 0.834         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | 0.0478        |\n",
      "|    mean_step_reward   | -0.0062099313 |\n",
      "|    n_updates          | 3104          |\n",
      "|    policyGradLoss     | -0.000861     |\n",
      "|    value_loss         | 0.356         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 710          |\n",
      "|    iterations         | 18           |\n",
      "|    time_elapsed       | 207          |\n",
      "|    total_timesteps    | 6373376      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.008147462  |\n",
      "|    entropy_loss       | -2.4         |\n",
      "|    explained_variance | 0.876        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0187      |\n",
      "|    mean_step_reward   | -0.009747008 |\n",
      "|    n_updates          | 3108         |\n",
      "|    policyGradLoss     | -0.000516    |\n",
      "|    value_loss         | 0.139        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 709          |\n",
      "|    iterations         | 19           |\n",
      "|    time_elapsed       | 219          |\n",
      "|    total_timesteps    | 6381568      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0042443895 |\n",
      "|    entropy_loss       | -2.43        |\n",
      "|    explained_variance | -0.167       |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0645      |\n",
      "|    mean_step_reward   | -0.008695394 |\n",
      "|    n_updates          | 3112         |\n",
      "|    policyGradLoss     | -0.00409     |\n",
      "|    value_loss         | 0.0243       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 707           |\n",
      "|    iterations         | 20            |\n",
      "|    time_elapsed       | 231           |\n",
      "|    total_timesteps    | 6389760       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0037010254  |\n",
      "|    entropy_loss       | -2.4          |\n",
      "|    explained_variance | 0.901         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0344       |\n",
      "|    mean_step_reward   | -0.0052503115 |\n",
      "|    n_updates          | 3116          |\n",
      "|    policyGradLoss     | -0.00374      |\n",
      "|    value_loss         | 0.152         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 709           |\n",
      "|    iterations         | 21            |\n",
      "|    time_elapsed       | 242           |\n",
      "|    total_timesteps    | 6397952       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.004364511   |\n",
      "|    entropy_loss       | -2.3          |\n",
      "|    explained_variance | 0.95          |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | 0.126         |\n",
      "|    mean_step_reward   | -0.0061659366 |\n",
      "|    n_updates          | 3120          |\n",
      "|    policyGradLoss     | -0.00466      |\n",
      "|    value_loss         | 2.05          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 707          |\n",
      "|    iterations         | 22           |\n",
      "|    time_elapsed       | 254          |\n",
      "|    total_timesteps    | 6406144      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0084586525 |\n",
      "|    entropy_loss       | -2.22        |\n",
      "|    explained_variance | 0.896        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 19.8         |\n",
      "|    mean_step_reward   | 0.07113196   |\n",
      "|    n_updates          | 3124         |\n",
      "|    policyGradLoss     | 0.00494      |\n",
      "|    value_loss         | 57.6         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 709          |\n",
      "|    iterations         | 23           |\n",
      "|    time_elapsed       | 265          |\n",
      "|    total_timesteps    | 6414336      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0035888385 |\n",
      "|    entropy_loss       | -2.07        |\n",
      "|    explained_variance | 0.944        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 83.9         |\n",
      "|    mean_step_reward   | 0.37691522   |\n",
      "|    n_updates          | 3128         |\n",
      "|    policyGradLoss     | 0.000124     |\n",
      "|    value_loss         | 215          |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 707          |\n",
      "|    iterations         | 24           |\n",
      "|    time_elapsed       | 278          |\n",
      "|    total_timesteps    | 6422528      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0022985258 |\n",
      "|    entropy_loss       | -2.04        |\n",
      "|    explained_variance | 0.957        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 197          |\n",
      "|    mean_step_reward   | 0.78003573   |\n",
      "|    n_updates          | 3132         |\n",
      "|    policyGradLoss     | -0.000203    |\n",
      "|    value_loss         | 383          |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 706          |\n",
      "|    iterations         | 25           |\n",
      "|    time_elapsed       | 290          |\n",
      "|    total_timesteps    | 6430720      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0022262675 |\n",
      "|    entropy_loss       | -2.13        |\n",
      "|    explained_variance | 0.952        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 132          |\n",
      "|    mean_step_reward   | 0.5428344    |\n",
      "|    n_updates          | 3136         |\n",
      "|    policyGradLoss     | 0.00185      |\n",
      "|    value_loss         | 261          |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 705          |\n",
      "|    iterations         | 26           |\n",
      "|    time_elapsed       | 301          |\n",
      "|    total_timesteps    | 6438912      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0068533868 |\n",
      "|    entropy_loss       | -2.38        |\n",
      "|    explained_variance | 0.542        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0102       |\n",
      "|    mean_step_reward   | -0.004298838 |\n",
      "|    n_updates          | 3140         |\n",
      "|    policyGradLoss     | 0.0029       |\n",
      "|    value_loss         | 3.81         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 704          |\n",
      "|    iterations         | 27           |\n",
      "|    time_elapsed       | 313          |\n",
      "|    total_timesteps    | 6447104      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.004433739  |\n",
      "|    entropy_loss       | -2.4         |\n",
      "|    explained_variance | 0.788        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.00581      |\n",
      "|    mean_step_reward   | -0.006784818 |\n",
      "|    n_updates          | 3144         |\n",
      "|    policyGradLoss     | -0.00543     |\n",
      "|    value_loss         | 0.309        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 706          |\n",
      "|    iterations         | 28           |\n",
      "|    time_elapsed       | 324          |\n",
      "|    total_timesteps    | 6455296      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.003946631  |\n",
      "|    entropy_loss       | -2.28        |\n",
      "|    explained_variance | 0.862        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.893        |\n",
      "|    mean_step_reward   | 0.0033893962 |\n",
      "|    n_updates          | 3148         |\n",
      "|    policyGradLoss     | 0.000865     |\n",
      "|    value_loss         | 4.34         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 705          |\n",
      "|    iterations         | 29           |\n",
      "|    time_elapsed       | 336          |\n",
      "|    total_timesteps    | 6463488      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0036609606 |\n",
      "|    entropy_loss       | -2.32        |\n",
      "|    explained_variance | 0.939        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 16.8         |\n",
      "|    mean_step_reward   | 0.013468011  |\n",
      "|    n_updates          | 3152         |\n",
      "|    policyGradLoss     | 0.00158      |\n",
      "|    value_loss         | 17.1         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 706         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 348         |\n",
      "|    total_timesteps    | 6471680     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.002798321 |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 69.2        |\n",
      "|    mean_step_reward   | 0.30814436  |\n",
      "|    n_updates          | 3156        |\n",
      "|    policyGradLoss     | 7.94e-05    |\n",
      "|    value_loss         | 155         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 704         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 360         |\n",
      "|    total_timesteps    | 6479872     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.002974105 |\n",
      "|    entropy_loss       | -2.08       |\n",
      "|    explained_variance | 0.954       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 93.1        |\n",
      "|    mean_step_reward   | 0.41007197  |\n",
      "|    n_updates          | 3160        |\n",
      "|    policyGradLoss     | 0.00129     |\n",
      "|    value_loss         | 216         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 703         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 372         |\n",
      "|    total_timesteps    | 6488064     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.002137739 |\n",
      "|    entropy_loss       | -2.03       |\n",
      "|    explained_variance | 0.95        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 145         |\n",
      "|    mean_step_reward   | 0.6080828   |\n",
      "|    n_updates          | 3164        |\n",
      "|    policyGradLoss     | 0.00242     |\n",
      "|    value_loss         | 320         |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 703          |\n",
      "|    iterations         | 33           |\n",
      "|    time_elapsed       | 384          |\n",
      "|    total_timesteps    | 6496256      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0019425299 |\n",
      "|    entropy_loss       | -2.19        |\n",
      "|    explained_variance | 0.955        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 85.3         |\n",
      "|    mean_step_reward   | 0.3440233    |\n",
      "|    n_updates          | 3168         |\n",
      "|    policyGradLoss     | 0.000315     |\n",
      "|    value_loss         | 163          |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 702         |\n",
      "|    iterations         | 34          |\n",
      "|    time_elapsed       | 396         |\n",
      "|    total_timesteps    | 6504448     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.003192068 |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.952       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 58.5        |\n",
      "|    mean_step_reward   | 0.3238857   |\n",
      "|    n_updates          | 3172        |\n",
      "|    policyGradLoss     | 0.000892    |\n",
      "|    value_loss         | 169         |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 705          |\n",
      "|    iterations         | 35           |\n",
      "|    time_elapsed       | 406          |\n",
      "|    total_timesteps    | 6512640      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0010042286 |\n",
      "|    entropy_loss       | -2.24        |\n",
      "|    explained_variance | 0.956        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 75.5         |\n",
      "|    mean_step_reward   | 0.3071189    |\n",
      "|    n_updates          | 3176         |\n",
      "|    policyGradLoss     | 0.000415     |\n",
      "|    value_loss         | 156          |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 703          |\n",
      "|    iterations         | 36           |\n",
      "|    time_elapsed       | 419          |\n",
      "|    total_timesteps    | 6520832      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0016487399 |\n",
      "|    entropy_loss       | -2.3         |\n",
      "|    explained_variance | 0.952        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 52.7         |\n",
      "|    mean_step_reward   | 0.18688384   |\n",
      "|    n_updates          | 3180         |\n",
      "|    policyGradLoss     | 0.000977     |\n",
      "|    value_loss         | 89.5         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 704           |\n",
      "|    iterations         | 37            |\n",
      "|    time_elapsed       | 430           |\n",
      "|    total_timesteps    | 6529024       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0036128697  |\n",
      "|    entropy_loss       | -2.44         |\n",
      "|    explained_variance | 0.686         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0546       |\n",
      "|    mean_step_reward   | -0.0096108345 |\n",
      "|    n_updates          | 3184          |\n",
      "|    policyGradLoss     | -0.00388      |\n",
      "|    value_loss         | 0.0717        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 703          |\n",
      "|    iterations         | 38           |\n",
      "|    time_elapsed       | 442          |\n",
      "|    total_timesteps    | 6537216      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0031376402 |\n",
      "|    entropy_loss       | -2.44        |\n",
      "|    explained_variance | 0.799        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.048       |\n",
      "|    mean_step_reward   | -0.009227035 |\n",
      "|    n_updates          | 3188         |\n",
      "|    policyGradLoss     | -0.00212     |\n",
      "|    value_loss         | 0.0598       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 703         |\n",
      "|    iterations         | 39          |\n",
      "|    time_elapsed       | 454         |\n",
      "|    total_timesteps    | 6545408     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011279009 |\n",
      "|    entropy_loss       | -2.34       |\n",
      "|    explained_variance | 0.914       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 25.4        |\n",
      "|    mean_step_reward   | 0.14432082  |\n",
      "|    n_updates          | 3192        |\n",
      "|    policyGradLoss     | 0.00711     |\n",
      "|    value_loss         | 62.7        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 702          |\n",
      "|    iterations         | 40           |\n",
      "|    time_elapsed       | 466          |\n",
      "|    total_timesteps    | 6553600      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0025837873 |\n",
      "|    entropy_loss       | -2.35        |\n",
      "|    explained_variance | 0.919        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 5.18         |\n",
      "|    mean_step_reward   | 0.045413263  |\n",
      "|    n_updates          | 3196         |\n",
      "|    policyGradLoss     | -0.0027      |\n",
      "|    value_loss         | 18.4         |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/P_RWD18_19.zip\n",
      "[EVAL] Mean Return: -1.174, Best Return: -0.294\n",
      "Saved video to ./runs_smw/videos/P_RWD18/P_RWD18_19_-1.17.mp4\n",
      "\n",
      "=== Round 21 | Learn 327680 steps (Total trained: 6553600) ===\n",
      "Logging to ./runs_smw/tb/P_RWD18_0\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 990     |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 8       |\n",
      "|    total_timesteps | 6561792 |\n",
      "--------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 815          |\n",
      "|    iterations         | 2            |\n",
      "|    time_elapsed       | 20           |\n",
      "|    total_timesteps    | 6569984      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0020536731 |\n",
      "|    entropy_loss       | -2.34        |\n",
      "|    explained_variance | 0.89         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.277        |\n",
      "|    mean_step_reward   | -0.008481879 |\n",
      "|    n_updates          | 3204         |\n",
      "|    policyGradLoss     | 0.00188      |\n",
      "|    value_loss         | 2.14         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 32          |\n",
      "|    total_timesteps    | 6578176     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.006499907 |\n",
      "|    entropy_loss       | -2.05       |\n",
      "|    explained_variance | 0.945       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 7.42        |\n",
      "|    mean_step_reward   | 0.008595593 |\n",
      "|    n_updates          | 3208        |\n",
      "|    policyGradLoss     | 0.00477     |\n",
      "|    value_loss         | 22.5        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 739          |\n",
      "|    iterations         | 4            |\n",
      "|    time_elapsed       | 44           |\n",
      "|    total_timesteps    | 6586368      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0074619963 |\n",
      "|    entropy_loss       | -1.79        |\n",
      "|    explained_variance | 0.959        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 4.42         |\n",
      "|    mean_step_reward   | -0.006516577 |\n",
      "|    n_updates          | 3212         |\n",
      "|    policyGradLoss     | 0.00134      |\n",
      "|    value_loss         | 25.9         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 744         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 54          |\n",
      "|    total_timesteps    | 6594560     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008124276 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.904       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 30.2        |\n",
      "|    mean_step_reward   | 0.7170191   |\n",
      "|    n_updates          | 3216        |\n",
      "|    policyGradLoss     | 0.00255     |\n",
      "|    value_loss         | 138         |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 733          |\n",
      "|    iterations         | 6            |\n",
      "|    time_elapsed       | 67           |\n",
      "|    total_timesteps    | 6602752      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0031101964 |\n",
      "|    entropy_loss       | -1.9         |\n",
      "|    explained_variance | 0.937        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 135          |\n",
      "|    mean_step_reward   | 0.6673995    |\n",
      "|    n_updates          | 3220         |\n",
      "|    policyGradLoss     | -0.000156    |\n",
      "|    value_loss         | 306          |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 734          |\n",
      "|    iterations         | 7            |\n",
      "|    time_elapsed       | 78           |\n",
      "|    total_timesteps    | 6610944      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0037634713 |\n",
      "|    entropy_loss       | -1.88        |\n",
      "|    explained_variance | 0.937        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 178          |\n",
      "|    mean_step_reward   | 0.92834353   |\n",
      "|    n_updates          | 3224         |\n",
      "|    policyGradLoss     | 0.00115      |\n",
      "|    value_loss         | 384          |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 724          |\n",
      "|    iterations         | 8            |\n",
      "|    time_elapsed       | 90           |\n",
      "|    total_timesteps    | 6619136      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0030477417 |\n",
      "|    entropy_loss       | -2.08        |\n",
      "|    explained_variance | 0.949        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 107          |\n",
      "|    mean_step_reward   | 0.519269     |\n",
      "|    n_updates          | 3228         |\n",
      "|    policyGradLoss     | 0.00198      |\n",
      "|    value_loss         | 248          |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 717          |\n",
      "|    iterations         | 9            |\n",
      "|    time_elapsed       | 102          |\n",
      "|    total_timesteps    | 6627328      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0026719007 |\n",
      "|    entropy_loss       | -2.2         |\n",
      "|    explained_variance | 0.948        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 76.2         |\n",
      "|    mean_step_reward   | 0.46162203   |\n",
      "|    n_updates          | 3232         |\n",
      "|    policyGradLoss     | 0.00284      |\n",
      "|    value_loss         | 186          |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 716          |\n",
      "|    iterations         | 10           |\n",
      "|    time_elapsed       | 114          |\n",
      "|    total_timesteps    | 6635520      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0028135323 |\n",
      "|    entropy_loss       | -2.32        |\n",
      "|    explained_variance | 0.927        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 18.1         |\n",
      "|    mean_step_reward   | 0.0588533    |\n",
      "|    n_updates          | 3236         |\n",
      "|    policyGradLoss     | 0.00323      |\n",
      "|    value_loss         | 44.3         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 712          |\n",
      "|    iterations         | 11           |\n",
      "|    time_elapsed       | 126          |\n",
      "|    total_timesteps    | 6643712      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0057222843 |\n",
      "|    entropy_loss       | -2.25        |\n",
      "|    explained_variance | 0.936        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 3.42         |\n",
      "|    mean_step_reward   | 0.060724765  |\n",
      "|    n_updates          | 3240         |\n",
      "|    policyGradLoss     | 0.00228      |\n",
      "|    value_loss         | 25.2         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 718          |\n",
      "|    iterations         | 12           |\n",
      "|    time_elapsed       | 136          |\n",
      "|    total_timesteps    | 6651904      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0080752475 |\n",
      "|    entropy_loss       | -2.23        |\n",
      "|    explained_variance | 0.915        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 19.8         |\n",
      "|    mean_step_reward   | 0.175407     |\n",
      "|    n_updates          | 3244         |\n",
      "|    policyGradLoss     | -0.00207     |\n",
      "|    value_loss         | 57.6         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 713          |\n",
      "|    iterations         | 13           |\n",
      "|    time_elapsed       | 149          |\n",
      "|    total_timesteps    | 6660096      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0028305615 |\n",
      "|    entropy_loss       | -2.27        |\n",
      "|    explained_variance | 0.933        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 15.1         |\n",
      "|    mean_step_reward   | 0.29612637   |\n",
      "|    n_updates          | 3248         |\n",
      "|    policyGradLoss     | -0.000112    |\n",
      "|    value_loss         | 51.3         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 714          |\n",
      "|    iterations         | 14           |\n",
      "|    time_elapsed       | 160          |\n",
      "|    total_timesteps    | 6668288      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0023405193 |\n",
      "|    entropy_loss       | -2.19        |\n",
      "|    explained_variance | 0.956        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 72.6         |\n",
      "|    mean_step_reward   | 0.3024817    |\n",
      "|    n_updates          | 3252         |\n",
      "|    policyGradLoss     | -0.000763    |\n",
      "|    value_loss         | 151          |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 710          |\n",
      "|    iterations         | 15           |\n",
      "|    time_elapsed       | 172          |\n",
      "|    total_timesteps    | 6676480      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0019063381 |\n",
      "|    entropy_loss       | -2.19        |\n",
      "|    explained_variance | 0.957        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 102          |\n",
      "|    mean_step_reward   | 0.43875384   |\n",
      "|    n_updates          | 3256         |\n",
      "|    policyGradLoss     | 0.000202     |\n",
      "|    value_loss         | 213          |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 707          |\n",
      "|    iterations         | 16           |\n",
      "|    time_elapsed       | 185          |\n",
      "|    total_timesteps    | 6684672      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0007788242 |\n",
      "|    entropy_loss       | -2.3         |\n",
      "|    explained_variance | 0.962        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 63.3         |\n",
      "|    mean_step_reward   | 0.30257055   |\n",
      "|    n_updates          | 3260         |\n",
      "|    policyGradLoss     | -4.44e-05    |\n",
      "|    value_loss         | 145          |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 707        |\n",
      "|    iterations         | 17         |\n",
      "|    time_elapsed       | 196        |\n",
      "|    total_timesteps    | 6692864    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.00258368 |\n",
      "|    entropy_loss       | -2.36      |\n",
      "|    explained_variance | 0.962      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 25.3       |\n",
      "|    mean_step_reward   | 0.07928694 |\n",
      "|    n_updates          | 3264       |\n",
      "|    policyGradLoss     | -0.00193   |\n",
      "|    value_loss         | 26.7       |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 705          |\n",
      "|    iterations         | 18           |\n",
      "|    time_elapsed       | 208          |\n",
      "|    total_timesteps    | 6701056      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0016722174 |\n",
      "|    entropy_loss       | -2.4         |\n",
      "|    explained_variance | 0.886        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.354        |\n",
      "|    mean_step_reward   | -0.008310698 |\n",
      "|    n_updates          | 3268         |\n",
      "|    policyGradLoss     | -0.00269     |\n",
      "|    value_loss         | 4.36         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 709         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 219         |\n",
      "|    total_timesteps    | 6709248     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.004340958 |\n",
      "|    entropy_loss       | -2.34       |\n",
      "|    explained_variance | 0.952       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 36.3        |\n",
      "|    mean_step_reward   | 0.14480537  |\n",
      "|    n_updates          | 3272        |\n",
      "|    policyGradLoss     | 0.00907     |\n",
      "|    value_loss         | 87.5        |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 706           |\n",
      "|    iterations         | 20            |\n",
      "|    time_elapsed       | 231           |\n",
      "|    total_timesteps    | 6717440       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.00060782756 |\n",
      "|    entropy_loss       | -2.29         |\n",
      "|    explained_variance | 0.962         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | 75.7          |\n",
      "|    mean_step_reward   | 0.3036111     |\n",
      "|    n_updates          | 3276          |\n",
      "|    policyGradLoss     | 7.47e-05      |\n",
      "|    value_loss         | 147           |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 707          |\n",
      "|    iterations         | 21           |\n",
      "|    time_elapsed       | 243          |\n",
      "|    total_timesteps    | 6725632      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0010615478 |\n",
      "|    entropy_loss       | -2.28        |\n",
      "|    explained_variance | 0.962        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 65.3         |\n",
      "|    mean_step_reward   | 0.29975364   |\n",
      "|    n_updates          | 3280         |\n",
      "|    policyGradLoss     | -0.000206    |\n",
      "|    value_loss         | 141          |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 705          |\n",
      "|    iterations         | 22           |\n",
      "|    time_elapsed       | 255          |\n",
      "|    total_timesteps    | 6733824      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0012255138 |\n",
      "|    entropy_loss       | -2.38        |\n",
      "|    explained_variance | 0.964        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 17.9         |\n",
      "|    mean_step_reward   | 0.12671196   |\n",
      "|    n_updates          | 3284         |\n",
      "|    policyGradLoss     | 0.000523     |\n",
      "|    value_loss         | 51.8         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 703          |\n",
      "|    iterations         | 23           |\n",
      "|    time_elapsed       | 267          |\n",
      "|    total_timesteps    | 6742016      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0034677153 |\n",
      "|    entropy_loss       | -2.45        |\n",
      "|    explained_variance | 0.453        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0588      |\n",
      "|    mean_step_reward   | -0.009922259 |\n",
      "|    n_updates          | 3288         |\n",
      "|    policyGradLoss     | -0.00458     |\n",
      "|    value_loss         | 0.0397       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 705          |\n",
      "|    iterations         | 24           |\n",
      "|    time_elapsed       | 278          |\n",
      "|    total_timesteps    | 6750208      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0030849702 |\n",
      "|    entropy_loss       | -2.44        |\n",
      "|    explained_variance | 0.738        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0389      |\n",
      "|    mean_step_reward   | -0.008143004 |\n",
      "|    n_updates          | 3292         |\n",
      "|    policyGradLoss     | -0.00286     |\n",
      "|    value_loss         | 0.079        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 703         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 291         |\n",
      "|    total_timesteps    | 6758400     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.002703927 |\n",
      "|    entropy_loss       | -2.45       |\n",
      "|    explained_variance | 0.345       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0561     |\n",
      "|    mean_step_reward   | -0.01024274 |\n",
      "|    n_updates          | 3296        |\n",
      "|    policyGradLoss     | -0.00466    |\n",
      "|    value_loss         | 0.0305      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 705          |\n",
      "|    iterations         | 26           |\n",
      "|    time_elapsed       | 301          |\n",
      "|    total_timesteps    | 6766592      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0026103589 |\n",
      "|    entropy_loss       | -2.43        |\n",
      "|    explained_variance | 0.877        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0601      |\n",
      "|    mean_step_reward   | -0.010237482 |\n",
      "|    n_updates          | 3300         |\n",
      "|    policyGradLoss     | -0.00511     |\n",
      "|    value_loss         | 0.0416       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 703          |\n",
      "|    iterations         | 27           |\n",
      "|    time_elapsed       | 314          |\n",
      "|    total_timesteps    | 6774784      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0023002282 |\n",
      "|    entropy_loss       | -2.43        |\n",
      "|    explained_variance | 0.727        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0585      |\n",
      "|    mean_step_reward   | -0.009817803 |\n",
      "|    n_updates          | 3304         |\n",
      "|    policyGradLoss     | -0.00181     |\n",
      "|    value_loss         | 0.0737       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 703         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 326         |\n",
      "|    total_timesteps    | 6782976     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.003931232 |\n",
      "|    entropy_loss       | -2.45       |\n",
      "|    explained_variance | 0.453       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0441     |\n",
      "|    mean_step_reward   | -0.0091148  |\n",
      "|    n_updates          | 3308        |\n",
      "|    policyGradLoss     | -0.00425    |\n",
      "|    value_loss         | 0.0263      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 703        |\n",
      "|    iterations         | 29         |\n",
      "|    time_elapsed       | 337        |\n",
      "|    total_timesteps    | 6791168    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.00551749 |\n",
      "|    entropy_loss       | -2.36      |\n",
      "|    explained_variance | 0.942      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 23.1       |\n",
      "|    mean_step_reward   | 0.09539975 |\n",
      "|    n_updates          | 3312       |\n",
      "|    policyGradLoss     | 0.00279    |\n",
      "|    value_loss         | 49         |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 701          |\n",
      "|    iterations         | 30           |\n",
      "|    time_elapsed       | 350          |\n",
      "|    total_timesteps    | 6799360      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0025747968 |\n",
      "|    entropy_loss       | -2.19        |\n",
      "|    explained_variance | 0.962        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 81.5         |\n",
      "|    mean_step_reward   | 0.46392825   |\n",
      "|    n_updates          | 3316         |\n",
      "|    policyGradLoss     | 0.000115     |\n",
      "|    value_loss         | 217          |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 704          |\n",
      "|    iterations         | 31           |\n",
      "|    time_elapsed       | 360          |\n",
      "|    total_timesteps    | 6807552      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0014873348 |\n",
      "|    entropy_loss       | -2.14        |\n",
      "|    explained_variance | 0.957        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 153          |\n",
      "|    mean_step_reward   | 0.6165504    |\n",
      "|    n_updates          | 3320         |\n",
      "|    policyGradLoss     | -0.00119     |\n",
      "|    value_loss         | 297          |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 703          |\n",
      "|    iterations         | 32           |\n",
      "|    time_elapsed       | 372          |\n",
      "|    total_timesteps    | 6815744      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0011268283 |\n",
      "|    entropy_loss       | -2.16        |\n",
      "|    explained_variance | 0.961        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 103          |\n",
      "|    mean_step_reward   | 0.36067528   |\n",
      "|    n_updates          | 3324         |\n",
      "|    policyGradLoss     | -0.000166    |\n",
      "|    value_loss         | 199          |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 704          |\n",
      "|    iterations         | 33           |\n",
      "|    time_elapsed       | 383          |\n",
      "|    total_timesteps    | 6823936      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0007271352 |\n",
      "|    entropy_loss       | -2.15        |\n",
      "|    explained_variance | 0.959        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 102          |\n",
      "|    mean_step_reward   | 0.3031722    |\n",
      "|    n_updates          | 3328         |\n",
      "|    policyGradLoss     | -2.51e-05    |\n",
      "|    value_loss         | 213          |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 702          |\n",
      "|    iterations         | 34           |\n",
      "|    time_elapsed       | 396          |\n",
      "|    total_timesteps    | 6832128      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0034248237 |\n",
      "|    entropy_loss       | -2.18        |\n",
      "|    explained_variance | 0.951        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 61.5         |\n",
      "|    mean_step_reward   | 0.19007498   |\n",
      "|    n_updates          | 3332         |\n",
      "|    policyGradLoss     | 0.00296      |\n",
      "|    value_loss         | 139          |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 702          |\n",
      "|    iterations         | 35           |\n",
      "|    time_elapsed       | 408          |\n",
      "|    total_timesteps    | 6840320      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0048781573 |\n",
      "|    entropy_loss       | -2.31        |\n",
      "|    explained_variance | 0.936        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 37.8         |\n",
      "|    mean_step_reward   | 0.09718703   |\n",
      "|    n_updates          | 3336         |\n",
      "|    policyGradLoss     | 0.00812      |\n",
      "|    value_loss         | 70.5         |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 702        |\n",
      "|    iterations         | 36         |\n",
      "|    time_elapsed       | 419        |\n",
      "|    total_timesteps    | 6848512    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.00332057 |\n",
      "|    entropy_loss       | -2.34      |\n",
      "|    explained_variance | 0.951      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 24.9       |\n",
      "|    mean_step_reward   | 0.14975087 |\n",
      "|    n_updates          | 3340       |\n",
      "|    policyGradLoss     | 0.00219    |\n",
      "|    value_loss         | 59.6       |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 701          |\n",
      "|    iterations         | 37           |\n",
      "|    time_elapsed       | 431          |\n",
      "|    total_timesteps    | 6856704      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0028001943 |\n",
      "|    entropy_loss       | -2.26        |\n",
      "|    explained_variance | 0.94         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 30.5         |\n",
      "|    mean_step_reward   | 0.18728012   |\n",
      "|    n_updates          | 3344         |\n",
      "|    policyGradLoss     | 0.000326     |\n",
      "|    value_loss         | 68.8         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 704          |\n",
      "|    iterations         | 38           |\n",
      "|    time_elapsed       | 442          |\n",
      "|    total_timesteps    | 6864896      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0027540037 |\n",
      "|    entropy_loss       | -2.28        |\n",
      "|    explained_variance | 0.949        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 3.13         |\n",
      "|    mean_step_reward   | 0.024473099  |\n",
      "|    n_updates          | 3348         |\n",
      "|    policyGradLoss     | 0.00131      |\n",
      "|    value_loss         | 14.1         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 702         |\n",
      "|    iterations         | 39          |\n",
      "|    time_elapsed       | 454         |\n",
      "|    total_timesteps    | 6873088     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.002321618 |\n",
      "|    entropy_loss       | -2.32       |\n",
      "|    explained_variance | 0.882       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 7.19        |\n",
      "|    mean_step_reward   | 0.051818922 |\n",
      "|    n_updates          | 3352        |\n",
      "|    policyGradLoss     | -0.00165    |\n",
      "|    value_loss         | 31.4        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 703          |\n",
      "|    iterations         | 40           |\n",
      "|    time_elapsed       | 466          |\n",
      "|    total_timesteps    | 6881280      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0010835681 |\n",
      "|    entropy_loss       | -2.31        |\n",
      "|    explained_variance | 0.912        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 2.28         |\n",
      "|    mean_step_reward   | 0.18950848   |\n",
      "|    n_updates          | 3356         |\n",
      "|    policyGradLoss     | -0.000451    |\n",
      "|    value_loss         | 24.3         |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/P_RWD18_20.zip\n",
      "[EVAL] Mean Return: -0.544, Best Return: 1.056\n",
      "Saved video to ./runs_smw/videos/P_RWD18/P_RWD18_20_-0.54.mp4\n",
      "\n",
      "=== Round 22 | Learn 327680 steps (Total trained: 6881280) ===\n",
      "Logging to ./runs_smw/tb/P_RWD18_0\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1103    |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 7       |\n",
      "|    total_timesteps | 6889472 |\n",
      "--------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 838          |\n",
      "|    iterations         | 2            |\n",
      "|    time_elapsed       | 19           |\n",
      "|    total_timesteps    | 6897664      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0039384817 |\n",
      "|    entropy_loss       | -2.28        |\n",
      "|    explained_variance | 0.949        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 17.3         |\n",
      "|    mean_step_reward   | 0.11140385   |\n",
      "|    n_updates          | 3364         |\n",
      "|    policyGradLoss     | 0.00183      |\n",
      "|    value_loss         | 84.2         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 810         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 30          |\n",
      "|    total_timesteps    | 6905856     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.004028839 |\n",
      "|    entropy_loss       | -2.33       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.141       |\n",
      "|    mean_step_reward   | -0.00423944 |\n",
      "|    n_updates          | 3368        |\n",
      "|    policyGradLoss     | -0.00669    |\n",
      "|    value_loss         | 6.26        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 767          |\n",
      "|    iterations         | 4            |\n",
      "|    time_elapsed       | 42           |\n",
      "|    total_timesteps    | 6914048      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0025181589 |\n",
      "|    entropy_loss       | -2.38        |\n",
      "|    explained_variance | 0.928        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.646        |\n",
      "|    mean_step_reward   | 0.025280934  |\n",
      "|    n_updates          | 3372         |\n",
      "|    policyGradLoss     | 0.0032       |\n",
      "|    value_loss         | 6.27         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 768          |\n",
      "|    iterations         | 5            |\n",
      "|    time_elapsed       | 53           |\n",
      "|    total_timesteps    | 6922240      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0019432666 |\n",
      "|    entropy_loss       | -2.42        |\n",
      "|    explained_variance | 0.74         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 1.19         |\n",
      "|    mean_step_reward   | -0.010440592 |\n",
      "|    n_updates          | 3376         |\n",
      "|    policyGradLoss     | -0.00204     |\n",
      "|    value_loss         | 1.54         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 746          |\n",
      "|    iterations         | 6            |\n",
      "|    time_elapsed       | 65           |\n",
      "|    total_timesteps    | 6930432      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0024989576 |\n",
      "|    entropy_loss       | -2.44        |\n",
      "|    explained_variance | 0.723        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0241       |\n",
      "|    mean_step_reward   | -0.010795047 |\n",
      "|    n_updates          | 3380         |\n",
      "|    policyGradLoss     | 0.00231      |\n",
      "|    value_loss         | 0.643        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 740         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 77          |\n",
      "|    total_timesteps    | 6938624     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.005382211 |\n",
      "|    entropy_loss       | -2.45       |\n",
      "|    explained_variance | 0.757       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0122     |\n",
      "|    mean_step_reward   | -0.01051081 |\n",
      "|    n_updates          | 3384        |\n",
      "|    policyGradLoss     | 0.000691    |\n",
      "|    value_loss         | 0.157       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 731          |\n",
      "|    iterations         | 8            |\n",
      "|    time_elapsed       | 89           |\n",
      "|    total_timesteps    | 6946816      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0022333013 |\n",
      "|    entropy_loss       | -2.42        |\n",
      "|    explained_variance | 0.99         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0394      |\n",
      "|    mean_step_reward   | -0.00898171  |\n",
      "|    n_updates          | 3388         |\n",
      "|    policyGradLoss     | -0.00383     |\n",
      "|    value_loss         | 0.193        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 723          |\n",
      "|    iterations         | 9            |\n",
      "|    time_elapsed       | 101          |\n",
      "|    total_timesteps    | 6955008      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0027108896 |\n",
      "|    entropy_loss       | -2.43        |\n",
      "|    explained_variance | 0.582        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0648       |\n",
      "|    mean_step_reward   | -0.009623426 |\n",
      "|    n_updates          | 3392         |\n",
      "|    policyGradLoss     | 7e-05        |\n",
      "|    value_loss         | 1.57         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 724          |\n",
      "|    iterations         | 10           |\n",
      "|    time_elapsed       | 112          |\n",
      "|    total_timesteps    | 6963200      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0032721204 |\n",
      "|    entropy_loss       | -2.43        |\n",
      "|    explained_variance | -0.254       |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0396      |\n",
      "|    mean_step_reward   | -0.010824265 |\n",
      "|    n_updates          | 3396         |\n",
      "|    policyGradLoss     | -0.004       |\n",
      "|    value_loss         | 0.067        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 719          |\n",
      "|    iterations         | 11           |\n",
      "|    time_elapsed       | 125          |\n",
      "|    total_timesteps    | 6971392      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0033729393 |\n",
      "|    entropy_loss       | -2.43        |\n",
      "|    explained_variance | 0.0742       |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0226      |\n",
      "|    mean_step_reward   | -0.010383131 |\n",
      "|    n_updates          | 3400         |\n",
      "|    policyGradLoss     | 4.82e-05     |\n",
      "|    value_loss         | 0.0836       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 722          |\n",
      "|    iterations         | 12           |\n",
      "|    time_elapsed       | 136          |\n",
      "|    total_timesteps    | 6979584      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.002133851  |\n",
      "|    entropy_loss       | -2.41        |\n",
      "|    explained_variance | 0.644        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0541      |\n",
      "|    mean_step_reward   | -0.010419231 |\n",
      "|    n_updates          | 3404         |\n",
      "|    policyGradLoss     | -0.00221     |\n",
      "|    value_loss         | 0.101        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 716         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 148         |\n",
      "|    total_timesteps    | 6987776     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.00284906  |\n",
      "|    entropy_loss       | -2.37       |\n",
      "|    explained_variance | 0.958       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.7         |\n",
      "|    mean_step_reward   | 0.010816965 |\n",
      "|    n_updates          | 3408        |\n",
      "|    policyGradLoss     | -0.000865   |\n",
      "|    value_loss         | 10.3        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 714         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 160         |\n",
      "|    total_timesteps    | 6995968     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.002440765 |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 84.9        |\n",
      "|    mean_step_reward   | 0.30731055  |\n",
      "|    n_updates          | 3412        |\n",
      "|    policyGradLoss     | 6.32e-05    |\n",
      "|    value_loss         | 142         |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 714          |\n",
      "|    iterations         | 15           |\n",
      "|    time_elapsed       | 171          |\n",
      "|    total_timesteps    | 7004160      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0014256374 |\n",
      "|    entropy_loss       | -2.29        |\n",
      "|    explained_variance | 0.961        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 71.2         |\n",
      "|    mean_step_reward   | 0.26868153   |\n",
      "|    n_updates          | 3416         |\n",
      "|    policyGradLoss     | 0.000364     |\n",
      "|    value_loss         | 129          |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 713          |\n",
      "|    iterations         | 16           |\n",
      "|    time_elapsed       | 183          |\n",
      "|    total_timesteps    | 7012352      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0047692233 |\n",
      "|    entropy_loss       | -2.41        |\n",
      "|    explained_variance | 0.76         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 3.39         |\n",
      "|    mean_step_reward   | -0.009474356 |\n",
      "|    n_updates          | 3420         |\n",
      "|    policyGradLoss     | 0.0147       |\n",
      "|    value_loss         | 26           |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 712          |\n",
      "|    iterations         | 17           |\n",
      "|    time_elapsed       | 195          |\n",
      "|    total_timesteps    | 7020544      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.003984773  |\n",
      "|    entropy_loss       | -2.41        |\n",
      "|    explained_variance | 0.0967       |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.032       |\n",
      "|    mean_step_reward   | -0.009080443 |\n",
      "|    n_updates          | 3424         |\n",
      "|    policyGradLoss     | -0.00275     |\n",
      "|    value_loss         | 0.0789       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 711          |\n",
      "|    iterations         | 18           |\n",
      "|    time_elapsed       | 207          |\n",
      "|    total_timesteps    | 7028736      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0025577578 |\n",
      "|    entropy_loss       | -2.37        |\n",
      "|    explained_variance | 0.873        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0371       |\n",
      "|    mean_step_reward   | -0.008212656 |\n",
      "|    n_updates          | 3428         |\n",
      "|    policyGradLoss     | -0.00196     |\n",
      "|    value_loss         | 0.362        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 710          |\n",
      "|    iterations         | 19           |\n",
      "|    time_elapsed       | 218          |\n",
      "|    total_timesteps    | 7036928      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0038584892 |\n",
      "|    entropy_loss       | -2.27        |\n",
      "|    explained_variance | 0.964        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 55.7         |\n",
      "|    mean_step_reward   | 0.23644856   |\n",
      "|    n_updates          | 3432         |\n",
      "|    policyGradLoss     | 0.00035      |\n",
      "|    value_loss         | 111          |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 709         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 230         |\n",
      "|    total_timesteps    | 7045120     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.000591174 |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 70.9        |\n",
      "|    mean_step_reward   | 0.30300122  |\n",
      "|    n_updates          | 3436        |\n",
      "|    policyGradLoss     | 0.00115     |\n",
      "|    value_loss         | 139         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 706         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 243         |\n",
      "|    total_timesteps    | 7053312     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.002294599 |\n",
      "|    entropy_loss       | -2.15       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 59.1        |\n",
      "|    mean_step_reward   | 0.30553818  |\n",
      "|    n_updates          | 3440        |\n",
      "|    policyGradLoss     | 0.000476    |\n",
      "|    value_loss         | 147         |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 707          |\n",
      "|    iterations         | 22           |\n",
      "|    time_elapsed       | 254          |\n",
      "|    total_timesteps    | 7061504      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0034062248 |\n",
      "|    entropy_loss       | -2.18        |\n",
      "|    explained_variance | 0.956        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 78.2         |\n",
      "|    mean_step_reward   | 0.3447336    |\n",
      "|    n_updates          | 3444         |\n",
      "|    policyGradLoss     | 0.0017       |\n",
      "|    value_loss         | 173          |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 705          |\n",
      "|    iterations         | 23           |\n",
      "|    time_elapsed       | 267          |\n",
      "|    total_timesteps    | 7069696      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0026503233 |\n",
      "|    entropy_loss       | -2.26        |\n",
      "|    explained_variance | 0.951        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 10.2         |\n",
      "|    mean_step_reward   | 0.042843297  |\n",
      "|    n_updates          | 3448         |\n",
      "|    policyGradLoss     | 0.000326     |\n",
      "|    value_loss         | 35.8         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 707           |\n",
      "|    iterations         | 24            |\n",
      "|    time_elapsed       | 277           |\n",
      "|    total_timesteps    | 7077888       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.001515191   |\n",
      "|    entropy_loss       | -2.42         |\n",
      "|    explained_variance | 0.317         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | 0.653         |\n",
      "|    mean_step_reward   | -0.0099315755 |\n",
      "|    n_updates          | 3452          |\n",
      "|    policyGradLoss     | 0.00107       |\n",
      "|    value_loss         | 5.78          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 706           |\n",
      "|    iterations         | 25            |\n",
      "|    time_elapsed       | 290           |\n",
      "|    total_timesteps    | 7086080       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.001926219   |\n",
      "|    entropy_loss       | -2.33         |\n",
      "|    explained_variance | 0.968         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | 0.00478       |\n",
      "|    mean_step_reward   | -0.0076130065 |\n",
      "|    n_updates          | 3456          |\n",
      "|    policyGradLoss     | -0.00185      |\n",
      "|    value_loss         | 0.33          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 705          |\n",
      "|    iterations         | 26           |\n",
      "|    time_elapsed       | 301          |\n",
      "|    total_timesteps    | 7094272      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0034617318 |\n",
      "|    entropy_loss       | -2.33        |\n",
      "|    explained_variance | 0.873        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 2.53         |\n",
      "|    mean_step_reward   | -0.010057388 |\n",
      "|    n_updates          | 3460         |\n",
      "|    policyGradLoss     | 0.00468      |\n",
      "|    value_loss         | 12.7         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 705          |\n",
      "|    iterations         | 27           |\n",
      "|    time_elapsed       | 313          |\n",
      "|    total_timesteps    | 7102464      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0017541251 |\n",
      "|    entropy_loss       | -2.33        |\n",
      "|    explained_variance | 0.948        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 3.02         |\n",
      "|    mean_step_reward   | 0.052434072  |\n",
      "|    n_updates          | 3464         |\n",
      "|    policyGradLoss     | -0.000248    |\n",
      "|    value_loss         | 7.41         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 704          |\n",
      "|    iterations         | 28           |\n",
      "|    time_elapsed       | 325          |\n",
      "|    total_timesteps    | 7110656      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0026954173 |\n",
      "|    entropy_loss       | -2.38        |\n",
      "|    explained_variance | 0.667        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 8.28e-05     |\n",
      "|    mean_step_reward   | -0.009118627 |\n",
      "|    n_updates          | 3468         |\n",
      "|    policyGradLoss     | -0.00376     |\n",
      "|    value_loss         | 0.24         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 706          |\n",
      "|    iterations         | 29           |\n",
      "|    time_elapsed       | 336          |\n",
      "|    total_timesteps    | 7118848      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0029926274 |\n",
      "|    entropy_loss       | -2.24        |\n",
      "|    explained_variance | 0.922        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.595        |\n",
      "|    mean_step_reward   | -0.006102822 |\n",
      "|    n_updates          | 3472         |\n",
      "|    policyGradLoss     | 0.00298      |\n",
      "|    value_loss         | 3.37         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 705          |\n",
      "|    iterations         | 30           |\n",
      "|    time_elapsed       | 348          |\n",
      "|    total_timesteps    | 7127040      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0057969615 |\n",
      "|    entropy_loss       | -2.03        |\n",
      "|    explained_variance | 0.919        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 11.9         |\n",
      "|    mean_step_reward   | 0.24419801   |\n",
      "|    n_updates          | 3476         |\n",
      "|    policyGradLoss     | 0.00161      |\n",
      "|    value_loss         | 62.1         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 706         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 359         |\n",
      "|    total_timesteps    | 7135232     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011730178 |\n",
      "|    entropy_loss       | -2.14       |\n",
      "|    explained_variance | 0.934       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 23.1        |\n",
      "|    mean_step_reward   | 0.41987956  |\n",
      "|    n_updates          | 3480        |\n",
      "|    policyGradLoss     | 0.00528     |\n",
      "|    value_loss         | 106         |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 704          |\n",
      "|    iterations         | 32           |\n",
      "|    time_elapsed       | 371          |\n",
      "|    total_timesteps    | 7143424      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0028375129 |\n",
      "|    entropy_loss       | -2.3         |\n",
      "|    explained_variance | 0.85         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 14.6         |\n",
      "|    mean_step_reward   | 0.04006181   |\n",
      "|    n_updates          | 3484         |\n",
      "|    policyGradLoss     | 0.00389      |\n",
      "|    value_loss         | 43           |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 704          |\n",
      "|    iterations         | 33           |\n",
      "|    time_elapsed       | 383          |\n",
      "|    total_timesteps    | 7151616      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0031423357 |\n",
      "|    entropy_loss       | -2.36        |\n",
      "|    explained_variance | 0.0575       |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.302        |\n",
      "|    mean_step_reward   | -0.005299901 |\n",
      "|    n_updates          | 3488         |\n",
      "|    policyGradLoss     | -0.00225     |\n",
      "|    value_loss         | 1.6          |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 704          |\n",
      "|    iterations         | 34           |\n",
      "|    time_elapsed       | 395          |\n",
      "|    total_timesteps    | 7159808      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0049901796 |\n",
      "|    entropy_loss       | -2.21        |\n",
      "|    explained_variance | 0.952        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 53.7         |\n",
      "|    mean_step_reward   | 0.23830265   |\n",
      "|    n_updates          | 3492         |\n",
      "|    policyGradLoss     | -0.000549    |\n",
      "|    value_loss         | 150          |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 703          |\n",
      "|    iterations         | 35           |\n",
      "|    time_elapsed       | 407          |\n",
      "|    total_timesteps    | 7168000      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0027832356 |\n",
      "|    entropy_loss       | -2.23        |\n",
      "|    explained_variance | 0.954        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 54.8         |\n",
      "|    mean_step_reward   | 0.2428329    |\n",
      "|    n_updates          | 3496         |\n",
      "|    policyGradLoss     | 0.000676     |\n",
      "|    value_loss         | 105          |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 704           |\n",
      "|    iterations         | 36            |\n",
      "|    time_elapsed       | 418           |\n",
      "|    total_timesteps    | 7176192       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0022269213  |\n",
      "|    entropy_loss       | -2.39         |\n",
      "|    explained_variance | 0.827         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | 0.262         |\n",
      "|    mean_step_reward   | -0.0058531966 |\n",
      "|    n_updates          | 3500          |\n",
      "|    policyGradLoss     | 0.000933      |\n",
      "|    value_loss         | 2.1           |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 704           |\n",
      "|    iterations         | 37            |\n",
      "|    time_elapsed       | 430           |\n",
      "|    total_timesteps    | 7184384       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0030016096  |\n",
      "|    entropy_loss       | -2.39         |\n",
      "|    explained_variance | 0.847         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | 0.0159        |\n",
      "|    mean_step_reward   | -0.0064144926 |\n",
      "|    n_updates          | 3504          |\n",
      "|    policyGradLoss     | -0.0022       |\n",
      "|    value_loss         | 0.462         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 704          |\n",
      "|    iterations         | 38           |\n",
      "|    time_elapsed       | 441          |\n",
      "|    total_timesteps    | 7192576      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0037685155 |\n",
      "|    entropy_loss       | -2.4         |\n",
      "|    explained_variance | 0.41         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.000885     |\n",
      "|    mean_step_reward   | -0.009175534 |\n",
      "|    n_updates          | 3508         |\n",
      "|    policyGradLoss     | -0.00321     |\n",
      "|    value_loss         | 0.164        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 703          |\n",
      "|    iterations         | 39           |\n",
      "|    time_elapsed       | 454          |\n",
      "|    total_timesteps    | 7200768      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0027576033 |\n",
      "|    entropy_loss       | -2.39        |\n",
      "|    explained_variance | 0.843        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0181       |\n",
      "|    mean_step_reward   | -0.010220694 |\n",
      "|    n_updates          | 3512         |\n",
      "|    policyGradLoss     | -0.00149     |\n",
      "|    value_loss         | 0.203        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 702          |\n",
      "|    iterations         | 40           |\n",
      "|    time_elapsed       | 466          |\n",
      "|    total_timesteps    | 7208960      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0039910674 |\n",
      "|    entropy_loss       | -2.37        |\n",
      "|    explained_variance | 0.862        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.011       |\n",
      "|    mean_step_reward   | -0.008208062 |\n",
      "|    n_updates          | 3516         |\n",
      "|    policyGradLoss     | -0.00246     |\n",
      "|    value_loss         | 0.187        |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/P_RWD18_21.zip\n",
      "[EVAL] Mean Return: -1.154, Best Return: -0.274\n",
      "Saved video to ./runs_smw/videos/P_RWD18/P_RWD18_21_-1.15.mp4\n",
      "\n",
      "=== Round 23 | Learn 327680 steps (Total trained: 7208960) ===\n",
      "Logging to ./runs_smw/tb/P_RWD18_0\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1238    |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 6       |\n",
      "|    total_timesteps | 7217152 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 867           |\n",
      "|    iterations         | 2             |\n",
      "|    time_elapsed       | 18            |\n",
      "|    total_timesteps    | 7225344       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0023927274  |\n",
      "|    entropy_loss       | -2.33         |\n",
      "|    explained_variance | 0.373         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | 0.0618        |\n",
      "|    mean_step_reward   | -0.0020875768 |\n",
      "|    n_updates          | 3524          |\n",
      "|    policyGradLoss     | -0.00187      |\n",
      "|    value_loss         | 1.34          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 833           |\n",
      "|    iterations         | 3             |\n",
      "|    time_elapsed       | 29            |\n",
      "|    total_timesteps    | 7233536       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0018615662  |\n",
      "|    entropy_loss       | -2.32         |\n",
      "|    explained_variance | 0.958         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | 0.0109        |\n",
      "|    mean_step_reward   | -0.0069564655 |\n",
      "|    n_updates          | 3528          |\n",
      "|    policyGradLoss     | -0.000997     |\n",
      "|    value_loss         | 0.324         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 779          |\n",
      "|    iterations         | 4            |\n",
      "|    time_elapsed       | 42           |\n",
      "|    total_timesteps    | 7241728      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0017383203 |\n",
      "|    entropy_loss       | -2.27        |\n",
      "|    explained_variance | 0.951        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0759       |\n",
      "|    mean_step_reward   | 0.0010260696 |\n",
      "|    n_updates          | 3532         |\n",
      "|    policyGradLoss     | -0.00112     |\n",
      "|    value_loss         | 0.571        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 764         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 53          |\n",
      "|    total_timesteps    | 7249920     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.005422825 |\n",
      "|    entropy_loss       | -2.32       |\n",
      "|    explained_variance | 0.761       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 3.49        |\n",
      "|    mean_step_reward   | 0.031080594 |\n",
      "|    n_updates          | 3536        |\n",
      "|    policyGradLoss     | 0.00796     |\n",
      "|    value_loss         | 10.8        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 748          |\n",
      "|    iterations         | 6            |\n",
      "|    time_elapsed       | 65           |\n",
      "|    total_timesteps    | 7258112      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.00264811   |\n",
      "|    entropy_loss       | -2.38        |\n",
      "|    explained_variance | 0.743        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.009       |\n",
      "|    mean_step_reward   | -0.005565846 |\n",
      "|    n_updates          | 3540         |\n",
      "|    policyGradLoss     | -0.00433     |\n",
      "|    value_loss         | 0.249        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 733          |\n",
      "|    iterations         | 7            |\n",
      "|    time_elapsed       | 78           |\n",
      "|    total_timesteps    | 7266304      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0034881623 |\n",
      "|    entropy_loss       | -2.39        |\n",
      "|    explained_variance | -1.25        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.00792     |\n",
      "|    mean_step_reward   | -0.008792298 |\n",
      "|    n_updates          | 3544         |\n",
      "|    policyGradLoss     | -0.00182     |\n",
      "|    value_loss         | 0.445        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 731         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 89          |\n",
      "|    total_timesteps    | 7274496     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009348117 |\n",
      "|    entropy_loss       | -2.33       |\n",
      "|    explained_variance | 0.643       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.933       |\n",
      "|    mean_step_reward   | 0.009585571 |\n",
      "|    n_updates          | 3548        |\n",
      "|    policyGradLoss     | 0.00414     |\n",
      "|    value_loss         | 9.61        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 723          |\n",
      "|    iterations         | 9            |\n",
      "|    time_elapsed       | 101          |\n",
      "|    total_timesteps    | 7282688      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0044162935 |\n",
      "|    entropy_loss       | -2.33        |\n",
      "|    explained_variance | 0.594        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 8.63         |\n",
      "|    mean_step_reward   | 0.025085233  |\n",
      "|    n_updates          | 3552         |\n",
      "|    policyGradLoss     | 0.00308      |\n",
      "|    value_loss         | 19           |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 728          |\n",
      "|    iterations         | 10           |\n",
      "|    time_elapsed       | 112          |\n",
      "|    total_timesteps    | 7290880      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.002744114  |\n",
      "|    entropy_loss       | -2.36        |\n",
      "|    explained_variance | 0.801        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.327        |\n",
      "|    mean_step_reward   | 0.0019402318 |\n",
      "|    n_updates          | 3556         |\n",
      "|    policyGradLoss     | 0.000761     |\n",
      "|    value_loss         | 2.55         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 720          |\n",
      "|    iterations         | 11           |\n",
      "|    time_elapsed       | 125          |\n",
      "|    total_timesteps    | 7299072      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0057325037 |\n",
      "|    entropy_loss       | -2.35        |\n",
      "|    explained_variance | 0.719        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 1.34         |\n",
      "|    mean_step_reward   | 0.026544742  |\n",
      "|    n_updates          | 3560         |\n",
      "|    policyGradLoss     | 0.00607      |\n",
      "|    value_loss         | 7.8          |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 720          |\n",
      "|    iterations         | 12           |\n",
      "|    time_elapsed       | 136          |\n",
      "|    total_timesteps    | 7307264      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0059905564 |\n",
      "|    entropy_loss       | -2.32        |\n",
      "|    explained_variance | 0.541        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 5.91         |\n",
      "|    mean_step_reward   | 0.049194455  |\n",
      "|    n_updates          | 3564         |\n",
      "|    policyGradLoss     | 0.0026       |\n",
      "|    value_loss         | 21.6         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 716          |\n",
      "|    iterations         | 13           |\n",
      "|    time_elapsed       | 148          |\n",
      "|    total_timesteps    | 7315456      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0037127049 |\n",
      "|    entropy_loss       | -2.33        |\n",
      "|    explained_variance | 0.698        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 1.81         |\n",
      "|    mean_step_reward   | 0.04492354   |\n",
      "|    n_updates          | 3568         |\n",
      "|    policyGradLoss     | 0.00535      |\n",
      "|    value_loss         | 11.3         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 712          |\n",
      "|    iterations         | 14           |\n",
      "|    time_elapsed       | 160          |\n",
      "|    total_timesteps    | 7323648      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0030078276 |\n",
      "|    entropy_loss       | -2.39        |\n",
      "|    explained_variance | 0.761        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 3.3          |\n",
      "|    mean_step_reward   | 0.009745875  |\n",
      "|    n_updates          | 3572         |\n",
      "|    policyGradLoss     | 0.00246      |\n",
      "|    value_loss         | 4.13         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 714          |\n",
      "|    iterations         | 15           |\n",
      "|    time_elapsed       | 172          |\n",
      "|    total_timesteps    | 7331840      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0031717592 |\n",
      "|    entropy_loss       | -2.4         |\n",
      "|    explained_variance | 0.71         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 1.5          |\n",
      "|    mean_step_reward   | 0.015481497  |\n",
      "|    n_updates          | 3576         |\n",
      "|    policyGradLoss     | 0.00192      |\n",
      "|    value_loss         | 4.75         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 711          |\n",
      "|    iterations         | 16           |\n",
      "|    time_elapsed       | 184          |\n",
      "|    total_timesteps    | 7340032      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0019183273 |\n",
      "|    entropy_loss       | -2.42        |\n",
      "|    explained_variance | 0.69         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 1.2          |\n",
      "|    mean_step_reward   | 0.024241192  |\n",
      "|    n_updates          | 3580         |\n",
      "|    policyGradLoss     | -0.000352    |\n",
      "|    value_loss         | 4.48         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 715          |\n",
      "|    iterations         | 17           |\n",
      "|    time_elapsed       | 194          |\n",
      "|    total_timesteps    | 7348224      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.004838413  |\n",
      "|    entropy_loss       | -2.47        |\n",
      "|    explained_variance | -0.0143      |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0507      |\n",
      "|    mean_step_reward   | -0.007904792 |\n",
      "|    n_updates          | 3584         |\n",
      "|    policyGradLoss     | -0.000868    |\n",
      "|    value_loss         | 0.198        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 711          |\n",
      "|    iterations         | 18           |\n",
      "|    time_elapsed       | 207          |\n",
      "|    total_timesteps    | 7356416      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0043693446 |\n",
      "|    entropy_loss       | -2.46        |\n",
      "|    explained_variance | 0.818        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0555      |\n",
      "|    mean_step_reward   | -0.009020936 |\n",
      "|    n_updates          | 3588         |\n",
      "|    policyGradLoss     | -0.00108     |\n",
      "|    value_loss         | 0.0303       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 711          |\n",
      "|    iterations         | 19           |\n",
      "|    time_elapsed       | 218          |\n",
      "|    total_timesteps    | 7364608      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0017186078 |\n",
      "|    entropy_loss       | -2.47        |\n",
      "|    explained_variance | 0.77         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0562      |\n",
      "|    mean_step_reward   | -0.009153647 |\n",
      "|    n_updates          | 3592         |\n",
      "|    policyGradLoss     | -0.00275     |\n",
      "|    value_loss         | 0.024        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 710          |\n",
      "|    iterations         | 20           |\n",
      "|    time_elapsed       | 230          |\n",
      "|    total_timesteps    | 7372800      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.003222494  |\n",
      "|    entropy_loss       | -2.46        |\n",
      "|    explained_variance | 0.494        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0548      |\n",
      "|    mean_step_reward   | -0.009554794 |\n",
      "|    n_updates          | 3596         |\n",
      "|    policyGradLoss     | -0.00346     |\n",
      "|    value_loss         | 0.0318       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 709          |\n",
      "|    iterations         | 21           |\n",
      "|    time_elapsed       | 242          |\n",
      "|    total_timesteps    | 7380992      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.004514728  |\n",
      "|    entropy_loss       | -2.47        |\n",
      "|    explained_variance | 0.443        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0605      |\n",
      "|    mean_step_reward   | -0.008584967 |\n",
      "|    n_updates          | 3600         |\n",
      "|    policyGradLoss     | -0.00373     |\n",
      "|    value_loss         | 0.0246       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 712          |\n",
      "|    iterations         | 22           |\n",
      "|    time_elapsed       | 252          |\n",
      "|    total_timesteps    | 7389184      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0045532435 |\n",
      "|    entropy_loss       | -2.45        |\n",
      "|    explained_variance | 0.857        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0519      |\n",
      "|    mean_step_reward   | -0.007892338 |\n",
      "|    n_updates          | 3604         |\n",
      "|    policyGradLoss     | -0.00278     |\n",
      "|    value_loss         | 0.0554       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 710          |\n",
      "|    iterations         | 23           |\n",
      "|    time_elapsed       | 265          |\n",
      "|    total_timesteps    | 7397376      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.003185026  |\n",
      "|    entropy_loss       | -2.42        |\n",
      "|    explained_variance | 0.794        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.236        |\n",
      "|    mean_step_reward   | -0.001263327 |\n",
      "|    n_updates          | 3608         |\n",
      "|    policyGradLoss     | 0.000485     |\n",
      "|    value_loss         | 1.91         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 711           |\n",
      "|    iterations         | 24            |\n",
      "|    time_elapsed       | 276           |\n",
      "|    total_timesteps    | 7405568       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0030928727  |\n",
      "|    entropy_loss       | -2.44         |\n",
      "|    explained_variance | 0.673         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | 0.000336      |\n",
      "|    mean_step_reward   | -0.0061161425 |\n",
      "|    n_updates          | 3612          |\n",
      "|    policyGradLoss     | -0.00306      |\n",
      "|    value_loss         | 0.462         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 709          |\n",
      "|    iterations         | 25           |\n",
      "|    time_elapsed       | 288          |\n",
      "|    total_timesteps    | 7413760      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0021027946 |\n",
      "|    entropy_loss       | -2.43        |\n",
      "|    explained_variance | 0.839        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0269      |\n",
      "|    mean_step_reward   | -0.008498464 |\n",
      "|    n_updates          | 3616         |\n",
      "|    policyGradLoss     | -0.00269     |\n",
      "|    value_loss         | 0.17         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 708           |\n",
      "|    iterations         | 26            |\n",
      "|    time_elapsed       | 300           |\n",
      "|    total_timesteps    | 7421952       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.003151359   |\n",
      "|    entropy_loss       | -2.41         |\n",
      "|    explained_variance | 0.669         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | 0.0962        |\n",
      "|    mean_step_reward   | 0.00089170877 |\n",
      "|    n_updates          | 3620          |\n",
      "|    policyGradLoss     | 0.00424       |\n",
      "|    value_loss         | 1.22          |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 709         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 311         |\n",
      "|    total_timesteps    | 7430144     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.006424132 |\n",
      "|    entropy_loss       | -2.37       |\n",
      "|    explained_variance | 0.77        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.23        |\n",
      "|    mean_step_reward   | 0.0398065   |\n",
      "|    n_updates          | 3624        |\n",
      "|    policyGradLoss     | 0.00361     |\n",
      "|    value_loss         | 7.01        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 706          |\n",
      "|    iterations         | 28           |\n",
      "|    time_elapsed       | 324          |\n",
      "|    total_timesteps    | 7438336      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0028113478 |\n",
      "|    entropy_loss       | -2.4         |\n",
      "|    explained_variance | 0.782        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 1.01         |\n",
      "|    mean_step_reward   | 0.018667566  |\n",
      "|    n_updates          | 3628         |\n",
      "|    policyGradLoss     | -0.000274    |\n",
      "|    value_loss         | 5.14         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 709          |\n",
      "|    iterations         | 29           |\n",
      "|    time_elapsed       | 334          |\n",
      "|    total_timesteps    | 7446528      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0034413456 |\n",
      "|    entropy_loss       | -2.41        |\n",
      "|    explained_variance | 0.815        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.368        |\n",
      "|    mean_step_reward   | 0.01697604   |\n",
      "|    n_updates          | 3632         |\n",
      "|    policyGradLoss     | 0.00277      |\n",
      "|    value_loss         | 3.63         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 707          |\n",
      "|    iterations         | 30           |\n",
      "|    time_elapsed       | 347          |\n",
      "|    total_timesteps    | 7454720      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.003609619  |\n",
      "|    entropy_loss       | -2.37        |\n",
      "|    explained_variance | 0.907        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0935       |\n",
      "|    mean_step_reward   | -0.002771089 |\n",
      "|    n_updates          | 3636         |\n",
      "|    policyGradLoss     | -0.0014      |\n",
      "|    value_loss         | 0.917        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 708          |\n",
      "|    iterations         | 31           |\n",
      "|    time_elapsed       | 358          |\n",
      "|    total_timesteps    | 7462912      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0034756716 |\n",
      "|    entropy_loss       | -2.38        |\n",
      "|    explained_variance | 0.691        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.607        |\n",
      "|    mean_step_reward   | 0.010489795  |\n",
      "|    n_updates          | 3640         |\n",
      "|    policyGradLoss     | 0.000395     |\n",
      "|    value_loss         | 3.74         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 706         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 370         |\n",
      "|    total_timesteps    | 7471104     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.003034144 |\n",
      "|    entropy_loss       | -2.4        |\n",
      "|    explained_variance | 0.742       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.205       |\n",
      "|    mean_step_reward   | 0.005046571 |\n",
      "|    n_updates          | 3644        |\n",
      "|    policyGradLoss     | -0.00234    |\n",
      "|    value_loss         | 2.52        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 705          |\n",
      "|    iterations         | 33           |\n",
      "|    time_elapsed       | 383          |\n",
      "|    total_timesteps    | 7479296      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0038189162 |\n",
      "|    entropy_loss       | -2.41        |\n",
      "|    explained_variance | 0.644        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.117        |\n",
      "|    mean_step_reward   | 0.02370502   |\n",
      "|    n_updates          | 3648         |\n",
      "|    policyGradLoss     | 0.00123      |\n",
      "|    value_loss         | 3.29         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 705           |\n",
      "|    iterations         | 34            |\n",
      "|    time_elapsed       | 394           |\n",
      "|    total_timesteps    | 7487488       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0040063406  |\n",
      "|    entropy_loss       | -2.41         |\n",
      "|    explained_variance | 0.859         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | 0.0124        |\n",
      "|    mean_step_reward   | -0.0088669425 |\n",
      "|    n_updates          | 3652          |\n",
      "|    policyGradLoss     | -0.00158      |\n",
      "|    value_loss         | 0.289         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 704           |\n",
      "|    iterations         | 35            |\n",
      "|    time_elapsed       | 407           |\n",
      "|    total_timesteps    | 7495680       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0040382617  |\n",
      "|    entropy_loss       | -2.37         |\n",
      "|    explained_variance | 0.881         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | 0.028         |\n",
      "|    mean_step_reward   | -0.0058236434 |\n",
      "|    n_updates          | 3656          |\n",
      "|    policyGradLoss     | -0.00263      |\n",
      "|    value_loss         | 0.525         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 706          |\n",
      "|    iterations         | 36           |\n",
      "|    time_elapsed       | 417          |\n",
      "|    total_timesteps    | 7503872      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0024250653 |\n",
      "|    entropy_loss       | -2.33        |\n",
      "|    explained_variance | 0.934        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0268       |\n",
      "|    mean_step_reward   | -0.006011172 |\n",
      "|    n_updates          | 3660         |\n",
      "|    policyGradLoss     | -0.00241     |\n",
      "|    value_loss         | 0.305        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 705          |\n",
      "|    iterations         | 37           |\n",
      "|    time_elapsed       | 429          |\n",
      "|    total_timesteps    | 7512064      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0036014523 |\n",
      "|    entropy_loss       | -2.32        |\n",
      "|    explained_variance | 0.561        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 2.8          |\n",
      "|    mean_step_reward   | 0.030713178  |\n",
      "|    n_updates          | 3664         |\n",
      "|    policyGradLoss     | 0.00107      |\n",
      "|    value_loss         | 6.3          |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 705          |\n",
      "|    iterations         | 38           |\n",
      "|    time_elapsed       | 441          |\n",
      "|    total_timesteps    | 7520256      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0031462088 |\n",
      "|    entropy_loss       | -2.33        |\n",
      "|    explained_variance | 0.717        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 5.06         |\n",
      "|    mean_step_reward   | 0.023773804  |\n",
      "|    n_updates          | 3668         |\n",
      "|    policyGradLoss     | 0.00157      |\n",
      "|    value_loss         | 8.7          |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 704          |\n",
      "|    iterations         | 39           |\n",
      "|    time_elapsed       | 453          |\n",
      "|    total_timesteps    | 7528448      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.002974479  |\n",
      "|    entropy_loss       | -2.38        |\n",
      "|    explained_variance | 0.718        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 2.88         |\n",
      "|    mean_step_reward   | 0.0052709314 |\n",
      "|    n_updates          | 3672         |\n",
      "|    policyGradLoss     | 0.000543     |\n",
      "|    value_loss         | 7.09         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 704           |\n",
      "|    iterations         | 40            |\n",
      "|    time_elapsed       | 464           |\n",
      "|    total_timesteps    | 7536640       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.003531457   |\n",
      "|    entropy_loss       | -2.37         |\n",
      "|    explained_variance | 0.746         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | 0.0467        |\n",
      "|    mean_step_reward   | -0.0026220987 |\n",
      "|    n_updates          | 3676          |\n",
      "|    policyGradLoss     | -0.000786     |\n",
      "|    value_loss         | 1.59          |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/P_RWD18_22.zip\n",
      "[EVAL] Mean Return: -1.154, Best Return: -0.274\n",
      "Saved video to ./runs_smw/videos/P_RWD18/P_RWD18_22_-1.15.mp4\n",
      "\n",
      "=== Round 24 | Learn 327680 steps (Total trained: 7536640) ===\n",
      "Logging to ./runs_smw/tb/P_RWD18_0\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1195    |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 6       |\n",
      "|    total_timesteps | 7544832 |\n",
      "--------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 858          |\n",
      "|    iterations         | 2            |\n",
      "|    time_elapsed       | 19           |\n",
      "|    total_timesteps    | 7553024      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0035401718 |\n",
      "|    entropy_loss       | -2.36        |\n",
      "|    explained_variance | 0.861        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.294        |\n",
      "|    mean_step_reward   | 0.0064881397 |\n",
      "|    n_updates          | 3684         |\n",
      "|    policyGradLoss     | -0.000786    |\n",
      "|    value_loss         | 2.56         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 835         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 29          |\n",
      "|    total_timesteps    | 7561216     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.003120848 |\n",
      "|    entropy_loss       | -2.37       |\n",
      "|    explained_variance | 0.676       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.14        |\n",
      "|    mean_step_reward   | 0.04105512  |\n",
      "|    n_updates          | 3688        |\n",
      "|    policyGradLoss     | 0.00168     |\n",
      "|    value_loss         | 6.47        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 41          |\n",
      "|    total_timesteps    | 7569408     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.004698947 |\n",
      "|    entropy_loss       | -2.36       |\n",
      "|    explained_variance | 0.823       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.743       |\n",
      "|    mean_step_reward   | 0.03802363  |\n",
      "|    n_updates          | 3692        |\n",
      "|    policyGradLoss     | 0.00332     |\n",
      "|    value_loss         | 7.04        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 767          |\n",
      "|    iterations         | 5            |\n",
      "|    time_elapsed       | 53           |\n",
      "|    total_timesteps    | 7577600      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0034197788 |\n",
      "|    entropy_loss       | -2.34        |\n",
      "|    explained_variance | 0.807        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 2.55         |\n",
      "|    mean_step_reward   | 0.04993099   |\n",
      "|    n_updates          | 3696         |\n",
      "|    policyGradLoss     | 0.00127      |\n",
      "|    value_loss         | 9.35         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 749         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 65          |\n",
      "|    total_timesteps    | 7585792     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.002817178 |\n",
      "|    entropy_loss       | -2.38       |\n",
      "|    explained_variance | 0.799       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.983       |\n",
      "|    mean_step_reward   | 0.050689504 |\n",
      "|    n_updates          | 3700        |\n",
      "|    policyGradLoss     | -0.000228   |\n",
      "|    value_loss         | 6.57        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 735          |\n",
      "|    iterations         | 7            |\n",
      "|    time_elapsed       | 77           |\n",
      "|    total_timesteps    | 7593984      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.003297411  |\n",
      "|    entropy_loss       | -2.43        |\n",
      "|    explained_variance | 0.878        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0483       |\n",
      "|    mean_step_reward   | -0.008354703 |\n",
      "|    n_updates          | 3704         |\n",
      "|    policyGradLoss     | -0.00138     |\n",
      "|    value_loss         | 0.563        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 735         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 89          |\n",
      "|    total_timesteps    | 7602176     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.00325765  |\n",
      "|    entropy_loss       | -2.4        |\n",
      "|    explained_variance | 0.775       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.104       |\n",
      "|    mean_step_reward   | 0.000663874 |\n",
      "|    n_updates          | 3708        |\n",
      "|    policyGradLoss     | 0.00138     |\n",
      "|    value_loss         | 1.14        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 727          |\n",
      "|    iterations         | 9            |\n",
      "|    time_elapsed       | 101          |\n",
      "|    total_timesteps    | 7610368      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0040330817 |\n",
      "|    entropy_loss       | -2.39        |\n",
      "|    explained_variance | 0.748        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 1.43         |\n",
      "|    mean_step_reward   | 0.0076319    |\n",
      "|    n_updates          | 3712         |\n",
      "|    policyGradLoss     | 0.00216      |\n",
      "|    value_loss         | 2.61         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 732          |\n",
      "|    iterations         | 10           |\n",
      "|    time_elapsed       | 111          |\n",
      "|    total_timesteps    | 7618560      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.003331548  |\n",
      "|    entropy_loss       | -2.42        |\n",
      "|    explained_variance | 0.76         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0283      |\n",
      "|    mean_step_reward   | -0.009353782 |\n",
      "|    n_updates          | 3716         |\n",
      "|    policyGradLoss     | -0.00258     |\n",
      "|    value_loss         | 0.134        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 725          |\n",
      "|    iterations         | 11           |\n",
      "|    time_elapsed       | 124          |\n",
      "|    total_timesteps    | 7626752      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0027579672 |\n",
      "|    entropy_loss       | -2.37        |\n",
      "|    explained_variance | 0.901        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.023       |\n",
      "|    mean_step_reward   | -0.005656358 |\n",
      "|    n_updates          | 3720         |\n",
      "|    policyGradLoss     | 0.00198      |\n",
      "|    value_loss         | 0.225        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 723         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 135         |\n",
      "|    total_timesteps    | 7634944     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.003474894 |\n",
      "|    entropy_loss       | -2.37       |\n",
      "|    explained_variance | 0.638       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.155       |\n",
      "|    mean_step_reward   | 0.025738642 |\n",
      "|    n_updates          | 3724        |\n",
      "|    policyGradLoss     | 0.00242     |\n",
      "|    value_loss         | 2.83        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 720          |\n",
      "|    iterations         | 13           |\n",
      "|    time_elapsed       | 147          |\n",
      "|    total_timesteps    | 7643136      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0034277095 |\n",
      "|    entropy_loss       | -2.41        |\n",
      "|    explained_variance | 0.765        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.6          |\n",
      "|    mean_step_reward   | 0.005152795  |\n",
      "|    n_updates          | 3728         |\n",
      "|    policyGradLoss     | -0.00155     |\n",
      "|    value_loss         | 1.76         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 716         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 160         |\n",
      "|    total_timesteps    | 7651328     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.002149978 |\n",
      "|    entropy_loss       | -2.4        |\n",
      "|    explained_variance | 0.805       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.246       |\n",
      "|    mean_step_reward   | 0.01549279  |\n",
      "|    n_updates          | 3732        |\n",
      "|    policyGradLoss     | -0.00135    |\n",
      "|    value_loss         | 1.9         |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 718          |\n",
      "|    iterations         | 15           |\n",
      "|    time_elapsed       | 171          |\n",
      "|    total_timesteps    | 7659520      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0033312594 |\n",
      "|    entropy_loss       | -2.4         |\n",
      "|    explained_variance | 0.836        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.148        |\n",
      "|    mean_step_reward   | 0.0029237815 |\n",
      "|    n_updates          | 3736         |\n",
      "|    policyGradLoss     | -0.00234     |\n",
      "|    value_loss         | 1.57         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 714          |\n",
      "|    iterations         | 16           |\n",
      "|    time_elapsed       | 183          |\n",
      "|    total_timesteps    | 7667712      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0030826083 |\n",
      "|    entropy_loss       | -2.39        |\n",
      "|    explained_variance | 0.748        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.613        |\n",
      "|    mean_step_reward   | 0.015896097  |\n",
      "|    n_updates          | 3740         |\n",
      "|    policyGradLoss     | -0.00152     |\n",
      "|    value_loss         | 2.91         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 717          |\n",
      "|    iterations         | 17           |\n",
      "|    time_elapsed       | 194          |\n",
      "|    total_timesteps    | 7675904      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0023559525 |\n",
      "|    entropy_loss       | -2.39        |\n",
      "|    explained_variance | 0.897        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.133        |\n",
      "|    mean_step_reward   | -0.006784429 |\n",
      "|    n_updates          | 3744         |\n",
      "|    policyGradLoss     | -0.00086     |\n",
      "|    value_loss         | 0.562        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 713         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 206         |\n",
      "|    total_timesteps    | 7684096     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.003700091 |\n",
      "|    entropy_loss       | -2.39       |\n",
      "|    explained_variance | 0.721       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.946       |\n",
      "|    mean_step_reward   | 0.031944007 |\n",
      "|    n_updates          | 3748        |\n",
      "|    policyGradLoss     | 0.00308     |\n",
      "|    value_loss         | 3.04        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 712          |\n",
      "|    iterations         | 19           |\n",
      "|    time_elapsed       | 218          |\n",
      "|    total_timesteps    | 7692288      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0048200646 |\n",
      "|    entropy_loss       | -2.4         |\n",
      "|    explained_variance | 0.856        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.505        |\n",
      "|    mean_step_reward   | 0.0216295    |\n",
      "|    n_updates          | 3752         |\n",
      "|    policyGradLoss     | 0.00105      |\n",
      "|    value_loss         | 2.8          |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 711          |\n",
      "|    iterations         | 20           |\n",
      "|    time_elapsed       | 230          |\n",
      "|    total_timesteps    | 7700480      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0035168803 |\n",
      "|    entropy_loss       | -2.41        |\n",
      "|    explained_variance | 0.893        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.552        |\n",
      "|    mean_step_reward   | 0.017605094  |\n",
      "|    n_updates          | 3756         |\n",
      "|    policyGradLoss     | -0.00252     |\n",
      "|    value_loss         | 2.09         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 709           |\n",
      "|    iterations         | 21            |\n",
      "|    time_elapsed       | 242           |\n",
      "|    total_timesteps    | 7708672       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.002425147   |\n",
      "|    entropy_loss       | -2.43         |\n",
      "|    explained_variance | 0.845         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | 0.0572        |\n",
      "|    mean_step_reward   | -0.0035528464 |\n",
      "|    n_updates          | 3760          |\n",
      "|    policyGradLoss     | -0.00253      |\n",
      "|    value_loss         | 0.609         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 712          |\n",
      "|    iterations         | 22           |\n",
      "|    time_elapsed       | 253          |\n",
      "|    total_timesteps    | 7716864      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0062393094 |\n",
      "|    entropy_loss       | -2.43        |\n",
      "|    explained_variance | 0.818        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.00928     |\n",
      "|    mean_step_reward   | -0.008473116 |\n",
      "|    n_updates          | 3764         |\n",
      "|    policyGradLoss     | 0.000953     |\n",
      "|    value_loss         | 0.0531       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 710          |\n",
      "|    iterations         | 23           |\n",
      "|    time_elapsed       | 265          |\n",
      "|    total_timesteps    | 7725056      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.004575599  |\n",
      "|    entropy_loss       | -2.43        |\n",
      "|    explained_variance | 0.461        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0493      |\n",
      "|    mean_step_reward   | -0.009736376 |\n",
      "|    n_updates          | 3768         |\n",
      "|    policyGradLoss     | -0.00262     |\n",
      "|    value_loss         | 0.0265       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 711          |\n",
      "|    iterations         | 24           |\n",
      "|    time_elapsed       | 276          |\n",
      "|    total_timesteps    | 7733248      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0028881943 |\n",
      "|    entropy_loss       | -2.44        |\n",
      "|    explained_variance | 0.256        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0606      |\n",
      "|    mean_step_reward   | -0.009534176 |\n",
      "|    n_updates          | 3772         |\n",
      "|    policyGradLoss     | -0.00416     |\n",
      "|    value_loss         | 0.0243       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 708          |\n",
      "|    iterations         | 25           |\n",
      "|    time_elapsed       | 288          |\n",
      "|    total_timesteps    | 7741440      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0038923088 |\n",
      "|    entropy_loss       | -2.44        |\n",
      "|    explained_variance | 0.43         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0544      |\n",
      "|    mean_step_reward   | -0.008390991 |\n",
      "|    n_updates          | 3776         |\n",
      "|    policyGradLoss     | -0.00437     |\n",
      "|    value_loss         | 0.0259       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 707           |\n",
      "|    iterations         | 26            |\n",
      "|    time_elapsed       | 301           |\n",
      "|    total_timesteps    | 7749632       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0032164545  |\n",
      "|    entropy_loss       | -2.41         |\n",
      "|    explained_variance | 0.851         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | 0.123         |\n",
      "|    mean_step_reward   | -0.0018603669 |\n",
      "|    n_updates          | 3780          |\n",
      "|    policyGradLoss     | -0.000298     |\n",
      "|    value_loss         | 0.566         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 707          |\n",
      "|    iterations         | 27           |\n",
      "|    time_elapsed       | 312          |\n",
      "|    total_timesteps    | 7757824      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0017477465 |\n",
      "|    entropy_loss       | -2.41        |\n",
      "|    explained_variance | 0.872        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.249        |\n",
      "|    mean_step_reward   | 0.0047789575 |\n",
      "|    n_updates          | 3784         |\n",
      "|    policyGradLoss     | 0.00139      |\n",
      "|    value_loss         | 1.28         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 705          |\n",
      "|    iterations         | 28           |\n",
      "|    time_elapsed       | 324          |\n",
      "|    total_timesteps    | 7766016      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.002764319  |\n",
      "|    entropy_loss       | -2.42        |\n",
      "|    explained_variance | 0.782        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.395        |\n",
      "|    mean_step_reward   | 0.0027009614 |\n",
      "|    n_updates          | 3788         |\n",
      "|    policyGradLoss     | 0.000187     |\n",
      "|    value_loss         | 1.91         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 708          |\n",
      "|    iterations         | 29           |\n",
      "|    time_elapsed       | 335          |\n",
      "|    total_timesteps    | 7774208      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0035127187 |\n",
      "|    entropy_loss       | -2.4         |\n",
      "|    explained_variance | 0.712        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.452        |\n",
      "|    mean_step_reward   | 0.039856132  |\n",
      "|    n_updates          | 3792         |\n",
      "|    policyGradLoss     | 0.000913     |\n",
      "|    value_loss         | 6.39         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 706          |\n",
      "|    iterations         | 30           |\n",
      "|    time_elapsed       | 347          |\n",
      "|    total_timesteps    | 7782400      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0029427893 |\n",
      "|    entropy_loss       | -2.42        |\n",
      "|    explained_variance | 0.771        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 1.18         |\n",
      "|    mean_step_reward   | 0.01656242   |\n",
      "|    n_updates          | 3796         |\n",
      "|    policyGradLoss     | -0.000112    |\n",
      "|    value_loss         | 5.55         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 706          |\n",
      "|    iterations         | 31           |\n",
      "|    time_elapsed       | 359          |\n",
      "|    total_timesteps    | 7790592      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0019891516 |\n",
      "|    entropy_loss       | -2.42        |\n",
      "|    explained_variance | 0.735        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 1.26         |\n",
      "|    mean_step_reward   | 0.019920198  |\n",
      "|    n_updates          | 3800         |\n",
      "|    policyGradLoss     | 0.00168      |\n",
      "|    value_loss         | 2.91         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 705         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 371         |\n",
      "|    total_timesteps    | 7798784     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.002193969 |\n",
      "|    entropy_loss       | -2.44       |\n",
      "|    explained_variance | 0.828       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.438       |\n",
      "|    mean_step_reward   | 0.024761643 |\n",
      "|    n_updates          | 3804        |\n",
      "|    policyGradLoss     | -0.00187    |\n",
      "|    value_loss         | 3.76        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 704          |\n",
      "|    iterations         | 33           |\n",
      "|    time_elapsed       | 383          |\n",
      "|    total_timesteps    | 7806976      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0015498674 |\n",
      "|    entropy_loss       | -2.44        |\n",
      "|    explained_variance | 0.783        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.405        |\n",
      "|    mean_step_reward   | 0.011614611  |\n",
      "|    n_updates          | 3808         |\n",
      "|    policyGradLoss     | 0.00116      |\n",
      "|    value_loss         | 4.26         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 705          |\n",
      "|    iterations         | 34           |\n",
      "|    time_elapsed       | 394          |\n",
      "|    total_timesteps    | 7815168      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0017977909 |\n",
      "|    entropy_loss       | -2.43        |\n",
      "|    explained_variance | 0.781        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.257        |\n",
      "|    mean_step_reward   | 0.0040203393 |\n",
      "|    n_updates          | 3812         |\n",
      "|    policyGradLoss     | 0.00136      |\n",
      "|    value_loss         | 2.23         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 704          |\n",
      "|    iterations         | 35           |\n",
      "|    time_elapsed       | 406          |\n",
      "|    total_timesteps    | 7823360      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0033325087 |\n",
      "|    entropy_loss       | -2.44        |\n",
      "|    explained_variance | 0.882        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0521      |\n",
      "|    mean_step_reward   | -0.009541449 |\n",
      "|    n_updates          | 3816         |\n",
      "|    policyGradLoss     | -0.00381     |\n",
      "|    value_loss         | 0.062        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 706          |\n",
      "|    iterations         | 36           |\n",
      "|    time_elapsed       | 417          |\n",
      "|    total_timesteps    | 7831552      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0032861677 |\n",
      "|    entropy_loss       | -2.41        |\n",
      "|    explained_variance | 0.857        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0379      |\n",
      "|    mean_step_reward   | -0.008571677 |\n",
      "|    n_updates          | 3820         |\n",
      "|    policyGradLoss     | -0.00314     |\n",
      "|    value_loss         | 0.0617       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 704          |\n",
      "|    iterations         | 37           |\n",
      "|    time_elapsed       | 430          |\n",
      "|    total_timesteps    | 7839744      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0020408076 |\n",
      "|    entropy_loss       | -2.43        |\n",
      "|    explained_variance | 0.623        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0502      |\n",
      "|    mean_step_reward   | -0.007508141 |\n",
      "|    n_updates          | 3824         |\n",
      "|    policyGradLoss     | -0.00384     |\n",
      "|    value_loss         | 0.0417       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 704           |\n",
      "|    iterations         | 38            |\n",
      "|    time_elapsed       | 441           |\n",
      "|    total_timesteps    | 7847936       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.003131168   |\n",
      "|    entropy_loss       | -2.42         |\n",
      "|    explained_variance | 0.883         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0524       |\n",
      "|    mean_step_reward   | -0.0076606674 |\n",
      "|    n_updates          | 3828          |\n",
      "|    policyGradLoss     | -0.00522      |\n",
      "|    value_loss         | 0.0568        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 704          |\n",
      "|    iterations         | 39           |\n",
      "|    time_elapsed       | 453          |\n",
      "|    total_timesteps    | 7856128      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0024014227 |\n",
      "|    entropy_loss       | -2.43        |\n",
      "|    explained_variance | 0.842        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.162        |\n",
      "|    mean_step_reward   | 0.015948642  |\n",
      "|    n_updates          | 3832         |\n",
      "|    policyGradLoss     | 0.000986     |\n",
      "|    value_loss         | 2.37         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 703          |\n",
      "|    iterations         | 40           |\n",
      "|    time_elapsed       | 465          |\n",
      "|    total_timesteps    | 7864320      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0018617039 |\n",
      "|    entropy_loss       | -2.4         |\n",
      "|    explained_variance | 0.884        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.291        |\n",
      "|    mean_step_reward   | 0.015792457  |\n",
      "|    n_updates          | 3836         |\n",
      "|    policyGradLoss     | 0.000177     |\n",
      "|    value_loss         | 2.78         |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/P_RWD18_23.zip\n",
      "[EVAL] Mean Return: -1.810, Best Return: -1.624\n",
      "Saved video to ./runs_smw/videos/P_RWD18/P_RWD18_23_-1.81.mp4\n",
      "\n",
      "=== Round 25 | Learn 327680 steps (Total trained: 7864320) ===\n",
      "Logging to ./runs_smw/tb/P_RWD18_0\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1364    |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 6       |\n",
      "|    total_timesteps | 7872512 |\n",
      "--------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 894          |\n",
      "|    iterations         | 2            |\n",
      "|    time_elapsed       | 18           |\n",
      "|    total_timesteps    | 7880704      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0035821241 |\n",
      "|    entropy_loss       | -2.39        |\n",
      "|    explained_variance | 0.95         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 2.25         |\n",
      "|    mean_step_reward   | 0.052059233  |\n",
      "|    n_updates          | 3844         |\n",
      "|    policyGradLoss     | -0.00064     |\n",
      "|    value_loss         | 4.77         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 840          |\n",
      "|    iterations         | 3            |\n",
      "|    time_elapsed       | 29           |\n",
      "|    total_timesteps    | 7888896      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0025419071 |\n",
      "|    entropy_loss       | -2.35        |\n",
      "|    explained_variance | 0.914        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 3.08         |\n",
      "|    mean_step_reward   | 0.06295788   |\n",
      "|    n_updates          | 3848         |\n",
      "|    policyGradLoss     | -0.000234    |\n",
      "|    value_loss         | 9.71         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 786          |\n",
      "|    iterations         | 4            |\n",
      "|    time_elapsed       | 41           |\n",
      "|    total_timesteps    | 7897088      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0015465893 |\n",
      "|    entropy_loss       | -2.35        |\n",
      "|    explained_variance | 0.929        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 1.87         |\n",
      "|    mean_step_reward   | 0.056995936  |\n",
      "|    n_updates          | 3852         |\n",
      "|    policyGradLoss     | 0.000702     |\n",
      "|    value_loss         | 7.64         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 761          |\n",
      "|    iterations         | 5            |\n",
      "|    time_elapsed       | 53           |\n",
      "|    total_timesteps    | 7905280      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0013086116 |\n",
      "|    entropy_loss       | -2.37        |\n",
      "|    explained_variance | 0.94         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 1.04         |\n",
      "|    mean_step_reward   | 0.039087884  |\n",
      "|    n_updates          | 3856         |\n",
      "|    policyGradLoss     | 2.32e-05     |\n",
      "|    value_loss         | 5.71         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 754          |\n",
      "|    iterations         | 6            |\n",
      "|    time_elapsed       | 65           |\n",
      "|    total_timesteps    | 7913472      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0023705647 |\n",
      "|    entropy_loss       | -2.36        |\n",
      "|    explained_variance | 0.926        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 1.96         |\n",
      "|    mean_step_reward   | 0.059115797  |\n",
      "|    n_updates          | 3860         |\n",
      "|    policyGradLoss     | 0.00153      |\n",
      "|    value_loss         | 7.45         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 740         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 77          |\n",
      "|    total_timesteps    | 7921664     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.002665333 |\n",
      "|    entropy_loss       | -2.36       |\n",
      "|    explained_variance | 0.917       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.55        |\n",
      "|    mean_step_reward   | 0.062093776 |\n",
      "|    n_updates          | 3864        |\n",
      "|    policyGradLoss     | -0.00169    |\n",
      "|    value_loss         | 11.5        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 746          |\n",
      "|    iterations         | 8            |\n",
      "|    time_elapsed       | 87           |\n",
      "|    total_timesteps    | 7929856      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0030261613 |\n",
      "|    entropy_loss       | -2.39        |\n",
      "|    explained_variance | 0.916        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 3.85         |\n",
      "|    mean_step_reward   | 0.10190877   |\n",
      "|    n_updates          | 3868         |\n",
      "|    policyGradLoss     | 0.00459      |\n",
      "|    value_loss         | 14.6         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 734          |\n",
      "|    iterations         | 9            |\n",
      "|    time_elapsed       | 100          |\n",
      "|    total_timesteps    | 7938048      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0022129854 |\n",
      "|    entropy_loss       | -2.39        |\n",
      "|    explained_variance | 0.908        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 3.06         |\n",
      "|    mean_step_reward   | 0.078568265  |\n",
      "|    n_updates          | 3872         |\n",
      "|    policyGradLoss     | 0.00172      |\n",
      "|    value_loss         | 14.6         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 733          |\n",
      "|    iterations         | 10           |\n",
      "|    time_elapsed       | 111          |\n",
      "|    total_timesteps    | 7946240      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0024080423 |\n",
      "|    entropy_loss       | -2.41        |\n",
      "|    explained_variance | 0.93         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 2.08         |\n",
      "|    mean_step_reward   | 0.0645539    |\n",
      "|    n_updates          | 3876         |\n",
      "|    policyGradLoss     | 0.000892     |\n",
      "|    value_loss         | 7.41         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 726          |\n",
      "|    iterations         | 11           |\n",
      "|    time_elapsed       | 123          |\n",
      "|    total_timesteps    | 7954432      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0025335841 |\n",
      "|    entropy_loss       | -2.39        |\n",
      "|    explained_variance | 0.937        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 1.63         |\n",
      "|    mean_step_reward   | 0.06583628   |\n",
      "|    n_updates          | 3880         |\n",
      "|    policyGradLoss     | 0.00289      |\n",
      "|    value_loss         | 10.1         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 721          |\n",
      "|    iterations         | 12           |\n",
      "|    time_elapsed       | 136          |\n",
      "|    total_timesteps    | 7962624      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0034418642 |\n",
      "|    entropy_loss       | -2.4         |\n",
      "|    explained_variance | 0.948        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 2.25         |\n",
      "|    mean_step_reward   | 0.059347413  |\n",
      "|    n_updates          | 3884         |\n",
      "|    policyGradLoss     | -0.000137    |\n",
      "|    value_loss         | 7.71         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 723          |\n",
      "|    iterations         | 13           |\n",
      "|    time_elapsed       | 147          |\n",
      "|    total_timesteps    | 7970816      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0017025557 |\n",
      "|    entropy_loss       | -2.42        |\n",
      "|    explained_variance | 0.929        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.986        |\n",
      "|    mean_step_reward   | 0.029764436  |\n",
      "|    n_updates          | 3888         |\n",
      "|    policyGradLoss     | 0.000745     |\n",
      "|    value_loss         | 6.8          |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 719          |\n",
      "|    iterations         | 14           |\n",
      "|    time_elapsed       | 159          |\n",
      "|    total_timesteps    | 7979008      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0013298058 |\n",
      "|    entropy_loss       | -2.4         |\n",
      "|    explained_variance | 0.929        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 6.78         |\n",
      "|    mean_step_reward   | 0.045956433  |\n",
      "|    n_updates          | 3892         |\n",
      "|    policyGradLoss     | 0.00145      |\n",
      "|    value_loss         | 16.4         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 722         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 170         |\n",
      "|    total_timesteps    | 7987200     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.003338757 |\n",
      "|    entropy_loss       | -2.36       |\n",
      "|    explained_variance | 0.932       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 6.51        |\n",
      "|    mean_step_reward   | 0.14864486  |\n",
      "|    n_updates          | 3896        |\n",
      "|    policyGradLoss     | 0.00389     |\n",
      "|    value_loss         | 16.2        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 717          |\n",
      "|    iterations         | 16           |\n",
      "|    time_elapsed       | 182          |\n",
      "|    total_timesteps    | 7995392      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0028003315 |\n",
      "|    entropy_loss       | -2.37        |\n",
      "|    explained_variance | 0.903        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 6.78         |\n",
      "|    mean_step_reward   | 0.09946181   |\n",
      "|    n_updates          | 3900         |\n",
      "|    policyGradLoss     | 0.000692     |\n",
      "|    value_loss         | 24.4         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 717         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 194         |\n",
      "|    total_timesteps    | 8003584     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.00341153  |\n",
      "|    entropy_loss       | -2.36       |\n",
      "|    explained_variance | 0.915       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 6.23        |\n",
      "|    mean_step_reward   | 0.077510566 |\n",
      "|    n_updates          | 3904        |\n",
      "|    policyGradLoss     | 0.0021      |\n",
      "|    value_loss         | 19.6        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 715          |\n",
      "|    iterations         | 18           |\n",
      "|    time_elapsed       | 205          |\n",
      "|    total_timesteps    | 8011776      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0028660689 |\n",
      "|    entropy_loss       | -2.39        |\n",
      "|    explained_variance | 0.92         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 5.25         |\n",
      "|    mean_step_reward   | 0.099270135  |\n",
      "|    n_updates          | 3908         |\n",
      "|    policyGradLoss     | 0.0013       |\n",
      "|    value_loss         | 19.2         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 714          |\n",
      "|    iterations         | 19           |\n",
      "|    time_elapsed       | 217          |\n",
      "|    total_timesteps    | 8019968      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0029017774 |\n",
      "|    entropy_loss       | -2.4         |\n",
      "|    explained_variance | 0.908        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 10.6         |\n",
      "|    mean_step_reward   | 0.10502275   |\n",
      "|    n_updates          | 3912         |\n",
      "|    policyGradLoss     | 0.00466      |\n",
      "|    value_loss         | 28.4         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 712         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 229         |\n",
      "|    total_timesteps    | 8028160     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.005071195 |\n",
      "|    entropy_loss       | -2.42       |\n",
      "|    explained_variance | 0.904       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 2.14        |\n",
      "|    mean_step_reward   | 0.026066167 |\n",
      "|    n_updates          | 3916        |\n",
      "|    policyGradLoss     | 0.00767     |\n",
      "|    value_loss         | 9.5         |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 715          |\n",
      "|    iterations         | 21           |\n",
      "|    time_elapsed       | 240          |\n",
      "|    total_timesteps    | 8036352      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0038052336 |\n",
      "|    entropy_loss       | -2.43        |\n",
      "|    explained_variance | 0.906        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.237        |\n",
      "|    mean_step_reward   | 0.007184126  |\n",
      "|    n_updates          | 3920         |\n",
      "|    policyGradLoss     | 0.00176      |\n",
      "|    value_loss         | 3.53         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 713          |\n",
      "|    iterations         | 22           |\n",
      "|    time_elapsed       | 252          |\n",
      "|    total_timesteps    | 8044544      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0023875022 |\n",
      "|    entropy_loss       | -2.45        |\n",
      "|    explained_variance | 0.892        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.327        |\n",
      "|    mean_step_reward   | -0.008494301 |\n",
      "|    n_updates          | 3924         |\n",
      "|    policyGradLoss     | -0.000832    |\n",
      "|    value_loss         | 0.512        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 713          |\n",
      "|    iterations         | 23           |\n",
      "|    time_elapsed       | 264          |\n",
      "|    total_timesteps    | 8052736      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0041369307 |\n",
      "|    entropy_loss       | -2.45        |\n",
      "|    explained_variance | 0.0308       |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0619      |\n",
      "|    mean_step_reward   | -0.009102436 |\n",
      "|    n_updates          | 3928         |\n",
      "|    policyGradLoss     | -0.00318     |\n",
      "|    value_loss         | 0.0309       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 711          |\n",
      "|    iterations         | 24           |\n",
      "|    time_elapsed       | 276          |\n",
      "|    total_timesteps    | 8060928      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.00393588   |\n",
      "|    entropy_loss       | -2.44        |\n",
      "|    explained_variance | 0.617        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0622      |\n",
      "|    mean_step_reward   | -0.008276464 |\n",
      "|    n_updates          | 3932         |\n",
      "|    policyGradLoss     | -0.00488     |\n",
      "|    value_loss         | 0.0304       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 709          |\n",
      "|    iterations         | 25           |\n",
      "|    time_elapsed       | 288          |\n",
      "|    total_timesteps    | 8069120      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0029750664 |\n",
      "|    entropy_loss       | -2.45        |\n",
      "|    explained_variance | 0.769        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0513      |\n",
      "|    mean_step_reward   | -0.008801054 |\n",
      "|    n_updates          | 3936         |\n",
      "|    policyGradLoss     | -0.00229     |\n",
      "|    value_loss         | 0.0547       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 711          |\n",
      "|    iterations         | 26           |\n",
      "|    time_elapsed       | 299          |\n",
      "|    total_timesteps    | 8077312      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0019747145 |\n",
      "|    entropy_loss       | -2.44        |\n",
      "|    explained_variance | 0.638        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0223      |\n",
      "|    mean_step_reward   | -0.007476094 |\n",
      "|    n_updates          | 3940         |\n",
      "|    policyGradLoss     | -0.00175     |\n",
      "|    value_loss         | 0.25         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 709          |\n",
      "|    iterations         | 27           |\n",
      "|    time_elapsed       | 311          |\n",
      "|    total_timesteps    | 8085504      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.001794751  |\n",
      "|    entropy_loss       | -2.44        |\n",
      "|    explained_variance | 0.747        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0435      |\n",
      "|    mean_step_reward   | -0.008986978 |\n",
      "|    n_updates          | 3944         |\n",
      "|    policyGradLoss     | -0.00485     |\n",
      "|    value_loss         | 0.216        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 711          |\n",
      "|    iterations         | 28           |\n",
      "|    time_elapsed       | 322          |\n",
      "|    total_timesteps    | 8093696      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0039108493 |\n",
      "|    entropy_loss       | -2.42        |\n",
      "|    explained_variance | 0.627        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0507      |\n",
      "|    mean_step_reward   | -0.008753311 |\n",
      "|    n_updates          | 3948         |\n",
      "|    policyGradLoss     | -0.0065      |\n",
      "|    value_loss         | 0.0432       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 709          |\n",
      "|    iterations         | 29           |\n",
      "|    time_elapsed       | 335          |\n",
      "|    total_timesteps    | 8101888      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0042481916 |\n",
      "|    entropy_loss       | -2.44        |\n",
      "|    explained_variance | 0.729        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.066       |\n",
      "|    mean_step_reward   | -0.009675526 |\n",
      "|    n_updates          | 3952         |\n",
      "|    policyGradLoss     | -0.00688     |\n",
      "|    value_loss         | 0.0236       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 709          |\n",
      "|    iterations         | 30           |\n",
      "|    time_elapsed       | 346          |\n",
      "|    total_timesteps    | 8110080      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0032639652 |\n",
      "|    entropy_loss       | -2.44        |\n",
      "|    explained_variance | 0.575        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0576      |\n",
      "|    mean_step_reward   | -0.008899026 |\n",
      "|    n_updates          | 3956         |\n",
      "|    policyGradLoss     | -0.00375     |\n",
      "|    value_loss         | 0.0465       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 708          |\n",
      "|    iterations         | 31           |\n",
      "|    time_elapsed       | 358          |\n",
      "|    total_timesteps    | 8118272      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0022883662 |\n",
      "|    entropy_loss       | -2.41        |\n",
      "|    explained_variance | 0.943        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0357      |\n",
      "|    mean_step_reward   | -0.008674272 |\n",
      "|    n_updates          | 3960         |\n",
      "|    policyGradLoss     | -0.00234     |\n",
      "|    value_loss         | 0.111        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 707          |\n",
      "|    iterations         | 32           |\n",
      "|    time_elapsed       | 370          |\n",
      "|    total_timesteps    | 8126464      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0034510018 |\n",
      "|    entropy_loss       | -2.39        |\n",
      "|    explained_variance | 0.841        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 1.33         |\n",
      "|    mean_step_reward   | 0.024608066  |\n",
      "|    n_updates          | 3964         |\n",
      "|    policyGradLoss     | 0.000323     |\n",
      "|    value_loss         | 4.92         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 709         |\n",
      "|    iterations         | 33          |\n",
      "|    time_elapsed       | 380         |\n",
      "|    total_timesteps    | 8134656     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.003928832 |\n",
      "|    entropy_loss       | -2.37       |\n",
      "|    explained_variance | 0.89        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.698       |\n",
      "|    mean_step_reward   | 0.016482402 |\n",
      "|    n_updates          | 3968        |\n",
      "|    policyGradLoss     | 0.000631    |\n",
      "|    value_loss         | 4.7         |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 708          |\n",
      "|    iterations         | 34           |\n",
      "|    time_elapsed       | 393          |\n",
      "|    total_timesteps    | 8142848      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0036853622 |\n",
      "|    entropy_loss       | -2.38        |\n",
      "|    explained_variance | 0.801        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 2.82         |\n",
      "|    mean_step_reward   | 0.052596796  |\n",
      "|    n_updates          | 3972         |\n",
      "|    policyGradLoss     | 0.00164      |\n",
      "|    value_loss         | 15.8         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 709          |\n",
      "|    iterations         | 35           |\n",
      "|    time_elapsed       | 404          |\n",
      "|    total_timesteps    | 8151040      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.004829257  |\n",
      "|    entropy_loss       | -2.4         |\n",
      "|    explained_variance | 0.81         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 1.28         |\n",
      "|    mean_step_reward   | 0.0066181677 |\n",
      "|    n_updates          | 3976         |\n",
      "|    policyGradLoss     | 0.000803     |\n",
      "|    value_loss         | 6.02         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 707          |\n",
      "|    iterations         | 36           |\n",
      "|    time_elapsed       | 416          |\n",
      "|    total_timesteps    | 8159232      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.001677552  |\n",
      "|    entropy_loss       | -2.38        |\n",
      "|    explained_variance | 0.856        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.884        |\n",
      "|    mean_step_reward   | 0.0042696306 |\n",
      "|    n_updates          | 3980         |\n",
      "|    policyGradLoss     | 0.000696     |\n",
      "|    value_loss         | 3.97         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 706         |\n",
      "|    iterations         | 37          |\n",
      "|    time_elapsed       | 428         |\n",
      "|    total_timesteps    | 8167424     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.003368203 |\n",
      "|    entropy_loss       | -2.34       |\n",
      "|    explained_variance | 0.884       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.34        |\n",
      "|    mean_step_reward   | 0.020066608 |\n",
      "|    n_updates          | 3984        |\n",
      "|    policyGradLoss     | -0.00171    |\n",
      "|    value_loss         | 4.82        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 706          |\n",
      "|    iterations         | 38           |\n",
      "|    time_elapsed       | 440          |\n",
      "|    total_timesteps    | 8175616      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0046074064 |\n",
      "|    entropy_loss       | -2.36        |\n",
      "|    explained_variance | 0.794        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 1.4          |\n",
      "|    mean_step_reward   | 0.041823193  |\n",
      "|    n_updates          | 3988         |\n",
      "|    policyGradLoss     | 0.00133      |\n",
      "|    value_loss         | 7.04         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 705          |\n",
      "|    iterations         | 39           |\n",
      "|    time_elapsed       | 453          |\n",
      "|    total_timesteps    | 8183808      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0032821018 |\n",
      "|    entropy_loss       | -2.36        |\n",
      "|    explained_variance | 0.789        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 1.8          |\n",
      "|    mean_step_reward   | 0.029476661  |\n",
      "|    n_updates          | 3992         |\n",
      "|    policyGradLoss     | 0.00196      |\n",
      "|    value_loss         | 7.45         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 707         |\n",
      "|    iterations         | 40          |\n",
      "|    time_elapsed       | 463         |\n",
      "|    total_timesteps    | 8192000     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008090543 |\n",
      "|    entropy_loss       | -2.36       |\n",
      "|    explained_variance | 0.806       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 2.86        |\n",
      "|    mean_step_reward   | 0.072871864 |\n",
      "|    n_updates          | 3996        |\n",
      "|    policyGradLoss     | 0.00842     |\n",
      "|    value_loss         | 16.1        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/P_RWD18_24.zip\n",
      "[EVAL] Mean Return: -1.151, Best Return: -0.271\n",
      "Saved video to ./runs_smw/videos/P_RWD18/P_RWD18_24_-1.15.mp4\n",
      "\n",
      "=== Round 26 | Learn 327680 steps (Total trained: 8192000) ===\n",
      "Logging to ./runs_smw/tb/P_RWD18_0\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1005    |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 8       |\n",
      "|    total_timesteps | 8200192 |\n",
      "--------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 821          |\n",
      "|    iterations         | 2            |\n",
      "|    time_elapsed       | 19           |\n",
      "|    total_timesteps    | 8208384      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0020751841 |\n",
      "|    entropy_loss       | -2.36        |\n",
      "|    explained_variance | 0.797        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.687        |\n",
      "|    mean_step_reward   | 0.01193483   |\n",
      "|    n_updates          | 4004         |\n",
      "|    policyGradLoss     | 0.00437      |\n",
      "|    value_loss         | 4.96         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 772          |\n",
      "|    iterations         | 3            |\n",
      "|    time_elapsed       | 31           |\n",
      "|    total_timesteps    | 8216576      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0029490264 |\n",
      "|    entropy_loss       | -2.33        |\n",
      "|    explained_variance | 0.828        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 3.44         |\n",
      "|    mean_step_reward   | 0.0720253    |\n",
      "|    n_updates          | 4008         |\n",
      "|    policyGradLoss     | 0.00408      |\n",
      "|    value_loss         | 16.1         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 743          |\n",
      "|    iterations         | 4            |\n",
      "|    time_elapsed       | 44           |\n",
      "|    total_timesteps    | 8224768      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0035024378 |\n",
      "|    entropy_loss       | -2.33        |\n",
      "|    explained_variance | 0.784        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 7.42         |\n",
      "|    mean_step_reward   | 0.117376834  |\n",
      "|    n_updates          | 4012         |\n",
      "|    policyGradLoss     | 0.002        |\n",
      "|    value_loss         | 23.3         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 746          |\n",
      "|    iterations         | 5            |\n",
      "|    time_elapsed       | 54           |\n",
      "|    total_timesteps    | 8232960      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0036861394 |\n",
      "|    entropy_loss       | -2.35        |\n",
      "|    explained_variance | 0.856        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 1.86         |\n",
      "|    mean_step_reward   | 0.070735395  |\n",
      "|    n_updates          | 4016         |\n",
      "|    policyGradLoss     | 0.00549      |\n",
      "|    value_loss         | 10.8         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 731          |\n",
      "|    iterations         | 6            |\n",
      "|    time_elapsed       | 67           |\n",
      "|    total_timesteps    | 8241152      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0035603354 |\n",
      "|    entropy_loss       | -2.35        |\n",
      "|    explained_variance | 0.835        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 5.85         |\n",
      "|    mean_step_reward   | 0.12931475   |\n",
      "|    n_updates          | 4020         |\n",
      "|    policyGradLoss     | 0.003        |\n",
      "|    value_loss         | 26.5         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 733          |\n",
      "|    iterations         | 7            |\n",
      "|    time_elapsed       | 78           |\n",
      "|    total_timesteps    | 8249344      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0022879886 |\n",
      "|    entropy_loss       | -2.35        |\n",
      "|    explained_variance | 0.858        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 2.56         |\n",
      "|    mean_step_reward   | 0.03630199   |\n",
      "|    n_updates          | 4024         |\n",
      "|    policyGradLoss     | 0.00239      |\n",
      "|    value_loss         | 14.3         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 722          |\n",
      "|    iterations         | 8            |\n",
      "|    time_elapsed       | 90           |\n",
      "|    total_timesteps    | 8257536      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0024014432 |\n",
      "|    entropy_loss       | -2.38        |\n",
      "|    explained_variance | 0.871        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.771        |\n",
      "|    mean_step_reward   | 0.008333073  |\n",
      "|    n_updates          | 4028         |\n",
      "|    policyGradLoss     | 0.00219      |\n",
      "|    value_loss         | 4.3          |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 718          |\n",
      "|    iterations         | 9            |\n",
      "|    time_elapsed       | 102          |\n",
      "|    total_timesteps    | 8265728      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0013243156 |\n",
      "|    entropy_loss       | -2.37        |\n",
      "|    explained_variance | 0.914        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 2.06         |\n",
      "|    mean_step_reward   | 0.03664814   |\n",
      "|    n_updates          | 4032         |\n",
      "|    policyGradLoss     | 0.000711     |\n",
      "|    value_loss         | 6.62         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 716          |\n",
      "|    iterations         | 10           |\n",
      "|    time_elapsed       | 114          |\n",
      "|    total_timesteps    | 8273920      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0019118461 |\n",
      "|    entropy_loss       | -2.37        |\n",
      "|    explained_variance | 0.885        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 1.15         |\n",
      "|    mean_step_reward   | 0.0317426    |\n",
      "|    n_updates          | 4036         |\n",
      "|    policyGradLoss     | 0.00051      |\n",
      "|    value_loss         | 5.73         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 712          |\n",
      "|    iterations         | 11           |\n",
      "|    time_elapsed       | 126          |\n",
      "|    total_timesteps    | 8282112      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0019365815 |\n",
      "|    entropy_loss       | -2.38        |\n",
      "|    explained_variance | 0.876        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.87         |\n",
      "|    mean_step_reward   | 0.016672462  |\n",
      "|    n_updates          | 4040         |\n",
      "|    policyGradLoss     | -0.000426    |\n",
      "|    value_loss         | 5.04         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 718         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 136         |\n",
      "|    total_timesteps    | 8290304     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.002222945 |\n",
      "|    entropy_loss       | -2.38       |\n",
      "|    explained_variance | 0.873       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.23        |\n",
      "|    mean_step_reward   | 0.038324963 |\n",
      "|    n_updates          | 4044        |\n",
      "|    policyGradLoss     | 0.00194     |\n",
      "|    value_loss         | 5.41        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 713          |\n",
      "|    iterations         | 13           |\n",
      "|    time_elapsed       | 149          |\n",
      "|    total_timesteps    | 8298496      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0040917145 |\n",
      "|    entropy_loss       | -2.38        |\n",
      "|    explained_variance | 0.885        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 1.09         |\n",
      "|    mean_step_reward   | 0.044726975  |\n",
      "|    n_updates          | 4048         |\n",
      "|    policyGradLoss     | 0.000671     |\n",
      "|    value_loss         | 6.75         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 714         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 160         |\n",
      "|    total_timesteps    | 8306688     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.002780385 |\n",
      "|    entropy_loss       | -2.36       |\n",
      "|    explained_variance | 0.882       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 5.53        |\n",
      "|    mean_step_reward   | 0.10585096  |\n",
      "|    n_updates          | 4052        |\n",
      "|    policyGradLoss     | 0.00313     |\n",
      "|    value_loss         | 12.5        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 710          |\n",
      "|    iterations         | 15           |\n",
      "|    time_elapsed       | 172          |\n",
      "|    total_timesteps    | 8314880      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0020037685 |\n",
      "|    entropy_loss       | -2.36        |\n",
      "|    explained_variance | 0.907        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 2.37         |\n",
      "|    mean_step_reward   | 0.06789991   |\n",
      "|    n_updates          | 4056         |\n",
      "|    policyGradLoss     | 0.00123      |\n",
      "|    value_loss         | 8.51         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 707          |\n",
      "|    iterations         | 16           |\n",
      "|    time_elapsed       | 185          |\n",
      "|    total_timesteps    | 8323072      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0019422142 |\n",
      "|    entropy_loss       | -2.35        |\n",
      "|    explained_variance | 0.896        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 3.6          |\n",
      "|    mean_step_reward   | 0.10101447   |\n",
      "|    n_updates          | 4060         |\n",
      "|    policyGradLoss     | -0.000545    |\n",
      "|    value_loss         | 12.9         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 706         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 197         |\n",
      "|    total_timesteps    | 8331264     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.005160665 |\n",
      "|    entropy_loss       | -2.36       |\n",
      "|    explained_variance | 0.889       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 2.74        |\n",
      "|    mean_step_reward   | 0.10650336  |\n",
      "|    n_updates          | 4064        |\n",
      "|    policyGradLoss     | 0.00128     |\n",
      "|    value_loss         | 15.7        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 703         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 209         |\n",
      "|    total_timesteps    | 8339456     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.003988742 |\n",
      "|    entropy_loss       | -2.4        |\n",
      "|    explained_variance | 0.908       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.83        |\n",
      "|    mean_step_reward   | 0.060505837 |\n",
      "|    n_updates          | 4068        |\n",
      "|    policyGradLoss     | 0.001       |\n",
      "|    value_loss         | 7.48        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 707         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 219         |\n",
      "|    total_timesteps    | 8347648     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.003789187 |\n",
      "|    entropy_loss       | -2.39       |\n",
      "|    explained_variance | 0.927       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 3.13        |\n",
      "|    mean_step_reward   | 0.041310262 |\n",
      "|    n_updates          | 4072        |\n",
      "|    policyGradLoss     | 0.00186     |\n",
      "|    value_loss         | 6.95        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 706          |\n",
      "|    iterations         | 20           |\n",
      "|    time_elapsed       | 232          |\n",
      "|    total_timesteps    | 8355840      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0021985234 |\n",
      "|    entropy_loss       | -2.39        |\n",
      "|    explained_variance | 0.943        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.776        |\n",
      "|    mean_step_reward   | 0.051995836  |\n",
      "|    n_updates          | 4076         |\n",
      "|    policyGradLoss     | 0.000178     |\n",
      "|    value_loss         | 5.85         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 707          |\n",
      "|    iterations         | 21           |\n",
      "|    time_elapsed       | 243          |\n",
      "|    total_timesteps    | 8364032      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0026040664 |\n",
      "|    entropy_loss       | -2.4         |\n",
      "|    explained_variance | 0.947        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.372        |\n",
      "|    mean_step_reward   | 0.006010141  |\n",
      "|    n_updates          | 4080         |\n",
      "|    policyGradLoss     | -0.000223    |\n",
      "|    value_loss         | 2.94         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 705          |\n",
      "|    iterations         | 22           |\n",
      "|    time_elapsed       | 255          |\n",
      "|    total_timesteps    | 8372224      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0031232028 |\n",
      "|    entropy_loss       | -2.4         |\n",
      "|    explained_variance | 0.917        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.806        |\n",
      "|    mean_step_reward   | 0.018288385  |\n",
      "|    n_updates          | 4084         |\n",
      "|    policyGradLoss     | -0.000779    |\n",
      "|    value_loss         | 3.95         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 703           |\n",
      "|    iterations         | 23            |\n",
      "|    time_elapsed       | 267           |\n",
      "|    total_timesteps    | 8380416       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.002148178   |\n",
      "|    entropy_loss       | -2.4          |\n",
      "|    explained_variance | 0.916         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | 0.183         |\n",
      "|    mean_step_reward   | -0.0019552293 |\n",
      "|    n_updates          | 4088          |\n",
      "|    policyGradLoss     | 7.25e-05      |\n",
      "|    value_loss         | 1.53          |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 704         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 279         |\n",
      "|    total_timesteps    | 8388608     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.002079821 |\n",
      "|    entropy_loss       | -2.39       |\n",
      "|    explained_variance | 0.942       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0562      |\n",
      "|    mean_step_reward   | 0.007342112 |\n",
      "|    n_updates          | 4092        |\n",
      "|    policyGradLoss     | -0.000702   |\n",
      "|    value_loss         | 0.994       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 703          |\n",
      "|    iterations         | 25           |\n",
      "|    time_elapsed       | 291          |\n",
      "|    total_timesteps    | 8396800      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0018296592 |\n",
      "|    entropy_loss       | -2.37        |\n",
      "|    explained_variance | 0.9          |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 1.32         |\n",
      "|    mean_step_reward   | 0.06543601   |\n",
      "|    n_updates          | 4096         |\n",
      "|    policyGradLoss     | -0.00107     |\n",
      "|    value_loss         | 8.62         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 706         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 301         |\n",
      "|    total_timesteps    | 8404992     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.003070837 |\n",
      "|    entropy_loss       | -2.36       |\n",
      "|    explained_variance | 0.926       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 2.06        |\n",
      "|    mean_step_reward   | 0.082561135 |\n",
      "|    n_updates          | 4100        |\n",
      "|    policyGradLoss     | 0.000387    |\n",
      "|    value_loss         | 8.94        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 704          |\n",
      "|    iterations         | 27           |\n",
      "|    time_elapsed       | 313          |\n",
      "|    total_timesteps    | 8413184      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0024829907 |\n",
      "|    entropy_loss       | -2.39        |\n",
      "|    explained_variance | 0.905        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 2.32         |\n",
      "|    mean_step_reward   | 0.08294146   |\n",
      "|    n_updates          | 4104         |\n",
      "|    policyGradLoss     | 0.00366      |\n",
      "|    value_loss         | 12.3         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 705          |\n",
      "|    iterations         | 28           |\n",
      "|    time_elapsed       | 325          |\n",
      "|    total_timesteps    | 8421376      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0033847042 |\n",
      "|    entropy_loss       | -2.39        |\n",
      "|    explained_variance | 0.932        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.835        |\n",
      "|    mean_step_reward   | 0.035133258  |\n",
      "|    n_updates          | 4108         |\n",
      "|    policyGradLoss     | 0.00116      |\n",
      "|    value_loss         | 5.58         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 704          |\n",
      "|    iterations         | 29           |\n",
      "|    time_elapsed       | 337          |\n",
      "|    total_timesteps    | 8429568      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0055027865 |\n",
      "|    entropy_loss       | -2.38        |\n",
      "|    explained_variance | 0.916        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 2.01         |\n",
      "|    mean_step_reward   | 0.0802591    |\n",
      "|    n_updates          | 4112         |\n",
      "|    policyGradLoss     | 2.83e-05     |\n",
      "|    value_loss         | 8.95         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 703          |\n",
      "|    iterations         | 30           |\n",
      "|    time_elapsed       | 349          |\n",
      "|    total_timesteps    | 8437760      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0028118195 |\n",
      "|    entropy_loss       | -2.38        |\n",
      "|    explained_variance | 0.939        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 1.24         |\n",
      "|    mean_step_reward   | 0.06164735   |\n",
      "|    n_updates          | 4116         |\n",
      "|    policyGradLoss     | -0.000341    |\n",
      "|    value_loss         | 8.05         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 704         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 360         |\n",
      "|    total_timesteps    | 8445952     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.005580443 |\n",
      "|    entropy_loss       | -2.42       |\n",
      "|    explained_variance | 0.916       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.02        |\n",
      "|    mean_step_reward   | 0.07166745  |\n",
      "|    n_updates          | 4120        |\n",
      "|    policyGradLoss     | 0.00281     |\n",
      "|    value_loss         | 9.07        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 702          |\n",
      "|    iterations         | 32           |\n",
      "|    time_elapsed       | 373          |\n",
      "|    total_timesteps    | 8454144      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0047137486 |\n",
      "|    entropy_loss       | -2.45        |\n",
      "|    explained_variance | -0.299       |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0517      |\n",
      "|    mean_step_reward   | -0.00801447  |\n",
      "|    n_updates          | 4124         |\n",
      "|    policyGradLoss     | -0.00517     |\n",
      "|    value_loss         | 0.0509       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 704          |\n",
      "|    iterations         | 33           |\n",
      "|    time_elapsed       | 383          |\n",
      "|    total_timesteps    | 8462336      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.004122437  |\n",
      "|    entropy_loss       | -2.43        |\n",
      "|    explained_variance | 0.457        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0514      |\n",
      "|    mean_step_reward   | -0.009251693 |\n",
      "|    n_updates          | 4128         |\n",
      "|    policyGradLoss     | -0.00452     |\n",
      "|    value_loss         | 0.0318       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 703          |\n",
      "|    iterations         | 34           |\n",
      "|    time_elapsed       | 396          |\n",
      "|    total_timesteps    | 8470528      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0022107628 |\n",
      "|    entropy_loss       | -2.41        |\n",
      "|    explained_variance | 0.956        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.00917     |\n",
      "|    mean_step_reward   | -0.008368967 |\n",
      "|    n_updates          | 4132         |\n",
      "|    policyGradLoss     | -0.000284    |\n",
      "|    value_loss         | 0.141        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 703           |\n",
      "|    iterations         | 35            |\n",
      "|    time_elapsed       | 407           |\n",
      "|    total_timesteps    | 8478720       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0035770326  |\n",
      "|    entropy_loss       | -2.37         |\n",
      "|    explained_variance | 0.954         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0382       |\n",
      "|    mean_step_reward   | -0.0064542983 |\n",
      "|    n_updates          | 4136          |\n",
      "|    policyGradLoss     | -0.00105      |\n",
      "|    value_loss         | 0.161         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 703           |\n",
      "|    iterations         | 36            |\n",
      "|    time_elapsed       | 418           |\n",
      "|    total_timesteps    | 8486912       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0048150495  |\n",
      "|    entropy_loss       | -2.36         |\n",
      "|    explained_variance | 0.923         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | 0.0735        |\n",
      "|    mean_step_reward   | -0.0054692915 |\n",
      "|    n_updates          | 4140          |\n",
      "|    policyGradLoss     | -0.0023       |\n",
      "|    value_loss         | 0.332         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 704          |\n",
      "|    iterations         | 37           |\n",
      "|    time_elapsed       | 430          |\n",
      "|    total_timesteps    | 8495104      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0033291234 |\n",
      "|    entropy_loss       | -2.3         |\n",
      "|    explained_variance | 0.829        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.76         |\n",
      "|    mean_step_reward   | 0.023403881  |\n",
      "|    n_updates          | 4144         |\n",
      "|    policyGradLoss     | 0.00118      |\n",
      "|    value_loss         | 6.16         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 704          |\n",
      "|    iterations         | 38           |\n",
      "|    time_elapsed       | 442          |\n",
      "|    total_timesteps    | 8503296      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0030532759 |\n",
      "|    entropy_loss       | -2.27        |\n",
      "|    explained_variance | 0.805        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 2.63         |\n",
      "|    mean_step_reward   | 0.09258838   |\n",
      "|    n_updates          | 4148         |\n",
      "|    policyGradLoss     | 0.00683      |\n",
      "|    value_loss         | 16           |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 702          |\n",
      "|    iterations         | 39           |\n",
      "|    time_elapsed       | 454          |\n",
      "|    total_timesteps    | 8511488      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0031285738 |\n",
      "|    entropy_loss       | -2.27        |\n",
      "|    explained_variance | 0.814        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 5.45         |\n",
      "|    mean_step_reward   | 0.11896092   |\n",
      "|    n_updates          | 4152         |\n",
      "|    policyGradLoss     | 0.0005       |\n",
      "|    value_loss         | 24.7         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 703          |\n",
      "|    iterations         | 40           |\n",
      "|    time_elapsed       | 465          |\n",
      "|    total_timesteps    | 8519680      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0040175207 |\n",
      "|    entropy_loss       | -2.27        |\n",
      "|    explained_variance | 0.886        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 2.35         |\n",
      "|    mean_step_reward   | 0.052823517  |\n",
      "|    n_updates          | 4156         |\n",
      "|    policyGradLoss     | 0.002        |\n",
      "|    value_loss         | 14.7         |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/P_RWD18_25.zip\n",
      "[EVAL] Mean Return: -1.151, Best Return: -0.271\n",
      "Saved video to ./runs_smw/videos/P_RWD18/P_RWD18_25_-1.15.mp4\n",
      "\n",
      "=== Round 27 | Learn 327680 steps (Total trained: 8519680) ===\n",
      "Logging to ./runs_smw/tb/P_RWD18_0\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1104    |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 7       |\n",
      "|    total_timesteps | 8527872 |\n",
      "--------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 837          |\n",
      "|    iterations         | 2            |\n",
      "|    time_elapsed       | 19           |\n",
      "|    total_timesteps    | 8536064      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0027714798 |\n",
      "|    entropy_loss       | -2.28        |\n",
      "|    explained_variance | 0.87         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 2.85         |\n",
      "|    mean_step_reward   | 0.0678898    |\n",
      "|    n_updates          | 4164         |\n",
      "|    policyGradLoss     | -0.000176    |\n",
      "|    value_loss         | 15.1         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 30          |\n",
      "|    total_timesteps    | 8544256     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.003405101 |\n",
      "|    entropy_loss       | -2.28       |\n",
      "|    explained_variance | 0.855       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 6.55        |\n",
      "|    mean_step_reward   | 0.10505942  |\n",
      "|    n_updates          | 4168        |\n",
      "|    policyGradLoss     | 0.00282     |\n",
      "|    value_loss         | 31.6        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 769          |\n",
      "|    iterations         | 4            |\n",
      "|    time_elapsed       | 42           |\n",
      "|    total_timesteps    | 8552448      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0023276391 |\n",
      "|    entropy_loss       | -2.26        |\n",
      "|    explained_variance | 0.912        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 4.07         |\n",
      "|    mean_step_reward   | 0.15669855   |\n",
      "|    n_updates          | 4172         |\n",
      "|    policyGradLoss     | 0.000628     |\n",
      "|    value_loss         | 24.7         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 764         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 53          |\n",
      "|    total_timesteps    | 8560640     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.002544388 |\n",
      "|    entropy_loss       | -2.3        |\n",
      "|    explained_variance | 0.88        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 6.41        |\n",
      "|    mean_step_reward   | 0.14651187  |\n",
      "|    n_updates          | 4176        |\n",
      "|    policyGradLoss     | 0.00146     |\n",
      "|    value_loss         | 31.6        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 743          |\n",
      "|    iterations         | 6            |\n",
      "|    time_elapsed       | 66           |\n",
      "|    total_timesteps    | 8568832      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0023532957 |\n",
      "|    entropy_loss       | -2.32        |\n",
      "|    explained_variance | 0.877        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 2.32         |\n",
      "|    mean_step_reward   | 0.04601995   |\n",
      "|    n_updates          | 4180         |\n",
      "|    policyGradLoss     | 0.000292     |\n",
      "|    value_loss         | 11.4         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 734          |\n",
      "|    iterations         | 7            |\n",
      "|    time_elapsed       | 78           |\n",
      "|    total_timesteps    | 8577024      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0023305658 |\n",
      "|    entropy_loss       | -2.3         |\n",
      "|    explained_variance | 0.89         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 3.7          |\n",
      "|    mean_step_reward   | 0.07548302   |\n",
      "|    n_updates          | 4184         |\n",
      "|    policyGradLoss     | 0.000224     |\n",
      "|    value_loss         | 17.2         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 729          |\n",
      "|    iterations         | 8            |\n",
      "|    time_elapsed       | 89           |\n",
      "|    total_timesteps    | 8585216      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0022187135 |\n",
      "|    entropy_loss       | -2.32        |\n",
      "|    explained_variance | 0.874        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 1.74         |\n",
      "|    mean_step_reward   | 0.0523405    |\n",
      "|    n_updates          | 4188         |\n",
      "|    policyGradLoss     | 0.00106      |\n",
      "|    value_loss         | 10.7         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 721          |\n",
      "|    iterations         | 9            |\n",
      "|    time_elapsed       | 102          |\n",
      "|    total_timesteps    | 8593408      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0030020447 |\n",
      "|    entropy_loss       | -2.33        |\n",
      "|    explained_variance | 0.864        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 1.79         |\n",
      "|    mean_step_reward   | 0.06329458   |\n",
      "|    n_updates          | 4192         |\n",
      "|    policyGradLoss     | 0.000111     |\n",
      "|    value_loss         | 11.7         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 729         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 112         |\n",
      "|    total_timesteps    | 8601600     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.002016961 |\n",
      "|    entropy_loss       | -2.33       |\n",
      "|    explained_variance | 0.881       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.646       |\n",
      "|    mean_step_reward   | 0.02113341  |\n",
      "|    n_updates          | 4196        |\n",
      "|    policyGradLoss     | 0.00121     |\n",
      "|    value_loss         | 3.89        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 723          |\n",
      "|    iterations         | 11           |\n",
      "|    time_elapsed       | 124          |\n",
      "|    total_timesteps    | 8609792      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0026441412 |\n",
      "|    entropy_loss       | -2.31        |\n",
      "|    explained_variance | 0.897        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 2.62         |\n",
      "|    mean_step_reward   | 0.073011056  |\n",
      "|    n_updates          | 4200         |\n",
      "|    policyGradLoss     | 0.00199      |\n",
      "|    value_loss         | 14           |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 724         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 135         |\n",
      "|    total_timesteps    | 8617984     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.002424005 |\n",
      "|    entropy_loss       | -2.32       |\n",
      "|    explained_variance | 0.902       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 2.23        |\n",
      "|    mean_step_reward   | 0.051057965 |\n",
      "|    n_updates          | 4204        |\n",
      "|    policyGradLoss     | 0.00116     |\n",
      "|    value_loss         | 9.69        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 719          |\n",
      "|    iterations         | 13           |\n",
      "|    time_elapsed       | 148          |\n",
      "|    total_timesteps    | 8626176      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0022281823 |\n",
      "|    entropy_loss       | -2.33        |\n",
      "|    explained_variance | 0.836        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 1.16         |\n",
      "|    mean_step_reward   | 0.044243407  |\n",
      "|    n_updates          | 4208         |\n",
      "|    policyGradLoss     | 0.00165      |\n",
      "|    value_loss         | 8.08         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 715         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 160         |\n",
      "|    total_timesteps    | 8634368     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.003667569 |\n",
      "|    entropy_loss       | -2.33       |\n",
      "|    explained_variance | 0.862       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 5.41        |\n",
      "|    mean_step_reward   | 0.09883541  |\n",
      "|    n_updates          | 4212        |\n",
      "|    policyGradLoss     | 0.00103     |\n",
      "|    value_loss         | 20.5        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 715          |\n",
      "|    iterations         | 15           |\n",
      "|    time_elapsed       | 171          |\n",
      "|    total_timesteps    | 8642560      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0020123152 |\n",
      "|    entropy_loss       | -2.34        |\n",
      "|    explained_variance | 0.85         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 1.72         |\n",
      "|    mean_step_reward   | 0.040036667  |\n",
      "|    n_updates          | 4216         |\n",
      "|    policyGradLoss     | 0.000124     |\n",
      "|    value_loss         | 9.36         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 711          |\n",
      "|    iterations         | 16           |\n",
      "|    time_elapsed       | 184          |\n",
      "|    total_timesteps    | 8650752      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0027378292 |\n",
      "|    entropy_loss       | -2.36        |\n",
      "|    explained_variance | 0.819        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 3.31         |\n",
      "|    mean_step_reward   | 0.077591635  |\n",
      "|    n_updates          | 4220         |\n",
      "|    policyGradLoss     | 0.0009       |\n",
      "|    value_loss         | 12.7         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 716          |\n",
      "|    iterations         | 17           |\n",
      "|    time_elapsed       | 194          |\n",
      "|    total_timesteps    | 8658944      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0033006035 |\n",
      "|    entropy_loss       | -2.33        |\n",
      "|    explained_variance | 0.872        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 4.08         |\n",
      "|    mean_step_reward   | 0.12700588   |\n",
      "|    n_updates          | 4224         |\n",
      "|    policyGradLoss     | -0.000353    |\n",
      "|    value_loss         | 20.7         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 712         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 206         |\n",
      "|    total_timesteps    | 8667136     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.001383731 |\n",
      "|    entropy_loss       | -2.34       |\n",
      "|    explained_variance | 0.9         |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.16        |\n",
      "|    mean_step_reward   | 0.02737775  |\n",
      "|    n_updates          | 4228        |\n",
      "|    policyGradLoss     | 0.00195     |\n",
      "|    value_loss         | 7.54        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 711         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 218         |\n",
      "|    total_timesteps    | 8675328     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.003541316 |\n",
      "|    entropy_loss       | -2.34       |\n",
      "|    explained_variance | 0.862       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 2.15        |\n",
      "|    mean_step_reward   | 0.1069991   |\n",
      "|    n_updates          | 4232        |\n",
      "|    policyGradLoss     | 0.000254    |\n",
      "|    value_loss         | 15.1        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 708          |\n",
      "|    iterations         | 20           |\n",
      "|    time_elapsed       | 231          |\n",
      "|    total_timesteps    | 8683520      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0034280252 |\n",
      "|    entropy_loss       | -2.36        |\n",
      "|    explained_variance | 0.897        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 2.62         |\n",
      "|    mean_step_reward   | 0.084277704  |\n",
      "|    n_updates          | 4236         |\n",
      "|    policyGradLoss     | 0.000388     |\n",
      "|    value_loss         | 15.4         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 706          |\n",
      "|    iterations         | 21           |\n",
      "|    time_elapsed       | 243          |\n",
      "|    total_timesteps    | 8691712      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0025273836 |\n",
      "|    entropy_loss       | -2.34        |\n",
      "|    explained_variance | 0.894        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 7.36         |\n",
      "|    mean_step_reward   | 0.1510368    |\n",
      "|    n_updates          | 4240         |\n",
      "|    policyGradLoss     | -0.000132    |\n",
      "|    value_loss         | 24           |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 707         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 254         |\n",
      "|    total_timesteps    | 8699904     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.003913817 |\n",
      "|    entropy_loss       | -2.36       |\n",
      "|    explained_variance | 0.91        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 3.86        |\n",
      "|    mean_step_reward   | 0.13258101  |\n",
      "|    n_updates          | 4244        |\n",
      "|    policyGradLoss     | 0.000439    |\n",
      "|    value_loss         | 19.6        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 705          |\n",
      "|    iterations         | 23           |\n",
      "|    time_elapsed       | 266          |\n",
      "|    total_timesteps    | 8708096      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0017392982 |\n",
      "|    entropy_loss       | -2.36        |\n",
      "|    explained_variance | 0.916        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 4.51         |\n",
      "|    mean_step_reward   | 0.113116845  |\n",
      "|    n_updates          | 4248         |\n",
      "|    policyGradLoss     | -0.000471    |\n",
      "|    value_loss         | 17.9         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 708          |\n",
      "|    iterations         | 24           |\n",
      "|    time_elapsed       | 277          |\n",
      "|    total_timesteps    | 8716288      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0025847196 |\n",
      "|    entropy_loss       | -2.39        |\n",
      "|    explained_variance | 0.865        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.756        |\n",
      "|    mean_step_reward   | 0.029064946  |\n",
      "|    n_updates          | 4252         |\n",
      "|    policyGradLoss     | -0.000116    |\n",
      "|    value_loss         | 8.77         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 705          |\n",
      "|    iterations         | 25           |\n",
      "|    time_elapsed       | 290          |\n",
      "|    total_timesteps    | 8724480      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0016804081 |\n",
      "|    entropy_loss       | -2.39        |\n",
      "|    explained_variance | 0.935        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.787        |\n",
      "|    mean_step_reward   | 0.08000499   |\n",
      "|    n_updates          | 4256         |\n",
      "|    policyGradLoss     | 0.00256      |\n",
      "|    value_loss         | 6.09         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 705         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 301         |\n",
      "|    total_timesteps    | 8732672     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.001395942 |\n",
      "|    entropy_loss       | -2.4        |\n",
      "|    explained_variance | 0.899       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.579       |\n",
      "|    mean_step_reward   | 0.009456197 |\n",
      "|    n_updates          | 4260        |\n",
      "|    policyGradLoss     | -0.000977   |\n",
      "|    value_loss         | 4.47        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 705         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 313         |\n",
      "|    total_timesteps    | 8740864     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.002355072 |\n",
      "|    entropy_loss       | -2.4        |\n",
      "|    explained_variance | 0.926       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.983       |\n",
      "|    mean_step_reward   | 0.06430268  |\n",
      "|    n_updates          | 4264        |\n",
      "|    policyGradLoss     | 0.00153     |\n",
      "|    value_loss         | 8           |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 703          |\n",
      "|    iterations         | 28           |\n",
      "|    time_elapsed       | 325          |\n",
      "|    total_timesteps    | 8749056      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0020778724 |\n",
      "|    entropy_loss       | -2.42        |\n",
      "|    explained_variance | 0.915        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.939        |\n",
      "|    mean_step_reward   | 0.019666709  |\n",
      "|    n_updates          | 4268         |\n",
      "|    policyGradLoss     | 0.00275      |\n",
      "|    value_loss         | 3.35         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 706          |\n",
      "|    iterations         | 29           |\n",
      "|    time_elapsed       | 336          |\n",
      "|    total_timesteps    | 8757248      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0023759794 |\n",
      "|    entropy_loss       | -2.42        |\n",
      "|    explained_variance | 0.942        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.224        |\n",
      "|    mean_step_reward   | 0.030052524  |\n",
      "|    n_updates          | 4272         |\n",
      "|    policyGradLoss     | 0.000166     |\n",
      "|    value_loss         | 2.83         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 704           |\n",
      "|    iterations         | 30            |\n",
      "|    time_elapsed       | 348           |\n",
      "|    total_timesteps    | 8765440       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0017797896  |\n",
      "|    entropy_loss       | -2.41         |\n",
      "|    explained_variance | 0.951         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | 0.0813        |\n",
      "|    mean_step_reward   | 2.8776936e-05 |\n",
      "|    n_updates          | 4276          |\n",
      "|    policyGradLoss     | -0.000606     |\n",
      "|    value_loss         | 1.2           |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 705          |\n",
      "|    iterations         | 31           |\n",
      "|    time_elapsed       | 360          |\n",
      "|    total_timesteps    | 8773632      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0028389832 |\n",
      "|    entropy_loss       | -2.4         |\n",
      "|    explained_variance | 0.952        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 1.67         |\n",
      "|    mean_step_reward   | 0.023886817  |\n",
      "|    n_updates          | 4280         |\n",
      "|    policyGradLoss     | 0.00134      |\n",
      "|    value_loss         | 3.83         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 704         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 372         |\n",
      "|    total_timesteps    | 8781824     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.00340966  |\n",
      "|    entropy_loss       | -2.42       |\n",
      "|    explained_variance | 0.93        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.655       |\n",
      "|    mean_step_reward   | 0.030299041 |\n",
      "|    n_updates          | 4284        |\n",
      "|    policyGradLoss     | 0.000209    |\n",
      "|    value_loss         | 4.52        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 703         |\n",
      "|    iterations         | 33          |\n",
      "|    time_elapsed       | 384         |\n",
      "|    total_timesteps    | 8790016     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.002448593 |\n",
      "|    entropy_loss       | -2.43       |\n",
      "|    explained_variance | 0.906       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.291       |\n",
      "|    mean_step_reward   | 0.009609173 |\n",
      "|    n_updates          | 4288        |\n",
      "|    policyGradLoss     | 0.000333    |\n",
      "|    value_loss         | 3.51        |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 703           |\n",
      "|    iterations         | 34            |\n",
      "|    time_elapsed       | 395           |\n",
      "|    total_timesteps    | 8798208       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.004353945   |\n",
      "|    entropy_loss       | -2.44         |\n",
      "|    explained_variance | 0.759         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0561       |\n",
      "|    mean_step_reward   | -0.0071862387 |\n",
      "|    n_updates          | 4292          |\n",
      "|    policyGradLoss     | -0.00349      |\n",
      "|    value_loss         | 0.0863        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 702           |\n",
      "|    iterations         | 35            |\n",
      "|    time_elapsed       | 408           |\n",
      "|    total_timesteps    | 8806400       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.003257954   |\n",
      "|    entropy_loss       | -2.44         |\n",
      "|    explained_variance | 0.727         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.029        |\n",
      "|    mean_step_reward   | -0.0096174525 |\n",
      "|    n_updates          | 4296          |\n",
      "|    policyGradLoss     | -0.00415      |\n",
      "|    value_loss         | 0.068         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 704          |\n",
      "|    iterations         | 36           |\n",
      "|    time_elapsed       | 418          |\n",
      "|    total_timesteps    | 8814592      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0038988197 |\n",
      "|    entropy_loss       | -2.44        |\n",
      "|    explained_variance | 0.786        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0566      |\n",
      "|    mean_step_reward   | -0.007982044 |\n",
      "|    n_updates          | 4300         |\n",
      "|    policyGradLoss     | -0.00474     |\n",
      "|    value_loss         | 0.047        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 702          |\n",
      "|    iterations         | 37           |\n",
      "|    time_elapsed       | 431          |\n",
      "|    total_timesteps    | 8822784      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0040995227 |\n",
      "|    entropy_loss       | -2.43        |\n",
      "|    explained_variance | 0.668        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0495      |\n",
      "|    mean_step_reward   | -0.009265896 |\n",
      "|    n_updates          | 4304         |\n",
      "|    policyGradLoss     | -0.00599     |\n",
      "|    value_loss         | 0.0567       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 702          |\n",
      "|    iterations         | 38           |\n",
      "|    time_elapsed       | 442          |\n",
      "|    total_timesteps    | 8830976      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0020243884 |\n",
      "|    entropy_loss       | -2.42        |\n",
      "|    explained_variance | 0.903        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0693       |\n",
      "|    mean_step_reward   | -0.003786827 |\n",
      "|    n_updates          | 4308         |\n",
      "|    policyGradLoss     | 0.00056      |\n",
      "|    value_loss         | 0.882        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 701         |\n",
      "|    iterations         | 39          |\n",
      "|    time_elapsed       | 455         |\n",
      "|    total_timesteps    | 8839168     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.002563612 |\n",
      "|    entropy_loss       | -2.4        |\n",
      "|    explained_variance | 0.922       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.301       |\n",
      "|    mean_step_reward   | 0.032601077 |\n",
      "|    n_updates          | 4312        |\n",
      "|    policyGradLoss     | -0.000103   |\n",
      "|    value_loss         | 3.78        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 700          |\n",
      "|    iterations         | 40           |\n",
      "|    time_elapsed       | 467          |\n",
      "|    total_timesteps    | 8847360      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0020028374 |\n",
      "|    entropy_loss       | -2.38        |\n",
      "|    explained_variance | 0.902        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.838        |\n",
      "|    mean_step_reward   | 0.029954886  |\n",
      "|    n_updates          | 4316         |\n",
      "|    policyGradLoss     | 0.00082      |\n",
      "|    value_loss         | 7.24         |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/P_RWD18_26.zip\n",
      "[EVAL] Mean Return: -1.290, Best Return: -1.284\n",
      "Saved video to ./runs_smw/videos/P_RWD18/P_RWD18_26_-1.29.mp4\n",
      "\n",
      "=== Round 28 | Learn 327680 steps (Total trained: 8847360) ===\n",
      "Logging to ./runs_smw/tb/P_RWD18_0\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1356    |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 6       |\n",
      "|    total_timesteps | 8855552 |\n",
      "--------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 893          |\n",
      "|    iterations         | 2            |\n",
      "|    time_elapsed       | 18           |\n",
      "|    total_timesteps    | 8863744      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0024916972 |\n",
      "|    entropy_loss       | -2.33        |\n",
      "|    explained_variance | 0.936        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 4.34         |\n",
      "|    mean_step_reward   | 0.09888987   |\n",
      "|    n_updates          | 4324         |\n",
      "|    policyGradLoss     | 0.00127      |\n",
      "|    value_loss         | 18.4         |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 839        |\n",
      "|    iterations         | 3          |\n",
      "|    time_elapsed       | 29         |\n",
      "|    total_timesteps    | 8871936    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.00387335 |\n",
      "|    entropy_loss       | -2.32      |\n",
      "|    explained_variance | 0.914      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 5.76       |\n",
      "|    mean_step_reward   | 0.11458111 |\n",
      "|    n_updates          | 4328       |\n",
      "|    policyGradLoss     | 0.00317    |\n",
      "|    value_loss         | 24         |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 781          |\n",
      "|    iterations         | 4            |\n",
      "|    time_elapsed       | 41           |\n",
      "|    total_timesteps    | 8880128      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0032018132 |\n",
      "|    entropy_loss       | -2.3         |\n",
      "|    explained_variance | 0.896        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 4.45         |\n",
      "|    mean_step_reward   | 0.07950985   |\n",
      "|    n_updates          | 4332         |\n",
      "|    policyGradLoss     | 0.00314      |\n",
      "|    value_loss         | 19.8         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 757          |\n",
      "|    iterations         | 5            |\n",
      "|    time_elapsed       | 54           |\n",
      "|    total_timesteps    | 8888320      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0033631974 |\n",
      "|    entropy_loss       | -2.27        |\n",
      "|    explained_variance | 0.893        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 9.27         |\n",
      "|    mean_step_reward   | 0.22553635   |\n",
      "|    n_updates          | 4336         |\n",
      "|    policyGradLoss     | 0.00019      |\n",
      "|    value_loss         | 40           |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 748          |\n",
      "|    iterations         | 6            |\n",
      "|    time_elapsed       | 65           |\n",
      "|    total_timesteps    | 8896512      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0032886846 |\n",
      "|    entropy_loss       | -2.27        |\n",
      "|    explained_variance | 0.886        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 10.4         |\n",
      "|    mean_step_reward   | 0.1649634    |\n",
      "|    n_updates          | 4340         |\n",
      "|    policyGradLoss     | 0.00447      |\n",
      "|    value_loss         | 41.6         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 736          |\n",
      "|    iterations         | 7            |\n",
      "|    time_elapsed       | 77           |\n",
      "|    total_timesteps    | 8904704      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0025081653 |\n",
      "|    entropy_loss       | -2.32        |\n",
      "|    explained_variance | 0.897        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 2.62         |\n",
      "|    mean_step_reward   | 0.12069386   |\n",
      "|    n_updates          | 4344         |\n",
      "|    policyGradLoss     | 0.00321      |\n",
      "|    value_loss         | 17.6         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 742         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 88          |\n",
      "|    total_timesteps    | 8912896     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.004418023 |\n",
      "|    entropy_loss       | -2.31       |\n",
      "|    explained_variance | 0.914       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 5.36        |\n",
      "|    mean_step_reward   | 0.14527686  |\n",
      "|    n_updates          | 4348        |\n",
      "|    policyGradLoss     | 0.00172     |\n",
      "|    value_loss         | 27.2        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 731          |\n",
      "|    iterations         | 9            |\n",
      "|    time_elapsed       | 100          |\n",
      "|    total_timesteps    | 8921088      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0041357363 |\n",
      "|    entropy_loss       | -2.32        |\n",
      "|    explained_variance | 0.879        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 8.46         |\n",
      "|    mean_step_reward   | 0.11193684   |\n",
      "|    n_updates          | 4352         |\n",
      "|    policyGradLoss     | 0.00184      |\n",
      "|    value_loss         | 33.4         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 730          |\n",
      "|    iterations         | 10           |\n",
      "|    time_elapsed       | 112          |\n",
      "|    total_timesteps    | 8929280      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0026408373 |\n",
      "|    entropy_loss       | -2.32        |\n",
      "|    explained_variance | 0.868        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 1.76         |\n",
      "|    mean_step_reward   | 0.028995004  |\n",
      "|    n_updates          | 4356         |\n",
      "|    policyGradLoss     | 0.00121      |\n",
      "|    value_loss         | 16.5         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 725          |\n",
      "|    iterations         | 11           |\n",
      "|    time_elapsed       | 124          |\n",
      "|    total_timesteps    | 8937472      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0042932574 |\n",
      "|    entropy_loss       | -2.32        |\n",
      "|    explained_variance | 0.919        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 2.82         |\n",
      "|    mean_step_reward   | 0.110428505  |\n",
      "|    n_updates          | 4360         |\n",
      "|    policyGradLoss     | 0.00189      |\n",
      "|    value_loss         | 16.3         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 720          |\n",
      "|    iterations         | 12           |\n",
      "|    time_elapsed       | 136          |\n",
      "|    total_timesteps    | 8945664      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0031953482 |\n",
      "|    entropy_loss       | -2.35        |\n",
      "|    explained_variance | 0.909        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 3.13         |\n",
      "|    mean_step_reward   | 0.05146314   |\n",
      "|    n_updates          | 4364         |\n",
      "|    policyGradLoss     | 0.00233      |\n",
      "|    value_loss         | 12.5         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 722          |\n",
      "|    iterations         | 13           |\n",
      "|    time_elapsed       | 147          |\n",
      "|    total_timesteps    | 8953856      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0033897143 |\n",
      "|    entropy_loss       | -2.37        |\n",
      "|    explained_variance | 0.918        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 2.46         |\n",
      "|    mean_step_reward   | 0.08845795   |\n",
      "|    n_updates          | 4368         |\n",
      "|    policyGradLoss     | 6.06e-05     |\n",
      "|    value_loss         | 10.8         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 719          |\n",
      "|    iterations         | 14           |\n",
      "|    time_elapsed       | 159          |\n",
      "|    total_timesteps    | 8962048      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0016442705 |\n",
      "|    entropy_loss       | -2.37        |\n",
      "|    explained_variance | 0.938        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 1.3          |\n",
      "|    mean_step_reward   | 0.038457017  |\n",
      "|    n_updates          | 4372         |\n",
      "|    policyGradLoss     | 0.000546     |\n",
      "|    value_loss         | 7.43         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 716          |\n",
      "|    iterations         | 15           |\n",
      "|    time_elapsed       | 171          |\n",
      "|    total_timesteps    | 8970240      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0017257169 |\n",
      "|    entropy_loss       | -2.41        |\n",
      "|    explained_variance | 0.912        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.13         |\n",
      "|    mean_step_reward   | 0.0029348065 |\n",
      "|    n_updates          | 4376         |\n",
      "|    policyGradLoss     | -0.000135    |\n",
      "|    value_loss         | 2.67         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 716          |\n",
      "|    iterations         | 16           |\n",
      "|    time_elapsed       | 183          |\n",
      "|    total_timesteps    | 8978432      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0021147507 |\n",
      "|    entropy_loss       | -2.43        |\n",
      "|    explained_variance | 0.935        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.162        |\n",
      "|    mean_step_reward   | 0.005672873  |\n",
      "|    n_updates          | 4380         |\n",
      "|    policyGradLoss     | -3.85e-05    |\n",
      "|    value_loss         | 1.47         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 715          |\n",
      "|    iterations         | 17           |\n",
      "|    time_elapsed       | 194          |\n",
      "|    total_timesteps    | 8986624      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0024664602 |\n",
      "|    entropy_loss       | -2.44        |\n",
      "|    explained_variance | 0.907        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0233      |\n",
      "|    mean_step_reward   | -0.008817587 |\n",
      "|    n_updates          | 4384         |\n",
      "|    policyGradLoss     | -0.0016      |\n",
      "|    value_loss         | 0.44         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 713          |\n",
      "|    iterations         | 18           |\n",
      "|    time_elapsed       | 206          |\n",
      "|    total_timesteps    | 8994816      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0034293218 |\n",
      "|    entropy_loss       | -2.45        |\n",
      "|    explained_variance | 0.608        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0587      |\n",
      "|    mean_step_reward   | -0.008948881 |\n",
      "|    n_updates          | 4388         |\n",
      "|    policyGradLoss     | -0.00328     |\n",
      "|    value_loss         | 0.0275       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 710         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 218         |\n",
      "|    total_timesteps    | 9003008     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.003310214 |\n",
      "|    entropy_loss       | -2.46       |\n",
      "|    explained_variance | 0.607       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0682     |\n",
      "|    mean_step_reward   | -0.00878232 |\n",
      "|    n_updates          | 4392        |\n",
      "|    policyGradLoss     | -0.0042     |\n",
      "|    value_loss         | 0.0176      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 711          |\n",
      "|    iterations         | 20           |\n",
      "|    time_elapsed       | 230          |\n",
      "|    total_timesteps    | 9011200      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0027365715 |\n",
      "|    entropy_loss       | -2.46        |\n",
      "|    explained_variance | 0.562        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.066       |\n",
      "|    mean_step_reward   | -0.009365327 |\n",
      "|    n_updates          | 4396         |\n",
      "|    policyGradLoss     | -0.0048      |\n",
      "|    value_loss         | 0.0126       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 709          |\n",
      "|    iterations         | 21           |\n",
      "|    time_elapsed       | 242          |\n",
      "|    total_timesteps    | 9019392      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.004025099  |\n",
      "|    entropy_loss       | -2.46        |\n",
      "|    explained_variance | 0.404        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0645      |\n",
      "|    mean_step_reward   | -0.009525847 |\n",
      "|    n_updates          | 4400         |\n",
      "|    policyGradLoss     | -0.00399     |\n",
      "|    value_loss         | 0.0229       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 712          |\n",
      "|    iterations         | 22           |\n",
      "|    time_elapsed       | 253          |\n",
      "|    total_timesteps    | 9027584      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.00315999   |\n",
      "|    entropy_loss       | -2.46        |\n",
      "|    explained_variance | 0.338        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0633      |\n",
      "|    mean_step_reward   | -0.007847799 |\n",
      "|    n_updates          | 4404         |\n",
      "|    policyGradLoss     | -0.00448     |\n",
      "|    value_loss         | 0.0281       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 709          |\n",
      "|    iterations         | 23           |\n",
      "|    time_elapsed       | 265          |\n",
      "|    total_timesteps    | 9035776      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0043247277 |\n",
      "|    entropy_loss       | -2.43        |\n",
      "|    explained_variance | 0.52         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0627      |\n",
      "|    mean_step_reward   | -0.008616823 |\n",
      "|    n_updates          | 4408         |\n",
      "|    policyGradLoss     | -0.00735     |\n",
      "|    value_loss         | 0.0359       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 710           |\n",
      "|    iterations         | 24            |\n",
      "|    time_elapsed       | 276           |\n",
      "|    total_timesteps    | 9043968       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0032369904  |\n",
      "|    entropy_loss       | -2.42         |\n",
      "|    explained_variance | 0.521         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0284       |\n",
      "|    mean_step_reward   | -0.0058440627 |\n",
      "|    n_updates          | 4412          |\n",
      "|    policyGradLoss     | -0.00624      |\n",
      "|    value_loss         | 0.105         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 708           |\n",
      "|    iterations         | 25            |\n",
      "|    time_elapsed       | 289           |\n",
      "|    total_timesteps    | 9052160       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0013026717  |\n",
      "|    entropy_loss       | -2.41         |\n",
      "|    explained_variance | 0.947         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0297       |\n",
      "|    mean_step_reward   | -0.0059168832 |\n",
      "|    n_updates          | 4416          |\n",
      "|    policyGradLoss     | -0.00124      |\n",
      "|    value_loss         | 0.186         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 707           |\n",
      "|    iterations         | 26            |\n",
      "|    time_elapsed       | 301           |\n",
      "|    total_timesteps    | 9060352       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0020403108  |\n",
      "|    entropy_loss       | -2.37         |\n",
      "|    explained_variance | 0.917         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | 0.166         |\n",
      "|    mean_step_reward   | -0.0053014783 |\n",
      "|    n_updates          | 4420          |\n",
      "|    policyGradLoss     | 0.000351      |\n",
      "|    value_loss         | 1.21          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 708          |\n",
      "|    iterations         | 27           |\n",
      "|    time_elapsed       | 312          |\n",
      "|    total_timesteps    | 9068544      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0024062046 |\n",
      "|    entropy_loss       | -2.35        |\n",
      "|    explained_variance | 0.91         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.523        |\n",
      "|    mean_step_reward   | 0.0054844767 |\n",
      "|    n_updates          | 4424         |\n",
      "|    policyGradLoss     | -3.04e-05    |\n",
      "|    value_loss         | 2.41         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 707          |\n",
      "|    iterations         | 28           |\n",
      "|    time_elapsed       | 324          |\n",
      "|    total_timesteps    | 9076736      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0028582257 |\n",
      "|    entropy_loss       | -2.34        |\n",
      "|    explained_variance | 0.882        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 1.21         |\n",
      "|    mean_step_reward   | 0.021055095  |\n",
      "|    n_updates          | 4428         |\n",
      "|    policyGradLoss     | -0.000263    |\n",
      "|    value_loss         | 4.41         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 709         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 335         |\n",
      "|    total_timesteps    | 9084928     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.002679009 |\n",
      "|    entropy_loss       | -2.36       |\n",
      "|    explained_variance | 0.898       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.315       |\n",
      "|    mean_step_reward   | 0.016595056 |\n",
      "|    n_updates          | 4432        |\n",
      "|    policyGradLoss     | 0.00143     |\n",
      "|    value_loss         | 2.68        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 706          |\n",
      "|    iterations         | 30           |\n",
      "|    time_elapsed       | 347          |\n",
      "|    total_timesteps    | 9093120      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0024326784 |\n",
      "|    entropy_loss       | -2.37        |\n",
      "|    explained_variance | 0.863        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.524        |\n",
      "|    mean_step_reward   | 0.03073802   |\n",
      "|    n_updates          | 4436         |\n",
      "|    policyGradLoss     | 0.00158      |\n",
      "|    value_loss         | 3.99         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 705         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 359         |\n",
      "|    total_timesteps    | 9101312     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.003064713 |\n",
      "|    entropy_loss       | -2.35       |\n",
      "|    explained_variance | 0.842       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.813       |\n",
      "|    mean_step_reward   | 0.03701436  |\n",
      "|    n_updates          | 4440        |\n",
      "|    policyGradLoss     | 0.000226    |\n",
      "|    value_loss         | 4.08        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 705          |\n",
      "|    iterations         | 32           |\n",
      "|    time_elapsed       | 371          |\n",
      "|    total_timesteps    | 9109504      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0023755878 |\n",
      "|    entropy_loss       | -2.33        |\n",
      "|    explained_variance | 0.858        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 2.44         |\n",
      "|    mean_step_reward   | 0.07767546   |\n",
      "|    n_updates          | 4444         |\n",
      "|    policyGradLoss     | 0.000553     |\n",
      "|    value_loss         | 9.82         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 703          |\n",
      "|    iterations         | 33           |\n",
      "|    time_elapsed       | 384          |\n",
      "|    total_timesteps    | 9117696      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0031620576 |\n",
      "|    entropy_loss       | -2.34        |\n",
      "|    explained_variance | 0.823        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 3.79         |\n",
      "|    mean_step_reward   | 0.1853876    |\n",
      "|    n_updates          | 4448         |\n",
      "|    policyGradLoss     | 0.000914     |\n",
      "|    value_loss         | 19.6         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 705          |\n",
      "|    iterations         | 34           |\n",
      "|    time_elapsed       | 395          |\n",
      "|    total_timesteps    | 9125888      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0034340154 |\n",
      "|    entropy_loss       | -2.35        |\n",
      "|    explained_variance | 0.879        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 3.08         |\n",
      "|    mean_step_reward   | 0.13306788   |\n",
      "|    n_updates          | 4452         |\n",
      "|    policyGradLoss     | 0.000692     |\n",
      "|    value_loss         | 14.2         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 703         |\n",
      "|    iterations         | 35          |\n",
      "|    time_elapsed       | 407         |\n",
      "|    total_timesteps    | 9134080     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.005173114 |\n",
      "|    entropy_loss       | -2.33       |\n",
      "|    explained_variance | 0.87        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 3.84        |\n",
      "|    mean_step_reward   | 0.12550762  |\n",
      "|    n_updates          | 4456        |\n",
      "|    policyGradLoss     | 0.000786    |\n",
      "|    value_loss         | 20.3        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 705          |\n",
      "|    iterations         | 36           |\n",
      "|    time_elapsed       | 418          |\n",
      "|    total_timesteps    | 9142272      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0027751753 |\n",
      "|    entropy_loss       | -2.34        |\n",
      "|    explained_variance | 0.91         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 3.66         |\n",
      "|    mean_step_reward   | 0.13734226   |\n",
      "|    n_updates          | 4460         |\n",
      "|    policyGradLoss     | 0.00185      |\n",
      "|    value_loss         | 15.9         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 703          |\n",
      "|    iterations         | 37           |\n",
      "|    time_elapsed       | 431          |\n",
      "|    total_timesteps    | 9150464      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0033078154 |\n",
      "|    entropy_loss       | -2.36        |\n",
      "|    explained_variance | 0.904        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 1.77         |\n",
      "|    mean_step_reward   | 0.08498968   |\n",
      "|    n_updates          | 4464         |\n",
      "|    policyGradLoss     | 0.00381      |\n",
      "|    value_loss         | 10.9         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 702          |\n",
      "|    iterations         | 38           |\n",
      "|    time_elapsed       | 443          |\n",
      "|    total_timesteps    | 9158656      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0043368773 |\n",
      "|    entropy_loss       | -2.36        |\n",
      "|    explained_variance | 0.9          |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 1.41         |\n",
      "|    mean_step_reward   | 0.07827428   |\n",
      "|    n_updates          | 4468         |\n",
      "|    policyGradLoss     | 0.000156     |\n",
      "|    value_loss         | 14.4         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 702          |\n",
      "|    iterations         | 39           |\n",
      "|    time_elapsed       | 455          |\n",
      "|    total_timesteps    | 9166848      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0026555043 |\n",
      "|    entropy_loss       | -2.39        |\n",
      "|    explained_variance | 0.92         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 1.36         |\n",
      "|    mean_step_reward   | 0.0815663    |\n",
      "|    n_updates          | 4472         |\n",
      "|    policyGradLoss     | 0.00101      |\n",
      "|    value_loss         | 9.07         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 701         |\n",
      "|    iterations         | 40          |\n",
      "|    time_elapsed       | 467         |\n",
      "|    total_timesteps    | 9175040     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.002907068 |\n",
      "|    entropy_loss       | -2.4        |\n",
      "|    explained_variance | 0.931       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 3.35        |\n",
      "|    mean_step_reward   | 0.061730225 |\n",
      "|    n_updates          | 4476        |\n",
      "|    policyGradLoss     | 0.00021     |\n",
      "|    value_loss         | 10.6        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/P_RWD18_27.zip\n",
      "[EVAL] Mean Return: -1.124, Best Return: -0.191\n",
      "Saved video to ./runs_smw/videos/P_RWD18/P_RWD18_27_-1.12.mp4\n",
      "\n",
      "=== Round 29 | Learn 327680 steps (Total trained: 9175040) ===\n",
      "Logging to ./runs_smw/tb/P_RWD18_0\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1181    |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 6       |\n",
      "|    total_timesteps | 9183232 |\n",
      "--------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 838          |\n",
      "|    iterations         | 2            |\n",
      "|    time_elapsed       | 19           |\n",
      "|    total_timesteps    | 9191424      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0031539914 |\n",
      "|    entropy_loss       | -2.42        |\n",
      "|    explained_variance | 0.951        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0223      |\n",
      "|    mean_step_reward   | -0.008024803 |\n",
      "|    n_updates          | 4484         |\n",
      "|    policyGradLoss     | -0.00317     |\n",
      "|    value_loss         | 0.187        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 31          |\n",
      "|    total_timesteps    | 9199616     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.003406337 |\n",
      "|    entropy_loss       | -2.39       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.39        |\n",
      "|    mean_step_reward   | 0.022365525 |\n",
      "|    n_updates          | 4488        |\n",
      "|    policyGradLoss     | 0.000167    |\n",
      "|    value_loss         | 2.51        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 754        |\n",
      "|    iterations         | 4          |\n",
      "|    time_elapsed       | 43         |\n",
      "|    total_timesteps    | 9207808    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.00407439 |\n",
      "|    entropy_loss       | -2.35      |\n",
      "|    explained_variance | 0.928      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 1.51       |\n",
      "|    mean_step_reward   | 0.07609542 |\n",
      "|    n_updates          | 4492       |\n",
      "|    policyGradLoss     | 0.00303    |\n",
      "|    value_loss         | 11.6       |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 739          |\n",
      "|    iterations         | 5            |\n",
      "|    time_elapsed       | 55           |\n",
      "|    total_timesteps    | 9216000      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0023909695 |\n",
      "|    entropy_loss       | -2.32        |\n",
      "|    explained_variance | 0.925        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 4.2          |\n",
      "|    mean_step_reward   | 0.112057984  |\n",
      "|    n_updates          | 4496         |\n",
      "|    policyGradLoss     | 0.00216      |\n",
      "|    value_loss         | 14.7         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 747          |\n",
      "|    iterations         | 6            |\n",
      "|    time_elapsed       | 65           |\n",
      "|    total_timesteps    | 9224192      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0037066685 |\n",
      "|    entropy_loss       | -2.26        |\n",
      "|    explained_variance | 0.922        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 7.07         |\n",
      "|    mean_step_reward   | 0.24061505   |\n",
      "|    n_updates          | 4500         |\n",
      "|    policyGradLoss     | 0.00228      |\n",
      "|    value_loss         | 34.6         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 735          |\n",
      "|    iterations         | 7            |\n",
      "|    time_elapsed       | 77           |\n",
      "|    total_timesteps    | 9232384      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0023819774 |\n",
      "|    entropy_loss       | -2.25        |\n",
      "|    explained_variance | 0.921        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 15.3         |\n",
      "|    mean_step_reward   | 0.20551455   |\n",
      "|    n_updates          | 4504         |\n",
      "|    policyGradLoss     | 0.00211      |\n",
      "|    value_loss         | 44.2         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 732          |\n",
      "|    iterations         | 8            |\n",
      "|    time_elapsed       | 89           |\n",
      "|    total_timesteps    | 9240576      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0043519065 |\n",
      "|    entropy_loss       | -2.23        |\n",
      "|    explained_variance | 0.908        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 12.4         |\n",
      "|    mean_step_reward   | 0.22936058   |\n",
      "|    n_updates          | 4508         |\n",
      "|    policyGradLoss     | 0.00441      |\n",
      "|    value_loss         | 47.1         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 725          |\n",
      "|    iterations         | 9            |\n",
      "|    time_elapsed       | 101          |\n",
      "|    total_timesteps    | 9248768      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0042617074 |\n",
      "|    entropy_loss       | -2.22        |\n",
      "|    explained_variance | 0.901        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 14.4         |\n",
      "|    mean_step_reward   | 0.29252133   |\n",
      "|    n_updates          | 4512         |\n",
      "|    policyGradLoss     | 0.000645     |\n",
      "|    value_loss         | 56.2         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 719         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 113         |\n",
      "|    total_timesteps    | 9256960     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.003763976 |\n",
      "|    entropy_loss       | -2.27       |\n",
      "|    explained_variance | 0.908       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 5.84        |\n",
      "|    mean_step_reward   | 0.11856538  |\n",
      "|    n_updates          | 4516        |\n",
      "|    policyGradLoss     | 0.00162     |\n",
      "|    value_loss         | 35.5        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 721          |\n",
      "|    iterations         | 11           |\n",
      "|    time_elapsed       | 124          |\n",
      "|    total_timesteps    | 9265152      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0035044148 |\n",
      "|    entropy_loss       | -2.3         |\n",
      "|    explained_variance | 0.944        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 4.27         |\n",
      "|    mean_step_reward   | 0.121638425  |\n",
      "|    n_updates          | 4520         |\n",
      "|    policyGradLoss     | 0.00224      |\n",
      "|    value_loss         | 17.6         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 716          |\n",
      "|    iterations         | 12           |\n",
      "|    time_elapsed       | 137          |\n",
      "|    total_timesteps    | 9273344      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0038713682 |\n",
      "|    entropy_loss       | -2.3         |\n",
      "|    explained_variance | 0.928        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 4.96         |\n",
      "|    mean_step_reward   | 0.13978969   |\n",
      "|    n_updates          | 4524         |\n",
      "|    policyGradLoss     | 0.00138      |\n",
      "|    value_loss         | 25.1         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 720          |\n",
      "|    iterations         | 13           |\n",
      "|    time_elapsed       | 147          |\n",
      "|    total_timesteps    | 9281536      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0019972746 |\n",
      "|    entropy_loss       | -2.32        |\n",
      "|    explained_variance | 0.944        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 3.37         |\n",
      "|    mean_step_reward   | 0.12246262   |\n",
      "|    n_updates          | 4528         |\n",
      "|    policyGradLoss     | 0.00231      |\n",
      "|    value_loss         | 21.3         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 714         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 160         |\n",
      "|    total_timesteps    | 9289728     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.003159963 |\n",
      "|    entropy_loss       | -2.3        |\n",
      "|    explained_variance | 0.943       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 8.76        |\n",
      "|    mean_step_reward   | 0.22551215  |\n",
      "|    n_updates          | 4532        |\n",
      "|    policyGradLoss     | 0.00144     |\n",
      "|    value_loss         | 31.9        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 713          |\n",
      "|    iterations         | 15           |\n",
      "|    time_elapsed       | 172          |\n",
      "|    total_timesteps    | 9297920      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0025714773 |\n",
      "|    entropy_loss       | -2.33        |\n",
      "|    explained_variance | 0.946        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 4.78         |\n",
      "|    mean_step_reward   | 0.07763077   |\n",
      "|    n_updates          | 4536         |\n",
      "|    policyGradLoss     | 0.00402      |\n",
      "|    value_loss         | 21.6         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 713          |\n",
      "|    iterations         | 16           |\n",
      "|    time_elapsed       | 183          |\n",
      "|    total_timesteps    | 9306112      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0023150444 |\n",
      "|    entropy_loss       | -2.31        |\n",
      "|    explained_variance | 0.96         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 1.19         |\n",
      "|    mean_step_reward   | 0.05748992   |\n",
      "|    n_updates          | 4540         |\n",
      "|    policyGradLoss     | 0.00022      |\n",
      "|    value_loss         | 10.1         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 710          |\n",
      "|    iterations         | 17           |\n",
      "|    time_elapsed       | 195          |\n",
      "|    total_timesteps    | 9314304      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0032146396 |\n",
      "|    entropy_loss       | -2.3         |\n",
      "|    explained_variance | 0.952        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 4.21         |\n",
      "|    mean_step_reward   | 0.17825334   |\n",
      "|    n_updates          | 4544         |\n",
      "|    policyGradLoss     | 0.0014       |\n",
      "|    value_loss         | 25           |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 716        |\n",
      "|    iterations         | 18         |\n",
      "|    time_elapsed       | 205        |\n",
      "|    total_timesteps    | 9322496    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.00375233 |\n",
      "|    entropy_loss       | -2.24      |\n",
      "|    explained_variance | 0.947      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 15         |\n",
      "|    mean_step_reward   | 0.3150491  |\n",
      "|    n_updates          | 4548       |\n",
      "|    policyGradLoss     | 0.00149    |\n",
      "|    value_loss         | 53.8       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 713         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 218         |\n",
      "|    total_timesteps    | 9330688     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.004013405 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 8.99        |\n",
      "|    mean_step_reward   | 0.2409136   |\n",
      "|    n_updates          | 4552        |\n",
      "|    policyGradLoss     | 0.000715    |\n",
      "|    value_loss         | 39.1        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 713          |\n",
      "|    iterations         | 20           |\n",
      "|    time_elapsed       | 229          |\n",
      "|    total_timesteps    | 9338880      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0034151396 |\n",
      "|    entropy_loss       | -2.25        |\n",
      "|    explained_variance | 0.932        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 9.69         |\n",
      "|    mean_step_reward   | 0.12783131   |\n",
      "|    n_updates          | 4556         |\n",
      "|    policyGradLoss     | 0.00267      |\n",
      "|    value_loss         | 36.4         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 712          |\n",
      "|    iterations         | 21           |\n",
      "|    time_elapsed       | 241          |\n",
      "|    total_timesteps    | 9347072      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0043520886 |\n",
      "|    entropy_loss       | -2.26        |\n",
      "|    explained_variance | 0.943        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 6.83         |\n",
      "|    mean_step_reward   | 0.15868348   |\n",
      "|    n_updates          | 4560         |\n",
      "|    policyGradLoss     | 0.00168      |\n",
      "|    value_loss         | 30.8         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 710          |\n",
      "|    iterations         | 22           |\n",
      "|    time_elapsed       | 253          |\n",
      "|    total_timesteps    | 9355264      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0033991155 |\n",
      "|    entropy_loss       | -2.3         |\n",
      "|    explained_variance | 0.923        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 4.85         |\n",
      "|    mean_step_reward   | 0.1101713    |\n",
      "|    n_updates          | 4564         |\n",
      "|    policyGradLoss     | -0.000392    |\n",
      "|    value_loss         | 27           |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 712         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 264         |\n",
      "|    total_timesteps    | 9363456     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.002821784 |\n",
      "|    entropy_loss       | -2.35       |\n",
      "|    explained_variance | 0.892       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 2.66        |\n",
      "|    mean_step_reward   | 0.029012525 |\n",
      "|    n_updates          | 4568        |\n",
      "|    policyGradLoss     | -0.000405   |\n",
      "|    value_loss         | 9.27        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 710         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 276         |\n",
      "|    total_timesteps    | 9371648     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.00304001  |\n",
      "|    entropy_loss       | -2.35       |\n",
      "|    explained_variance | 0.917       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.92        |\n",
      "|    mean_step_reward   | 0.060353868 |\n",
      "|    n_updates          | 4572        |\n",
      "|    policyGradLoss     | -0.000508   |\n",
      "|    value_loss         | 9.05        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 712          |\n",
      "|    iterations         | 25           |\n",
      "|    time_elapsed       | 287          |\n",
      "|    total_timesteps    | 9379840      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0038237078 |\n",
      "|    entropy_loss       | -2.34        |\n",
      "|    explained_variance | 0.901        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 2.18         |\n",
      "|    mean_step_reward   | 0.100156516  |\n",
      "|    n_updates          | 4576         |\n",
      "|    policyGradLoss     | 0.000842     |\n",
      "|    value_loss         | 22.9         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 710          |\n",
      "|    iterations         | 26           |\n",
      "|    time_elapsed       | 299          |\n",
      "|    total_timesteps    | 9388032      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0041365433 |\n",
      "|    entropy_loss       | -2.32        |\n",
      "|    explained_variance | 0.904        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 8.18         |\n",
      "|    mean_step_reward   | 0.09735704   |\n",
      "|    n_updates          | 4580         |\n",
      "|    policyGradLoss     | 0.0024       |\n",
      "|    value_loss         | 37.2         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 709          |\n",
      "|    iterations         | 27           |\n",
      "|    time_elapsed       | 311          |\n",
      "|    total_timesteps    | 9396224      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0041012787 |\n",
      "|    entropy_loss       | -2.33        |\n",
      "|    explained_variance | 0.931        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 5.74         |\n",
      "|    mean_step_reward   | 0.077395335  |\n",
      "|    n_updates          | 4584         |\n",
      "|    policyGradLoss     | 0.00444      |\n",
      "|    value_loss         | 22.2         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 709         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 323         |\n",
      "|    total_timesteps    | 9404416     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008021945 |\n",
      "|    entropy_loss       | -2.29       |\n",
      "|    explained_variance | 0.917       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 6.05        |\n",
      "|    mean_step_reward   | 0.13047892  |\n",
      "|    n_updates          | 4588        |\n",
      "|    policyGradLoss     | 9.58e-05    |\n",
      "|    value_loss         | 35.2        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 708         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 335         |\n",
      "|    total_timesteps    | 9412608     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.004340253 |\n",
      "|    entropy_loss       | -2.3        |\n",
      "|    explained_variance | 0.91        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 8.29        |\n",
      "|    mean_step_reward   | 0.06966993  |\n",
      "|    n_updates          | 4592        |\n",
      "|    policyGradLoss     | 0.00378     |\n",
      "|    value_loss         | 31.2        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 709         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 346         |\n",
      "|    total_timesteps    | 9420800     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.003754468 |\n",
      "|    entropy_loss       | -2.3        |\n",
      "|    explained_variance | 0.909       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 12.8        |\n",
      "|    mean_step_reward   | 0.15653148  |\n",
      "|    n_updates          | 4596        |\n",
      "|    policyGradLoss     | 0.00404     |\n",
      "|    value_loss         | 47.2        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 708          |\n",
      "|    iterations         | 31           |\n",
      "|    time_elapsed       | 358          |\n",
      "|    total_timesteps    | 9428992      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0030363249 |\n",
      "|    entropy_loss       | -2.34        |\n",
      "|    explained_variance | 0.909        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 5.54         |\n",
      "|    mean_step_reward   | 0.031664558  |\n",
      "|    n_updates          | 4600         |\n",
      "|    policyGradLoss     | 0.000436     |\n",
      "|    value_loss         | 23.6         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 710          |\n",
      "|    iterations         | 32           |\n",
      "|    time_elapsed       | 369          |\n",
      "|    total_timesteps    | 9437184      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0024633636 |\n",
      "|    entropy_loss       | -2.35        |\n",
      "|    explained_variance | 0.938        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 2.06         |\n",
      "|    mean_step_reward   | 0.057619654  |\n",
      "|    n_updates          | 4604         |\n",
      "|    policyGradLoss     | 0.000379     |\n",
      "|    value_loss         | 11.3         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 708           |\n",
      "|    iterations         | 33            |\n",
      "|    time_elapsed       | 381           |\n",
      "|    total_timesteps    | 9445376       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0056476975  |\n",
      "|    entropy_loss       | -2.43         |\n",
      "|    explained_variance | -0.716        |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.033        |\n",
      "|    mean_step_reward   | -0.0053095617 |\n",
      "|    n_updates          | 4608          |\n",
      "|    policyGradLoss     | -0.00116      |\n",
      "|    value_loss         | 0.555         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 707          |\n",
      "|    iterations         | 34           |\n",
      "|    time_elapsed       | 393          |\n",
      "|    total_timesteps    | 9453568      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0047672205 |\n",
      "|    entropy_loss       | -2.42        |\n",
      "|    explained_variance | 0.321        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0595      |\n",
      "|    mean_step_reward   | -0.009147698 |\n",
      "|    n_updates          | 4612         |\n",
      "|    policyGradLoss     | -0.00268     |\n",
      "|    value_loss         | 0.038        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 708           |\n",
      "|    iterations         | 35            |\n",
      "|    time_elapsed       | 404           |\n",
      "|    total_timesteps    | 9461760       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.004304902   |\n",
      "|    entropy_loss       | -2.42         |\n",
      "|    explained_variance | 0.367         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0397       |\n",
      "|    mean_step_reward   | -0.0059451205 |\n",
      "|    n_updates          | 4616          |\n",
      "|    policyGradLoss     | -0.00459      |\n",
      "|    value_loss         | 0.0595        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 708           |\n",
      "|    iterations         | 36            |\n",
      "|    time_elapsed       | 416           |\n",
      "|    total_timesteps    | 9469952       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0039459877  |\n",
      "|    entropy_loss       | -2.41         |\n",
      "|    explained_variance | 0.272         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0515       |\n",
      "|    mean_step_reward   | -0.0066994093 |\n",
      "|    n_updates          | 4620          |\n",
      "|    policyGradLoss     | -0.00469      |\n",
      "|    value_loss         | 0.0491        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 707          |\n",
      "|    iterations         | 37           |\n",
      "|    time_elapsed       | 428          |\n",
      "|    total_timesteps    | 9478144      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0045368704 |\n",
      "|    entropy_loss       | -2.42        |\n",
      "|    explained_variance | 0.308        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.067       |\n",
      "|    mean_step_reward   | -0.008666881 |\n",
      "|    n_updates          | 4624         |\n",
      "|    policyGradLoss     | -0.00597     |\n",
      "|    value_loss         | 0.0226       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 707          |\n",
      "|    iterations         | 38           |\n",
      "|    time_elapsed       | 440          |\n",
      "|    total_timesteps    | 9486336      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0053699994 |\n",
      "|    entropy_loss       | -2.41        |\n",
      "|    explained_variance | -0.0552      |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0666      |\n",
      "|    mean_step_reward   | -0.008987533 |\n",
      "|    n_updates          | 4628         |\n",
      "|    policyGradLoss     | -0.00619     |\n",
      "|    value_loss         | 0.0147       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 707          |\n",
      "|    iterations         | 39           |\n",
      "|    time_elapsed       | 451          |\n",
      "|    total_timesteps    | 9494528      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.005498257  |\n",
      "|    entropy_loss       | -2.39        |\n",
      "|    explained_variance | 0.116        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0609      |\n",
      "|    mean_step_reward   | -0.007810902 |\n",
      "|    n_updates          | 4632         |\n",
      "|    policyGradLoss     | -0.0084      |\n",
      "|    value_loss         | 0.0252       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 705          |\n",
      "|    iterations         | 40           |\n",
      "|    time_elapsed       | 464          |\n",
      "|    total_timesteps    | 9502720      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.00621564   |\n",
      "|    entropy_loss       | -2.39        |\n",
      "|    explained_variance | 0.395        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0694      |\n",
      "|    mean_step_reward   | -0.008291557 |\n",
      "|    n_updates          | 4636         |\n",
      "|    policyGradLoss     | -0.00882     |\n",
      "|    value_loss         | 0.0165       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/P_RWD18_28.zip\n",
      "[EVAL] Mean Return: 28.305, Best Return: 28.305\n",
      "Saved video to ./runs_smw/videos/P_RWD18/P_RWD18_28_28.30.mp4\n",
      "\n",
      "=== Round 30 | Learn 327680 steps (Total trained: 9502720) ===\n",
      "Logging to ./runs_smw/tb/P_RWD18_0\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 991     |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 8       |\n",
      "|    total_timesteps | 9510912 |\n",
      "--------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 847          |\n",
      "|    iterations         | 2            |\n",
      "|    time_elapsed       | 19           |\n",
      "|    total_timesteps    | 9519104      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.004311569  |\n",
      "|    entropy_loss       | -2.38        |\n",
      "|    explained_variance | 0.393        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0573      |\n",
      "|    mean_step_reward   | -0.008158368 |\n",
      "|    n_updates          | 4644         |\n",
      "|    policyGradLoss     | -0.00797     |\n",
      "|    value_loss         | 0.0325       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 764          |\n",
      "|    iterations         | 3            |\n",
      "|    time_elapsed       | 32           |\n",
      "|    total_timesteps    | 9527296      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.005767132  |\n",
      "|    entropy_loss       | -2.39        |\n",
      "|    explained_variance | 0.359        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0608      |\n",
      "|    mean_step_reward   | -0.008085322 |\n",
      "|    n_updates          | 4648         |\n",
      "|    policyGradLoss     | -0.00717     |\n",
      "|    value_loss         | 0.0175       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 741          |\n",
      "|    iterations         | 4            |\n",
      "|    time_elapsed       | 44           |\n",
      "|    total_timesteps    | 9535488      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0035925296 |\n",
      "|    entropy_loss       | -2.39        |\n",
      "|    explained_variance | 0.268        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0537      |\n",
      "|    mean_step_reward   | -0.007308536 |\n",
      "|    n_updates          | 4652         |\n",
      "|    policyGradLoss     | -0.00665     |\n",
      "|    value_loss         | 0.0328       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 732           |\n",
      "|    iterations         | 5             |\n",
      "|    time_elapsed       | 55            |\n",
      "|    total_timesteps    | 9543680       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0068674656  |\n",
      "|    entropy_loss       | -2.39         |\n",
      "|    explained_variance | 0.451         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0474       |\n",
      "|    mean_step_reward   | -0.0073951343 |\n",
      "|    n_updates          | 4656          |\n",
      "|    policyGradLoss     | -0.00354      |\n",
      "|    value_loss         | 0.0357        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 720         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 68          |\n",
      "|    total_timesteps    | 9551872     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.005754635 |\n",
      "|    entropy_loss       | -2.38       |\n",
      "|    explained_variance | 0.441       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0573     |\n",
      "|    mean_step_reward   | -0.00617891 |\n",
      "|    n_updates          | 4660        |\n",
      "|    policyGradLoss     | -0.0063     |\n",
      "|    value_loss         | 0.0492      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 731          |\n",
      "|    iterations         | 7            |\n",
      "|    time_elapsed       | 78           |\n",
      "|    total_timesteps    | 9560064      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0054006595 |\n",
      "|    entropy_loss       | -2.37        |\n",
      "|    explained_variance | 0.404        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0515      |\n",
      "|    mean_step_reward   | -0.006979173 |\n",
      "|    n_updates          | 4664         |\n",
      "|    policyGradLoss     | -0.00675     |\n",
      "|    value_loss         | 0.0394       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 722          |\n",
      "|    iterations         | 8            |\n",
      "|    time_elapsed       | 90           |\n",
      "|    total_timesteps    | 9568256      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0051490646 |\n",
      "|    entropy_loss       | -2.37        |\n",
      "|    explained_variance | 0.467        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0528      |\n",
      "|    mean_step_reward   | -0.006504979 |\n",
      "|    n_updates          | 4668         |\n",
      "|    policyGradLoss     | -0.00855     |\n",
      "|    value_loss         | 0.0431       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 726           |\n",
      "|    iterations         | 9             |\n",
      "|    time_elapsed       | 101           |\n",
      "|    total_timesteps    | 9576448       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0036799568  |\n",
      "|    entropy_loss       | -2.37         |\n",
      "|    explained_variance | 0.399         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0523       |\n",
      "|    mean_step_reward   | -0.0064513376 |\n",
      "|    n_updates          | 4672          |\n",
      "|    policyGradLoss     | -0.00695      |\n",
      "|    value_loss         | 0.056         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 718          |\n",
      "|    iterations         | 10           |\n",
      "|    time_elapsed       | 114          |\n",
      "|    total_timesteps    | 9584640      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0044342587 |\n",
      "|    entropy_loss       | -2.36        |\n",
      "|    explained_variance | 0.406        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0498      |\n",
      "|    mean_step_reward   | -0.006139095 |\n",
      "|    n_updates          | 4676         |\n",
      "|    policyGradLoss     | -0.00634     |\n",
      "|    value_loss         | 0.0605       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 715           |\n",
      "|    iterations         | 11            |\n",
      "|    time_elapsed       | 125           |\n",
      "|    total_timesteps    | 9592832       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0049259905  |\n",
      "|    entropy_loss       | -2.36         |\n",
      "|    explained_variance | 0.492         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0636       |\n",
      "|    mean_step_reward   | -0.0068969447 |\n",
      "|    n_updates          | 4680          |\n",
      "|    policyGradLoss     | -0.00851      |\n",
      "|    value_loss         | 0.0438        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 714           |\n",
      "|    iterations         | 12            |\n",
      "|    time_elapsed       | 137           |\n",
      "|    total_timesteps    | 9601024       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0035489905  |\n",
      "|    entropy_loss       | -2.35         |\n",
      "|    explained_variance | 0.442         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0404       |\n",
      "|    mean_step_reward   | -0.0036364396 |\n",
      "|    n_updates          | 4684          |\n",
      "|    policyGradLoss     | -0.0038       |\n",
      "|    value_loss         | 0.133         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 709           |\n",
      "|    iterations         | 13            |\n",
      "|    time_elapsed       | 150           |\n",
      "|    total_timesteps    | 9609216       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0035790275  |\n",
      "|    entropy_loss       | -2.34         |\n",
      "|    explained_variance | 0.703         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0453       |\n",
      "|    mean_step_reward   | -0.0082960995 |\n",
      "|    n_updates          | 4688          |\n",
      "|    policyGradLoss     | -0.00619      |\n",
      "|    value_loss         | 0.0888        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 714          |\n",
      "|    iterations         | 14           |\n",
      "|    time_elapsed       | 160          |\n",
      "|    total_timesteps    | 9617408      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.004168935  |\n",
      "|    entropy_loss       | -2.34        |\n",
      "|    explained_variance | 0.693        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0427      |\n",
      "|    mean_step_reward   | -0.003776852 |\n",
      "|    n_updates          | 4692         |\n",
      "|    policyGradLoss     | -0.0082      |\n",
      "|    value_loss         | 0.0995       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 711          |\n",
      "|    iterations         | 15           |\n",
      "|    time_elapsed       | 172          |\n",
      "|    total_timesteps    | 9625600      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0027734863 |\n",
      "|    entropy_loss       | -2.33        |\n",
      "|    explained_variance | 0.707        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0119      |\n",
      "|    mean_step_reward   | -0.004101063 |\n",
      "|    n_updates          | 4696         |\n",
      "|    policyGradLoss     | -0.00241     |\n",
      "|    value_loss         | 0.194        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 711          |\n",
      "|    iterations         | 16           |\n",
      "|    time_elapsed       | 184          |\n",
      "|    total_timesteps    | 9633792      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.005589229  |\n",
      "|    entropy_loss       | -2.36        |\n",
      "|    explained_variance | 0.793        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0494      |\n",
      "|    mean_step_reward   | -0.005856066 |\n",
      "|    n_updates          | 4700         |\n",
      "|    policyGradLoss     | -0.00848     |\n",
      "|    value_loss         | 0.0787       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 709           |\n",
      "|    iterations         | 17            |\n",
      "|    time_elapsed       | 196           |\n",
      "|    total_timesteps    | 9641984       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.004152543   |\n",
      "|    entropy_loss       | -2.34         |\n",
      "|    explained_variance | 0.833         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0336       |\n",
      "|    mean_step_reward   | -0.0038130349 |\n",
      "|    n_updates          | 4704          |\n",
      "|    policyGradLoss     | -0.00817      |\n",
      "|    value_loss         | 0.103         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 707           |\n",
      "|    iterations         | 18            |\n",
      "|    time_elapsed       | 208           |\n",
      "|    total_timesteps    | 9650176       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0048308102  |\n",
      "|    entropy_loss       | -2.35         |\n",
      "|    explained_variance | 0.636         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0573       |\n",
      "|    mean_step_reward   | -0.0052017765 |\n",
      "|    n_updates          | 4708          |\n",
      "|    policyGradLoss     | -0.00768      |\n",
      "|    value_loss         | 0.0605        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 707           |\n",
      "|    iterations         | 19            |\n",
      "|    time_elapsed       | 219           |\n",
      "|    total_timesteps    | 9658368       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0046030525  |\n",
      "|    entropy_loss       | -2.31         |\n",
      "|    explained_variance | 0.774         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0345       |\n",
      "|    mean_step_reward   | -0.0048699444 |\n",
      "|    n_updates          | 4712          |\n",
      "|    policyGradLoss     | -0.00881      |\n",
      "|    value_loss         | 0.149         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 705          |\n",
      "|    iterations         | 20           |\n",
      "|    time_elapsed       | 232          |\n",
      "|    total_timesteps    | 9666560      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0049621006 |\n",
      "|    entropy_loss       | -2.34        |\n",
      "|    explained_variance | 0.804        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0408      |\n",
      "|    mean_step_reward   | -0.004405284 |\n",
      "|    n_updates          | 4716         |\n",
      "|    policyGradLoss     | -0.00525     |\n",
      "|    value_loss         | 0.121        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 708           |\n",
      "|    iterations         | 21            |\n",
      "|    time_elapsed       | 242           |\n",
      "|    total_timesteps    | 9674752       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0059877345  |\n",
      "|    entropy_loss       | -2.36         |\n",
      "|    explained_variance | 0.701         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.048        |\n",
      "|    mean_step_reward   | -0.0021725616 |\n",
      "|    n_updates          | 4720          |\n",
      "|    policyGradLoss     | -0.00679      |\n",
      "|    value_loss         | 0.0794        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 705           |\n",
      "|    iterations         | 22            |\n",
      "|    time_elapsed       | 255           |\n",
      "|    total_timesteps    | 9682944       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.005686286   |\n",
      "|    entropy_loss       | -2.36         |\n",
      "|    explained_variance | 0.6           |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0463       |\n",
      "|    mean_step_reward   | -0.0047968915 |\n",
      "|    n_updates          | 4724          |\n",
      "|    policyGradLoss     | -0.00801      |\n",
      "|    value_loss         | 0.0891        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 704           |\n",
      "|    iterations         | 23            |\n",
      "|    time_elapsed       | 267           |\n",
      "|    total_timesteps    | 9691136       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.005291067   |\n",
      "|    entropy_loss       | -2.35         |\n",
      "|    explained_variance | 0.684         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0644       |\n",
      "|    mean_step_reward   | -0.0065362244 |\n",
      "|    n_updates          | 4728          |\n",
      "|    policyGradLoss     | -0.0098       |\n",
      "|    value_loss         | 0.0519        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 704           |\n",
      "|    iterations         | 24            |\n",
      "|    time_elapsed       | 279           |\n",
      "|    total_timesteps    | 9699328       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0054596746  |\n",
      "|    entropy_loss       | -2.34         |\n",
      "|    explained_variance | 0.771         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0549       |\n",
      "|    mean_step_reward   | -0.0061901477 |\n",
      "|    n_updates          | 4732          |\n",
      "|    policyGradLoss     | -0.00999      |\n",
      "|    value_loss         | 0.0577        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 702          |\n",
      "|    iterations         | 25           |\n",
      "|    time_elapsed       | 291          |\n",
      "|    total_timesteps    | 9707520      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0046269097 |\n",
      "|    entropy_loss       | -2.38        |\n",
      "|    explained_variance | 0.756        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0633      |\n",
      "|    mean_step_reward   | -0.007110811 |\n",
      "|    n_updates          | 4736         |\n",
      "|    policyGradLoss     | -0.00684     |\n",
      "|    value_loss         | 0.0286       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 705          |\n",
      "|    iterations         | 26           |\n",
      "|    time_elapsed       | 302          |\n",
      "|    total_timesteps    | 9715712      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0045524873 |\n",
      "|    entropy_loss       | -2.35        |\n",
      "|    explained_variance | 0.402        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.095        |\n",
      "|    mean_step_reward   | 0.0034495047 |\n",
      "|    n_updates          | 4740         |\n",
      "|    policyGradLoss     | 0.0014       |\n",
      "|    value_loss         | 0.832        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 703         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 314         |\n",
      "|    total_timesteps    | 9723904     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.003995088 |\n",
      "|    entropy_loss       | -2.35       |\n",
      "|    explained_variance | 0.57        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.162       |\n",
      "|    mean_step_reward   | 0.011895524 |\n",
      "|    n_updates          | 4744        |\n",
      "|    policyGradLoss     | 0.00136     |\n",
      "|    value_loss         | 1.94        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 704          |\n",
      "|    iterations         | 28           |\n",
      "|    time_elapsed       | 325          |\n",
      "|    total_timesteps    | 9732096      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0040175235 |\n",
      "|    entropy_loss       | -2.38        |\n",
      "|    explained_variance | 0.7          |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0496      |\n",
      "|    mean_step_reward   | -0.006691472 |\n",
      "|    n_updates          | 4748         |\n",
      "|    policyGradLoss     | -0.00676     |\n",
      "|    value_loss         | 0.0616       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 702          |\n",
      "|    iterations         | 29           |\n",
      "|    time_elapsed       | 338          |\n",
      "|    total_timesteps    | 9740288      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0028329538 |\n",
      "|    entropy_loss       | -2.37        |\n",
      "|    explained_variance | 0.00178      |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.00658     |\n",
      "|    mean_step_reward   | -0.005538742 |\n",
      "|    n_updates          | 4752         |\n",
      "|    policyGradLoss     | -0.00392     |\n",
      "|    value_loss         | 0.26         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 702           |\n",
      "|    iterations         | 30            |\n",
      "|    time_elapsed       | 349           |\n",
      "|    total_timesteps    | 9748480       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0028204191  |\n",
      "|    entropy_loss       | -2.36         |\n",
      "|    explained_variance | 0.411         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0144       |\n",
      "|    mean_step_reward   | -0.0024634784 |\n",
      "|    n_updates          | 4756          |\n",
      "|    policyGradLoss     | -0.00209      |\n",
      "|    value_loss         | 0.345         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 702          |\n",
      "|    iterations         | 31           |\n",
      "|    time_elapsed       | 361          |\n",
      "|    total_timesteps    | 9756672      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0027158111 |\n",
      "|    entropy_loss       | -2.37        |\n",
      "|    explained_variance | 0.639        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0285       |\n",
      "|    mean_step_reward   | 0.009027447  |\n",
      "|    n_updates          | 4760         |\n",
      "|    policyGradLoss     | 0.000195     |\n",
      "|    value_loss         | 1            |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 701         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 373         |\n",
      "|    total_timesteps    | 9764864     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.004226842 |\n",
      "|    entropy_loss       | -2.38       |\n",
      "|    explained_variance | 0.703       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.319       |\n",
      "|    mean_step_reward   | 0.011895779 |\n",
      "|    n_updates          | 4764        |\n",
      "|    policyGradLoss     | 3.89e-05    |\n",
      "|    value_loss         | 1.89        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 703          |\n",
      "|    iterations         | 33           |\n",
      "|    time_elapsed       | 384          |\n",
      "|    total_timesteps    | 9773056      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0041120676 |\n",
      "|    entropy_loss       | -2.36        |\n",
      "|    explained_variance | 0.707        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.464        |\n",
      "|    mean_step_reward   | 0.04670454   |\n",
      "|    n_updates          | 4768         |\n",
      "|    policyGradLoss     | 0.00464      |\n",
      "|    value_loss         | 4.61         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 702          |\n",
      "|    iterations         | 34           |\n",
      "|    time_elapsed       | 396          |\n",
      "|    total_timesteps    | 9781248      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0056640804 |\n",
      "|    entropy_loss       | -2.35        |\n",
      "|    explained_variance | 0.73         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 2.3          |\n",
      "|    mean_step_reward   | 0.055021886  |\n",
      "|    n_updates          | 4772         |\n",
      "|    policyGradLoss     | 0.00372      |\n",
      "|    value_loss         | 9.61         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 702         |\n",
      "|    iterations         | 35          |\n",
      "|    time_elapsed       | 407         |\n",
      "|    total_timesteps    | 9789440     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.005981544 |\n",
      "|    entropy_loss       | -2.36       |\n",
      "|    explained_variance | 0.768       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.56        |\n",
      "|    mean_step_reward   | 0.09177986  |\n",
      "|    n_updates          | 4776        |\n",
      "|    policyGradLoss     | 0.00271     |\n",
      "|    value_loss         | 9.22        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 701         |\n",
      "|    iterations         | 36          |\n",
      "|    time_elapsed       | 420         |\n",
      "|    total_timesteps    | 9797632     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.003836731 |\n",
      "|    entropy_loss       | -2.35       |\n",
      "|    explained_variance | 0.858       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.16        |\n",
      "|    mean_step_reward   | 0.0942408   |\n",
      "|    n_updates          | 4780        |\n",
      "|    policyGradLoss     | 0.0026      |\n",
      "|    value_loss         | 11.1        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 701          |\n",
      "|    iterations         | 37           |\n",
      "|    time_elapsed       | 432          |\n",
      "|    total_timesteps    | 9805824      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.003054112  |\n",
      "|    entropy_loss       | -2.36        |\n",
      "|    explained_variance | 0.759        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.301        |\n",
      "|    mean_step_reward   | 0.0063933227 |\n",
      "|    n_updates          | 4784         |\n",
      "|    policyGradLoss     | -0.000593    |\n",
      "|    value_loss         | 1.7          |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 701          |\n",
      "|    iterations         | 38           |\n",
      "|    time_elapsed       | 443          |\n",
      "|    total_timesteps    | 9814016      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0017871636 |\n",
      "|    entropy_loss       | -2.37        |\n",
      "|    explained_variance | 0.869        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0281       |\n",
      "|    mean_step_reward   | 0.0014103572 |\n",
      "|    n_updates          | 4788         |\n",
      "|    policyGradLoss     | -0.00134     |\n",
      "|    value_loss         | 0.598        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 700           |\n",
      "|    iterations         | 39            |\n",
      "|    time_elapsed       | 455           |\n",
      "|    total_timesteps    | 9822208       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0016715477  |\n",
      "|    entropy_loss       | -2.38         |\n",
      "|    explained_variance | 0.927         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | 0.0797        |\n",
      "|    mean_step_reward   | -0.0013809202 |\n",
      "|    n_updates          | 4792          |\n",
      "|    policyGradLoss     | -0.00166      |\n",
      "|    value_loss         | 0.633         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 703           |\n",
      "|    iterations         | 40            |\n",
      "|    time_elapsed       | 465           |\n",
      "|    total_timesteps    | 9830400       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.002314393   |\n",
      "|    entropy_loss       | -2.41         |\n",
      "|    explained_variance | 0.909         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | 0.0167        |\n",
      "|    mean_step_reward   | -0.0039015252 |\n",
      "|    n_updates          | 4796          |\n",
      "|    policyGradLoss     | -0.00184      |\n",
      "|    value_loss         | 0.488         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/P_RWD18_29.zip\n",
      "[EVAL] Mean Return: 17.761, Best Return: 23.908\n",
      "Saved video to ./runs_smw/videos/P_RWD18/P_RWD18_29_17.76.mp4\n",
      "\n",
      "=== Round 31 | Learn 327680 steps (Total trained: 9830400) ===\n",
      "Logging to ./runs_smw/tb/P_RWD18_0\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1221    |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 6       |\n",
      "|    total_timesteps | 9838592 |\n",
      "--------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 885          |\n",
      "|    iterations         | 2            |\n",
      "|    time_elapsed       | 18           |\n",
      "|    total_timesteps    | 9846784      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0022718632 |\n",
      "|    entropy_loss       | -2.41        |\n",
      "|    explained_variance | 0.828        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.783        |\n",
      "|    mean_step_reward   | 0.02041615   |\n",
      "|    n_updates          | 4804         |\n",
      "|    policyGradLoss     | -0.00188     |\n",
      "|    value_loss         | 2.64         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 795          |\n",
      "|    iterations         | 3            |\n",
      "|    time_elapsed       | 30           |\n",
      "|    total_timesteps    | 9854976      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0027822573 |\n",
      "|    entropy_loss       | -2.39        |\n",
      "|    explained_variance | 0.816        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0914       |\n",
      "|    mean_step_reward   | 0.00048046   |\n",
      "|    n_updates          | 4808         |\n",
      "|    policyGradLoss     | -0.00162     |\n",
      "|    value_loss         | 0.985        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 42          |\n",
      "|    total_timesteps    | 9863168     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.006584392 |\n",
      "|    entropy_loss       | -2.37       |\n",
      "|    explained_variance | 0.747       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.312       |\n",
      "|    mean_step_reward   | 0.023470476 |\n",
      "|    n_updates          | 4812        |\n",
      "|    policyGradLoss     | 0.00167     |\n",
      "|    value_loss         | 3.51        |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 759           |\n",
      "|    iterations         | 5             |\n",
      "|    time_elapsed       | 53            |\n",
      "|    total_timesteps    | 9871360       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.002885425   |\n",
      "|    entropy_loss       | -2.38         |\n",
      "|    explained_variance | 0.649         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | 0.0846        |\n",
      "|    mean_step_reward   | -0.0011776304 |\n",
      "|    n_updates          | 4816          |\n",
      "|    policyGradLoss     | -0.00133      |\n",
      "|    value_loss         | 0.946         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 742          |\n",
      "|    iterations         | 6            |\n",
      "|    time_elapsed       | 66           |\n",
      "|    total_timesteps    | 9879552      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0027738558 |\n",
      "|    entropy_loss       | -2.39        |\n",
      "|    explained_variance | 0.743        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.179        |\n",
      "|    mean_step_reward   | 0.033888213  |\n",
      "|    n_updates          | 4820         |\n",
      "|    policyGradLoss     | 0.000508     |\n",
      "|    value_loss         | 2.77         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 734           |\n",
      "|    iterations         | 7             |\n",
      "|    time_elapsed       | 78            |\n",
      "|    total_timesteps    | 9887744       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.003868895   |\n",
      "|    entropy_loss       | -2.39         |\n",
      "|    explained_variance | 0.771         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0212       |\n",
      "|    mean_step_reward   | -0.0065934923 |\n",
      "|    n_updates          | 4824          |\n",
      "|    policyGradLoss     | -0.00321      |\n",
      "|    value_loss         | 0.135         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 729          |\n",
      "|    iterations         | 8            |\n",
      "|    time_elapsed       | 89           |\n",
      "|    total_timesteps    | 9895936      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0025953683 |\n",
      "|    entropy_loss       | -2.4         |\n",
      "|    explained_variance | 0.838        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.382        |\n",
      "|    mean_step_reward   | 0.015361514  |\n",
      "|    n_updates          | 4828         |\n",
      "|    policyGradLoss     | -0.00012     |\n",
      "|    value_loss         | 2.12         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 721          |\n",
      "|    iterations         | 9            |\n",
      "|    time_elapsed       | 102          |\n",
      "|    total_timesteps    | 9904128      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0025891592 |\n",
      "|    entropy_loss       | -2.4         |\n",
      "|    explained_variance | 0.885        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.195        |\n",
      "|    mean_step_reward   | 0.01705454   |\n",
      "|    n_updates          | 4832         |\n",
      "|    policyGradLoss     | 0.00066      |\n",
      "|    value_loss         | 2.86         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 728          |\n",
      "|    iterations         | 10           |\n",
      "|    time_elapsed       | 112          |\n",
      "|    total_timesteps    | 9912320      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0023354688 |\n",
      "|    entropy_loss       | -2.39        |\n",
      "|    explained_variance | 0.813        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.965        |\n",
      "|    mean_step_reward   | 0.047495358  |\n",
      "|    n_updates          | 4836         |\n",
      "|    policyGradLoss     | 0.00038      |\n",
      "|    value_loss         | 8.64         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 722         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 124         |\n",
      "|    total_timesteps    | 9920512     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.003301839 |\n",
      "|    entropy_loss       | -2.4        |\n",
      "|    explained_variance | 0.846       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.781       |\n",
      "|    mean_step_reward   | 0.06417688  |\n",
      "|    n_updates          | 4840        |\n",
      "|    policyGradLoss     | 0.00247     |\n",
      "|    value_loss         | 9.76        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 723          |\n",
      "|    iterations         | 12           |\n",
      "|    time_elapsed       | 135          |\n",
      "|    total_timesteps    | 9928704      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0026887339 |\n",
      "|    entropy_loss       | -2.4         |\n",
      "|    explained_variance | 0.914        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.12         |\n",
      "|    mean_step_reward   | 0.026961323  |\n",
      "|    n_updates          | 4844         |\n",
      "|    policyGradLoss     | -0.00187     |\n",
      "|    value_loss         | 2.94         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 718          |\n",
      "|    iterations         | 13           |\n",
      "|    time_elapsed       | 148          |\n",
      "|    total_timesteps    | 9936896      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0050776727 |\n",
      "|    entropy_loss       | -2.4         |\n",
      "|    explained_variance | 0.484        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0466      |\n",
      "|    mean_step_reward   | -0.00736277  |\n",
      "|    n_updates          | 4848         |\n",
      "|    policyGradLoss     | -0.00552     |\n",
      "|    value_loss         | 0.0516       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 715           |\n",
      "|    iterations         | 14            |\n",
      "|    time_elapsed       | 160           |\n",
      "|    total_timesteps    | 9945088       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0035250315  |\n",
      "|    entropy_loss       | -2.4          |\n",
      "|    explained_variance | 0.641         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0548       |\n",
      "|    mean_step_reward   | -0.0074152155 |\n",
      "|    n_updates          | 4852          |\n",
      "|    policyGradLoss     | -0.00707      |\n",
      "|    value_loss         | 0.0659        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 716          |\n",
      "|    iterations         | 15           |\n",
      "|    time_elapsed       | 171          |\n",
      "|    total_timesteps    | 9953280      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0038706772 |\n",
      "|    entropy_loss       | -2.4         |\n",
      "|    explained_variance | 0.885        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.355        |\n",
      "|    mean_step_reward   | 0.02072268   |\n",
      "|    n_updates          | 4856         |\n",
      "|    policyGradLoss     | 0.0019       |\n",
      "|    value_loss         | 2.89         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 712         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 183         |\n",
      "|    total_timesteps    | 9961472     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.00515078  |\n",
      "|    entropy_loss       | -2.39       |\n",
      "|    explained_variance | 0.834       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 2.14        |\n",
      "|    mean_step_reward   | 0.096706204 |\n",
      "|    n_updates          | 4860        |\n",
      "|    policyGradLoss     | 0.00356     |\n",
      "|    value_loss         | 19.2        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 716         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 194         |\n",
      "|    total_timesteps    | 9969664     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.005656495 |\n",
      "|    entropy_loss       | -2.38       |\n",
      "|    explained_variance | 0.884       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 3.53        |\n",
      "|    mean_step_reward   | 0.04216055  |\n",
      "|    n_updates          | 4864        |\n",
      "|    policyGradLoss     | 0.00637     |\n",
      "|    value_loss         | 15.3        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 712          |\n",
      "|    iterations         | 18           |\n",
      "|    time_elapsed       | 206          |\n",
      "|    total_timesteps    | 9977856      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0029446825 |\n",
      "|    entropy_loss       | -2.36        |\n",
      "|    explained_variance | 0.86         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 4.6          |\n",
      "|    mean_step_reward   | 0.04109031   |\n",
      "|    n_updates          | 4868         |\n",
      "|    policyGradLoss     | 0.00211      |\n",
      "|    value_loss         | 16.7         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 712          |\n",
      "|    iterations         | 19           |\n",
      "|    time_elapsed       | 218          |\n",
      "|    total_timesteps    | 9986048      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0050564297 |\n",
      "|    entropy_loss       | -2.32        |\n",
      "|    explained_variance | 0.883        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 7.6          |\n",
      "|    mean_step_reward   | 0.15084288   |\n",
      "|    n_updates          | 4872         |\n",
      "|    policyGradLoss     | 0.00415      |\n",
      "|    value_loss         | 34.1         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 710          |\n",
      "|    iterations         | 20           |\n",
      "|    time_elapsed       | 230          |\n",
      "|    total_timesteps    | 9994240      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0046258215 |\n",
      "|    entropy_loss       | -2.33        |\n",
      "|    explained_variance | 0.861        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 3.32         |\n",
      "|    mean_step_reward   | 0.0691057    |\n",
      "|    n_updates          | 4876         |\n",
      "|    policyGradLoss     | -0.000801    |\n",
      "|    value_loss         | 21.1         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 708          |\n",
      "|    iterations         | 21           |\n",
      "|    time_elapsed       | 242          |\n",
      "|    total_timesteps    | 10002432     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0029693868 |\n",
      "|    entropy_loss       | -2.37        |\n",
      "|    explained_variance | 0.938        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.196        |\n",
      "|    mean_step_reward   | 0.02146998   |\n",
      "|    n_updates          | 4880         |\n",
      "|    policyGradLoss     | 0.00434      |\n",
      "|    value_loss         | 2.97         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 710          |\n",
      "|    iterations         | 22           |\n",
      "|    time_elapsed       | 253          |\n",
      "|    total_timesteps    | 10010624     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.002741865  |\n",
      "|    entropy_loss       | -2.36        |\n",
      "|    explained_variance | 0.916        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.57         |\n",
      "|    mean_step_reward   | -0.006255168 |\n",
      "|    n_updates          | 4884         |\n",
      "|    policyGradLoss     | -0.000787    |\n",
      "|    value_loss         | 2.05         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 708          |\n",
      "|    iterations         | 23           |\n",
      "|    time_elapsed       | 266          |\n",
      "|    total_timesteps    | 10018816     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0026269653 |\n",
      "|    entropy_loss       | -2.38        |\n",
      "|    explained_variance | 0.9          |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.631        |\n",
      "|    mean_step_reward   | 0.0029783768 |\n",
      "|    n_updates          | 4888         |\n",
      "|    policyGradLoss     | 0.00197      |\n",
      "|    value_loss         | 5.24         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 709          |\n",
      "|    iterations         | 24           |\n",
      "|    time_elapsed       | 277          |\n",
      "|    total_timesteps    | 10027008     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0031773462 |\n",
      "|    entropy_loss       | -2.37        |\n",
      "|    explained_variance | 0.914        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 1.81         |\n",
      "|    mean_step_reward   | 0.029157262  |\n",
      "|    n_updates          | 4892         |\n",
      "|    policyGradLoss     | 0.00146      |\n",
      "|    value_loss         | 6.13         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 707         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 289         |\n",
      "|    total_timesteps    | 10035200    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.004051335 |\n",
      "|    entropy_loss       | -2.36       |\n",
      "|    explained_variance | 0.901       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 2.9         |\n",
      "|    mean_step_reward   | 0.11803123  |\n",
      "|    n_updates          | 4896        |\n",
      "|    policyGradLoss     | 0.00187     |\n",
      "|    value_loss         | 15.1        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 705          |\n",
      "|    iterations         | 26           |\n",
      "|    time_elapsed       | 301          |\n",
      "|    total_timesteps    | 10043392     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0036775232 |\n",
      "|    entropy_loss       | -2.36        |\n",
      "|    explained_variance | 0.877        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 7.35         |\n",
      "|    mean_step_reward   | 0.16841103   |\n",
      "|    n_updates          | 4900         |\n",
      "|    policyGradLoss     | 0.000989     |\n",
      "|    value_loss         | 28.3         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 705          |\n",
      "|    iterations         | 27           |\n",
      "|    time_elapsed       | 313          |\n",
      "|    total_timesteps    | 10051584     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0035464657 |\n",
      "|    entropy_loss       | -2.37        |\n",
      "|    explained_variance | 0.881        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 6.14         |\n",
      "|    mean_step_reward   | 0.10713673   |\n",
      "|    n_updates          | 4904         |\n",
      "|    policyGradLoss     | 0.00496      |\n",
      "|    value_loss         | 22.5         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 704          |\n",
      "|    iterations         | 28           |\n",
      "|    time_elapsed       | 325          |\n",
      "|    total_timesteps    | 10059776     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0028378358 |\n",
      "|    entropy_loss       | -2.38        |\n",
      "|    explained_variance | 0.9          |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 5.53         |\n",
      "|    mean_step_reward   | 0.105995566  |\n",
      "|    n_updates          | 4908         |\n",
      "|    policyGradLoss     | -0.00034     |\n",
      "|    value_loss         | 13.4         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 707          |\n",
      "|    iterations         | 29           |\n",
      "|    time_elapsed       | 335          |\n",
      "|    total_timesteps    | 10067968     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0032622223 |\n",
      "|    entropy_loss       | -2.4         |\n",
      "|    explained_variance | 0.934        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0841       |\n",
      "|    mean_step_reward   | 0.021680241  |\n",
      "|    n_updates          | 4912         |\n",
      "|    policyGradLoss     | 0.00088      |\n",
      "|    value_loss         | 3.42         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 705           |\n",
      "|    iterations         | 30            |\n",
      "|    time_elapsed       | 348           |\n",
      "|    total_timesteps    | 10076160      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0031412228  |\n",
      "|    entropy_loss       | -2.42         |\n",
      "|    explained_variance | 0.809         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | 0.0883        |\n",
      "|    mean_step_reward   | -0.0071903723 |\n",
      "|    n_updates          | 4916          |\n",
      "|    policyGradLoss     | -0.00193      |\n",
      "|    value_loss         | 0.381         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 705           |\n",
      "|    iterations         | 31            |\n",
      "|    time_elapsed       | 359           |\n",
      "|    total_timesteps    | 10084352      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0044052713  |\n",
      "|    entropy_loss       | -2.39         |\n",
      "|    explained_variance | 0.698         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0128       |\n",
      "|    mean_step_reward   | -0.0068445727 |\n",
      "|    n_updates          | 4920          |\n",
      "|    policyGradLoss     | 0.00201       |\n",
      "|    value_loss         | 0.202         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 705          |\n",
      "|    iterations         | 32           |\n",
      "|    time_elapsed       | 371          |\n",
      "|    total_timesteps    | 10092544     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0032669718 |\n",
      "|    entropy_loss       | -2.36        |\n",
      "|    explained_variance | 0.944        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.583        |\n",
      "|    mean_step_reward   | 0.031913448  |\n",
      "|    n_updates          | 4924         |\n",
      "|    policyGradLoss     | 0.000419     |\n",
      "|    value_loss         | 3.97         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 703          |\n",
      "|    iterations         | 33           |\n",
      "|    time_elapsed       | 384          |\n",
      "|    total_timesteps    | 10100736     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0035594362 |\n",
      "|    entropy_loss       | -2.36        |\n",
      "|    explained_variance | 0.915        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 2.41         |\n",
      "|    mean_step_reward   | 0.08141949   |\n",
      "|    n_updates          | 4928         |\n",
      "|    policyGradLoss     | 0.00194      |\n",
      "|    value_loss         | 15.2         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 705          |\n",
      "|    iterations         | 34           |\n",
      "|    time_elapsed       | 394          |\n",
      "|    total_timesteps    | 10108928     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0061104754 |\n",
      "|    entropy_loss       | -2.32        |\n",
      "|    explained_variance | 0.927        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 6.19         |\n",
      "|    mean_step_reward   | 0.2312805    |\n",
      "|    n_updates          | 4932         |\n",
      "|    policyGradLoss     | 0.00451      |\n",
      "|    value_loss         | 39.9         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 704         |\n",
      "|    iterations         | 35          |\n",
      "|    time_elapsed       | 407         |\n",
      "|    total_timesteps    | 10117120    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.004194074 |\n",
      "|    entropy_loss       | -2.32       |\n",
      "|    explained_variance | 0.915       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 10.8        |\n",
      "|    mean_step_reward   | 0.18506557  |\n",
      "|    n_updates          | 4936        |\n",
      "|    policyGradLoss     | 0.00391     |\n",
      "|    value_loss         | 40.9        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 705          |\n",
      "|    iterations         | 36           |\n",
      "|    time_elapsed       | 418          |\n",
      "|    total_timesteps    | 10125312     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0044044526 |\n",
      "|    entropy_loss       | -2.31        |\n",
      "|    explained_variance | 0.931        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 16.8         |\n",
      "|    mean_step_reward   | 0.22890362   |\n",
      "|    n_updates          | 4940         |\n",
      "|    policyGradLoss     | 0.00247      |\n",
      "|    value_loss         | 45.6         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 703         |\n",
      "|    iterations         | 37          |\n",
      "|    time_elapsed       | 430         |\n",
      "|    total_timesteps    | 10133504    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.005110997 |\n",
      "|    entropy_loss       | -2.33       |\n",
      "|    explained_variance | 0.888       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 6.58        |\n",
      "|    mean_step_reward   | 0.12206023  |\n",
      "|    n_updates          | 4944        |\n",
      "|    policyGradLoss     | 0.00333     |\n",
      "|    value_loss         | 36.5        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 703          |\n",
      "|    iterations         | 38           |\n",
      "|    time_elapsed       | 442          |\n",
      "|    total_timesteps    | 10141696     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0041555734 |\n",
      "|    entropy_loss       | -2.36        |\n",
      "|    explained_variance | 0.902        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 2.12         |\n",
      "|    mean_step_reward   | 0.071431845  |\n",
      "|    n_updates          | 4948         |\n",
      "|    policyGradLoss     | 0.00257      |\n",
      "|    value_loss         | 14.7         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 703          |\n",
      "|    iterations         | 39           |\n",
      "|    time_elapsed       | 454          |\n",
      "|    total_timesteps    | 10149888     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.002137217  |\n",
      "|    entropy_loss       | -2.39        |\n",
      "|    explained_variance | 0.922        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.332        |\n",
      "|    mean_step_reward   | 0.0022740252 |\n",
      "|    n_updates          | 4952         |\n",
      "|    policyGradLoss     | -0.000488    |\n",
      "|    value_loss         | 3.26         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 702          |\n",
      "|    iterations         | 40           |\n",
      "|    time_elapsed       | 466          |\n",
      "|    total_timesteps    | 10158080     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0032325806 |\n",
      "|    entropy_loss       | -2.37        |\n",
      "|    explained_variance | 0.929        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 1.57         |\n",
      "|    mean_step_reward   | 0.07006505   |\n",
      "|    n_updates          | 4956         |\n",
      "|    policyGradLoss     | 0.00511      |\n",
      "|    value_loss         | 10.4         |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/P_RWD18_30.zip\n",
      "[EVAL] Mean Return: -1.154, Best Return: -0.274\n",
      "Saved video to ./runs_smw/videos/P_RWD18/P_RWD18_30_-1.15.mp4\n",
      "\n",
      "=== Round 32 | Learn 327680 steps (Total trained: 10158080) ===\n",
      "Logging to ./runs_smw/tb/P_RWD18_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1283     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 10166272 |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 875          |\n",
      "|    iterations         | 2            |\n",
      "|    time_elapsed       | 18           |\n",
      "|    total_timesteps    | 10174464     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0022012386 |\n",
      "|    entropy_loss       | -2.4         |\n",
      "|    explained_variance | 0.922        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.213        |\n",
      "|    mean_step_reward   | 0.014532257  |\n",
      "|    n_updates          | 4964         |\n",
      "|    policyGradLoss     | -0.000517    |\n",
      "|    value_loss         | 2.24         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 812          |\n",
      "|    iterations         | 3            |\n",
      "|    time_elapsed       | 30           |\n",
      "|    total_timesteps    | 10182656     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.001967249  |\n",
      "|    entropy_loss       | -2.4         |\n",
      "|    explained_variance | 0.673        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0889       |\n",
      "|    mean_step_reward   | -0.003075228 |\n",
      "|    n_updates          | 4968         |\n",
      "|    policyGradLoss     | -0.00015     |\n",
      "|    value_loss         | 0.512        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 775          |\n",
      "|    iterations         | 4            |\n",
      "|    time_elapsed       | 42           |\n",
      "|    total_timesteps    | 10190848     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0029770974 |\n",
      "|    entropy_loss       | -2.42        |\n",
      "|    explained_variance | 0.928        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.336        |\n",
      "|    mean_step_reward   | 0.025517683  |\n",
      "|    n_updates          | 4972         |\n",
      "|    policyGradLoss     | 0.000369     |\n",
      "|    value_loss         | 1.77         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 751           |\n",
      "|    iterations         | 5             |\n",
      "|    time_elapsed       | 54            |\n",
      "|    total_timesteps    | 10199040      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0017807309  |\n",
      "|    entropy_loss       | -2.41         |\n",
      "|    explained_variance | 0.941         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | 0.0645        |\n",
      "|    mean_step_reward   | -0.0060307523 |\n",
      "|    n_updates          | 4976          |\n",
      "|    policyGradLoss     | 8.22e-05      |\n",
      "|    value_loss         | 0.612         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 752          |\n",
      "|    iterations         | 6            |\n",
      "|    time_elapsed       | 65           |\n",
      "|    total_timesteps    | 10207232     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0028067576 |\n",
      "|    entropy_loss       | -2.42        |\n",
      "|    explained_variance | 0.935        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.238        |\n",
      "|    mean_step_reward   | 0.036789387  |\n",
      "|    n_updates          | 4980         |\n",
      "|    policyGradLoss     | 0.00297      |\n",
      "|    value_loss         | 2.14         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 738           |\n",
      "|    iterations         | 7             |\n",
      "|    time_elapsed       | 77            |\n",
      "|    total_timesteps    | 10215424      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0025330014  |\n",
      "|    entropy_loss       | -2.43         |\n",
      "|    explained_variance | 0.863         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | 0.285         |\n",
      "|    mean_step_reward   | -0.0028797914 |\n",
      "|    n_updates          | 4984          |\n",
      "|    policyGradLoss     | -0.00205      |\n",
      "|    value_loss         | 1.02          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 738          |\n",
      "|    iterations         | 8            |\n",
      "|    time_elapsed       | 88           |\n",
      "|    total_timesteps    | 10223616     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.003323689  |\n",
      "|    entropy_loss       | -2.43        |\n",
      "|    explained_variance | 0.904        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0348      |\n",
      "|    mean_step_reward   | -0.007698713 |\n",
      "|    n_updates          | 4988         |\n",
      "|    policyGradLoss     | -0.00319     |\n",
      "|    value_loss         | 0.138        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 727           |\n",
      "|    iterations         | 9             |\n",
      "|    time_elapsed       | 101           |\n",
      "|    total_timesteps    | 10231808      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.003120442   |\n",
      "|    entropy_loss       | -2.4          |\n",
      "|    explained_variance | 0.88          |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | 0.015         |\n",
      "|    mean_step_reward   | -0.0070382385 |\n",
      "|    n_updates          | 4992          |\n",
      "|    policyGradLoss     | -0.000658     |\n",
      "|    value_loss         | 0.166         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 724           |\n",
      "|    iterations         | 10            |\n",
      "|    time_elapsed       | 113           |\n",
      "|    total_timesteps    | 10240000      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.004324493   |\n",
      "|    entropy_loss       | -2.39         |\n",
      "|    explained_variance | 0.57          |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0358       |\n",
      "|    mean_step_reward   | -0.0056033838 |\n",
      "|    n_updates          | 4996          |\n",
      "|    policyGradLoss     | -0.00561      |\n",
      "|    value_loss         | 0.0929        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 722          |\n",
      "|    iterations         | 11           |\n",
      "|    time_elapsed       | 124          |\n",
      "|    total_timesteps    | 10248192     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.004762966  |\n",
      "|    entropy_loss       | -2.39        |\n",
      "|    explained_variance | 0.557        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0491      |\n",
      "|    mean_step_reward   | -0.007685654 |\n",
      "|    n_updates          | 5000         |\n",
      "|    policyGradLoss     | -0.00557     |\n",
      "|    value_loss         | 0.0557       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 717          |\n",
      "|    iterations         | 12           |\n",
      "|    time_elapsed       | 136          |\n",
      "|    total_timesteps    | 10256384     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.004564239  |\n",
      "|    entropy_loss       | -2.36        |\n",
      "|    explained_variance | 0.539        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0398      |\n",
      "|    mean_step_reward   | -0.005203654 |\n",
      "|    n_updates          | 5004         |\n",
      "|    policyGradLoss     | -0.0084      |\n",
      "|    value_loss         | 0.105        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 722           |\n",
      "|    iterations         | 13            |\n",
      "|    time_elapsed       | 147           |\n",
      "|    total_timesteps    | 10264576      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0028114403  |\n",
      "|    entropy_loss       | -2.38         |\n",
      "|    explained_variance | 0.843         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | 0.0182        |\n",
      "|    mean_step_reward   | -0.0047423122 |\n",
      "|    n_updates          | 5008          |\n",
      "|    policyGradLoss     | -0.000434     |\n",
      "|    value_loss         | 0.287         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 718           |\n",
      "|    iterations         | 14            |\n",
      "|    time_elapsed       | 159           |\n",
      "|    total_timesteps    | 10272768      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0019518813  |\n",
      "|    entropy_loss       | -2.39         |\n",
      "|    explained_variance | 0.908         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | 0.0297        |\n",
      "|    mean_step_reward   | -0.0036736587 |\n",
      "|    n_updates          | 5012          |\n",
      "|    policyGradLoss     | -0.00147      |\n",
      "|    value_loss         | 0.484         |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 719         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 170         |\n",
      "|    total_timesteps    | 10280960    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.006606612 |\n",
      "|    entropy_loss       | -2.36       |\n",
      "|    explained_variance | 0.842       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.799       |\n",
      "|    mean_step_reward   | 0.054885745 |\n",
      "|    n_updates          | 5016        |\n",
      "|    policyGradLoss     | 0.003       |\n",
      "|    value_loss         | 6.43        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 715          |\n",
      "|    iterations         | 16           |\n",
      "|    time_elapsed       | 183          |\n",
      "|    total_timesteps    | 10289152     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0027861411 |\n",
      "|    entropy_loss       | -2.34        |\n",
      "|    explained_variance | 0.893        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 2.21         |\n",
      "|    mean_step_reward   | 0.099104375  |\n",
      "|    n_updates          | 5020         |\n",
      "|    policyGradLoss     | -0.00179     |\n",
      "|    value_loss         | 13.2         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 712         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 195         |\n",
      "|    total_timesteps    | 10297344    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.003914702 |\n",
      "|    entropy_loss       | -2.34       |\n",
      "|    explained_variance | 0.886       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 5.77        |\n",
      "|    mean_step_reward   | 0.1436918   |\n",
      "|    n_updates          | 5024        |\n",
      "|    policyGradLoss     | 0.00111     |\n",
      "|    value_loss         | 17.9        |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 712           |\n",
      "|    iterations         | 18            |\n",
      "|    time_elapsed       | 206           |\n",
      "|    total_timesteps    | 10305536      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0035182969  |\n",
      "|    entropy_loss       | -2.39         |\n",
      "|    explained_variance | 0.893         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | 0.194         |\n",
      "|    mean_step_reward   | -0.0068098167 |\n",
      "|    n_updates          | 5028          |\n",
      "|    policyGradLoss     | -0.00068      |\n",
      "|    value_loss         | 1.36          |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 709         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 219         |\n",
      "|    total_timesteps    | 10313728    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.004455881 |\n",
      "|    entropy_loss       | -2.38       |\n",
      "|    explained_variance | 0.85        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.132       |\n",
      "|    mean_step_reward   | 0.008256149 |\n",
      "|    n_updates          | 5032        |\n",
      "|    policyGradLoss     | -0.00219    |\n",
      "|    value_loss         | 1.27        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 713          |\n",
      "|    iterations         | 20           |\n",
      "|    time_elapsed       | 229          |\n",
      "|    total_timesteps    | 10321920     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0060119038 |\n",
      "|    entropy_loss       | -2.4         |\n",
      "|    explained_variance | 0.594        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0491      |\n",
      "|    mean_step_reward   | -0.006879078 |\n",
      "|    n_updates          | 5036         |\n",
      "|    policyGradLoss     | -0.00869     |\n",
      "|    value_loss         | 0.0462       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 710           |\n",
      "|    iterations         | 21            |\n",
      "|    time_elapsed       | 242           |\n",
      "|    total_timesteps    | 10330112      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.004551216   |\n",
      "|    entropy_loss       | -2.4          |\n",
      "|    explained_variance | 0.639         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.062        |\n",
      "|    mean_step_reward   | -0.0070868134 |\n",
      "|    n_updates          | 5040          |\n",
      "|    policyGradLoss     | -0.0084       |\n",
      "|    value_loss         | 0.0415        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 710          |\n",
      "|    iterations         | 22           |\n",
      "|    time_elapsed       | 253          |\n",
      "|    total_timesteps    | 10338304     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.005761533  |\n",
      "|    entropy_loss       | -2.4         |\n",
      "|    explained_variance | 0.558        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0553      |\n",
      "|    mean_step_reward   | -0.006247865 |\n",
      "|    n_updates          | 5044         |\n",
      "|    policyGradLoss     | -0.00756     |\n",
      "|    value_loss         | 0.0453       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 710          |\n",
      "|    iterations         | 23           |\n",
      "|    time_elapsed       | 265          |\n",
      "|    total_timesteps    | 10346496     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.004349052  |\n",
      "|    entropy_loss       | -2.39        |\n",
      "|    explained_variance | 0.813        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0448      |\n",
      "|    mean_step_reward   | -0.004659711 |\n",
      "|    n_updates          | 5048         |\n",
      "|    policyGradLoss     | -0.00797     |\n",
      "|    value_loss         | 0.0853       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 710           |\n",
      "|    iterations         | 24            |\n",
      "|    time_elapsed       | 276           |\n",
      "|    total_timesteps    | 10354688      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.003560579   |\n",
      "|    entropy_loss       | -2.39         |\n",
      "|    explained_variance | 0.91          |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | 0.0393        |\n",
      "|    mean_step_reward   | -0.0052362075 |\n",
      "|    n_updates          | 5052          |\n",
      "|    policyGradLoss     | -0.000637     |\n",
      "|    value_loss         | 0.653         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 709          |\n",
      "|    iterations         | 25           |\n",
      "|    time_elapsed       | 288          |\n",
      "|    total_timesteps    | 10362880     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0029227985 |\n",
      "|    entropy_loss       | -2.38        |\n",
      "|    explained_variance | 0.906        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.227        |\n",
      "|    mean_step_reward   | 0.0065100044 |\n",
      "|    n_updates          | 5056         |\n",
      "|    policyGradLoss     | -0.000677    |\n",
      "|    value_loss         | 1.49         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 709          |\n",
      "|    iterations         | 26           |\n",
      "|    time_elapsed       | 300          |\n",
      "|    total_timesteps    | 10371072     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0028519966 |\n",
      "|    entropy_loss       | -2.37        |\n",
      "|    explained_variance | 0.889        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.24         |\n",
      "|    mean_step_reward   | 0.007201662  |\n",
      "|    n_updates          | 5060         |\n",
      "|    policyGradLoss     | 0.00123      |\n",
      "|    value_loss         | 1.83         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 709          |\n",
      "|    iterations         | 27           |\n",
      "|    time_elapsed       | 311          |\n",
      "|    total_timesteps    | 10379264     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0040193144 |\n",
      "|    entropy_loss       | -2.37        |\n",
      "|    explained_variance | 0.879        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.932        |\n",
      "|    mean_step_reward   | 0.019140592  |\n",
      "|    n_updates          | 5064         |\n",
      "|    policyGradLoss     | 0.00141      |\n",
      "|    value_loss         | 3.36         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 708          |\n",
      "|    iterations         | 28           |\n",
      "|    time_elapsed       | 323          |\n",
      "|    total_timesteps    | 10387456     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0023583476 |\n",
      "|    entropy_loss       | -2.36        |\n",
      "|    explained_variance | 0.873        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.355        |\n",
      "|    mean_step_reward   | 0.015252532  |\n",
      "|    n_updates          | 5068         |\n",
      "|    policyGradLoss     | -0.00146     |\n",
      "|    value_loss         | 2.52         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 706          |\n",
      "|    iterations         | 29           |\n",
      "|    time_elapsed       | 336          |\n",
      "|    total_timesteps    | 10395648     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0034952667 |\n",
      "|    entropy_loss       | -2.36        |\n",
      "|    explained_variance | 0.907        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 1.41         |\n",
      "|    mean_step_reward   | 0.037335478  |\n",
      "|    n_updates          | 5072         |\n",
      "|    policyGradLoss     | -0.000695    |\n",
      "|    value_loss         | 6.28         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 706          |\n",
      "|    iterations         | 30           |\n",
      "|    time_elapsed       | 347          |\n",
      "|    total_timesteps    | 10403840     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0034523848 |\n",
      "|    entropy_loss       | -2.34        |\n",
      "|    explained_variance | 0.898        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 1.38         |\n",
      "|    mean_step_reward   | 0.10794878   |\n",
      "|    n_updates          | 5076         |\n",
      "|    policyGradLoss     | 0.00142      |\n",
      "|    value_loss         | 12.5         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 705         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 359         |\n",
      "|    total_timesteps    | 10412032    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.004767998 |\n",
      "|    entropy_loss       | -2.35       |\n",
      "|    explained_variance | 0.89        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 2.56        |\n",
      "|    mean_step_reward   | 0.112568416 |\n",
      "|    n_updates          | 5080        |\n",
      "|    policyGradLoss     | 0.000402    |\n",
      "|    value_loss         | 15.4        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 707          |\n",
      "|    iterations         | 32           |\n",
      "|    time_elapsed       | 370          |\n",
      "|    total_timesteps    | 10420224     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0049420726 |\n",
      "|    entropy_loss       | -2.35        |\n",
      "|    explained_variance | 0.903        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 2.36         |\n",
      "|    mean_step_reward   | 0.128847     |\n",
      "|    n_updates          | 5084         |\n",
      "|    policyGradLoss     | 0.00445      |\n",
      "|    value_loss         | 14.4         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 705          |\n",
      "|    iterations         | 33           |\n",
      "|    time_elapsed       | 383          |\n",
      "|    total_timesteps    | 10428416     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0050095823 |\n",
      "|    entropy_loss       | -2.33        |\n",
      "|    explained_variance | 0.919        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 3.83         |\n",
      "|    mean_step_reward   | 0.15915102   |\n",
      "|    n_updates          | 5088         |\n",
      "|    policyGradLoss     | 0.00173      |\n",
      "|    value_loss         | 27           |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 705          |\n",
      "|    iterations         | 34           |\n",
      "|    time_elapsed       | 394          |\n",
      "|    total_timesteps    | 10436608     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0044024126 |\n",
      "|    entropy_loss       | -2.34        |\n",
      "|    explained_variance | 0.946        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 3.96         |\n",
      "|    mean_step_reward   | 0.13678741   |\n",
      "|    n_updates          | 5092         |\n",
      "|    policyGradLoss     | 6.06e-05     |\n",
      "|    value_loss         | 17.8         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 704          |\n",
      "|    iterations         | 35           |\n",
      "|    time_elapsed       | 406          |\n",
      "|    total_timesteps    | 10444800     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0042607663 |\n",
      "|    entropy_loss       | -2.36        |\n",
      "|    explained_variance | 0.881        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.751        |\n",
      "|    mean_step_reward   | 0.009416111  |\n",
      "|    n_updates          | 5096         |\n",
      "|    policyGradLoss     | 0.00465      |\n",
      "|    value_loss         | 6.2          |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 703          |\n",
      "|    iterations         | 36           |\n",
      "|    time_elapsed       | 419          |\n",
      "|    total_timesteps    | 10452992     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.003969728  |\n",
      "|    entropy_loss       | -2.37        |\n",
      "|    explained_variance | 0.897        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0411       |\n",
      "|    mean_step_reward   | -0.007709183 |\n",
      "|    n_updates          | 5100         |\n",
      "|    policyGradLoss     | 0.00595      |\n",
      "|    value_loss         | 2.38         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 703           |\n",
      "|    iterations         | 37            |\n",
      "|    time_elapsed       | 430           |\n",
      "|    total_timesteps    | 10461184      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.001756178   |\n",
      "|    entropy_loss       | -2.38         |\n",
      "|    explained_variance | 0.945         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0204       |\n",
      "|    mean_step_reward   | -0.0033317448 |\n",
      "|    n_updates          | 5104          |\n",
      "|    policyGradLoss     | -0.0016       |\n",
      "|    value_loss         | 0.535         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 702          |\n",
      "|    iterations         | 38           |\n",
      "|    time_elapsed       | 443          |\n",
      "|    total_timesteps    | 10469376     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0050945077 |\n",
      "|    entropy_loss       | -2.38        |\n",
      "|    explained_variance | 0.934        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 1.51         |\n",
      "|    mean_step_reward   | 0.031321853  |\n",
      "|    n_updates          | 5108         |\n",
      "|    policyGradLoss     | 0.00304      |\n",
      "|    value_loss         | 5.21         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 704         |\n",
      "|    iterations         | 39          |\n",
      "|    time_elapsed       | 453         |\n",
      "|    total_timesteps    | 10477568    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.004249785 |\n",
      "|    entropy_loss       | -2.36       |\n",
      "|    explained_variance | 0.934       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.06        |\n",
      "|    mean_step_reward   | 0.08127642  |\n",
      "|    n_updates          | 5112        |\n",
      "|    policyGradLoss     | 0.00183     |\n",
      "|    value_loss         | 7.67        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 702          |\n",
      "|    iterations         | 40           |\n",
      "|    time_elapsed       | 466          |\n",
      "|    total_timesteps    | 10485760     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0071250186 |\n",
      "|    entropy_loss       | -2.3         |\n",
      "|    explained_variance | 0.929        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 4.83         |\n",
      "|    mean_step_reward   | 0.17724618   |\n",
      "|    n_updates          | 5116         |\n",
      "|    policyGradLoss     | 0.00493      |\n",
      "|    value_loss         | 22.5         |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/P_RWD18_31.zip\n",
      "[EVAL] Mean Return: -1.537, Best Return: -1.444\n",
      "Saved video to ./runs_smw/videos/P_RWD18/P_RWD18_31_-1.54.mp4\n",
      "\n",
      "=== Round 33 | Learn 327680 steps (Total trained: 10485760) ===\n",
      "Logging to ./runs_smw/tb/P_RWD18_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1027     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 10493952 |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 830          |\n",
      "|    iterations         | 2            |\n",
      "|    time_elapsed       | 19           |\n",
      "|    total_timesteps    | 10502144     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0071380185 |\n",
      "|    entropy_loss       | -2.23        |\n",
      "|    explained_variance | 0.903        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 17.2         |\n",
      "|    mean_step_reward   | 0.4174527    |\n",
      "|    n_updates          | 5124         |\n",
      "|    policyGradLoss     | 0.00186      |\n",
      "|    value_loss         | 71.7         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 31          |\n",
      "|    total_timesteps    | 10510336    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008898421 |\n",
      "|    entropy_loss       | -2.29       |\n",
      "|    explained_variance | 0.915       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 7.97        |\n",
      "|    mean_step_reward   | 0.20069905  |\n",
      "|    n_updates          | 5128        |\n",
      "|    policyGradLoss     | 0.00923     |\n",
      "|    value_loss         | 45.9        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 770          |\n",
      "|    iterations         | 4            |\n",
      "|    time_elapsed       | 42           |\n",
      "|    total_timesteps    | 10518528     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0037137682 |\n",
      "|    entropy_loss       | -2.33        |\n",
      "|    explained_variance | 0.932        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 3.73         |\n",
      "|    mean_step_reward   | 0.103306234  |\n",
      "|    n_updates          | 5132         |\n",
      "|    policyGradLoss     | 0.00146      |\n",
      "|    value_loss         | 27.2         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 745          |\n",
      "|    iterations         | 5            |\n",
      "|    time_elapsed       | 54           |\n",
      "|    total_timesteps    | 10526720     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0033650757 |\n",
      "|    entropy_loss       | -2.35        |\n",
      "|    explained_variance | 0.949        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 2.44         |\n",
      "|    mean_step_reward   | 0.07341138   |\n",
      "|    n_updates          | 5136         |\n",
      "|    policyGradLoss     | 0.00471      |\n",
      "|    value_loss         | 11.6         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 742           |\n",
      "|    iterations         | 6             |\n",
      "|    time_elapsed       | 66            |\n",
      "|    total_timesteps    | 10534912      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.003370818   |\n",
      "|    entropy_loss       | -2.41         |\n",
      "|    explained_variance | 0.862         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | 0.0866        |\n",
      "|    mean_step_reward   | -0.0041465266 |\n",
      "|    n_updates          | 5140          |\n",
      "|    policyGradLoss     | 0.00232       |\n",
      "|    value_loss         | 1.42          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 729           |\n",
      "|    iterations         | 7             |\n",
      "|    time_elapsed       | 78            |\n",
      "|    total_timesteps    | 10543104      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0060546333  |\n",
      "|    entropy_loss       | -2.42         |\n",
      "|    explained_variance | 0.291         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0602       |\n",
      "|    mean_step_reward   | -0.0067307362 |\n",
      "|    n_updates          | 5144          |\n",
      "|    policyGradLoss     | -0.00724      |\n",
      "|    value_loss         | 0.0497        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 721          |\n",
      "|    iterations         | 8            |\n",
      "|    time_elapsed       | 90           |\n",
      "|    total_timesteps    | 10551296     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0062242304 |\n",
      "|    entropy_loss       | -2.42        |\n",
      "|    explained_variance | 0.509        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0654      |\n",
      "|    mean_step_reward   | -0.008305441 |\n",
      "|    n_updates          | 5148         |\n",
      "|    policyGradLoss     | -0.00833     |\n",
      "|    value_loss         | 0.0296       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 719           |\n",
      "|    iterations         | 9             |\n",
      "|    time_elapsed       | 102           |\n",
      "|    total_timesteps    | 10559488      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0032057553  |\n",
      "|    entropy_loss       | -2.42         |\n",
      "|    explained_variance | 0.613         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.056        |\n",
      "|    mean_step_reward   | -0.0067964066 |\n",
      "|    n_updates          | 5152          |\n",
      "|    policyGradLoss     | -0.00474      |\n",
      "|    value_loss         | 0.0506        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 715          |\n",
      "|    iterations         | 10           |\n",
      "|    time_elapsed       | 114          |\n",
      "|    total_timesteps    | 10567680     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.006230616  |\n",
      "|    entropy_loss       | -2.42        |\n",
      "|    explained_variance | 0.665        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0318      |\n",
      "|    mean_step_reward   | -0.007825499 |\n",
      "|    n_updates          | 5156         |\n",
      "|    policyGradLoss     | -0.00399     |\n",
      "|    value_loss         | 0.0364       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 720          |\n",
      "|    iterations         | 11           |\n",
      "|    time_elapsed       | 125          |\n",
      "|    total_timesteps    | 10575872     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.004353418  |\n",
      "|    entropy_loss       | -2.42        |\n",
      "|    explained_variance | 0.765        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0722      |\n",
      "|    mean_step_reward   | -0.008492523 |\n",
      "|    n_updates          | 5160         |\n",
      "|    policyGradLoss     | -0.00638     |\n",
      "|    value_loss         | 0.0175       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 714           |\n",
      "|    iterations         | 12            |\n",
      "|    time_elapsed       | 137           |\n",
      "|    total_timesteps    | 10584064      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0058050035  |\n",
      "|    entropy_loss       | -2.4          |\n",
      "|    explained_variance | 0.468         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0532       |\n",
      "|    mean_step_reward   | -0.0075416453 |\n",
      "|    n_updates          | 5164          |\n",
      "|    policyGradLoss     | -0.00738      |\n",
      "|    value_loss         | 0.0526        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 714          |\n",
      "|    iterations         | 13           |\n",
      "|    time_elapsed       | 148          |\n",
      "|    total_timesteps    | 10592256     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0057780487 |\n",
      "|    entropy_loss       | -2.38        |\n",
      "|    explained_variance | 0.566        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0574      |\n",
      "|    mean_step_reward   | -0.006303856 |\n",
      "|    n_updates          | 5168         |\n",
      "|    policyGradLoss     | -0.00764     |\n",
      "|    value_loss         | 0.0563       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 711          |\n",
      "|    iterations         | 14           |\n",
      "|    time_elapsed       | 161          |\n",
      "|    total_timesteps    | 10600448     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0049405117 |\n",
      "|    entropy_loss       | -2.39        |\n",
      "|    explained_variance | 0.477        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0557      |\n",
      "|    mean_step_reward   | -0.007983614 |\n",
      "|    n_updates          | 5172         |\n",
      "|    policyGradLoss     | -0.00757     |\n",
      "|    value_loss         | 0.0385       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 708          |\n",
      "|    iterations         | 15           |\n",
      "|    time_elapsed       | 173          |\n",
      "|    total_timesteps    | 10608640     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.005684547  |\n",
      "|    entropy_loss       | -2.36        |\n",
      "|    explained_variance | 0.499        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.045       |\n",
      "|    mean_step_reward   | -0.007932106 |\n",
      "|    n_updates          | 5176         |\n",
      "|    policyGradLoss     | -0.0077      |\n",
      "|    value_loss         | 0.0451       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 709          |\n",
      "|    iterations         | 16           |\n",
      "|    time_elapsed       | 184          |\n",
      "|    total_timesteps    | 10616832     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.004833287  |\n",
      "|    entropy_loss       | -2.37        |\n",
      "|    explained_variance | 0.471        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.06        |\n",
      "|    mean_step_reward   | -0.008294808 |\n",
      "|    n_updates          | 5180         |\n",
      "|    policyGradLoss     | -0.00905     |\n",
      "|    value_loss         | 0.0464       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 707           |\n",
      "|    iterations         | 17            |\n",
      "|    time_elapsed       | 196           |\n",
      "|    total_timesteps    | 10625024      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.00498291    |\n",
      "|    entropy_loss       | -2.34         |\n",
      "|    explained_variance | 0.904         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0324       |\n",
      "|    mean_step_reward   | -0.0055129826 |\n",
      "|    n_updates          | 5184          |\n",
      "|    policyGradLoss     | -0.00646      |\n",
      "|    value_loss         | 0.109         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 710          |\n",
      "|    iterations         | 18           |\n",
      "|    time_elapsed       | 207          |\n",
      "|    total_timesteps    | 10633216     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0028951846 |\n",
      "|    entropy_loss       | -2.31        |\n",
      "|    explained_variance | 0.847        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.109        |\n",
      "|    mean_step_reward   | -0.006084825 |\n",
      "|    n_updates          | 5188         |\n",
      "|    policyGradLoss     | -0.0019      |\n",
      "|    value_loss         | 0.528        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 707         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 219         |\n",
      "|    total_timesteps    | 10641408    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.005592436 |\n",
      "|    entropy_loss       | -2.3        |\n",
      "|    explained_variance | 0.926       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.606       |\n",
      "|    mean_step_reward   | 0.06687024  |\n",
      "|    n_updates          | 5192        |\n",
      "|    policyGradLoss     | 0.00301     |\n",
      "|    value_loss         | 6.37        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 708         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 231         |\n",
      "|    total_timesteps    | 10649600    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008028239 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.928       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 4.09        |\n",
      "|    mean_step_reward   | 0.18039379  |\n",
      "|    n_updates          | 5196        |\n",
      "|    policyGradLoss     | 0.00281     |\n",
      "|    value_loss         | 25.4        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 706         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 243         |\n",
      "|    total_timesteps    | 10657792    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007528638 |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.938       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 4.94        |\n",
      "|    mean_step_reward   | 0.27893162  |\n",
      "|    n_updates          | 5200        |\n",
      "|    policyGradLoss     | 0.00561     |\n",
      "|    value_loss         | 32.6        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 704          |\n",
      "|    iterations         | 22           |\n",
      "|    time_elapsed       | 255          |\n",
      "|    total_timesteps    | 10665984     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0048292736 |\n",
      "|    entropy_loss       | -2.2         |\n",
      "|    explained_variance | 0.945        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 7.96         |\n",
      "|    mean_step_reward   | 0.28514838   |\n",
      "|    n_updates          | 5204         |\n",
      "|    policyGradLoss     | 0.00362      |\n",
      "|    value_loss         | 36.1         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 706         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 266         |\n",
      "|    total_timesteps    | 10674176    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.004971831 |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.937       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 7.37        |\n",
      "|    mean_step_reward   | 0.19203226  |\n",
      "|    n_updates          | 5208        |\n",
      "|    policyGradLoss     | 0.00199     |\n",
      "|    value_loss         | 29.3        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 704          |\n",
      "|    iterations         | 24           |\n",
      "|    time_elapsed       | 279          |\n",
      "|    total_timesteps    | 10682368     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0054750736 |\n",
      "|    entropy_loss       | -2.27        |\n",
      "|    explained_variance | 0.902        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 2.94         |\n",
      "|    mean_step_reward   | 0.048825577  |\n",
      "|    n_updates          | 5212         |\n",
      "|    policyGradLoss     | 0.000872     |\n",
      "|    value_loss         | 18.4         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 706          |\n",
      "|    iterations         | 25           |\n",
      "|    time_elapsed       | 289          |\n",
      "|    total_timesteps    | 10690560     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0059650773 |\n",
      "|    entropy_loss       | -2.23        |\n",
      "|    explained_variance | 0.946        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 5.91         |\n",
      "|    mean_step_reward   | 0.19915742   |\n",
      "|    n_updates          | 5216         |\n",
      "|    policyGradLoss     | 0.00112      |\n",
      "|    value_loss         | 28.6         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 704          |\n",
      "|    iterations         | 26           |\n",
      "|    time_elapsed       | 302          |\n",
      "|    total_timesteps    | 10698752     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0064452104 |\n",
      "|    entropy_loss       | -2.21        |\n",
      "|    explained_variance | 0.941        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 8.43         |\n",
      "|    mean_step_reward   | 0.15277636   |\n",
      "|    n_updates          | 5220         |\n",
      "|    policyGradLoss     | 0.0048       |\n",
      "|    value_loss         | 30.1         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 704         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 314         |\n",
      "|    total_timesteps    | 10706944    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.005061037 |\n",
      "|    entropy_loss       | -2.18       |\n",
      "|    explained_variance | 0.943       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 11.8        |\n",
      "|    mean_step_reward   | 0.29506916  |\n",
      "|    n_updates          | 5224        |\n",
      "|    policyGradLoss     | 0.00629     |\n",
      "|    value_loss         | 47          |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 703          |\n",
      "|    iterations         | 28           |\n",
      "|    time_elapsed       | 326          |\n",
      "|    total_timesteps    | 10715136     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0039683064 |\n",
      "|    entropy_loss       | -2.2         |\n",
      "|    explained_variance | 0.937        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 6.48         |\n",
      "|    mean_step_reward   | 0.15786283   |\n",
      "|    n_updates          | 5228         |\n",
      "|    policyGradLoss     | 0.00277      |\n",
      "|    value_loss         | 37.2         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 701         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 338         |\n",
      "|    total_timesteps    | 10723328    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.006300551 |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.927       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 7.58        |\n",
      "|    mean_step_reward   | 0.18554892  |\n",
      "|    n_updates          | 5232        |\n",
      "|    policyGradLoss     | 0.00112     |\n",
      "|    value_loss         | 37.8        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 702         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 349         |\n",
      "|    total_timesteps    | 10731520    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.005130765 |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.932       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 7.63        |\n",
      "|    mean_step_reward   | 0.22159228  |\n",
      "|    n_updates          | 5236        |\n",
      "|    policyGradLoss     | 0.00424     |\n",
      "|    value_loss         | 36.3        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 701          |\n",
      "|    iterations         | 31           |\n",
      "|    time_elapsed       | 362          |\n",
      "|    total_timesteps    | 10739712     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0038938546 |\n",
      "|    entropy_loss       | -2.25        |\n",
      "|    explained_variance | 0.942        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 3.96         |\n",
      "|    mean_step_reward   | 0.11905888   |\n",
      "|    n_updates          | 5240         |\n",
      "|    policyGradLoss     | 0.000902     |\n",
      "|    value_loss         | 19.1         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 702          |\n",
      "|    iterations         | 32           |\n",
      "|    time_elapsed       | 373          |\n",
      "|    total_timesteps    | 10747904     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0044377283 |\n",
      "|    entropy_loss       | -2.24        |\n",
      "|    explained_variance | 0.961        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 3.59         |\n",
      "|    mean_step_reward   | 0.1773561    |\n",
      "|    n_updates          | 5244         |\n",
      "|    policyGradLoss     | 0.00138      |\n",
      "|    value_loss         | 18.6         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 700         |\n",
      "|    iterations         | 33          |\n",
      "|    time_elapsed       | 385         |\n",
      "|    total_timesteps    | 10756096    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.005876723 |\n",
      "|    entropy_loss       | -2.18       |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 5.79        |\n",
      "|    mean_step_reward   | 0.310427    |\n",
      "|    n_updates          | 5248        |\n",
      "|    policyGradLoss     | 0.00444     |\n",
      "|    value_loss         | 34          |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 700         |\n",
      "|    iterations         | 34          |\n",
      "|    time_elapsed       | 397         |\n",
      "|    total_timesteps    | 10764288    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.005166343 |\n",
      "|    entropy_loss       | -2.15       |\n",
      "|    explained_variance | 0.949       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 10.8        |\n",
      "|    mean_step_reward   | 0.2625833   |\n",
      "|    n_updates          | 5252        |\n",
      "|    policyGradLoss     | 0.00553     |\n",
      "|    value_loss         | 39.8        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 700          |\n",
      "|    iterations         | 35           |\n",
      "|    time_elapsed       | 409          |\n",
      "|    total_timesteps    | 10772480     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0063851182 |\n",
      "|    entropy_loss       | -2.2         |\n",
      "|    explained_variance | 0.933        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 5.49         |\n",
      "|    mean_step_reward   | 0.10699862   |\n",
      "|    n_updates          | 5256         |\n",
      "|    policyGradLoss     | 0.00545      |\n",
      "|    value_loss         | 29.1         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 699         |\n",
      "|    iterations         | 36          |\n",
      "|    time_elapsed       | 421         |\n",
      "|    total_timesteps    | 10780672    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.004455712 |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.958       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 4.32        |\n",
      "|    mean_step_reward   | 0.13525295  |\n",
      "|    n_updates          | 5260        |\n",
      "|    policyGradLoss     | 0.000187    |\n",
      "|    value_loss         | 20.8        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 702         |\n",
      "|    iterations         | 37          |\n",
      "|    time_elapsed       | 431         |\n",
      "|    total_timesteps    | 10788864    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.005080702 |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.957       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 3.6         |\n",
      "|    mean_step_reward   | 0.16964409  |\n",
      "|    n_updates          | 5264        |\n",
      "|    policyGradLoss     | 0.00441     |\n",
      "|    value_loss         | 20.4        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 700        |\n",
      "|    iterations         | 38         |\n",
      "|    time_elapsed       | 444        |\n",
      "|    total_timesteps    | 10797056   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.00948941 |\n",
      "|    entropy_loss       | -2.18      |\n",
      "|    explained_variance | 0.948      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 12         |\n",
      "|    mean_step_reward   | 0.31359944 |\n",
      "|    n_updates          | 5268       |\n",
      "|    policyGradLoss     | 0.00143    |\n",
      "|    value_loss         | 52.8       |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 701          |\n",
      "|    iterations         | 39           |\n",
      "|    time_elapsed       | 455          |\n",
      "|    total_timesteps    | 10805248     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0100739775 |\n",
      "|    entropy_loss       | -2.23        |\n",
      "|    explained_variance | 0.953        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 4.64         |\n",
      "|    mean_step_reward   | 0.22591667   |\n",
      "|    n_updates          | 5272         |\n",
      "|    policyGradLoss     | 0.00217      |\n",
      "|    value_loss         | 28.7         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 700          |\n",
      "|    iterations         | 40           |\n",
      "|    time_elapsed       | 467          |\n",
      "|    total_timesteps    | 10813440     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0073939525 |\n",
      "|    entropy_loss       | -2.25        |\n",
      "|    explained_variance | 0.966        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 2.79         |\n",
      "|    mean_step_reward   | 0.16425407   |\n",
      "|    n_updates          | 5276         |\n",
      "|    policyGradLoss     | 0.00279      |\n",
      "|    value_loss         | 16           |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/P_RWD18_32.zip\n",
      "[EVAL] Mean Return: -1.255, Best Return: -0.521\n",
      "Saved video to ./runs_smw/videos/P_RWD18/P_RWD18_32_-1.25.mp4\n",
      "\n",
      "=== Round 34 | Learn 327680 steps (Total trained: 10813440) ===\n",
      "Logging to ./runs_smw/tb/P_RWD18_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 993      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 8        |\n",
      "|    total_timesteps | 10821632 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 888         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 10829824    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008391628 |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.932       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 11.3        |\n",
      "|    mean_step_reward   | 0.2751063   |\n",
      "|    n_updates          | 5284        |\n",
      "|    policyGradLoss     | 0.00718     |\n",
      "|    value_loss         | 53.2        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 808          |\n",
      "|    iterations         | 3            |\n",
      "|    time_elapsed       | 30           |\n",
      "|    total_timesteps    | 10838016     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0088466145 |\n",
      "|    entropy_loss       | -2.24        |\n",
      "|    explained_variance | 0.957        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 5.14         |\n",
      "|    mean_step_reward   | 0.18497875   |\n",
      "|    n_updates          | 5288         |\n",
      "|    policyGradLoss     | 0.00645      |\n",
      "|    value_loss         | 31           |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 770          |\n",
      "|    iterations         | 4            |\n",
      "|    time_elapsed       | 42           |\n",
      "|    total_timesteps    | 10846208     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0056305453 |\n",
      "|    entropy_loss       | -2.25        |\n",
      "|    explained_variance | 0.951        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 5.51         |\n",
      "|    mean_step_reward   | 0.103489056  |\n",
      "|    n_updates          | 5292         |\n",
      "|    policyGradLoss     | 0.0061       |\n",
      "|    value_loss         | 31.5         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 750         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 54          |\n",
      "|    total_timesteps    | 10854400    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008263592 |\n",
      "|    entropy_loss       | -2.29       |\n",
      "|    explained_variance | 0.943       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 3.16        |\n",
      "|    mean_step_reward   | 0.116813235 |\n",
      "|    n_updates          | 5296        |\n",
      "|    policyGradLoss     | 0.00386     |\n",
      "|    value_loss         | 18.8        |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 743           |\n",
      "|    iterations         | 6             |\n",
      "|    time_elapsed       | 66            |\n",
      "|    total_timesteps    | 10862592      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0029964577  |\n",
      "|    entropy_loss       | -2.36         |\n",
      "|    explained_variance | 0.94          |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | 0.0477        |\n",
      "|    mean_step_reward   | -0.0043986742 |\n",
      "|    n_updates          | 5300          |\n",
      "|    policyGradLoss     | 0.000212      |\n",
      "|    value_loss         | 0.67          |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 733         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 78          |\n",
      "|    total_timesteps    | 10870784    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.006794179 |\n",
      "|    entropy_loss       | -2.31       |\n",
      "|    explained_variance | 0.935       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 2.89        |\n",
      "|    mean_step_reward   | 0.11777956  |\n",
      "|    n_updates          | 5304        |\n",
      "|    policyGradLoss     | 0.00529     |\n",
      "|    value_loss         | 21.5        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 724          |\n",
      "|    iterations         | 8            |\n",
      "|    time_elapsed       | 90           |\n",
      "|    total_timesteps    | 10878976     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0036936975 |\n",
      "|    entropy_loss       | -2.31        |\n",
      "|    explained_variance | 0.949        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 5.97         |\n",
      "|    mean_step_reward   | 0.13048634   |\n",
      "|    n_updates          | 5308         |\n",
      "|    policyGradLoss     | 0.00101      |\n",
      "|    value_loss         | 22.7         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 730         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 100         |\n",
      "|    total_timesteps    | 10887168    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.003471921 |\n",
      "|    entropy_loss       | -2.33       |\n",
      "|    explained_variance | 0.95        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.394       |\n",
      "|    mean_step_reward   | 0.010918412 |\n",
      "|    n_updates          | 5312        |\n",
      "|    policyGradLoss     | -0.000149   |\n",
      "|    value_loss         | 6.49        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 723          |\n",
      "|    iterations         | 10           |\n",
      "|    time_elapsed       | 113          |\n",
      "|    total_timesteps    | 10895360     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0077447803 |\n",
      "|    entropy_loss       | -2.23        |\n",
      "|    explained_variance | 0.953        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 7.14         |\n",
      "|    mean_step_reward   | 0.16312635   |\n",
      "|    n_updates          | 5316         |\n",
      "|    policyGradLoss     | 0.00316      |\n",
      "|    value_loss         | 30.4         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 725         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 124         |\n",
      "|    total_timesteps    | 10903552    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009399027 |\n",
      "|    entropy_loss       | -2.19       |\n",
      "|    explained_variance | 0.933       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 6.27        |\n",
      "|    mean_step_reward   | 0.29288507  |\n",
      "|    n_updates          | 5320        |\n",
      "|    policyGradLoss     | 0.00217     |\n",
      "|    value_loss         | 39.9        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 718         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 136         |\n",
      "|    total_timesteps    | 10911744    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010629631 |\n",
      "|    entropy_loss       | -2.15       |\n",
      "|    explained_variance | 0.948       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 19.7        |\n",
      "|    mean_step_reward   | 0.4240759   |\n",
      "|    n_updates          | 5324        |\n",
      "|    policyGradLoss     | 0.00915     |\n",
      "|    value_loss         | 78.5        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 715         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 148         |\n",
      "|    total_timesteps    | 10919936    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009521016 |\n",
      "|    entropy_loss       | -2.09       |\n",
      "|    explained_variance | 0.95        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 23.8        |\n",
      "|    mean_step_reward   | 0.4405987   |\n",
      "|    n_updates          | 5328        |\n",
      "|    policyGradLoss     | 0.000405    |\n",
      "|    value_loss         | 97.2        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 715          |\n",
      "|    iterations         | 14           |\n",
      "|    time_elapsed       | 160          |\n",
      "|    total_timesteps    | 10928128     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0072806943 |\n",
      "|    entropy_loss       | -2.05        |\n",
      "|    explained_variance | 0.953        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 31.2         |\n",
      "|    mean_step_reward   | 0.57801425   |\n",
      "|    n_updates          | 5332         |\n",
      "|    policyGradLoss     | 0.00524      |\n",
      "|    value_loss         | 109          |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 711          |\n",
      "|    iterations         | 15           |\n",
      "|    time_elapsed       | 172          |\n",
      "|    total_timesteps    | 10936320     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0077930465 |\n",
      "|    entropy_loss       | -2.08        |\n",
      "|    explained_variance | 0.936        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 17.8         |\n",
      "|    mean_step_reward   | 0.3781331    |\n",
      "|    n_updates          | 5336         |\n",
      "|    policyGradLoss     | 0.00358      |\n",
      "|    value_loss         | 82.4         |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 715        |\n",
      "|    iterations         | 16         |\n",
      "|    time_elapsed       | 183        |\n",
      "|    total_timesteps    | 10944512   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.00731669 |\n",
      "|    entropy_loss       | -2.08      |\n",
      "|    explained_variance | 0.939      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 35.1       |\n",
      "|    mean_step_reward   | 0.44523218 |\n",
      "|    n_updates          | 5340       |\n",
      "|    policyGradLoss     | 0.0071     |\n",
      "|    value_loss         | 107        |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 711         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 195         |\n",
      "|    total_timesteps    | 10952704    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010391535 |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.94        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 9.27        |\n",
      "|    mean_step_reward   | 0.17864099  |\n",
      "|    n_updates          | 5344        |\n",
      "|    policyGradLoss     | 0.00576     |\n",
      "|    value_loss         | 69.4        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 713         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 206         |\n",
      "|    total_timesteps    | 10960896    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013057607 |\n",
      "|    entropy_loss       | -2.12       |\n",
      "|    explained_variance | 0.939       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 19.5        |\n",
      "|    mean_step_reward   | 0.36919484  |\n",
      "|    n_updates          | 5348        |\n",
      "|    policyGradLoss     | 0.00654     |\n",
      "|    value_loss         | 80.5        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 710         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 219         |\n",
      "|    total_timesteps    | 10969088    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008070282 |\n",
      "|    entropy_loss       | -2.09       |\n",
      "|    explained_variance | 0.924       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 17.8        |\n",
      "|    mean_step_reward   | 0.32236516  |\n",
      "|    n_updates          | 5352        |\n",
      "|    policyGradLoss     | 0.00191     |\n",
      "|    value_loss         | 81.1        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 707          |\n",
      "|    iterations         | 20           |\n",
      "|    time_elapsed       | 231          |\n",
      "|    total_timesteps    | 10977280     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0068504056 |\n",
      "|    entropy_loss       | -2.1         |\n",
      "|    explained_variance | 0.942        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 14.4         |\n",
      "|    mean_step_reward   | 0.40838295   |\n",
      "|    n_updates          | 5356         |\n",
      "|    policyGradLoss     | 0.00367      |\n",
      "|    value_loss         | 79.6         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 707         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 243         |\n",
      "|    total_timesteps    | 10985472    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.004905194 |\n",
      "|    entropy_loss       | -2.18       |\n",
      "|    explained_variance | 0.938       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 8.08        |\n",
      "|    mean_step_reward   | 0.21388827  |\n",
      "|    n_updates          | 5360        |\n",
      "|    policyGradLoss     | 0.000661    |\n",
      "|    value_loss         | 55.8        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 705         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 255         |\n",
      "|    total_timesteps    | 10993664    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009347964 |\n",
      "|    entropy_loss       | -2.11       |\n",
      "|    explained_variance | 0.94        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 21.6        |\n",
      "|    mean_step_reward   | 0.4621661   |\n",
      "|    n_updates          | 5364        |\n",
      "|    policyGradLoss     | 0.00471     |\n",
      "|    value_loss         | 97.9        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 708         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 265         |\n",
      "|    total_timesteps    | 11001856    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011828681 |\n",
      "|    entropy_loss       | -2.13       |\n",
      "|    explained_variance | 0.928       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 23.4        |\n",
      "|    mean_step_reward   | 0.43061212  |\n",
      "|    n_updates          | 5368        |\n",
      "|    policyGradLoss     | 0.00362     |\n",
      "|    value_loss         | 118         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 706         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 278         |\n",
      "|    total_timesteps    | 11010048    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007613466 |\n",
      "|    entropy_loss       | -2.17       |\n",
      "|    explained_variance | 0.932       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 25.6        |\n",
      "|    mean_step_reward   | 0.389108    |\n",
      "|    n_updates          | 5372        |\n",
      "|    policyGradLoss     | 0.00374     |\n",
      "|    value_loss         | 89.4        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 707         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 289         |\n",
      "|    total_timesteps    | 11018240    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008885849 |\n",
      "|    entropy_loss       | -2.28       |\n",
      "|    explained_variance | 0.948       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 4.08        |\n",
      "|    mean_step_reward   | 0.15088311  |\n",
      "|    n_updates          | 5376        |\n",
      "|    policyGradLoss     | 0.00802     |\n",
      "|    value_loss         | 35.7        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 705          |\n",
      "|    iterations         | 26           |\n",
      "|    time_elapsed       | 301          |\n",
      "|    total_timesteps    | 11026432     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0026531871 |\n",
      "|    entropy_loss       | -2.34        |\n",
      "|    explained_variance | 0.936        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.692        |\n",
      "|    mean_step_reward   | 0.018612463  |\n",
      "|    n_updates          | 5380         |\n",
      "|    policyGradLoss     | 0.000719     |\n",
      "|    value_loss         | 5.49         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 703          |\n",
      "|    iterations         | 27           |\n",
      "|    time_elapsed       | 314          |\n",
      "|    total_timesteps    | 11034624     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0048424695 |\n",
      "|    entropy_loss       | -2.35        |\n",
      "|    explained_variance | 0.953        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.201        |\n",
      "|    mean_step_reward   | 0.014236741  |\n",
      "|    n_updates          | 5384         |\n",
      "|    policyGradLoss     | 0.000875     |\n",
      "|    value_loss         | 2.79         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 704         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 325         |\n",
      "|    total_timesteps    | 11042816    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008535316 |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.951       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 14.2        |\n",
      "|    mean_step_reward   | 0.21202618  |\n",
      "|    n_updates          | 5388        |\n",
      "|    policyGradLoss     | 0.00641     |\n",
      "|    value_loss         | 55.1        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 703        |\n",
      "|    iterations         | 29         |\n",
      "|    time_elapsed       | 337        |\n",
      "|    total_timesteps    | 11051008   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.008203   |\n",
      "|    entropy_loss       | -2.22      |\n",
      "|    explained_variance | 0.941      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 5.3        |\n",
      "|    mean_step_reward   | 0.15529506 |\n",
      "|    n_updates          | 5392       |\n",
      "|    policyGradLoss     | 0.00753    |\n",
      "|    value_loss         | 38.4       |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 705          |\n",
      "|    iterations         | 30           |\n",
      "|    time_elapsed       | 348          |\n",
      "|    total_timesteps    | 11059200     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0063962964 |\n",
      "|    entropy_loss       | -2.2         |\n",
      "|    explained_variance | 0.951        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 5.37         |\n",
      "|    mean_step_reward   | 0.18260151   |\n",
      "|    n_updates          | 5396         |\n",
      "|    policyGradLoss     | 0.00539      |\n",
      "|    value_loss         | 36.3         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 703         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 360         |\n",
      "|    total_timesteps    | 11067392    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.006597938 |\n",
      "|    entropy_loss       | -2.16       |\n",
      "|    explained_variance | 0.929       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 15.4        |\n",
      "|    mean_step_reward   | 0.3740419   |\n",
      "|    n_updates          | 5400        |\n",
      "|    policyGradLoss     | 0.00423     |\n",
      "|    value_loss         | 93.3        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 704         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 372         |\n",
      "|    total_timesteps    | 11075584    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.006784059 |\n",
      "|    entropy_loss       | -2.17       |\n",
      "|    explained_variance | 0.93        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 23.1        |\n",
      "|    mean_step_reward   | 0.30124283  |\n",
      "|    n_updates          | 5404        |\n",
      "|    policyGradLoss     | 0.00296     |\n",
      "|    value_loss         | 87.6        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 703        |\n",
      "|    iterations         | 33         |\n",
      "|    time_elapsed       | 384        |\n",
      "|    total_timesteps    | 11083776   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.00936739 |\n",
      "|    entropy_loss       | -2.19      |\n",
      "|    explained_variance | 0.927      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 12.5       |\n",
      "|    mean_step_reward   | 0.24257506 |\n",
      "|    n_updates          | 5408       |\n",
      "|    policyGradLoss     | 0.00486    |\n",
      "|    value_loss         | 63.6       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 701         |\n",
      "|    iterations         | 34          |\n",
      "|    time_elapsed       | 396         |\n",
      "|    total_timesteps    | 11091968    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.006370845 |\n",
      "|    entropy_loss       | -2.18       |\n",
      "|    explained_variance | 0.918       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 10.6        |\n",
      "|    mean_step_reward   | 0.23147516  |\n",
      "|    n_updates          | 5412        |\n",
      "|    policyGradLoss     | 0.0042      |\n",
      "|    value_loss         | 55.2        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 703         |\n",
      "|    iterations         | 35          |\n",
      "|    time_elapsed       | 407         |\n",
      "|    total_timesteps    | 11100160    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009223088 |\n",
      "|    entropy_loss       | -2.2        |\n",
      "|    explained_variance | 0.899       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 6.49        |\n",
      "|    mean_step_reward   | 0.16541085  |\n",
      "|    n_updates          | 5416        |\n",
      "|    policyGradLoss     | 0.00666     |\n",
      "|    value_loss         | 51.4        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 702         |\n",
      "|    iterations         | 36          |\n",
      "|    time_elapsed       | 419         |\n",
      "|    total_timesteps    | 11108352    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.005772362 |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.916       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 6.53        |\n",
      "|    mean_step_reward   | 0.1205517   |\n",
      "|    n_updates          | 5420        |\n",
      "|    policyGradLoss     | 0.00733     |\n",
      "|    value_loss         | 29.4        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 703         |\n",
      "|    iterations         | 37          |\n",
      "|    time_elapsed       | 430         |\n",
      "|    total_timesteps    | 11116544    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.005445325 |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.907       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 6.89        |\n",
      "|    mean_step_reward   | 0.15049036  |\n",
      "|    n_updates          | 5424        |\n",
      "|    policyGradLoss     | 0.0035      |\n",
      "|    value_loss         | 31.1        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 701          |\n",
      "|    iterations         | 38           |\n",
      "|    time_elapsed       | 443          |\n",
      "|    total_timesteps    | 11124736     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0049685594 |\n",
      "|    entropy_loss       | -2.22        |\n",
      "|    explained_variance | 0.924        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 4.55         |\n",
      "|    mean_step_reward   | 0.15378708   |\n",
      "|    n_updates          | 5428         |\n",
      "|    policyGradLoss     | 0.00492      |\n",
      "|    value_loss         | 35.6         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 701         |\n",
      "|    iterations         | 39          |\n",
      "|    time_elapsed       | 455         |\n",
      "|    total_timesteps    | 11132928    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.006576775 |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.908       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 6.06        |\n",
      "|    mean_step_reward   | 0.1537526   |\n",
      "|    n_updates          | 5432        |\n",
      "|    policyGradLoss     | 0.00493     |\n",
      "|    value_loss         | 31.7        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 701         |\n",
      "|    iterations         | 40          |\n",
      "|    time_elapsed       | 467         |\n",
      "|    total_timesteps    | 11141120    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008600943 |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.922       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 5.53        |\n",
      "|    mean_step_reward   | 0.09953039  |\n",
      "|    n_updates          | 5436        |\n",
      "|    policyGradLoss     | 0.0103      |\n",
      "|    value_loss         | 20          |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/P_RWD18_33.zip\n",
      "[EVAL] Mean Return: -1.344, Best Return: -0.704\n",
      "Saved video to ./runs_smw/videos/P_RWD18/P_RWD18_33_-1.34.mp4\n",
      "\n",
      "=== Round 35 | Learn 327680 steps (Total trained: 11141120) ===\n",
      "Logging to ./runs_smw/tb/P_RWD18_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 994      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 8        |\n",
      "|    total_timesteps | 11149312 |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 845          |\n",
      "|    iterations         | 2            |\n",
      "|    time_elapsed       | 19           |\n",
      "|    total_timesteps    | 11157504     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0035270182 |\n",
      "|    entropy_loss       | -2.22        |\n",
      "|    explained_variance | 0.913        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 7.71         |\n",
      "|    mean_step_reward   | 0.20928358   |\n",
      "|    n_updates          | 5444         |\n",
      "|    policyGradLoss     | 0.00283      |\n",
      "|    value_loss         | 32.2         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 762         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 32          |\n",
      "|    total_timesteps    | 11165696    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008161871 |\n",
      "|    entropy_loss       | -2.18       |\n",
      "|    explained_variance | 0.897       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 7.2         |\n",
      "|    mean_step_reward   | 0.28659284  |\n",
      "|    n_updates          | 5448        |\n",
      "|    policyGradLoss     | 0.0072      |\n",
      "|    value_loss         | 43.3        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 742          |\n",
      "|    iterations         | 4            |\n",
      "|    time_elapsed       | 44           |\n",
      "|    total_timesteps    | 11173888     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0069894264 |\n",
      "|    entropy_loss       | -2.15        |\n",
      "|    explained_variance | 0.891        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 17.6         |\n",
      "|    mean_step_reward   | 0.4304579    |\n",
      "|    n_updates          | 5452         |\n",
      "|    policyGradLoss     | 0.000458     |\n",
      "|    value_loss         | 76.6         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 737          |\n",
      "|    iterations         | 5            |\n",
      "|    time_elapsed       | 55           |\n",
      "|    total_timesteps    | 11182080     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0060528377 |\n",
      "|    entropy_loss       | -2.23        |\n",
      "|    explained_variance | 0.906        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 9.1          |\n",
      "|    mean_step_reward   | 0.21162279   |\n",
      "|    n_updates          | 5456         |\n",
      "|    policyGradLoss     | 0.00292      |\n",
      "|    value_loss         | 47.7         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 724          |\n",
      "|    iterations         | 6            |\n",
      "|    time_elapsed       | 67           |\n",
      "|    total_timesteps    | 11190272     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0061719427 |\n",
      "|    entropy_loss       | -2.2         |\n",
      "|    explained_variance | 0.922        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 9.97         |\n",
      "|    mean_step_reward   | 0.41201317   |\n",
      "|    n_updates          | 5460         |\n",
      "|    policyGradLoss     | 0.00651      |\n",
      "|    value_loss         | 51.1         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 732          |\n",
      "|    iterations         | 7            |\n",
      "|    time_elapsed       | 78           |\n",
      "|    total_timesteps    | 11198464     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0079047065 |\n",
      "|    entropy_loss       | -2.23        |\n",
      "|    explained_variance | 0.934        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 8.59         |\n",
      "|    mean_step_reward   | 0.21165055   |\n",
      "|    n_updates          | 5464         |\n",
      "|    policyGradLoss     | 0.00489      |\n",
      "|    value_loss         | 30.6         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 721          |\n",
      "|    iterations         | 8            |\n",
      "|    time_elapsed       | 90           |\n",
      "|    total_timesteps    | 11206656     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0069491584 |\n",
      "|    entropy_loss       | -2.22        |\n",
      "|    explained_variance | 0.943        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 7.75         |\n",
      "|    mean_step_reward   | 0.21571687   |\n",
      "|    n_updates          | 5468         |\n",
      "|    policyGradLoss     | 0.00302      |\n",
      "|    value_loss         | 34.2         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 725          |\n",
      "|    iterations         | 9            |\n",
      "|    time_elapsed       | 101          |\n",
      "|    total_timesteps    | 11214848     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0062902574 |\n",
      "|    entropy_loss       | -2.24        |\n",
      "|    explained_variance | 0.932        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 4.31         |\n",
      "|    mean_step_reward   | 0.14232758   |\n",
      "|    n_updates          | 5472         |\n",
      "|    policyGradLoss     | 0.00406      |\n",
      "|    value_loss         | 32.1         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 716         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 114         |\n",
      "|    total_timesteps    | 11223040    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007278785 |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.936       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 4.23        |\n",
      "|    mean_step_reward   | 0.22278933  |\n",
      "|    n_updates          | 5476        |\n",
      "|    policyGradLoss     | 0.00123     |\n",
      "|    value_loss         | 32.3        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 714         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 126         |\n",
      "|    total_timesteps    | 11231232    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.005426552 |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.948       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 4.71        |\n",
      "|    mean_step_reward   | 0.11304549  |\n",
      "|    n_updates          | 5480        |\n",
      "|    policyGradLoss     | 0.00553     |\n",
      "|    value_loss         | 21.6        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 711         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 138         |\n",
      "|    total_timesteps    | 11239424    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008878804 |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.946       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 3.09        |\n",
      "|    mean_step_reward   | 0.13687335  |\n",
      "|    n_updates          | 5484        |\n",
      "|    policyGradLoss     | 0.00659     |\n",
      "|    value_loss         | 18.2        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 708         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 150         |\n",
      "|    total_timesteps    | 11247616    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007103374 |\n",
      "|    entropy_loss       | -2.28       |\n",
      "|    explained_variance | 0.917       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.68        |\n",
      "|    mean_step_reward   | 0.06866109  |\n",
      "|    n_updates          | 5488        |\n",
      "|    policyGradLoss     | 0.00628     |\n",
      "|    value_loss         | 9.95        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 714         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 160         |\n",
      "|    total_timesteps    | 11255808    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009983469 |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.913       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 6.23        |\n",
      "|    mean_step_reward   | 0.16385967  |\n",
      "|    n_updates          | 5492        |\n",
      "|    policyGradLoss     | 0.00278     |\n",
      "|    value_loss         | 40.7        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 711          |\n",
      "|    iterations         | 15           |\n",
      "|    time_elapsed       | 172          |\n",
      "|    total_timesteps    | 11264000     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0064000967 |\n",
      "|    entropy_loss       | -2.23        |\n",
      "|    explained_variance | 0.926        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 10.4         |\n",
      "|    mean_step_reward   | 0.32222116   |\n",
      "|    n_updates          | 5496         |\n",
      "|    policyGradLoss     | 0.00339      |\n",
      "|    value_loss         | 49.1         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 712         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 184         |\n",
      "|    total_timesteps    | 11272192    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008237818 |\n",
      "|    entropy_loss       | -2.2        |\n",
      "|    explained_variance | 0.951       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 10.2        |\n",
      "|    mean_step_reward   | 0.3993362   |\n",
      "|    n_updates          | 5500        |\n",
      "|    policyGradLoss     | 0.00496     |\n",
      "|    value_loss         | 62.5        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 709         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 196         |\n",
      "|    total_timesteps    | 11280384    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.006553113 |\n",
      "|    entropy_loss       | -2.16       |\n",
      "|    explained_variance | 0.942       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 14.6        |\n",
      "|    mean_step_reward   | 0.414105    |\n",
      "|    n_updates          | 5504        |\n",
      "|    policyGradLoss     | 0.0031      |\n",
      "|    value_loss         | 68.2        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 707          |\n",
      "|    iterations         | 18           |\n",
      "|    time_elapsed       | 208          |\n",
      "|    total_timesteps    | 11288576     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0055469163 |\n",
      "|    entropy_loss       | -2.16        |\n",
      "|    explained_variance | 0.95         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 15.5         |\n",
      "|    mean_step_reward   | 0.44075504   |\n",
      "|    n_updates          | 5508         |\n",
      "|    policyGradLoss     | 0.00345      |\n",
      "|    value_loss         | 67.7         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 707          |\n",
      "|    iterations         | 19           |\n",
      "|    time_elapsed       | 219          |\n",
      "|    total_timesteps    | 11296768     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0054088067 |\n",
      "|    entropy_loss       | -2.23        |\n",
      "|    explained_variance | 0.951        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 4.59         |\n",
      "|    mean_step_reward   | 0.2659227    |\n",
      "|    n_updates          | 5512         |\n",
      "|    policyGradLoss     | 0.00337      |\n",
      "|    value_loss         | 37.7         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 705         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 232         |\n",
      "|    total_timesteps    | 11304960    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007015539 |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 5.98        |\n",
      "|    mean_step_reward   | 0.16598248  |\n",
      "|    n_updates          | 5516        |\n",
      "|    policyGradLoss     | 0.00312     |\n",
      "|    value_loss         | 39.1        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 709         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 242         |\n",
      "|    total_timesteps    | 11313152    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.005295215 |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.947       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 15.7        |\n",
      "|    mean_step_reward   | 0.28553426  |\n",
      "|    n_updates          | 5520        |\n",
      "|    policyGradLoss     | 0.00564     |\n",
      "|    value_loss         | 55.6        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 706          |\n",
      "|    iterations         | 22           |\n",
      "|    time_elapsed       | 254          |\n",
      "|    total_timesteps    | 11321344     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0070049046 |\n",
      "|    entropy_loss       | -2.18        |\n",
      "|    explained_variance | 0.935        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 16.5         |\n",
      "|    mean_step_reward   | 0.3249703    |\n",
      "|    n_updates          | 5524         |\n",
      "|    policyGradLoss     | 0.000353     |\n",
      "|    value_loss         | 78.6         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 706         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 266         |\n",
      "|    total_timesteps    | 11329536    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007572979 |\n",
      "|    entropy_loss       | -2.17       |\n",
      "|    explained_variance | 0.931       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 21.9        |\n",
      "|    mean_step_reward   | 0.33252752  |\n",
      "|    n_updates          | 5528        |\n",
      "|    policyGradLoss     | 0.007       |\n",
      "|    value_loss         | 87.4        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 706          |\n",
      "|    iterations         | 24           |\n",
      "|    time_elapsed       | 278          |\n",
      "|    total_timesteps    | 11337728     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0051286137 |\n",
      "|    entropy_loss       | -2.14        |\n",
      "|    explained_variance | 0.94         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 17.6         |\n",
      "|    mean_step_reward   | 0.44605187   |\n",
      "|    n_updates          | 5532         |\n",
      "|    policyGradLoss     | 0.000829     |\n",
      "|    value_loss         | 83.3         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 704         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 290         |\n",
      "|    total_timesteps    | 11345920    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008525454 |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.932       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 7.43        |\n",
      "|    mean_step_reward   | 0.1953844   |\n",
      "|    n_updates          | 5536        |\n",
      "|    policyGradLoss     | 0.00507     |\n",
      "|    value_loss         | 35.3        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 704          |\n",
      "|    iterations         | 26           |\n",
      "|    time_elapsed       | 302          |\n",
      "|    total_timesteps    | 11354112     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0029710606 |\n",
      "|    entropy_loss       | -2.32        |\n",
      "|    explained_variance | 0.95         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.183        |\n",
      "|    mean_step_reward   | -0.004606082 |\n",
      "|    n_updates          | 5540         |\n",
      "|    policyGradLoss     | -0.00191     |\n",
      "|    value_loss         | 3.44         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 705          |\n",
      "|    iterations         | 27           |\n",
      "|    time_elapsed       | 313          |\n",
      "|    total_timesteps    | 11362304     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0052321954 |\n",
      "|    entropy_loss       | -2.34        |\n",
      "|    explained_variance | 0.956        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 4.91         |\n",
      "|    mean_step_reward   | 0.07360942   |\n",
      "|    n_updates          | 5544         |\n",
      "|    policyGradLoss     | 0.00168      |\n",
      "|    value_loss         | 9.19         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 705          |\n",
      "|    iterations         | 28           |\n",
      "|    time_elapsed       | 325          |\n",
      "|    total_timesteps    | 11370496     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.004489266  |\n",
      "|    entropy_loss       | -2.41        |\n",
      "|    explained_variance | -0.00546     |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0498      |\n",
      "|    mean_step_reward   | -0.005781185 |\n",
      "|    n_updates          | 5548         |\n",
      "|    policyGradLoss     | -0.00255     |\n",
      "|    value_loss         | 0.0918       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 703          |\n",
      "|    iterations         | 29           |\n",
      "|    time_elapsed       | 337          |\n",
      "|    total_timesteps    | 11378688     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0037338883 |\n",
      "|    entropy_loss       | -2.42        |\n",
      "|    explained_variance | 0.238        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0635      |\n",
      "|    mean_step_reward   | -0.008223321 |\n",
      "|    n_updates          | 5552         |\n",
      "|    policyGradLoss     | -0.00547     |\n",
      "|    value_loss         | 0.0352       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 703          |\n",
      "|    iterations         | 30           |\n",
      "|    time_elapsed       | 349          |\n",
      "|    total_timesteps    | 11386880     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0052150926 |\n",
      "|    entropy_loss       | -2.41        |\n",
      "|    explained_variance | 0.507        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0607      |\n",
      "|    mean_step_reward   | -0.00787789  |\n",
      "|    n_updates          | 5556         |\n",
      "|    policyGradLoss     | -0.00806     |\n",
      "|    value_loss         | 0.0272       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 702           |\n",
      "|    iterations         | 31            |\n",
      "|    time_elapsed       | 361           |\n",
      "|    total_timesteps    | 11395072      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0061161052  |\n",
      "|    entropy_loss       | -2.4          |\n",
      "|    explained_variance | 0.197         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0536       |\n",
      "|    mean_step_reward   | -0.0059629274 |\n",
      "|    n_updates          | 5560          |\n",
      "|    policyGradLoss     | -0.00649      |\n",
      "|    value_loss         | 0.0592        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 701          |\n",
      "|    iterations         | 32           |\n",
      "|    time_elapsed       | 373          |\n",
      "|    total_timesteps    | 11403264     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0057284376 |\n",
      "|    entropy_loss       | -2.39        |\n",
      "|    explained_variance | 0.524        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0621      |\n",
      "|    mean_step_reward   | -0.00720878  |\n",
      "|    n_updates          | 5564         |\n",
      "|    policyGradLoss     | -0.0089      |\n",
      "|    value_loss         | 0.0481       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 702           |\n",
      "|    iterations         | 33            |\n",
      "|    time_elapsed       | 384           |\n",
      "|    total_timesteps    | 11411456      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.004210245   |\n",
      "|    entropy_loss       | -2.37         |\n",
      "|    explained_variance | 0.768         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0388       |\n",
      "|    mean_step_reward   | -0.0058118375 |\n",
      "|    n_updates          | 5568          |\n",
      "|    policyGradLoss     | -0.0064       |\n",
      "|    value_loss         | 0.0893        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 701          |\n",
      "|    iterations         | 34           |\n",
      "|    time_elapsed       | 397          |\n",
      "|    total_timesteps    | 11419648     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0053488743 |\n",
      "|    entropy_loss       | -2.37        |\n",
      "|    explained_variance | 0.935        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.334        |\n",
      "|    mean_step_reward   | 0.0023046052 |\n",
      "|    n_updates          | 5572         |\n",
      "|    policyGradLoss     | 3.7e-05      |\n",
      "|    value_loss         | 3.19         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 702           |\n",
      "|    iterations         | 35            |\n",
      "|    time_elapsed       | 407           |\n",
      "|    total_timesteps    | 11427840      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.001986654   |\n",
      "|    entropy_loss       | -2.37         |\n",
      "|    explained_variance | 0.935         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | 0.453         |\n",
      "|    mean_step_reward   | -0.0006708357 |\n",
      "|    n_updates          | 5576          |\n",
      "|    policyGradLoss     | 0.00102       |\n",
      "|    value_loss         | 2.02          |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 701         |\n",
      "|    iterations         | 36          |\n",
      "|    time_elapsed       | 420         |\n",
      "|    total_timesteps    | 11436032    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.005793566 |\n",
      "|    entropy_loss       | -2.31       |\n",
      "|    explained_variance | 0.941       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.66        |\n",
      "|    mean_step_reward   | 0.06857824  |\n",
      "|    n_updates          | 5580        |\n",
      "|    policyGradLoss     | 0.00245     |\n",
      "|    value_loss         | 12.8        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 701         |\n",
      "|    iterations         | 37          |\n",
      "|    time_elapsed       | 432         |\n",
      "|    total_timesteps    | 11444224    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007009312 |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.921       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 11.2        |\n",
      "|    mean_step_reward   | 0.23658285  |\n",
      "|    n_updates          | 5584        |\n",
      "|    policyGradLoss     | 0.00455     |\n",
      "|    value_loss         | 47.9        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 700         |\n",
      "|    iterations         | 38          |\n",
      "|    time_elapsed       | 444         |\n",
      "|    total_timesteps    | 11452416    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.005580073 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.916       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 11.3        |\n",
      "|    mean_step_reward   | 0.29652175  |\n",
      "|    n_updates          | 5588        |\n",
      "|    policyGradLoss     | 0.00338     |\n",
      "|    value_loss         | 46.2        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 699         |\n",
      "|    iterations         | 39          |\n",
      "|    time_elapsed       | 456         |\n",
      "|    total_timesteps    | 11460608    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.005235469 |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.95        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 6.03        |\n",
      "|    mean_step_reward   | 0.26627156  |\n",
      "|    n_updates          | 5592        |\n",
      "|    policyGradLoss     | 0.000474    |\n",
      "|    value_loss         | 39.6        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 700          |\n",
      "|    iterations         | 40           |\n",
      "|    time_elapsed       | 467          |\n",
      "|    total_timesteps    | 11468800     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0046622027 |\n",
      "|    entropy_loss       | -2.3         |\n",
      "|    explained_variance | 0.918        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 3.2          |\n",
      "|    mean_step_reward   | 0.13999729   |\n",
      "|    n_updates          | 5596         |\n",
      "|    policyGradLoss     | 0.000599     |\n",
      "|    value_loss         | 18.3         |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/P_RWD18_34.zip\n",
      "[EVAL] Mean Return: -1.154, Best Return: -0.274\n",
      "Saved video to ./runs_smw/videos/P_RWD18/P_RWD18_34_-1.15.mp4\n",
      "\n",
      "=== Round 36 | Learn 327680 steps (Total trained: 11468800) ===\n",
      "Logging to ./runs_smw/tb/P_RWD18_0\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    while trained < TOTAL_STEPS:\n",
    "        round_idx += 1\n",
    "        chunk = min(TRAIN_CHUNK, TOTAL_STEPS - trained)\n",
    "        # chunk = 2000\n",
    "        label = \"P_RWD18\"\n",
    "        tagged_label = f\"{label}_{int(trained/TRAIN_CHUNK)}\"\n",
    "\n",
    "        print(f\"\\n=== Round {round_idx} | Learn {chunk} steps (Total trained: {trained}) ===\")\n",
    "        \n",
    "        # --- Train ---\n",
    "        model.learn(total_timesteps=chunk, reset_num_timesteps=False, tb_log_name=label)\n",
    "        trained += chunk\n",
    "\n",
    "        # --- Save Checkpoint ---\n",
    "        ckpt_path = os.path.join(CKPT_DIR, f\"{tagged_label}.zip\")\n",
    "        model.save(ckpt_path)\n",
    "        print(f\"Saved checkpoint: {ckpt_path}\")\n",
    "\n",
    "        # --- Evaluate ---\n",
    "        mean_ret, best_ret = evaluate_policy(\n",
    "            model,\n",
    "            GAME,\n",
    "            STATE,\n",
    "            n_episodes=EVAL_EPISODES,\n",
    "            max_steps=EVAL_MAX_STEPS,\n",
    "        )\n",
    "        print(f\"[EVAL] Mean Return: {mean_ret:.3f}, Best Return: {best_ret:.3f}\")\n",
    "\n",
    "        # --- Save Best Model ---\n",
    "        # if mean_ret > best_mean:\n",
    "        #     best_mean = mean_ret\n",
    "        #     best_path = os.path.join(LOG_DIR, \"best_model.zip\")\n",
    "        #     model.save(best_path)\n",
    "        #     print(f\"New best record. Saved to {best_path}\")\n",
    "\n",
    "        # --- Record Video ---\n",
    "        out_path = os.path.join(VIDEO_DIR, label)\n",
    "        os.makedirs(out_path,  exist_ok=True)\n",
    "        record_video(\n",
    "            model,\n",
    "            GAME,\n",
    "            STATE,\n",
    "            VIDEO_DIR,\n",
    "            video_len=RECORD_STEPS,\n",
    "            prefix=f\"{label}/{tagged_label}_{mean_ret:.2f}\",\n",
    "        )\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nTraining interrupted manually.\")\n",
    "\n",
    "finally:\n",
    "    train_env.close()\n",
    "    print(\"Training finished. Environment closed.\")\n",
    "    \n",
    "\"\"\"\n",
    "tensorboard --logdir=./runs_smw/tb\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f088b0b3-2418-4866-b332-0312c9f6467f",
   "metadata": {},
   "source": [
    "## Display Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73191bb-e875-4939-b04c-a4670abd9612",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Video\n",
    "import glob\n",
    "\n",
    "list_of_files = glob.glob(os.path.join(VIDEO_DIR, '*.mp4')) \n",
    "if list_of_files:\n",
    "    latest_file = max(list_of_files, key=os.path.getctime)\n",
    "    print(f\"Playing: {latest_file}\")\n",
    "    display(Video(latest_file, embed=True, width=600))\n",
    "else:\n",
    "    print(\"No videos found yet.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942adf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(\"runs_smw/videos/test_16.mp4\")\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    cv2.imshow(\"Frame-by-Frame\", frame)\n",
    "\n",
    "    # 關鍵：這裡等待按鍵。按 'n' 鍵跳到下一幀，按 'q' 離開\n",
    "    key = cv2.waitKey(0) \n",
    "    if key == ord('q'):\n",
    "        break\n",
    "    elif key == ord('n'):\n",
    "        continue\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Lab8 (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
