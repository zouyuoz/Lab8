{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dceedafe-2782-41a1-8119-50ee3d6c21fd",
   "metadata": {},
   "source": [
    "# 2025 DL Lab8: RL Assignment_Super Mario World"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fa555a-e61c-4fb3-b5d0-289b66570139",
   "metadata": {},
   "source": [
    "**Your Answer:**    \n",
    "Hi I'm XXX, XXXXXXXXXX."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5b0974-9605-488a-9fd5-00816e7832cc",
   "metadata": {},
   "source": [
    "## Overview\n",
    "This project implements a **Deep Reinforcement Learning** pipeline to train an autonomous agent for Super Mario World. Leveraging the **Proximal Policy Optimization (PPO)** algorithm, the system interacts with the **stable-retro** environment to master the YoshiIsland1 level. Key components include a custom Vision Backbone for extracting features from raw pixel data and a suite of Environment Wrappers that handle frame preprocessing, action discretization, and reward shaping to facilitate efficient learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02696447",
   "metadata": {},
   "source": [
    "Reward function implement  \n",
    "should do something in the beginning (monster attack)  \n",
    "Custom PPO implement  \n",
    "pre train weight 差不多，主要是 reward function  \n",
    "model weight capacity 1GB  \n",
    "class name 不要動 (可以新增，但是原本有的不要動)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8a0ab9-f86d-4038-833d-761ec81fc4f2",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00b10def-362c-4910-9ed0-f3d0904343ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/m314834001/Lab8/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import retro\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, SubprocVecEnv\n",
    "from stable_baselines3.common.vec_env import VecNormalize\n",
    "\n",
    "from eval import evaluate_policy, record_video\n",
    "from custom_policy import VisionBackbonePolicy, CustomPPO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10361fd-f291-4d93-b50d-cc749a3af588",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b4f6a25-738c-49dd-8e66-ae164b74a45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Game Settings\n",
    "GAME = \"SuperMarioWorld-Snes\"\n",
    "STATE = \"YoshiIsland1\"\n",
    "\n",
    "# Training Settings\n",
    "BASE_CHUNK  = 8192\n",
    "TRAIN_CHUNK = BASE_CHUNK * 32\n",
    "TOTAL_STEPS = TRAIN_CHUNK * 256\n",
    "N_ENVS = 16\n",
    "\n",
    "# Evaluation & Recording Settingsc\n",
    "EVAL_EPISODES = 3\n",
    "EVAL_MAX_STEPS = 18000\n",
    "RECORD_STEPS = 1200\n",
    "\n",
    "# Directories\n",
    "LOG_DIR = \"./runs_smw\"\n",
    "VIDEO_DIR       = os.path.join(LOG_DIR, \"videos\")\n",
    "CKPT_DIR        = os.path.join(LOG_DIR, \"checkpoints\")\n",
    "TENSORBOARD_LOG = os.path.join(LOG_DIR, \"tb\")\n",
    "\n",
    "os.makedirs(LOG_DIR,   exist_ok=True)\n",
    "os.makedirs(CKPT_DIR,  exist_ok=True)\n",
    "os.makedirs(VIDEO_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a34b783-0273-4835-ad2e-f9186064f76f",
   "metadata": {},
   "source": [
    "## Environment Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c34213d-2c7c-42b8-922d-bafa285d1ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wrappers import make_base_env\n",
    "def _make_env_thunk(game: str, state: str):\n",
    "    \"\"\"Return a function that creates an environment (for multiprocessing).\"\"\"\n",
    "    def _thunk():\n",
    "        return make_base_env(game, state)\n",
    "    return _thunk\n",
    "\n",
    "def make_vec_env(game: str, state: str, n_envs: int, use_subproc: bool = True):\n",
    "    \"\"\"Create a vectorized environment (multiple envs running in parallel).\"\"\"\n",
    "    env_fns = [_make_env_thunk(game, state) for _ in range(n_envs)]\n",
    "    \n",
    "    if use_subproc and n_envs > 1:\n",
    "        vec_env = SubprocVecEnv(env_fns)\n",
    "    else:\n",
    "        vec_env = DummyVecEnv(env_fns)\n",
    "\n",
    "    return vec_env"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71dff476-ea2e-4262-8780-afb32ef1b233",
   "metadata": {},
   "source": [
    "## Initialize Env & Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8c7c5fe-6421-4dbc-9bd8-822d61769c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment created: SuperMarioWorld-Snes - YoshiIsland1 with 16 parallel envs.\n",
      "[Sucess] Loaded model from runs_smw/checkpoints/NoArti_147.zip\n",
      "trained: 38797312, round_index: 148\n"
     ]
    }
   ],
   "source": [
    "# 1. Create Training Environment\n",
    "train_env = make_vec_env(GAME, STATE, n_envs=N_ENVS)\n",
    "# train_env = VecNormalize(train_env, norm_obs=True, norm_reward=True, clip_obs=10., clip_reward=10.)\n",
    "print(f\"Environment created: {GAME} - {STATE} with {N_ENVS} parallel envs.\")\n",
    "\n",
    "checkpoint_path = \"None\"\n",
    "checkpoint_path = \"runs_smw/checkpoints/NoArti_147.zip\"\n",
    "\n",
    "best_mean = -1e18\n",
    "trained = 0\n",
    "round_idx = 0\n",
    "\n",
    "# 2. Initialize Model\n",
    "if os.path.exists(checkpoint_path):\n",
    "    # 讀取現有模型\n",
    "    model = CustomPPO.load(\n",
    "        checkpoint_path, \n",
    "        env=train_env,\n",
    "        device=\"cuda:0\" # 確保使用 GPU\n",
    "    )\n",
    "    trained = model.num_timesteps\n",
    "    round_idx = int(trained / TRAIN_CHUNK)\n",
    "    print(f\"[Sucess] Loaded model from {checkpoint_path}\")\n",
    "    print(f\"trained: {trained}, round_index: {round_idx}\")\n",
    "else:\n",
    "    print(f\"[Fail] Can't load {checkpoint_path}. Will use new model\")\n",
    "    model = CustomPPO(\n",
    "        VisionBackbonePolicy,\n",
    "        train_env,\n",
    "        policy_kwargs   = dict(normalize_images=False),\n",
    "        n_epochs        = 4,\n",
    "        n_steps         = 512,\n",
    "        batch_size      = 512,\n",
    "        learning_rate   = 1e-4,\n",
    "        verbose         = 1,\n",
    "        gamma           = 0.9875,\n",
    "        gae_lambda      = 0.975,\n",
    "        kl_coef         = 1,\n",
    "        clip_range      = 0.125,\n",
    "        ent_coef        = 0.045,\n",
    "        tensorboard_log = TENSORBOARD_LOG,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f594e443-843f-42c1-9fc6-3fbc82962021",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3af4932-c531-4113-a33a-defc6fb5858e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Round 149 | Learn 262144 steps (Total trained: 38797312) ===\n",
      "Logging to ./runs_smw/tb/NoArti_0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/m314834001/Lab8/.venv/lib/python3.12/site-packages/rich/live.py:256: UserWarning: install \"ipywidgets\" for \n",
       "Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/m314834001/Lab8/.venv/lib/python3.12/site-packages/rich/live.py:256: UserWarning: install \"ipywidgets\" for \n",
       "Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1075     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 38805504 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 893         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 38813696    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029153772 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.794       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0381      |\n",
      "|    mean_step_reward   | 0.058806583 |\n",
      "|    n_updates          | 4/128       |\n",
      "|    policyGradLoss     | -0.0139     |\n",
      "|    value_loss         | 0.408       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 906         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 27          |\n",
      "|    total_timesteps    | 38821888    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023640417 |\n",
      "|    entropy_loss       | -1.97       |\n",
      "|    explained_variance | 0.908       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00695    |\n",
      "|    mean_step_reward   | 0.08689609  |\n",
      "|    n_updates          | 8/128       |\n",
      "|    policyGradLoss     | -0.00744    |\n",
      "|    value_loss         | 0.592       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 900         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 36          |\n",
      "|    total_timesteps    | 38830080    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016878165 |\n",
      "|    entropy_loss       | -2.01       |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0617      |\n",
      "|    mean_step_reward   | 0.08244425  |\n",
      "|    n_updates          | 12/128      |\n",
      "|    policyGradLoss     | -0.0163     |\n",
      "|    value_loss         | 0.36        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 894         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 45          |\n",
      "|    total_timesteps    | 38838272    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021228686 |\n",
      "|    entropy_loss       | -1.98       |\n",
      "|    explained_variance | 0.938       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0411     |\n",
      "|    mean_step_reward   | 0.09261368  |\n",
      "|    n_updates          | 16/128      |\n",
      "|    policyGradLoss     | -0.0165     |\n",
      "|    value_loss         | 0.313       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 865         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 56          |\n",
      "|    total_timesteps    | 38846464    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022169271 |\n",
      "|    entropy_loss       | -1.97       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0791      |\n",
      "|    mean_step_reward   | 0.07855198  |\n",
      "|    n_updates          | 20/128      |\n",
      "|    policyGradLoss     | -0.0181     |\n",
      "|    value_loss         | 0.365       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 843         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 68          |\n",
      "|    total_timesteps    | 38854656    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025095314 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0111     |\n",
      "|    mean_step_reward   | 0.09491089  |\n",
      "|    n_updates          | 24/128      |\n",
      "|    policyGradLoss     | -0.0174     |\n",
      "|    value_loss         | 0.305       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 822         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 79          |\n",
      "|    total_timesteps    | 38862848    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02356498  |\n",
      "|    entropy_loss       | -2          |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0785      |\n",
      "|    mean_step_reward   | 0.086980656 |\n",
      "|    n_updates          | 28/128      |\n",
      "|    policyGradLoss     | -0.0182     |\n",
      "|    value_loss         | 0.296       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 810         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 90          |\n",
      "|    total_timesteps    | 38871040    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027807679 |\n",
      "|    entropy_loss       | -1.98       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0775     |\n",
      "|    mean_step_reward   | 0.079324275 |\n",
      "|    n_updates          | 32/128      |\n",
      "|    policyGradLoss     | -0.0223     |\n",
      "|    value_loss         | 0.194       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 803         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 101         |\n",
      "|    total_timesteps    | 38879232    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019613631 |\n",
      "|    entropy_loss       | -2.02       |\n",
      "|    explained_variance | 0.935       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0145     |\n",
      "|    mean_step_reward   | 0.072215095 |\n",
      "|    n_updates          | 36/128      |\n",
      "|    policyGradLoss     | -0.0167     |\n",
      "|    value_loss         | 0.39        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 797         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 113         |\n",
      "|    total_timesteps    | 38887424    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024556078 |\n",
      "|    entropy_loss       | -1.99       |\n",
      "|    explained_variance | 0.946       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0163     |\n",
      "|    mean_step_reward   | 0.085833676 |\n",
      "|    n_updates          | 40/128      |\n",
      "|    policyGradLoss     | -0.0132     |\n",
      "|    value_loss         | 0.483       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 790         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 124         |\n",
      "|    total_timesteps    | 38895616    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017546978 |\n",
      "|    entropy_loss       | -2.01       |\n",
      "|    explained_variance | 0.94        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0634     |\n",
      "|    mean_step_reward   | 0.06964205  |\n",
      "|    n_updates          | 44/128      |\n",
      "|    policyGradLoss     | -0.014      |\n",
      "|    value_loss         | 0.331       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 135         |\n",
      "|    total_timesteps    | 38903808    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020392254 |\n",
      "|    entropy_loss       | -2.02       |\n",
      "|    explained_variance | 0.875       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0343      |\n",
      "|    mean_step_reward   | 0.06494355  |\n",
      "|    n_updates          | 48/128      |\n",
      "|    policyGradLoss     | -0.0112     |\n",
      "|    value_loss         | 0.696       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 147         |\n",
      "|    total_timesteps    | 38912000    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017847665 |\n",
      "|    entropy_loss       | -2.01       |\n",
      "|    explained_variance | 0.947       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0138     |\n",
      "|    mean_step_reward   | 0.0832481   |\n",
      "|    n_updates          | 52/128      |\n",
      "|    policyGradLoss     | -0.0153     |\n",
      "|    value_loss         | 0.327       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 158         |\n",
      "|    total_timesteps    | 38920192    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025746282 |\n",
      "|    entropy_loss       | -2.01       |\n",
      "|    explained_variance | 0.911       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.18        |\n",
      "|    mean_step_reward   | 0.06169562  |\n",
      "|    n_updates          | 56/128      |\n",
      "|    policyGradLoss     | -0.0143     |\n",
      "|    value_loss         | 0.597       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 169         |\n",
      "|    total_timesteps    | 38928384    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027061738 |\n",
      "|    entropy_loss       | -2          |\n",
      "|    explained_variance | 0.951       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0533     |\n",
      "|    mean_step_reward   | 0.071753144 |\n",
      "|    n_updates          | 60/128      |\n",
      "|    policyGradLoss     | -0.022      |\n",
      "|    value_loss         | 0.214       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 180         |\n",
      "|    total_timesteps    | 38936576    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017151125 |\n",
      "|    entropy_loss       | -1.99       |\n",
      "|    explained_variance | 0.944       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0334      |\n",
      "|    mean_step_reward   | 0.09643071  |\n",
      "|    n_updates          | 64/128      |\n",
      "|    policyGradLoss     | -0.0129     |\n",
      "|    value_loss         | 0.567       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 191         |\n",
      "|    total_timesteps    | 38944768    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02325009  |\n",
      "|    entropy_loss       | -2.04       |\n",
      "|    explained_variance | 0.911       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00985     |\n",
      "|    mean_step_reward   | 0.055636004 |\n",
      "|    n_updates          | 68/128      |\n",
      "|    policyGradLoss     | -0.0173     |\n",
      "|    value_loss         | 0.496       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 764        |\n",
      "|    iterations         | 19         |\n",
      "|    time_elapsed       | 203        |\n",
      "|    total_timesteps    | 38952960   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02031552 |\n",
      "|    entropy_loss       | -2.08      |\n",
      "|    explained_variance | 0.964      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0712    |\n",
      "|    mean_step_reward   | 0.07487107 |\n",
      "|    n_updates          | 72/128     |\n",
      "|    policyGradLoss     | -0.0211    |\n",
      "|    value_loss         | 0.207      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 762         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 214         |\n",
      "|    total_timesteps    | 38961152    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023277333 |\n",
      "|    entropy_loss       | -2.09       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0808     |\n",
      "|    mean_step_reward   | 0.05964955  |\n",
      "|    n_updates          | 76/128      |\n",
      "|    policyGradLoss     | -0.0154     |\n",
      "|    value_loss         | 0.225       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 761         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 225         |\n",
      "|    total_timesteps    | 38969344    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01892436  |\n",
      "|    entropy_loss       | -2.12       |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0809     |\n",
      "|    mean_step_reward   | 0.054866366 |\n",
      "|    n_updates          | 80/128      |\n",
      "|    policyGradLoss     | -0.0183     |\n",
      "|    value_loss         | 0.248       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 761         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 236         |\n",
      "|    total_timesteps    | 38977536    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018095637 |\n",
      "|    entropy_loss       | -2.14       |\n",
      "|    explained_variance | 0.913       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0313      |\n",
      "|    mean_step_reward   | 0.036930002 |\n",
      "|    n_updates          | 84/128      |\n",
      "|    policyGradLoss     | -0.0152     |\n",
      "|    value_loss         | 0.443       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 759         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 247         |\n",
      "|    total_timesteps    | 38985728    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015863344 |\n",
      "|    entropy_loss       | -2.08       |\n",
      "|    explained_variance | 0.883       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0491     |\n",
      "|    mean_step_reward   | 0.051134687 |\n",
      "|    n_updates          | 88/128      |\n",
      "|    policyGradLoss     | -0.0153     |\n",
      "|    value_loss         | 0.329       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 757         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 259         |\n",
      "|    total_timesteps    | 38993920    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022969985 |\n",
      "|    entropy_loss       | -2.08       |\n",
      "|    explained_variance | 0.952       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0205     |\n",
      "|    mean_step_reward   | 0.0635043   |\n",
      "|    n_updates          | 92/128      |\n",
      "|    policyGradLoss     | -0.0184     |\n",
      "|    value_loss         | 0.315       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 755         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 271         |\n",
      "|    total_timesteps    | 39002112    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019299172 |\n",
      "|    entropy_loss       | -2.12       |\n",
      "|    explained_variance | 0.893       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0268     |\n",
      "|    mean_step_reward   | 0.04153435  |\n",
      "|    n_updates          | 96/128      |\n",
      "|    policyGradLoss     | -0.0184     |\n",
      "|    value_loss         | 0.321       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 754         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 282         |\n",
      "|    total_timesteps    | 39010304    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030487837 |\n",
      "|    entropy_loss       | -2.12       |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.101      |\n",
      "|    mean_step_reward   | 0.056600735 |\n",
      "|    n_updates          | 100/128     |\n",
      "|    policyGradLoss     | -0.0233     |\n",
      "|    value_loss         | 0.182       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 755         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 292         |\n",
      "|    total_timesteps    | 39018496    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01741578  |\n",
      "|    entropy_loss       | -2.09       |\n",
      "|    explained_variance | 0.901       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0194      |\n",
      "|    mean_step_reward   | 0.043612566 |\n",
      "|    n_updates          | 104/128     |\n",
      "|    policyGradLoss     | -0.0125     |\n",
      "|    value_loss         | 0.557       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 754         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 304         |\n",
      "|    total_timesteps    | 39026688    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018998064 |\n",
      "|    entropy_loss       | -2.04       |\n",
      "|    explained_variance | 0.872       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.031      |\n",
      "|    mean_step_reward   | 0.06032943  |\n",
      "|    n_updates          | 108/128     |\n",
      "|    policyGradLoss     | -0.0129     |\n",
      "|    value_loss         | 0.464       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 752         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 315         |\n",
      "|    total_timesteps    | 39034880    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020271584 |\n",
      "|    entropy_loss       | -2.01       |\n",
      "|    explained_variance | 0.929       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0124     |\n",
      "|    mean_step_reward   | 0.066911474 |\n",
      "|    n_updates          | 112/128     |\n",
      "|    policyGradLoss     | -0.0164     |\n",
      "|    value_loss         | 0.464       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 751         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 327         |\n",
      "|    total_timesteps    | 39043072    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024041817 |\n",
      "|    entropy_loss       | -2.03       |\n",
      "|    explained_variance | 0.902       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0623      |\n",
      "|    mean_step_reward   | 0.050261468 |\n",
      "|    n_updates          | 116/128     |\n",
      "|    policyGradLoss     | -0.0165     |\n",
      "|    value_loss         | 0.487       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 750         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 338         |\n",
      "|    total_timesteps    | 39051264    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021343857 |\n",
      "|    entropy_loss       | -2.07       |\n",
      "|    explained_variance | 0.923       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0453     |\n",
      "|    mean_step_reward   | 0.051085338 |\n",
      "|    n_updates          | 120/128     |\n",
      "|    policyGradLoss     | -0.0181     |\n",
      "|    value_loss         | 0.319       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 750         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 349         |\n",
      "|    total_timesteps    | 39059456    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018040817 |\n",
      "|    entropy_loss       | -2.07       |\n",
      "|    explained_variance | 0.858       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0147      |\n",
      "|    mean_step_reward   | 0.05746822  |\n",
      "|    n_updates          | 124/128     |\n",
      "|    policyGradLoss     | -0.0144     |\n",
      "|    value_loss         | 0.745       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/NoArti_148.zip\n",
      "[EVAL] Mean Return: 132.989, Best Return: 135.589\n",
      "Saved video to ./runs_smw/videos/NoArti/NoArti_148_132.99.mp4\n",
      "\n",
      "=== Round 150 | Learn 262144 steps (Total trained: 39059456) ===\n",
      "Logging to ./runs_smw/tb/NoArti_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1439     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 39067648 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 1090        |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 15          |\n",
      "|    total_timesteps    | 39075840    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021987619 |\n",
      "|    entropy_loss       | -2.05       |\n",
      "|    explained_variance | 0.941       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.123       |\n",
      "|    mean_step_reward   | 0.05698403  |\n",
      "|    n_updates          | 4/128       |\n",
      "|    policyGradLoss     | -0.0207     |\n",
      "|    value_loss         | 0.422       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 970         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 25          |\n",
      "|    total_timesteps    | 39084032    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020649191 |\n",
      "|    entropy_loss       | -2.05       |\n",
      "|    explained_variance | 0.94        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0475     |\n",
      "|    mean_step_reward   | 0.06448726  |\n",
      "|    n_updates          | 8/128       |\n",
      "|    policyGradLoss     | -0.0178     |\n",
      "|    value_loss         | 0.31        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 886         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 36          |\n",
      "|    total_timesteps    | 39092224    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018555118 |\n",
      "|    entropy_loss       | -2.08       |\n",
      "|    explained_variance | 0.92        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00392    |\n",
      "|    mean_step_reward   | 0.060484625 |\n",
      "|    n_updates          | 12/128      |\n",
      "|    policyGradLoss     | -0.0171     |\n",
      "|    value_loss         | 0.509       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 847         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 48          |\n",
      "|    total_timesteps    | 39100416    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.0216765   |\n",
      "|    entropy_loss       | -2.08       |\n",
      "|    explained_variance | 0.903       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0295     |\n",
      "|    mean_step_reward   | 0.045503475 |\n",
      "|    n_updates          | 16/128      |\n",
      "|    policyGradLoss     | -0.0194     |\n",
      "|    value_loss         | 0.306       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 830         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 59          |\n",
      "|    total_timesteps    | 39108608    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021989666 |\n",
      "|    entropy_loss       | -2.13       |\n",
      "|    explained_variance | 0.93        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0854     |\n",
      "|    mean_step_reward   | 0.04970881  |\n",
      "|    n_updates          | 20/128      |\n",
      "|    policyGradLoss     | -0.0215     |\n",
      "|    value_loss         | 0.227       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 817         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 70          |\n",
      "|    total_timesteps    | 39116800    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018679393 |\n",
      "|    entropy_loss       | -2.16       |\n",
      "|    explained_variance | 0.944       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.053      |\n",
      "|    mean_step_reward   | 0.04970111  |\n",
      "|    n_updates          | 24/128      |\n",
      "|    policyGradLoss     | -0.0189     |\n",
      "|    value_loss         | 0.259       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 803         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 81          |\n",
      "|    total_timesteps    | 39124992    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017384961 |\n",
      "|    entropy_loss       | -2.15       |\n",
      "|    explained_variance | 0.958       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0593     |\n",
      "|    mean_step_reward   | 0.05159045  |\n",
      "|    n_updates          | 28/128      |\n",
      "|    policyGradLoss     | -0.0165     |\n",
      "|    value_loss         | 0.203       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 789         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 93          |\n",
      "|    total_timesteps    | 39133184    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026788717 |\n",
      "|    entropy_loss       | -2.13       |\n",
      "|    explained_variance | 0.934       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0913     |\n",
      "|    mean_step_reward   | 0.05406771  |\n",
      "|    n_updates          | 32/128      |\n",
      "|    policyGradLoss     | -0.0188     |\n",
      "|    value_loss         | 0.228       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 104         |\n",
      "|    total_timesteps    | 39141376    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020237733 |\n",
      "|    entropy_loss       | -2.14       |\n",
      "|    explained_variance | 0.942       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.000925   |\n",
      "|    mean_step_reward   | 0.043265454 |\n",
      "|    n_updates          | 36/128      |\n",
      "|    policyGradLoss     | -0.0183     |\n",
      "|    value_loss         | 0.208       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 116         |\n",
      "|    total_timesteps    | 39149568    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021046428 |\n",
      "|    entropy_loss       | -2.12       |\n",
      "|    explained_variance | 0.916       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0641     |\n",
      "|    mean_step_reward   | 0.054050926 |\n",
      "|    n_updates          | 40/128      |\n",
      "|    policyGradLoss     | -0.0195     |\n",
      "|    value_loss         | 0.344       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 127         |\n",
      "|    total_timesteps    | 39157760    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026686838 |\n",
      "|    entropy_loss       | -2.18       |\n",
      "|    explained_variance | 0.925       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0802     |\n",
      "|    mean_step_reward   | 0.038998324 |\n",
      "|    n_updates          | 44/128      |\n",
      "|    policyGradLoss     | -0.0219     |\n",
      "|    value_loss         | 0.162       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 138         |\n",
      "|    total_timesteps    | 39165952    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015984626 |\n",
      "|    entropy_loss       | -2.15       |\n",
      "|    explained_variance | 0.919       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0566      |\n",
      "|    mean_step_reward   | 0.050379653 |\n",
      "|    n_updates          | 48/128      |\n",
      "|    policyGradLoss     | -0.0161     |\n",
      "|    value_loss         | 0.448       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 764         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 150         |\n",
      "|    total_timesteps    | 39174144    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017807424 |\n",
      "|    entropy_loss       | -2.11       |\n",
      "|    explained_variance | 0.876       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0514     |\n",
      "|    mean_step_reward   | 0.049199387 |\n",
      "|    n_updates          | 52/128      |\n",
      "|    policyGradLoss     | -0.0163     |\n",
      "|    value_loss         | 0.351       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 759         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 161         |\n",
      "|    total_timesteps    | 39182336    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017975155 |\n",
      "|    entropy_loss       | -2.1        |\n",
      "|    explained_variance | 0.931       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00426     |\n",
      "|    mean_step_reward   | 0.05427808  |\n",
      "|    n_updates          | 56/128      |\n",
      "|    policyGradLoss     | -0.0122     |\n",
      "|    value_loss         | 0.379       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 757         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 173         |\n",
      "|    total_timesteps    | 39190528    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020090336 |\n",
      "|    entropy_loss       | -2.12       |\n",
      "|    explained_variance | 0.776       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0362      |\n",
      "|    mean_step_reward   | 0.039680682 |\n",
      "|    n_updates          | 60/128      |\n",
      "|    policyGradLoss     | -0.0133     |\n",
      "|    value_loss         | 0.777       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 757         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 183         |\n",
      "|    total_timesteps    | 39198720    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021856219 |\n",
      "|    entropy_loss       | -2.14       |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0778     |\n",
      "|    mean_step_reward   | 0.055173296 |\n",
      "|    n_updates          | 64/128      |\n",
      "|    policyGradLoss     | -0.0201     |\n",
      "|    value_loss         | 0.196       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 756         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 195         |\n",
      "|    total_timesteps    | 39206912    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024775386 |\n",
      "|    entropy_loss       | -2.1        |\n",
      "|    explained_variance | 0.934       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.065      |\n",
      "|    mean_step_reward   | 0.0484401   |\n",
      "|    n_updates          | 68/128      |\n",
      "|    policyGradLoss     | -0.0229     |\n",
      "|    value_loss         | 0.203       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 754         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 206         |\n",
      "|    total_timesteps    | 39215104    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022888644 |\n",
      "|    entropy_loss       | -2.13       |\n",
      "|    explained_variance | 0.936       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0535      |\n",
      "|    mean_step_reward   | 0.05437989  |\n",
      "|    n_updates          | 72/128      |\n",
      "|    policyGradLoss     | -0.0149     |\n",
      "|    value_loss         | 0.416       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 751         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 218         |\n",
      "|    total_timesteps    | 39223296    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023708861 |\n",
      "|    entropy_loss       | -2.14       |\n",
      "|    explained_variance | 0.931       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0824     |\n",
      "|    mean_step_reward   | 0.049055025 |\n",
      "|    n_updates          | 76/128      |\n",
      "|    policyGradLoss     | -0.0226     |\n",
      "|    value_loss         | 0.204       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 749        |\n",
      "|    iterations         | 21         |\n",
      "|    time_elapsed       | 229        |\n",
      "|    total_timesteps    | 39231488   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02159496 |\n",
      "|    entropy_loss       | -2.11      |\n",
      "|    explained_variance | 0.833      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.041     |\n",
      "|    mean_step_reward   | 0.03960263 |\n",
      "|    n_updates          | 80/128     |\n",
      "|    policyGradLoss     | -0.0113    |\n",
      "|    value_loss         | 0.613      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 748         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 240         |\n",
      "|    total_timesteps    | 39239680    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018579213 |\n",
      "|    entropy_loss       | -2.14       |\n",
      "|    explained_variance | 0.819       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0548     |\n",
      "|    mean_step_reward   | 0.04950782  |\n",
      "|    n_updates          | 84/128      |\n",
      "|    policyGradLoss     | -0.0105     |\n",
      "|    value_loss         | 0.491       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 747         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 252         |\n",
      "|    total_timesteps    | 39247872    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019669017 |\n",
      "|    entropy_loss       | -2.13       |\n",
      "|    explained_variance | 0.89        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0123     |\n",
      "|    mean_step_reward   | 0.06302521  |\n",
      "|    n_updates          | 88/128      |\n",
      "|    policyGradLoss     | -0.00788    |\n",
      "|    value_loss         | 0.351       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 746         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 263         |\n",
      "|    total_timesteps    | 39256064    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020585116 |\n",
      "|    entropy_loss       | -2.14       |\n",
      "|    explained_variance | 0.931       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0238     |\n",
      "|    mean_step_reward   | 0.047643583 |\n",
      "|    n_updates          | 92/128      |\n",
      "|    policyGradLoss     | -0.0167     |\n",
      "|    value_loss         | 0.335       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 745         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 274         |\n",
      "|    total_timesteps    | 39264256    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01980112  |\n",
      "|    entropy_loss       | -2.14       |\n",
      "|    explained_variance | 0.936       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0308     |\n",
      "|    mean_step_reward   | 0.051202822 |\n",
      "|    n_updates          | 96/128      |\n",
      "|    policyGradLoss     | -0.0189     |\n",
      "|    value_loss         | 0.32        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 743        |\n",
      "|    iterations         | 26         |\n",
      "|    time_elapsed       | 286        |\n",
      "|    total_timesteps    | 39272448   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02569111 |\n",
      "|    entropy_loss       | -2.08      |\n",
      "|    explained_variance | 0.945      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0144    |\n",
      "|    mean_step_reward   | 0.06246582 |\n",
      "|    n_updates          | 100/128    |\n",
      "|    policyGradLoss     | -0.0228    |\n",
      "|    value_loss         | 0.384      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 742         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 297         |\n",
      "|    total_timesteps    | 39280640    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020928282 |\n",
      "|    entropy_loss       | -2.13       |\n",
      "|    explained_variance | 0.918       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.043      |\n",
      "|    mean_step_reward   | 0.056613967 |\n",
      "|    n_updates          | 104/128     |\n",
      "|    policyGradLoss     | -0.0168     |\n",
      "|    value_loss         | 0.393       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 743         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 308         |\n",
      "|    total_timesteps    | 39288832    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021485621 |\n",
      "|    entropy_loss       | -2.14       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0469     |\n",
      "|    mean_step_reward   | 0.05364244  |\n",
      "|    n_updates          | 108/128     |\n",
      "|    policyGradLoss     | -0.0237     |\n",
      "|    value_loss         | 0.173       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 743         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 319         |\n",
      "|    total_timesteps    | 39297024    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022954099 |\n",
      "|    entropy_loss       | -2.14       |\n",
      "|    explained_variance | 0.922       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0671     |\n",
      "|    mean_step_reward   | 0.037830964 |\n",
      "|    n_updates          | 112/128     |\n",
      "|    policyGradLoss     | -0.0211     |\n",
      "|    value_loss         | 0.209       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 742         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 330         |\n",
      "|    total_timesteps    | 39305216    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021398388 |\n",
      "|    entropy_loss       | -2.11       |\n",
      "|    explained_variance | 0.948       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00647    |\n",
      "|    mean_step_reward   | 0.059740655 |\n",
      "|    n_updates          | 116/128     |\n",
      "|    policyGradLoss     | -0.0165     |\n",
      "|    value_loss         | 0.32        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 741         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 342         |\n",
      "|    total_timesteps    | 39313408    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01842135  |\n",
      "|    entropy_loss       | -2.14       |\n",
      "|    explained_variance | 0.814       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0354     |\n",
      "|    mean_step_reward   | 0.033535562 |\n",
      "|    n_updates          | 120/128     |\n",
      "|    policyGradLoss     | -0.0113     |\n",
      "|    value_loss         | 0.455       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 740         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 354         |\n",
      "|    total_timesteps    | 39321600    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019934118 |\n",
      "|    entropy_loss       | -2.1        |\n",
      "|    explained_variance | 0.914       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0736     |\n",
      "|    mean_step_reward   | 0.047156967 |\n",
      "|    n_updates          | 124/128     |\n",
      "|    policyGradLoss     | -0.0215     |\n",
      "|    value_loss         | 0.223       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/NoArti_149.zip\n",
      "[EVAL] Mean Return: 80.233, Best Return: 82.633\n",
      "Saved video to ./runs_smw/videos/NoArti/NoArti_149_80.23.mp4\n",
      "\n",
      "=== Round 151 | Learn 262144 steps (Total trained: 39321600) ===\n",
      "Logging to ./runs_smw/tb/NoArti_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1171     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 39329792 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 990         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 16          |\n",
      "|    total_timesteps    | 39337984    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020859681 |\n",
      "|    entropy_loss       | -2.12       |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0903     |\n",
      "|    mean_step_reward   | 0.0577131   |\n",
      "|    n_updates          | 4/128       |\n",
      "|    policyGradLoss     | -0.021      |\n",
      "|    value_loss         | 0.235       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 962         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 25          |\n",
      "|    total_timesteps    | 39346176    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020428859 |\n",
      "|    entropy_loss       | -2.07       |\n",
      "|    explained_variance | 0.94        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.013      |\n",
      "|    mean_step_reward   | 0.06154186  |\n",
      "|    n_updates          | 8/128       |\n",
      "|    policyGradLoss     | -0.0186     |\n",
      "|    value_loss         | 0.331       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 941         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 34          |\n",
      "|    total_timesteps    | 39354368    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022281706 |\n",
      "|    entropy_loss       | -2.09       |\n",
      "|    explained_variance | 0.945       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0131     |\n",
      "|    mean_step_reward   | 0.056472532 |\n",
      "|    n_updates          | 12/128      |\n",
      "|    policyGradLoss     | -0.0208     |\n",
      "|    value_loss         | 0.349       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 909         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 45          |\n",
      "|    total_timesteps    | 39362560    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.031970315 |\n",
      "|    entropy_loss       | -2.15       |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.066      |\n",
      "|    mean_step_reward   | 0.048630863 |\n",
      "|    n_updates          | 16/128      |\n",
      "|    policyGradLoss     | -0.0257     |\n",
      "|    value_loss         | 0.212       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 869         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 56          |\n",
      "|    total_timesteps    | 39370752    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018866021 |\n",
      "|    entropy_loss       | -2.09       |\n",
      "|    explained_variance | 0.865       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0457     |\n",
      "|    mean_step_reward   | 0.044405565 |\n",
      "|    n_updates          | 20/128      |\n",
      "|    policyGradLoss     | -0.00602    |\n",
      "|    value_loss         | 0.456       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 847         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 67          |\n",
      "|    total_timesteps    | 39378944    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02477346  |\n",
      "|    entropy_loss       | -2.05       |\n",
      "|    explained_variance | 0.954       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.063      |\n",
      "|    mean_step_reward   | 0.074633926 |\n",
      "|    n_updates          | 24/128      |\n",
      "|    policyGradLoss     | -0.0152     |\n",
      "|    value_loss         | 0.284       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 831         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 78          |\n",
      "|    total_timesteps    | 39387136    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023018837 |\n",
      "|    entropy_loss       | -2.11       |\n",
      "|    explained_variance | 0.957       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0842     |\n",
      "|    mean_step_reward   | 0.04677265  |\n",
      "|    n_updates          | 28/128      |\n",
      "|    policyGradLoss     | -0.0217     |\n",
      "|    value_loss         | 0.195       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 818         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 90          |\n",
      "|    total_timesteps    | 39395328    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024796726 |\n",
      "|    entropy_loss       | -2.11       |\n",
      "|    explained_variance | 0.934       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0767     |\n",
      "|    mean_step_reward   | 0.04139696  |\n",
      "|    n_updates          | 32/128      |\n",
      "|    policyGradLoss     | -0.0215     |\n",
      "|    value_loss         | 0.233       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 805         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 101         |\n",
      "|    total_timesteps    | 39403520    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026179165 |\n",
      "|    entropy_loss       | -2.06       |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0589     |\n",
      "|    mean_step_reward   | 0.06430832  |\n",
      "|    n_updates          | 36/128      |\n",
      "|    policyGradLoss     | -0.0204     |\n",
      "|    value_loss         | 0.269       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 796         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 113         |\n",
      "|    total_timesteps    | 39411712    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023282731 |\n",
      "|    entropy_loss       | -2.13       |\n",
      "|    explained_variance | 0.897       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0296     |\n",
      "|    mean_step_reward   | 0.030918296 |\n",
      "|    n_updates          | 40/128      |\n",
      "|    policyGradLoss     | -0.0144     |\n",
      "|    value_loss         | 0.402       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 790         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 124         |\n",
      "|    total_timesteps    | 39419904    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021805447 |\n",
      "|    entropy_loss       | -2.11       |\n",
      "|    explained_variance | 0.941       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0631     |\n",
      "|    mean_step_reward   | 0.049749672 |\n",
      "|    n_updates          | 44/128      |\n",
      "|    policyGradLoss     | -0.019      |\n",
      "|    value_loss         | 0.281       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 135         |\n",
      "|    total_timesteps    | 39428096    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028954651 |\n",
      "|    entropy_loss       | -2.15       |\n",
      "|    explained_variance | 0.95        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.069      |\n",
      "|    mean_step_reward   | 0.042826224 |\n",
      "|    n_updates          | 48/128      |\n",
      "|    policyGradLoss     | -0.0209     |\n",
      "|    value_loss         | 0.206       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 146         |\n",
      "|    total_timesteps    | 39436288    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02195213  |\n",
      "|    entropy_loss       | -2.15       |\n",
      "|    explained_variance | 0.905       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0497     |\n",
      "|    mean_step_reward   | 0.039515823 |\n",
      "|    n_updates          | 52/128      |\n",
      "|    policyGradLoss     | -0.0161     |\n",
      "|    value_loss         | 0.349       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 157         |\n",
      "|    total_timesteps    | 39444480    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022688577 |\n",
      "|    entropy_loss       | -2.05       |\n",
      "|    explained_variance | 0.927       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0531     |\n",
      "|    mean_step_reward   | 0.048665397 |\n",
      "|    n_updates          | 56/128      |\n",
      "|    policyGradLoss     | -0.0201     |\n",
      "|    value_loss         | 0.301       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 169         |\n",
      "|    total_timesteps    | 39452672    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024908457 |\n",
      "|    entropy_loss       | -2.06       |\n",
      "|    explained_variance | 0.934       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0568     |\n",
      "|    mean_step_reward   | 0.06976162  |\n",
      "|    n_updates          | 60/128      |\n",
      "|    policyGradLoss     | -0.0149     |\n",
      "|    value_loss         | 0.296       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 181         |\n",
      "|    total_timesteps    | 39460864    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024812471 |\n",
      "|    entropy_loss       | -2.11       |\n",
      "|    explained_variance | 0.939       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0867     |\n",
      "|    mean_step_reward   | 0.04659666  |\n",
      "|    n_updates          | 64/128      |\n",
      "|    policyGradLoss     | -0.0186     |\n",
      "|    value_loss         | 0.256       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 192         |\n",
      "|    total_timesteps    | 39469056    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02150265  |\n",
      "|    entropy_loss       | -2.09       |\n",
      "|    explained_variance | 0.928       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.047       |\n",
      "|    mean_step_reward   | 0.052411452 |\n",
      "|    n_updates          | 68/128      |\n",
      "|    policyGradLoss     | -0.0145     |\n",
      "|    value_loss         | 0.353       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 765         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 203         |\n",
      "|    total_timesteps    | 39477248    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027979396 |\n",
      "|    entropy_loss       | -2.09       |\n",
      "|    explained_variance | 0.951       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0166     |\n",
      "|    mean_step_reward   | 0.054527692 |\n",
      "|    n_updates          | 72/128      |\n",
      "|    policyGradLoss     | -0.0189     |\n",
      "|    value_loss         | 0.237       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 763         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 214         |\n",
      "|    total_timesteps    | 39485440    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017478706 |\n",
      "|    entropy_loss       | -2.12       |\n",
      "|    explained_variance | 0.932       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0144     |\n",
      "|    mean_step_reward   | 0.04291609  |\n",
      "|    n_updates          | 76/128      |\n",
      "|    policyGradLoss     | -0.0173     |\n",
      "|    value_loss         | 0.261       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 760         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 226         |\n",
      "|    total_timesteps    | 39493632    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022857532 |\n",
      "|    entropy_loss       | -2.06       |\n",
      "|    explained_variance | 0.928       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0798     |\n",
      "|    mean_step_reward   | 0.046889864 |\n",
      "|    n_updates          | 80/128      |\n",
      "|    policyGradLoss     | -0.0183     |\n",
      "|    value_loss         | 0.233       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 757         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 237         |\n",
      "|    total_timesteps    | 39501824    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023409288 |\n",
      "|    entropy_loss       | -2.1        |\n",
      "|    explained_variance | 0.954       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0402      |\n",
      "|    mean_step_reward   | 0.049472537 |\n",
      "|    n_updates          | 84/128      |\n",
      "|    policyGradLoss     | -0.0184     |\n",
      "|    value_loss         | 0.279       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 756         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 248         |\n",
      "|    total_timesteps    | 39510016    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026920497 |\n",
      "|    entropy_loss       | -2.07       |\n",
      "|    explained_variance | 0.935       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0549     |\n",
      "|    mean_step_reward   | 0.049344145 |\n",
      "|    n_updates          | 88/128      |\n",
      "|    policyGradLoss     | -0.0222     |\n",
      "|    value_loss         | 0.312       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 756         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 260         |\n",
      "|    total_timesteps    | 39518208    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019704396 |\n",
      "|    entropy_loss       | -2.05       |\n",
      "|    explained_variance | 0.899       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0493     |\n",
      "|    mean_step_reward   | 0.050572786 |\n",
      "|    n_updates          | 92/128      |\n",
      "|    policyGradLoss     | -0.00986    |\n",
      "|    value_loss         | 0.354       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 755         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 271         |\n",
      "|    total_timesteps    | 39526400    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024147265 |\n",
      "|    entropy_loss       | -2.09       |\n",
      "|    explained_variance | 0.934       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.011      |\n",
      "|    mean_step_reward   | 0.049239244 |\n",
      "|    n_updates          | 96/128      |\n",
      "|    policyGradLoss     | -0.0151     |\n",
      "|    value_loss         | 0.329       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 754         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 282         |\n",
      "|    total_timesteps    | 39534592    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023768868 |\n",
      "|    entropy_loss       | -2.07       |\n",
      "|    explained_variance | 0.939       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0397     |\n",
      "|    mean_step_reward   | 0.053771712 |\n",
      "|    n_updates          | 100/128     |\n",
      "|    policyGradLoss     | -0.0209     |\n",
      "|    value_loss         | 0.254       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 752         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 294         |\n",
      "|    total_timesteps    | 39542784    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016376654 |\n",
      "|    entropy_loss       | -2.08       |\n",
      "|    explained_variance | 0.933       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0405     |\n",
      "|    mean_step_reward   | 0.06365502  |\n",
      "|    n_updates          | 104/128     |\n",
      "|    policyGradLoss     | -0.0145     |\n",
      "|    value_loss         | 0.492       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 751        |\n",
      "|    iterations         | 28         |\n",
      "|    time_elapsed       | 305        |\n",
      "|    total_timesteps    | 39550976   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03187058 |\n",
      "|    entropy_loss       | -2.09      |\n",
      "|    explained_variance | 0.966      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0986    |\n",
      "|    mean_step_reward   | 0.05250649 |\n",
      "|    n_updates          | 108/128    |\n",
      "|    policyGradLoss     | -0.0263    |\n",
      "|    value_loss         | 0.157      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 750         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 316         |\n",
      "|    total_timesteps    | 39559168    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022432975 |\n",
      "|    entropy_loss       | -2.11       |\n",
      "|    explained_variance | 0.947       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0768     |\n",
      "|    mean_step_reward   | 0.045772064 |\n",
      "|    n_updates          | 112/128     |\n",
      "|    policyGradLoss     | -0.0195     |\n",
      "|    value_loss         | 0.256       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 749         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 327         |\n",
      "|    total_timesteps    | 39567360    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023404792 |\n",
      "|    entropy_loss       | -2.07       |\n",
      "|    explained_variance | 0.958       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0674     |\n",
      "|    mean_step_reward   | 0.064771086 |\n",
      "|    n_updates          | 116/128     |\n",
      "|    policyGradLoss     | -0.0208     |\n",
      "|    value_loss         | 0.225       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 749         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 338         |\n",
      "|    total_timesteps    | 39575552    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029397797 |\n",
      "|    entropy_loss       | -2.09       |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0221     |\n",
      "|    mean_step_reward   | 0.051549897 |\n",
      "|    n_updates          | 120/128     |\n",
      "|    policyGradLoss     | -0.0179     |\n",
      "|    value_loss         | 0.249       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 748         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 350         |\n",
      "|    total_timesteps    | 39583744    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025151517 |\n",
      "|    entropy_loss       | -2.13       |\n",
      "|    explained_variance | 0.943       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0686     |\n",
      "|    mean_step_reward   | 0.04227799  |\n",
      "|    n_updates          | 124/128     |\n",
      "|    policyGradLoss     | -0.0151     |\n",
      "|    value_loss         | 0.178       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/NoArti_150.zip\n",
      "[EVAL] Mean Return: 134.097, Best Return: 136.697\n",
      "Saved video to ./runs_smw/videos/NoArti/NoArti_150_134.10.mp4\n",
      "\n",
      "=== Round 152 | Learn 262144 steps (Total trained: 39583744) ===\n",
      "Logging to ./runs_smw/tb/NoArti_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1426     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 39591936 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 1071        |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 15          |\n",
      "|    total_timesteps    | 39600128    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.035528522 |\n",
      "|    entropy_loss       | -2.08       |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0847     |\n",
      "|    mean_step_reward   | 0.058756366 |\n",
      "|    n_updates          | 4/128       |\n",
      "|    policyGradLoss     | -0.0226     |\n",
      "|    value_loss         | 0.168       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 947         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 25          |\n",
      "|    total_timesteps    | 39608320    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024403254 |\n",
      "|    entropy_loss       | -2.08       |\n",
      "|    explained_variance | 0.906       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0894      |\n",
      "|    mean_step_reward   | 0.041160613 |\n",
      "|    n_updates          | 8/128       |\n",
      "|    policyGradLoss     | -0.015      |\n",
      "|    value_loss         | 0.563       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 884        |\n",
      "|    iterations         | 4          |\n",
      "|    time_elapsed       | 37         |\n",
      "|    total_timesteps    | 39616512   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02157589 |\n",
      "|    entropy_loss       | -2         |\n",
      "|    explained_variance | 0.878      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.0696     |\n",
      "|    mean_step_reward   | 0.06443673 |\n",
      "|    n_updates          | 12/128     |\n",
      "|    policyGradLoss     | -0.00736   |\n",
      "|    value_loss         | 0.812      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 849        |\n",
      "|    iterations         | 5          |\n",
      "|    time_elapsed       | 48         |\n",
      "|    total_timesteps    | 39624704   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02271815 |\n",
      "|    entropy_loss       | -2.01      |\n",
      "|    explained_variance | 0.927      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.0584     |\n",
      "|    mean_step_reward   | 0.07110214 |\n",
      "|    n_updates          | 16/128     |\n",
      "|    policyGradLoss     | -0.0134    |\n",
      "|    value_loss         | 0.46       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 819         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 59          |\n",
      "|    total_timesteps    | 39632896    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022061981 |\n",
      "|    entropy_loss       | -2.06       |\n",
      "|    explained_variance | 0.932       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0156      |\n",
      "|    mean_step_reward   | 0.056476973 |\n",
      "|    n_updates          | 20/128      |\n",
      "|    policyGradLoss     | -0.0174     |\n",
      "|    value_loss         | 0.367       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 803         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 71          |\n",
      "|    total_timesteps    | 39641088    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021603387 |\n",
      "|    entropy_loss       | -2.08       |\n",
      "|    explained_variance | 0.888       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.026      |\n",
      "|    mean_step_reward   | 0.051487625 |\n",
      "|    n_updates          | 24/128      |\n",
      "|    policyGradLoss     | -0.0176     |\n",
      "|    value_loss         | 0.374       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 793         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 82          |\n",
      "|    total_timesteps    | 39649280    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020680442 |\n",
      "|    entropy_loss       | -2.08       |\n",
      "|    explained_variance | 0.947       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.037       |\n",
      "|    mean_step_reward   | 0.07637198  |\n",
      "|    n_updates          | 28/128      |\n",
      "|    policyGradLoss     | -0.0168     |\n",
      "|    value_loss         | 0.342       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 93          |\n",
      "|    total_timesteps    | 39657472    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019605234 |\n",
      "|    entropy_loss       | -2.11       |\n",
      "|    explained_variance | 0.743       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0342      |\n",
      "|    mean_step_reward   | 0.03755717  |\n",
      "|    n_updates          | 32/128      |\n",
      "|    policyGradLoss     | -0.0039     |\n",
      "|    value_loss         | 0.654       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 104         |\n",
      "|    total_timesteps    | 39665664    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021933664 |\n",
      "|    entropy_loss       | -2.1        |\n",
      "|    explained_variance | 0.88        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00625     |\n",
      "|    mean_step_reward   | 0.06299175  |\n",
      "|    n_updates          | 36/128      |\n",
      "|    policyGradLoss     | -0.00614    |\n",
      "|    value_loss         | 0.512       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 116         |\n",
      "|    total_timesteps    | 39673856    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017289674 |\n",
      "|    entropy_loss       | -2.07       |\n",
      "|    explained_variance | 0.853       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0417     |\n",
      "|    mean_step_reward   | 0.05089203  |\n",
      "|    n_updates          | 40/128      |\n",
      "|    policyGradLoss     | -0.00952    |\n",
      "|    value_loss         | 0.549       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 127         |\n",
      "|    total_timesteps    | 39682048    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018799547 |\n",
      "|    entropy_loss       | -2.1        |\n",
      "|    explained_variance | 0.766       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00739    |\n",
      "|    mean_step_reward   | 0.044159565 |\n",
      "|    n_updates          | 44/128      |\n",
      "|    policyGradLoss     | -0.0109     |\n",
      "|    value_loss         | 0.647       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 765         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 139         |\n",
      "|    total_timesteps    | 39690240    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021368116 |\n",
      "|    entropy_loss       | -2.13       |\n",
      "|    explained_variance | 0.832       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.045      |\n",
      "|    mean_step_reward   | 0.04066332  |\n",
      "|    n_updates          | 48/128      |\n",
      "|    policyGradLoss     | -0.0144     |\n",
      "|    value_loss         | 0.456       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 762         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 150         |\n",
      "|    total_timesteps    | 39698432    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01794133  |\n",
      "|    entropy_loss       | -2.1        |\n",
      "|    explained_variance | 0.922       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.000806    |\n",
      "|    mean_step_reward   | 0.052972466 |\n",
      "|    n_updates          | 52/128      |\n",
      "|    policyGradLoss     | -0.0177     |\n",
      "|    value_loss         | 0.344       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 761         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 161         |\n",
      "|    total_timesteps    | 39706624    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022116188 |\n",
      "|    entropy_loss       | -2.07       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0233     |\n",
      "|    mean_step_reward   | 0.06676344  |\n",
      "|    n_updates          | 56/128      |\n",
      "|    policyGradLoss     | -0.0219     |\n",
      "|    value_loss         | 0.23        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 759         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 172         |\n",
      "|    total_timesteps    | 39714816    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022531204 |\n",
      "|    entropy_loss       | -2.06       |\n",
      "|    explained_variance | 0.949       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0428     |\n",
      "|    mean_step_reward   | 0.07566359  |\n",
      "|    n_updates          | 60/128      |\n",
      "|    policyGradLoss     | -0.018      |\n",
      "|    value_loss         | 0.286       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 755         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 184         |\n",
      "|    total_timesteps    | 39723008    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02207995  |\n",
      "|    entropy_loss       | -2.04       |\n",
      "|    explained_variance | 0.904       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0471     |\n",
      "|    mean_step_reward   | 0.058006015 |\n",
      "|    n_updates          | 64/128      |\n",
      "|    policyGradLoss     | -0.0179     |\n",
      "|    value_loss         | 0.397       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 752         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 195         |\n",
      "|    total_timesteps    | 39731200    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023581993 |\n",
      "|    entropy_loss       | -2.05       |\n",
      "|    explained_variance | 0.952       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.057      |\n",
      "|    mean_step_reward   | 0.06445124  |\n",
      "|    n_updates          | 68/128      |\n",
      "|    policyGradLoss     | -0.0181     |\n",
      "|    value_loss         | 0.349       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 751         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 207         |\n",
      "|    total_timesteps    | 39739392    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026868623 |\n",
      "|    entropy_loss       | -2.11       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0709     |\n",
      "|    mean_step_reward   | 0.06355713  |\n",
      "|    n_updates          | 72/128      |\n",
      "|    policyGradLoss     | -0.0241     |\n",
      "|    value_loss         | 0.166       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 751         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 218         |\n",
      "|    total_timesteps    | 39747584    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018704193 |\n",
      "|    entropy_loss       | -2.14       |\n",
      "|    explained_variance | 0.887       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0177     |\n",
      "|    mean_step_reward   | 0.050414078 |\n",
      "|    n_updates          | 76/128      |\n",
      "|    policyGradLoss     | -0.00897    |\n",
      "|    value_loss         | 0.54        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 750         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 229         |\n",
      "|    total_timesteps    | 39755776    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018913116 |\n",
      "|    entropy_loss       | -2.12       |\n",
      "|    explained_variance | 0.955       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0662      |\n",
      "|    mean_step_reward   | 0.06329655  |\n",
      "|    n_updates          | 80/128      |\n",
      "|    policyGradLoss     | -0.0133     |\n",
      "|    value_loss         | 0.338       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 748         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 240         |\n",
      "|    total_timesteps    | 39763968    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022384174 |\n",
      "|    entropy_loss       | -2.09       |\n",
      "|    explained_variance | 0.937       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0535     |\n",
      "|    mean_step_reward   | 0.055494457 |\n",
      "|    n_updates          | 84/128      |\n",
      "|    policyGradLoss     | -0.0217     |\n",
      "|    value_loss         | 0.289       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 746         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 252         |\n",
      "|    total_timesteps    | 39772160    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01989787  |\n",
      "|    entropy_loss       | -2.09       |\n",
      "|    explained_variance | 0.937       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0581     |\n",
      "|    mean_step_reward   | 0.054733273 |\n",
      "|    n_updates          | 88/128      |\n",
      "|    policyGradLoss     | -0.0221     |\n",
      "|    value_loss         | 0.249       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 745         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 263         |\n",
      "|    total_timesteps    | 39780352    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020702446 |\n",
      "|    entropy_loss       | -2.11       |\n",
      "|    explained_variance | 0.938       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0462     |\n",
      "|    mean_step_reward   | 0.059510633 |\n",
      "|    n_updates          | 92/128      |\n",
      "|    policyGradLoss     | -0.0207     |\n",
      "|    value_loss         | 0.327       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 745        |\n",
      "|    iterations         | 25         |\n",
      "|    time_elapsed       | 274        |\n",
      "|    total_timesteps    | 39788544   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02129075 |\n",
      "|    entropy_loss       | -2.07      |\n",
      "|    explained_variance | 0.949      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0705    |\n",
      "|    mean_step_reward   | 0.06359782 |\n",
      "|    n_updates          | 96/128     |\n",
      "|    policyGradLoss     | -0.0192    |\n",
      "|    value_loss         | 0.235      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 745         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 285         |\n",
      "|    total_timesteps    | 39796736    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020033568 |\n",
      "|    entropy_loss       | -2.14       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0881     |\n",
      "|    mean_step_reward   | 0.06345071  |\n",
      "|    n_updates          | 100/128     |\n",
      "|    policyGradLoss     | -0.0219     |\n",
      "|    value_loss         | 0.163       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 744         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 296         |\n",
      "|    total_timesteps    | 39804928    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019512061 |\n",
      "|    entropy_loss       | -2.09       |\n",
      "|    explained_variance | 0.933       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0404     |\n",
      "|    mean_step_reward   | 0.057391696 |\n",
      "|    n_updates          | 104/128     |\n",
      "|    policyGradLoss     | -0.017      |\n",
      "|    value_loss         | 0.458       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 743         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 308         |\n",
      "|    total_timesteps    | 39813120    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018922891 |\n",
      "|    entropy_loss       | -2.11       |\n",
      "|    explained_variance | 0.929       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0199     |\n",
      "|    mean_step_reward   | 0.053973753 |\n",
      "|    n_updates          | 108/128     |\n",
      "|    policyGradLoss     | -0.0168     |\n",
      "|    value_loss         | 0.327       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 741         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 320         |\n",
      "|    total_timesteps    | 39821312    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026259288 |\n",
      "|    entropy_loss       | -2.06       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0463     |\n",
      "|    mean_step_reward   | 0.0781334   |\n",
      "|    n_updates          | 112/128     |\n",
      "|    policyGradLoss     | -0.0208     |\n",
      "|    value_loss         | 0.253       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 741         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 331         |\n",
      "|    total_timesteps    | 39829504    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016889803 |\n",
      "|    entropy_loss       | -2.03       |\n",
      "|    explained_variance | 0.785       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.176       |\n",
      "|    mean_step_reward   | 0.044170506 |\n",
      "|    n_updates          | 116/128     |\n",
      "|    policyGradLoss     | -0.0108     |\n",
      "|    value_loss         | 0.789       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 741        |\n",
      "|    iterations         | 31         |\n",
      "|    time_elapsed       | 342        |\n",
      "|    total_timesteps    | 39837696   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01815347 |\n",
      "|    entropy_loss       | -2.03      |\n",
      "|    explained_variance | 0.928      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.021     |\n",
      "|    mean_step_reward   | 0.0763163  |\n",
      "|    n_updates          | 120/128    |\n",
      "|    policyGradLoss     | -0.0117    |\n",
      "|    value_loss         | 0.383      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 741         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 353         |\n",
      "|    total_timesteps    | 39845888    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023788579 |\n",
      "|    entropy_loss       | -2.08       |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0456     |\n",
      "|    mean_step_reward   | 0.06949188  |\n",
      "|    n_updates          | 124/128     |\n",
      "|    policyGradLoss     | -0.0191     |\n",
      "|    value_loss         | 0.252       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/NoArti_151.zip\n",
      "[EVAL] Mean Return: 133.625, Best Return: 136.225\n",
      "Saved video to ./runs_smw/videos/NoArti/NoArti_151_133.62.mp4\n",
      "\n",
      "=== Round 153 | Learn 262144 steps (Total trained: 39845888) ===\n",
      "Logging to ./runs_smw/tb/NoArti_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1446     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 39854080 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 983         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 16          |\n",
      "|    total_timesteps    | 39862272    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020713303 |\n",
      "|    entropy_loss       | -2.17       |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0822     |\n",
      "|    mean_step_reward   | 0.048036158 |\n",
      "|    n_updates          | 4/128       |\n",
      "|    policyGradLoss     | -0.0147     |\n",
      "|    value_loss         | 0.158       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 867         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 39870464    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019976698 |\n",
      "|    entropy_loss       | -2.11       |\n",
      "|    explained_variance | 0.954       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0555     |\n",
      "|    mean_step_reward   | 0.05514767  |\n",
      "|    n_updates          | 8/128       |\n",
      "|    policyGradLoss     | -0.0162     |\n",
      "|    value_loss         | 0.306       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 821         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 39878656    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020385984 |\n",
      "|    entropy_loss       | -2.1        |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.073      |\n",
      "|    mean_step_reward   | 0.06285556  |\n",
      "|    n_updates          | 12/128      |\n",
      "|    policyGradLoss     | -0.0199     |\n",
      "|    value_loss         | 0.15        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 801         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 51          |\n",
      "|    total_timesteps    | 39886848    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019064715 |\n",
      "|    entropy_loss       | -2.06       |\n",
      "|    explained_variance | 0.847       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0188     |\n",
      "|    mean_step_reward   | 0.046223994 |\n",
      "|    n_updates          | 16/128      |\n",
      "|    policyGradLoss     | -0.0108     |\n",
      "|    value_loss         | 0.549       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 62          |\n",
      "|    total_timesteps    | 39895040    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025849741 |\n",
      "|    entropy_loss       | -2.04       |\n",
      "|    explained_variance | 0.943       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0839      |\n",
      "|    mean_step_reward   | 0.07609277  |\n",
      "|    n_updates          | 20/128      |\n",
      "|    policyGradLoss     | -0.0179     |\n",
      "|    value_loss         | 0.382       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 73          |\n",
      "|    total_timesteps    | 39903232    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025531076 |\n",
      "|    entropy_loss       | -2.11       |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0513     |\n",
      "|    mean_step_reward   | 0.062097702 |\n",
      "|    n_updates          | 24/128      |\n",
      "|    policyGradLoss     | -0.0221     |\n",
      "|    value_loss         | 0.195       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 84          |\n",
      "|    total_timesteps    | 39911424    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021991886 |\n",
      "|    entropy_loss       | -2.13       |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0346     |\n",
      "|    mean_step_reward   | 0.04936461  |\n",
      "|    n_updates          | 28/128      |\n",
      "|    policyGradLoss     | -0.0185     |\n",
      "|    value_loss         | 0.287       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 763         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 96          |\n",
      "|    total_timesteps    | 39919616    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015188942 |\n",
      "|    entropy_loss       | -2.17       |\n",
      "|    explained_variance | 0.902       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0545     |\n",
      "|    mean_step_reward   | 0.04881252  |\n",
      "|    n_updates          | 32/128      |\n",
      "|    policyGradLoss     | -0.0113     |\n",
      "|    value_loss         | 0.309       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 758         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 107         |\n",
      "|    total_timesteps    | 39927808    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022159407 |\n",
      "|    entropy_loss       | -2.16       |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0955     |\n",
      "|    mean_step_reward   | 0.05846276  |\n",
      "|    n_updates          | 36/128      |\n",
      "|    policyGradLoss     | -0.0195     |\n",
      "|    value_loss         | 0.154       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 757         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 119         |\n",
      "|    total_timesteps    | 39936000    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018862477 |\n",
      "|    entropy_loss       | -2.14       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0315     |\n",
      "|    mean_step_reward   | 0.04874585  |\n",
      "|    n_updates          | 40/128      |\n",
      "|    policyGradLoss     | -0.0158     |\n",
      "|    value_loss         | 0.19        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 756         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 129         |\n",
      "|    total_timesteps    | 39944192    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016082471 |\n",
      "|    entropy_loss       | -2.14       |\n",
      "|    explained_variance | 0.921       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0608     |\n",
      "|    mean_step_reward   | 0.04395779  |\n",
      "|    n_updates          | 44/128      |\n",
      "|    policyGradLoss     | -0.0161     |\n",
      "|    value_loss         | 0.31        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 755        |\n",
      "|    iterations         | 13         |\n",
      "|    time_elapsed       | 141        |\n",
      "|    total_timesteps    | 39952384   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01872386 |\n",
      "|    entropy_loss       | -2.12      |\n",
      "|    explained_variance | 0.908      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.00295   |\n",
      "|    mean_step_reward   | 0.06676105 |\n",
      "|    n_updates          | 48/128     |\n",
      "|    policyGradLoss     | -0.0125    |\n",
      "|    value_loss         | 0.462      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 751         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 152         |\n",
      "|    total_timesteps    | 39960576    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019964933 |\n",
      "|    entropy_loss       | -2.09       |\n",
      "|    explained_variance | 0.935       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.033      |\n",
      "|    mean_step_reward   | 0.049719617 |\n",
      "|    n_updates          | 52/128      |\n",
      "|    policyGradLoss     | -0.0174     |\n",
      "|    value_loss         | 0.359       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 748         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 164         |\n",
      "|    total_timesteps    | 39968768    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020605108 |\n",
      "|    entropy_loss       | -2.07       |\n",
      "|    explained_variance | 0.958       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0606     |\n",
      "|    mean_step_reward   | 0.07980152  |\n",
      "|    n_updates          | 56/128      |\n",
      "|    policyGradLoss     | -0.0203     |\n",
      "|    value_loss         | 0.264       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 747         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 175         |\n",
      "|    total_timesteps    | 39976960    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015548436 |\n",
      "|    entropy_loss       | -2.18       |\n",
      "|    explained_variance | 0.776       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.042      |\n",
      "|    mean_step_reward   | 0.0356708   |\n",
      "|    n_updates          | 60/128      |\n",
      "|    policyGradLoss     | -0.00767    |\n",
      "|    value_loss         | 0.62        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 745         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 186         |\n",
      "|    total_timesteps    | 39985152    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023262877 |\n",
      "|    entropy_loss       | -2.16       |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0743     |\n",
      "|    mean_step_reward   | 0.050913993 |\n",
      "|    n_updates          | 64/128      |\n",
      "|    policyGradLoss     | -0.0215     |\n",
      "|    value_loss         | 0.171       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 745         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 197         |\n",
      "|    total_timesteps    | 39993344    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01666161  |\n",
      "|    entropy_loss       | -2.18       |\n",
      "|    explained_variance | 0.887       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0497     |\n",
      "|    mean_step_reward   | 0.050011747 |\n",
      "|    n_updates          | 68/128      |\n",
      "|    policyGradLoss     | -0.00753    |\n",
      "|    value_loss         | 0.294       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 744         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 209         |\n",
      "|    total_timesteps    | 40001536    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020617044 |\n",
      "|    entropy_loss       | -2.17       |\n",
      "|    explained_variance | 0.941       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0221      |\n",
      "|    mean_step_reward   | 0.04274196  |\n",
      "|    n_updates          | 72/128      |\n",
      "|    policyGradLoss     | -0.0165     |\n",
      "|    value_loss         | 0.256       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 742         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 220         |\n",
      "|    total_timesteps    | 40009728    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018177653 |\n",
      "|    entropy_loss       | -2.19       |\n",
      "|    explained_variance | 0.878       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0223      |\n",
      "|    mean_step_reward   | 0.038492687 |\n",
      "|    n_updates          | 76/128      |\n",
      "|    policyGradLoss     | -0.0154     |\n",
      "|    value_loss         | 0.445       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 740         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 232         |\n",
      "|    total_timesteps    | 40017920    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018945806 |\n",
      "|    entropy_loss       | -2.18       |\n",
      "|    explained_variance | 0.88        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.06       |\n",
      "|    mean_step_reward   | 0.033250056 |\n",
      "|    n_updates          | 80/128      |\n",
      "|    policyGradLoss     | -0.016      |\n",
      "|    value_loss         | 0.263       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 740         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 243         |\n",
      "|    total_timesteps    | 40026112    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019205548 |\n",
      "|    entropy_loss       | -2.12       |\n",
      "|    explained_variance | 0.901       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0399     |\n",
      "|    mean_step_reward   | 0.057863235 |\n",
      "|    n_updates          | 84/128      |\n",
      "|    policyGradLoss     | -0.0146     |\n",
      "|    value_loss         | 0.422       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 740         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 254         |\n",
      "|    total_timesteps    | 40034304    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024771102 |\n",
      "|    entropy_loss       | -2.1        |\n",
      "|    explained_variance | 0.927       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0527     |\n",
      "|    mean_step_reward   | 0.066475675 |\n",
      "|    n_updates          | 88/128      |\n",
      "|    policyGradLoss     | -0.0149     |\n",
      "|    value_loss         | 0.331       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 740         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 265         |\n",
      "|    total_timesteps    | 40042496    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010889039 |\n",
      "|    entropy_loss       | -2.12       |\n",
      "|    explained_variance | 0.89        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0503      |\n",
      "|    mean_step_reward   | 0.048608188 |\n",
      "|    n_updates          | 92/128      |\n",
      "|    policyGradLoss     | -0.0104     |\n",
      "|    value_loss         | 0.463       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 738         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 277         |\n",
      "|    total_timesteps    | 40050688    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019413076 |\n",
      "|    entropy_loss       | -2.1        |\n",
      "|    explained_variance | 0.927       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0228     |\n",
      "|    mean_step_reward   | 0.05203125  |\n",
      "|    n_updates          | 96/128      |\n",
      "|    policyGradLoss     | -0.0161     |\n",
      "|    value_loss         | 0.381       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 737         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 288         |\n",
      "|    total_timesteps    | 40058880    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026315384 |\n",
      "|    entropy_loss       | -2.12       |\n",
      "|    explained_variance | 0.95        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0825     |\n",
      "|    mean_step_reward   | 0.051005162 |\n",
      "|    n_updates          | 100/128     |\n",
      "|    policyGradLoss     | -0.0257     |\n",
      "|    value_loss         | 0.191       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 737         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 300         |\n",
      "|    total_timesteps    | 40067072    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02204155  |\n",
      "|    entropy_loss       | -2.1        |\n",
      "|    explained_variance | 0.943       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0314     |\n",
      "|    mean_step_reward   | 0.062829554 |\n",
      "|    n_updates          | 104/128     |\n",
      "|    policyGradLoss     | -0.0155     |\n",
      "|    value_loss         | 0.341       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 737         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 311         |\n",
      "|    total_timesteps    | 40075264    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024535209 |\n",
      "|    entropy_loss       | -2.08       |\n",
      "|    explained_variance | 0.937       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0185     |\n",
      "|    mean_step_reward   | 0.059758462 |\n",
      "|    n_updates          | 108/128     |\n",
      "|    policyGradLoss     | -0.0155     |\n",
      "|    value_loss         | 0.4         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 737         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 322         |\n",
      "|    total_timesteps    | 40083456    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016642572 |\n",
      "|    entropy_loss       | -2.09       |\n",
      "|    explained_variance | 0.896       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.000575    |\n",
      "|    mean_step_reward   | 0.05056163  |\n",
      "|    n_updates          | 112/128     |\n",
      "|    policyGradLoss     | -0.0136     |\n",
      "|    value_loss         | 0.443       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 736         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 333         |\n",
      "|    total_timesteps    | 40091648    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022426855 |\n",
      "|    entropy_loss       | -2.11       |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0526     |\n",
      "|    mean_step_reward   | 0.06801042  |\n",
      "|    n_updates          | 116/128     |\n",
      "|    policyGradLoss     | -0.0187     |\n",
      "|    value_loss         | 0.23        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 736         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 344         |\n",
      "|    total_timesteps    | 40099840    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019030206 |\n",
      "|    entropy_loss       | -2.08       |\n",
      "|    explained_variance | 0.92        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00425     |\n",
      "|    mean_step_reward   | 0.05468487  |\n",
      "|    n_updates          | 120/128     |\n",
      "|    policyGradLoss     | -0.0162     |\n",
      "|    value_loss         | 0.365       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 741         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 353         |\n",
      "|    total_timesteps    | 40108032    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020581774 |\n",
      "|    entropy_loss       | -2.04       |\n",
      "|    explained_variance | 0.939       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0584     |\n",
      "|    mean_step_reward   | 0.07549243  |\n",
      "|    n_updates          | 124/128     |\n",
      "|    policyGradLoss     | -0.011      |\n",
      "|    value_loss         | 0.394       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/NoArti_152.zip\n",
      "[EVAL] Mean Return: 125.645, Best Return: 128.245\n",
      "Saved video to ./runs_smw/videos/NoArti/NoArti_152_125.65.mp4\n",
      "\n",
      "=== Round 154 | Learn 262144 steps (Total trained: 40108032) ===\n",
      "Logging to ./runs_smw/tb/NoArti_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1092     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 40116224 |\n",
      "---------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 859        |\n",
      "|    iterations         | 2          |\n",
      "|    time_elapsed       | 19         |\n",
      "|    total_timesteps    | 40124416   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02325277 |\n",
      "|    entropy_loss       | -2.04      |\n",
      "|    explained_variance | 0.97       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0492    |\n",
      "|    mean_step_reward   | 0.07926178 |\n",
      "|    n_updates          | 4/128      |\n",
      "|    policyGradLoss     | -0.0215    |\n",
      "|    value_loss         | 0.216      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 813         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 30          |\n",
      "|    total_timesteps    | 40132608    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018683508 |\n",
      "|    entropy_loss       | -2.03       |\n",
      "|    explained_variance | 0.938       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0184      |\n",
      "|    mean_step_reward   | 0.06966823  |\n",
      "|    n_updates          | 8/128       |\n",
      "|    policyGradLoss     | -0.0134     |\n",
      "|    value_loss         | 0.512       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 798         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 41          |\n",
      "|    total_timesteps    | 40140800    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01874847  |\n",
      "|    entropy_loss       | -2.06       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0245      |\n",
      "|    mean_step_reward   | 0.067694604 |\n",
      "|    n_updates          | 12/128      |\n",
      "|    policyGradLoss     | -0.0188     |\n",
      "|    value_loss         | 0.256       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 52          |\n",
      "|    total_timesteps    | 40148992    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014405508 |\n",
      "|    entropy_loss       | -2.06       |\n",
      "|    explained_variance | 0.848       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0478      |\n",
      "|    mean_step_reward   | 0.068960615 |\n",
      "|    n_updates          | 16/128      |\n",
      "|    policyGradLoss     | -0.00923    |\n",
      "|    value_loss         | 0.76        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 63          |\n",
      "|    total_timesteps    | 40157184    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022398815 |\n",
      "|    entropy_loss       | -2.08       |\n",
      "|    explained_variance | 0.951       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0106     |\n",
      "|    mean_step_reward   | 0.062193345 |\n",
      "|    n_updates          | 20/128      |\n",
      "|    policyGradLoss     | -0.0176     |\n",
      "|    value_loss         | 0.335       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 765         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 74          |\n",
      "|    total_timesteps    | 40165376    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01926084  |\n",
      "|    entropy_loss       | -2.04       |\n",
      "|    explained_variance | 0.938       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0238      |\n",
      "|    mean_step_reward   | 0.069620386 |\n",
      "|    n_updates          | 24/128      |\n",
      "|    policyGradLoss     | -0.015      |\n",
      "|    value_loss         | 0.486       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 759         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 86          |\n",
      "|    total_timesteps    | 40173568    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022767695 |\n",
      "|    entropy_loss       | -2.05       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00952    |\n",
      "|    mean_step_reward   | 0.07618819  |\n",
      "|    n_updates          | 28/128      |\n",
      "|    policyGradLoss     | -0.0203     |\n",
      "|    value_loss         | 0.298       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 756         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 97          |\n",
      "|    total_timesteps    | 40181760    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030834882 |\n",
      "|    entropy_loss       | -2.05       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0607     |\n",
      "|    mean_step_reward   | 0.07356918  |\n",
      "|    n_updates          | 32/128      |\n",
      "|    policyGradLoss     | -0.0256     |\n",
      "|    value_loss         | 0.195       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 755         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 108         |\n",
      "|    total_timesteps    | 40189952    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014655044 |\n",
      "|    entropy_loss       | -2.07       |\n",
      "|    explained_variance | 0.872       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00279    |\n",
      "|    mean_step_reward   | 0.06532946  |\n",
      "|    n_updates          | 36/128      |\n",
      "|    policyGradLoss     | -0.0133     |\n",
      "|    value_loss         | 0.615       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 752         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 119         |\n",
      "|    total_timesteps    | 40198144    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020623244 |\n",
      "|    entropy_loss       | -2.09       |\n",
      "|    explained_variance | 0.936       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0566     |\n",
      "|    mean_step_reward   | 0.054433286 |\n",
      "|    n_updates          | 40/128      |\n",
      "|    policyGradLoss     | -0.0171     |\n",
      "|    value_loss         | 0.315       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 748         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 131         |\n",
      "|    total_timesteps    | 40206336    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024941921 |\n",
      "|    entropy_loss       | -2          |\n",
      "|    explained_variance | 0.922       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0443     |\n",
      "|    mean_step_reward   | 0.07174887  |\n",
      "|    n_updates          | 44/128      |\n",
      "|    policyGradLoss     | -0.0173     |\n",
      "|    value_loss         | 0.408       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 744         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 143         |\n",
      "|    total_timesteps    | 40214528    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020995542 |\n",
      "|    entropy_loss       | -2.04       |\n",
      "|    explained_variance | 0.937       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0116      |\n",
      "|    mean_step_reward   | 0.06047503  |\n",
      "|    n_updates          | 48/128      |\n",
      "|    policyGradLoss     | -0.0193     |\n",
      "|    value_loss         | 0.368       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 743         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 154         |\n",
      "|    total_timesteps    | 40222720    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023567306 |\n",
      "|    entropy_loss       | -2.05       |\n",
      "|    explained_variance | 0.939       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.049      |\n",
      "|    mean_step_reward   | 0.06039297  |\n",
      "|    n_updates          | 52/128      |\n",
      "|    policyGradLoss     | -0.0189     |\n",
      "|    value_loss         | 0.295       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 743         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 165         |\n",
      "|    total_timesteps    | 40230912    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027957374 |\n",
      "|    entropy_loss       | -2.05       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0749     |\n",
      "|    mean_step_reward   | 0.07637617  |\n",
      "|    n_updates          | 56/128      |\n",
      "|    policyGradLoss     | -0.0183     |\n",
      "|    value_loss         | 0.198       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 743         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 176         |\n",
      "|    total_timesteps    | 40239104    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023242313 |\n",
      "|    entropy_loss       | -2.09       |\n",
      "|    explained_variance | 0.958       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0589     |\n",
      "|    mean_step_reward   | 0.054126225 |\n",
      "|    n_updates          | 60/128      |\n",
      "|    policyGradLoss     | -0.0187     |\n",
      "|    value_loss         | 0.225       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 742         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 187         |\n",
      "|    total_timesteps    | 40247296    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026945353 |\n",
      "|    entropy_loss       | -2          |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0689     |\n",
      "|    mean_step_reward   | 0.077952534 |\n",
      "|    n_updates          | 64/128      |\n",
      "|    policyGradLoss     | -0.0221     |\n",
      "|    value_loss         | 0.21        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 739         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 199         |\n",
      "|    total_timesteps    | 40255488    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.032537676 |\n",
      "|    entropy_loss       | -2.03       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0999     |\n",
      "|    mean_step_reward   | 0.06575589  |\n",
      "|    n_updates          | 68/128      |\n",
      "|    policyGradLoss     | -0.0238     |\n",
      "|    value_loss         | 0.159       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 738         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 210         |\n",
      "|    total_timesteps    | 40263680    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020718325 |\n",
      "|    entropy_loss       | -2.02       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0506     |\n",
      "|    mean_step_reward   | 0.07858314  |\n",
      "|    n_updates          | 72/128      |\n",
      "|    policyGradLoss     | -0.0174     |\n",
      "|    value_loss         | 0.289       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 737        |\n",
      "|    iterations         | 20         |\n",
      "|    time_elapsed       | 222        |\n",
      "|    total_timesteps    | 40271872   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02366088 |\n",
      "|    entropy_loss       | -2.02      |\n",
      "|    explained_variance | 0.951      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0131    |\n",
      "|    mean_step_reward   | 0.07169727 |\n",
      "|    n_updates          | 76/128     |\n",
      "|    policyGradLoss     | -0.018     |\n",
      "|    value_loss         | 0.378      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 737        |\n",
      "|    iterations         | 21         |\n",
      "|    time_elapsed       | 233        |\n",
      "|    total_timesteps    | 40280064   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.0164911  |\n",
      "|    entropy_loss       | -2.03      |\n",
      "|    explained_variance | 0.937      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0131    |\n",
      "|    mean_step_reward   | 0.07624926 |\n",
      "|    n_updates          | 80/128     |\n",
      "|    policyGradLoss     | -0.0112    |\n",
      "|    value_loss         | 0.496      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 737         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 244         |\n",
      "|    total_timesteps    | 40288256    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024646942 |\n",
      "|    entropy_loss       | -2.01       |\n",
      "|    explained_variance | 0.915       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00167     |\n",
      "|    mean_step_reward   | 0.07104823  |\n",
      "|    n_updates          | 84/128      |\n",
      "|    policyGradLoss     | -0.0175     |\n",
      "|    value_loss         | 0.306       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 736         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 255         |\n",
      "|    total_timesteps    | 40296448    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027513271 |\n",
      "|    entropy_loss       | -2.09       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0808     |\n",
      "|    mean_step_reward   | 0.058871098 |\n",
      "|    n_updates          | 88/128      |\n",
      "|    policyGradLoss     | -0.0214     |\n",
      "|    value_loss         | 0.181       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 734         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 267         |\n",
      "|    total_timesteps    | 40304640    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022922492 |\n",
      "|    entropy_loss       | -2.09       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0286     |\n",
      "|    mean_step_reward   | 0.06848268  |\n",
      "|    n_updates          | 92/128      |\n",
      "|    policyGradLoss     | -0.0152     |\n",
      "|    value_loss         | 0.249       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 734         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 278         |\n",
      "|    total_timesteps    | 40312832    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022033144 |\n",
      "|    entropy_loss       | -2.01       |\n",
      "|    explained_variance | 0.944       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.039      |\n",
      "|    mean_step_reward   | 0.07512912  |\n",
      "|    n_updates          | 96/128      |\n",
      "|    policyGradLoss     | -0.0168     |\n",
      "|    value_loss         | 0.322       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 735         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 289         |\n",
      "|    total_timesteps    | 40321024    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029763507 |\n",
      "|    entropy_loss       | -2.04       |\n",
      "|    explained_variance | 0.923       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.024      |\n",
      "|    mean_step_reward   | 0.05135984  |\n",
      "|    n_updates          | 100/128     |\n",
      "|    policyGradLoss     | -0.0169     |\n",
      "|    value_loss         | 0.407       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 735         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 300         |\n",
      "|    total_timesteps    | 40329216    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021942697 |\n",
      "|    entropy_loss       | -2.02       |\n",
      "|    explained_variance | 0.922       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0349     |\n",
      "|    mean_step_reward   | 0.06593348  |\n",
      "|    n_updates          | 104/128     |\n",
      "|    policyGradLoss     | -0.0199     |\n",
      "|    value_loss         | 0.393       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 734         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 312         |\n",
      "|    total_timesteps    | 40337408    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021240853 |\n",
      "|    entropy_loss       | -2.11       |\n",
      "|    explained_variance | 0.915       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0608     |\n",
      "|    mean_step_reward   | 0.05147469  |\n",
      "|    n_updates          | 108/128     |\n",
      "|    policyGradLoss     | -0.0178     |\n",
      "|    value_loss         | 0.291       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 733        |\n",
      "|    iterations         | 29         |\n",
      "|    time_elapsed       | 323        |\n",
      "|    total_timesteps    | 40345600   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02232325 |\n",
      "|    entropy_loss       | -2.06      |\n",
      "|    explained_variance | 0.953      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0678    |\n",
      "|    mean_step_reward   | 0.06650904 |\n",
      "|    n_updates          | 112/128    |\n",
      "|    policyGradLoss     | -0.0208    |\n",
      "|    value_loss         | 0.33       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 735         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 333         |\n",
      "|    total_timesteps    | 40353792    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.032442383 |\n",
      "|    entropy_loss       | -2.09       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.115      |\n",
      "|    mean_step_reward   | 0.05065251  |\n",
      "|    n_updates          | 116/128     |\n",
      "|    policyGradLoss     | -0.0288     |\n",
      "|    value_loss         | 0.113       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 740         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 342         |\n",
      "|    total_timesteps    | 40361984    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01982586  |\n",
      "|    entropy_loss       | -2.1        |\n",
      "|    explained_variance | 0.915       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0238     |\n",
      "|    mean_step_reward   | 0.043744445 |\n",
      "|    n_updates          | 120/128     |\n",
      "|    policyGradLoss     | -0.0144     |\n",
      "|    value_loss         | 0.393       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 743         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 352         |\n",
      "|    total_timesteps    | 40370176    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02048048  |\n",
      "|    entropy_loss       | -2.08       |\n",
      "|    explained_variance | 0.936       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0105     |\n",
      "|    mean_step_reward   | 0.059306256 |\n",
      "|    n_updates          | 124/128     |\n",
      "|    policyGradLoss     | -0.0124     |\n",
      "|    value_loss         | 0.303       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/NoArti_153.zip\n",
      "[EVAL] Mean Return: 131.616, Best Return: 134.016\n",
      "Saved video to ./runs_smw/videos/NoArti/NoArti_153_131.62.mp4\n",
      "\n",
      "=== Round 155 | Learn 262144 steps (Total trained: 40370176) ===\n",
      "Logging to ./runs_smw/tb/NoArti_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1131     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 40378368 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 887         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 40386560    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023774642 |\n",
      "|    entropy_loss       | -2.03       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0523     |\n",
      "|    mean_step_reward   | 0.082074724 |\n",
      "|    n_updates          | 4/128       |\n",
      "|    policyGradLoss     | -0.0229     |\n",
      "|    value_loss         | 0.148       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 828         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 29          |\n",
      "|    total_timesteps    | 40394752    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021041974 |\n",
      "|    entropy_loss       | -2.06       |\n",
      "|    explained_variance | 0.913       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0319      |\n",
      "|    mean_step_reward   | 0.055489454 |\n",
      "|    n_updates          | 8/128       |\n",
      "|    policyGradLoss     | -0.0139     |\n",
      "|    value_loss         | 0.548       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 799         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 40          |\n",
      "|    total_timesteps    | 40402944    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024667174 |\n",
      "|    entropy_loss       | -1.98       |\n",
      "|    explained_variance | 0.947       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0588     |\n",
      "|    mean_step_reward   | 0.08605118  |\n",
      "|    n_updates          | 12/128      |\n",
      "|    policyGradLoss     | -0.019      |\n",
      "|    value_loss         | 0.284       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 52          |\n",
      "|    total_timesteps    | 40411136    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022808302 |\n",
      "|    entropy_loss       | -2.04       |\n",
      "|    explained_variance | 0.941       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.049      |\n",
      "|    mean_step_reward   | 0.066269    |\n",
      "|    n_updates          | 16/128      |\n",
      "|    policyGradLoss     | -0.0201     |\n",
      "|    value_loss         | 0.425       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 64          |\n",
      "|    total_timesteps    | 40419328    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016239047 |\n",
      "|    entropy_loss       | -2.08       |\n",
      "|    explained_variance | 0.936       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0474     |\n",
      "|    mean_step_reward   | 0.05992208  |\n",
      "|    n_updates          | 20/128      |\n",
      "|    policyGradLoss     | -0.0177     |\n",
      "|    value_loss         | 0.268       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 762        |\n",
      "|    iterations         | 7          |\n",
      "|    time_elapsed       | 75         |\n",
      "|    total_timesteps    | 40427520   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02240096 |\n",
      "|    entropy_loss       | -2.12      |\n",
      "|    explained_variance | 0.933      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0474    |\n",
      "|    mean_step_reward   | 0.04515955 |\n",
      "|    n_updates          | 24/128     |\n",
      "|    policyGradLoss     | -0.0166    |\n",
      "|    value_loss         | 0.404      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 758         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 86          |\n",
      "|    total_timesteps    | 40435712    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024968881 |\n",
      "|    entropy_loss       | -2.14       |\n",
      "|    explained_variance | 0.932       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0693     |\n",
      "|    mean_step_reward   | 0.045505494 |\n",
      "|    n_updates          | 28/128      |\n",
      "|    policyGradLoss     | -0.0213     |\n",
      "|    value_loss         | 0.216       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 755        |\n",
      "|    iterations         | 9          |\n",
      "|    time_elapsed       | 97         |\n",
      "|    total_timesteps    | 40443904   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02188442 |\n",
      "|    entropy_loss       | -2.11      |\n",
      "|    explained_variance | 0.93       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0295    |\n",
      "|    mean_step_reward   | 0.04379227 |\n",
      "|    n_updates          | 32/128     |\n",
      "|    policyGradLoss     | -0.0187    |\n",
      "|    value_loss         | 0.308      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 751         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 109         |\n",
      "|    total_timesteps    | 40452096    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024997324 |\n",
      "|    entropy_loss       | -2.09       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0433     |\n",
      "|    mean_step_reward   | 0.058791593 |\n",
      "|    n_updates          | 36/128      |\n",
      "|    policyGradLoss     | -0.0215     |\n",
      "|    value_loss         | 0.208       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 745         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 120         |\n",
      "|    total_timesteps    | 40460288    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021199422 |\n",
      "|    entropy_loss       | -2.11       |\n",
      "|    explained_variance | 0.946       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0647     |\n",
      "|    mean_step_reward   | 0.050655305 |\n",
      "|    n_updates          | 40/128      |\n",
      "|    policyGradLoss     | -0.0176     |\n",
      "|    value_loss         | 0.282       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 743         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 132         |\n",
      "|    total_timesteps    | 40468480    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028357534 |\n",
      "|    entropy_loss       | -2.14       |\n",
      "|    explained_variance | 0.954       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.091      |\n",
      "|    mean_step_reward   | 0.046155196 |\n",
      "|    n_updates          | 44/128      |\n",
      "|    policyGradLoss     | -0.0209     |\n",
      "|    value_loss         | 0.143       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 743         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 143         |\n",
      "|    total_timesteps    | 40476672    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016187547 |\n",
      "|    entropy_loss       | -2.17       |\n",
      "|    explained_variance | 0.935       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0626     |\n",
      "|    mean_step_reward   | 0.043212563 |\n",
      "|    n_updates          | 48/128      |\n",
      "|    policyGradLoss     | -0.0124     |\n",
      "|    value_loss         | 0.247       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 743         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 154         |\n",
      "|    total_timesteps    | 40484864    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017268937 |\n",
      "|    entropy_loss       | -2.13       |\n",
      "|    explained_variance | 0.858       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 7.23e-05    |\n",
      "|    mean_step_reward   | 0.048150953 |\n",
      "|    n_updates          | 52/128      |\n",
      "|    policyGradLoss     | -0.00949    |\n",
      "|    value_loss         | 0.53        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 742        |\n",
      "|    iterations         | 15         |\n",
      "|    time_elapsed       | 165        |\n",
      "|    total_timesteps    | 40493056   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.0213827  |\n",
      "|    entropy_loss       | -2.15      |\n",
      "|    explained_variance | 0.963      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0583    |\n",
      "|    mean_step_reward   | 0.04966987 |\n",
      "|    n_updates          | 56/128     |\n",
      "|    policyGradLoss     | -0.0237    |\n",
      "|    value_loss         | 0.164      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 739         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 177         |\n",
      "|    total_timesteps    | 40501248    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021667426 |\n",
      "|    entropy_loss       | -2.18       |\n",
      "|    explained_variance | 0.934       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0866     |\n",
      "|    mean_step_reward   | 0.03457982  |\n",
      "|    n_updates          | 60/128      |\n",
      "|    policyGradLoss     | -0.0176     |\n",
      "|    value_loss         | 0.238       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 738         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 188         |\n",
      "|    total_timesteps    | 40509440    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016871875 |\n",
      "|    entropy_loss       | -2.12       |\n",
      "|    explained_variance | 0.868       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0743      |\n",
      "|    mean_step_reward   | 0.04144643  |\n",
      "|    n_updates          | 64/128      |\n",
      "|    policyGradLoss     | -0.0143     |\n",
      "|    value_loss         | 0.377       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 737         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 199         |\n",
      "|    total_timesteps    | 40517632    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023469754 |\n",
      "|    entropy_loss       | -2.16       |\n",
      "|    explained_variance | 0.917       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0735     |\n",
      "|    mean_step_reward   | 0.044602476 |\n",
      "|    n_updates          | 68/128      |\n",
      "|    policyGradLoss     | -0.0193     |\n",
      "|    value_loss         | 0.278       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 738         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 210         |\n",
      "|    total_timesteps    | 40525824    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02073722  |\n",
      "|    entropy_loss       | -2.16       |\n",
      "|    explained_variance | 0.856       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0394     |\n",
      "|    mean_step_reward   | 0.046106942 |\n",
      "|    n_updates          | 72/128      |\n",
      "|    policyGradLoss     | -0.0148     |\n",
      "|    value_loss         | 0.493       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 737         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 222         |\n",
      "|    total_timesteps    | 40534016    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017350148 |\n",
      "|    entropy_loss       | -2.14       |\n",
      "|    explained_variance | 0.85        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00671    |\n",
      "|    mean_step_reward   | 0.049792923 |\n",
      "|    n_updates          | 76/128      |\n",
      "|    policyGradLoss     | -0.0117     |\n",
      "|    value_loss         | 0.706       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 736         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 233         |\n",
      "|    total_timesteps    | 40542208    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02053483  |\n",
      "|    entropy_loss       | -2.18       |\n",
      "|    explained_variance | 0.928       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0381     |\n",
      "|    mean_step_reward   | 0.042707957 |\n",
      "|    n_updates          | 80/128      |\n",
      "|    policyGradLoss     | -0.0195     |\n",
      "|    value_loss         | 0.286       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 734         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 245         |\n",
      "|    total_timesteps    | 40550400    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014717903 |\n",
      "|    entropy_loss       | -2.17       |\n",
      "|    explained_variance | 0.754       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.13        |\n",
      "|    mean_step_reward   | 0.047348805 |\n",
      "|    n_updates          | 84/128      |\n",
      "|    policyGradLoss     | -0.00853    |\n",
      "|    value_loss         | 0.722       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 734         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 256         |\n",
      "|    total_timesteps    | 40558592    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017771993 |\n",
      "|    entropy_loss       | -2.18       |\n",
      "|    explained_variance | 0.837       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0147      |\n",
      "|    mean_step_reward   | 0.033795863 |\n",
      "|    n_updates          | 88/128      |\n",
      "|    policyGradLoss     | -0.0149     |\n",
      "|    value_loss         | 0.517       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 734         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 267         |\n",
      "|    total_timesteps    | 40566784    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011426802 |\n",
      "|    entropy_loss       | -2.16       |\n",
      "|    explained_variance | 0.878       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.042      |\n",
      "|    mean_step_reward   | 0.06266066  |\n",
      "|    n_updates          | 92/128      |\n",
      "|    policyGradLoss     | -0.0107     |\n",
      "|    value_loss         | 0.594       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 734         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 278         |\n",
      "|    total_timesteps    | 40574976    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017096793 |\n",
      "|    entropy_loss       | -2.18       |\n",
      "|    explained_variance | 0.792       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0368     |\n",
      "|    mean_step_reward   | 0.036009546 |\n",
      "|    n_updates          | 96/128      |\n",
      "|    policyGradLoss     | -0.0112     |\n",
      "|    value_loss         | 0.471       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 734        |\n",
      "|    iterations         | 26         |\n",
      "|    time_elapsed       | 290        |\n",
      "|    total_timesteps    | 40583168   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01899628 |\n",
      "|    entropy_loss       | -2.19      |\n",
      "|    explained_variance | 0.922      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0481    |\n",
      "|    mean_step_reward   | 0.05017055 |\n",
      "|    n_updates          | 100/128    |\n",
      "|    policyGradLoss     | -0.017     |\n",
      "|    value_loss         | 0.363      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 733         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 301         |\n",
      "|    total_timesteps    | 40591360    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021193529 |\n",
      "|    entropy_loss       | -2.18       |\n",
      "|    explained_variance | 0.637       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0339     |\n",
      "|    mean_step_reward   | 0.012898665 |\n",
      "|    n_updates          | 104/128     |\n",
      "|    policyGradLoss     | -0.0145     |\n",
      "|    value_loss         | 0.55        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 733         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 312         |\n",
      "|    total_timesteps    | 40599552    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020356284 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.782       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0942     |\n",
      "|    mean_step_reward   | 0.026336145 |\n",
      "|    n_updates          | 108/128     |\n",
      "|    policyGradLoss     | -0.0198     |\n",
      "|    value_loss         | 0.214       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 738         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 321         |\n",
      "|    total_timesteps    | 40607744    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016348902 |\n",
      "|    entropy_loss       | -2.28       |\n",
      "|    explained_variance | 0.845       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.1        |\n",
      "|    mean_step_reward   | 0.020544939 |\n",
      "|    n_updates          | 112/128     |\n",
      "|    policyGradLoss     | -0.0135     |\n",
      "|    value_loss         | 0.168       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 743         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 330         |\n",
      "|    total_timesteps    | 40615936    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021106236 |\n",
      "|    entropy_loss       | -2.28       |\n",
      "|    explained_variance | 0.865       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0507     |\n",
      "|    mean_step_reward   | 0.021017544 |\n",
      "|    n_updates          | 116/128     |\n",
      "|    policyGradLoss     | -0.0173     |\n",
      "|    value_loss         | 0.288       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 746         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 340         |\n",
      "|    total_timesteps    | 40624128    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012420606 |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.82        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.085      |\n",
      "|    mean_step_reward   | 0.028252257 |\n",
      "|    n_updates          | 120/128     |\n",
      "|    policyGradLoss     | -0.0127     |\n",
      "|    value_loss         | 0.326       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 747         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 350         |\n",
      "|    total_timesteps    | 40632320    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015599001 |\n",
      "|    entropy_loss       | -2.2        |\n",
      "|    explained_variance | 0.849       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0679     |\n",
      "|    mean_step_reward   | 0.03178219  |\n",
      "|    n_updates          | 124/128     |\n",
      "|    policyGradLoss     | -0.0147     |\n",
      "|    value_loss         | 0.381       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/NoArti_154.zip\n",
      "[EVAL] Mean Return: 122.517, Best Return: 125.117\n",
      "Saved video to ./runs_smw/videos/NoArti/NoArti_154_122.52.mp4\n",
      "\n",
      "=== Round 156 | Learn 262144 steps (Total trained: 40632320) ===\n",
      "Logging to ./runs_smw/tb/NoArti_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1061     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 40640512 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 855         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 19          |\n",
      "|    total_timesteps    | 40648704    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017158814 |\n",
      "|    entropy_loss       | -2.15       |\n",
      "|    explained_variance | 0.873       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0387     |\n",
      "|    mean_step_reward   | 0.037698157 |\n",
      "|    n_updates          | 4/128       |\n",
      "|    policyGradLoss     | -0.0174     |\n",
      "|    value_loss         | 0.449       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 806         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 30          |\n",
      "|    total_timesteps    | 40656896    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024065092 |\n",
      "|    entropy_loss       | -2.12       |\n",
      "|    explained_variance | 0.868       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0445      |\n",
      "|    mean_step_reward   | 0.03349746  |\n",
      "|    n_updates          | 8/128       |\n",
      "|    policyGradLoss     | -0.0211     |\n",
      "|    value_loss         | 0.51        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 794         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 41          |\n",
      "|    total_timesteps    | 40665088    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021148453 |\n",
      "|    entropy_loss       | -2.19       |\n",
      "|    explained_variance | 0.846       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0513     |\n",
      "|    mean_step_reward   | 0.04124815  |\n",
      "|    n_updates          | 12/128      |\n",
      "|    policyGradLoss     | -0.0166     |\n",
      "|    value_loss         | 0.413       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 52          |\n",
      "|    total_timesteps    | 40673280    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02551793  |\n",
      "|    entropy_loss       | -2.14       |\n",
      "|    explained_variance | 0.916       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0545     |\n",
      "|    mean_step_reward   | 0.039487176 |\n",
      "|    n_updates          | 16/128      |\n",
      "|    policyGradLoss     | -0.0204     |\n",
      "|    value_loss         | 0.324       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 63          |\n",
      "|    total_timesteps    | 40681472    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019230437 |\n",
      "|    entropy_loss       | -2.16       |\n",
      "|    explained_variance | 0.922       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0406     |\n",
      "|    mean_step_reward   | 0.056555547 |\n",
      "|    n_updates          | 20/128      |\n",
      "|    policyGradLoss     | -0.0143     |\n",
      "|    value_loss         | 0.404       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 758         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 75          |\n",
      "|    total_timesteps    | 40689664    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028049815 |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.884       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0887     |\n",
      "|    mean_step_reward   | 0.026061427 |\n",
      "|    n_updates          | 24/128      |\n",
      "|    policyGradLoss     | -0.0208     |\n",
      "|    value_loss         | 0.237       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 753         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 86          |\n",
      "|    total_timesteps    | 40697856    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021743495 |\n",
      "|    entropy_loss       | -2.18       |\n",
      "|    explained_variance | 0.897       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0645     |\n",
      "|    mean_step_reward   | 0.028106418 |\n",
      "|    n_updates          | 28/128      |\n",
      "|    policyGradLoss     | -0.0194     |\n",
      "|    value_loss         | 0.292       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 752         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 97          |\n",
      "|    total_timesteps    | 40706048    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023115829 |\n",
      "|    entropy_loss       | -2.2        |\n",
      "|    explained_variance | 0.915       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0913     |\n",
      "|    mean_step_reward   | 0.03251165  |\n",
      "|    n_updates          | 32/128      |\n",
      "|    policyGradLoss     | -0.0221     |\n",
      "|    value_loss         | 0.182       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 750         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 109         |\n",
      "|    total_timesteps    | 40714240    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021323295 |\n",
      "|    entropy_loss       | -2.17       |\n",
      "|    explained_variance | 0.796       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0816     |\n",
      "|    mean_step_reward   | 0.03535917  |\n",
      "|    n_updates          | 36/128      |\n",
      "|    policyGradLoss     | -0.0156     |\n",
      "|    value_loss         | 0.372       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 748         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 120         |\n",
      "|    total_timesteps    | 40722432    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.03675632  |\n",
      "|    entropy_loss       | -2.2        |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.117      |\n",
      "|    mean_step_reward   | 0.041357666 |\n",
      "|    n_updates          | 40/128      |\n",
      "|    policyGradLoss     | -0.0246     |\n",
      "|    value_loss         | 0.0985      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 744         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 132         |\n",
      "|    total_timesteps    | 40730624    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.0202744   |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.829       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0713     |\n",
      "|    mean_step_reward   | 0.022513809 |\n",
      "|    n_updates          | 44/128      |\n",
      "|    policyGradLoss     | -0.0081     |\n",
      "|    value_loss         | 0.364       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 742         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 143         |\n",
      "|    total_timesteps    | 40738816    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017993405 |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.912       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.08       |\n",
      "|    mean_step_reward   | 0.032167263 |\n",
      "|    n_updates          | 48/128      |\n",
      "|    policyGradLoss     | -0.0157     |\n",
      "|    value_loss         | 0.187       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 741         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 154         |\n",
      "|    total_timesteps    | 40747008    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023968078 |\n",
      "|    entropy_loss       | -2.17       |\n",
      "|    explained_variance | 0.919       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0797     |\n",
      "|    mean_step_reward   | 0.02998686  |\n",
      "|    n_updates          | 52/128      |\n",
      "|    policyGradLoss     | -0.0189     |\n",
      "|    value_loss         | 0.197       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 742         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 165         |\n",
      "|    total_timesteps    | 40755200    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02143824  |\n",
      "|    entropy_loss       | -2.17       |\n",
      "|    explained_variance | 0.856       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0292     |\n",
      "|    mean_step_reward   | 0.032746784 |\n",
      "|    n_updates          | 56/128      |\n",
      "|    policyGradLoss     | -0.0118     |\n",
      "|    value_loss         | 0.632       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 741         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 176         |\n",
      "|    total_timesteps    | 40763392    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017450629 |\n",
      "|    entropy_loss       | -2.14       |\n",
      "|    explained_variance | 0.787       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0353      |\n",
      "|    mean_step_reward   | 0.03461079  |\n",
      "|    n_updates          | 60/128      |\n",
      "|    policyGradLoss     | -0.0111     |\n",
      "|    value_loss         | 0.515       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 739         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 188         |\n",
      "|    total_timesteps    | 40771584    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015662206 |\n",
      "|    entropy_loss       | -2.15       |\n",
      "|    explained_variance | 0.851       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0448     |\n",
      "|    mean_step_reward   | 0.050188277 |\n",
      "|    n_updates          | 64/128      |\n",
      "|    policyGradLoss     | -0.0126     |\n",
      "|    value_loss         | 0.643       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 738         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 199         |\n",
      "|    total_timesteps    | 40779776    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020784369 |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.8         |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0836      |\n",
      "|    mean_step_reward   | 0.023582317 |\n",
      "|    n_updates          | 68/128      |\n",
      "|    policyGradLoss     | -0.0118     |\n",
      "|    value_loss         | 0.479       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 737         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 210         |\n",
      "|    total_timesteps    | 40787968    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02149478  |\n",
      "|    entropy_loss       | -2.2        |\n",
      "|    explained_variance | 0.915       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.068      |\n",
      "|    mean_step_reward   | 0.044742495 |\n",
      "|    n_updates          | 72/128      |\n",
      "|    policyGradLoss     | -0.0193     |\n",
      "|    value_loss         | 0.192       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 737         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 222         |\n",
      "|    total_timesteps    | 40796160    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024635825 |\n",
      "|    entropy_loss       | -2.15       |\n",
      "|    explained_variance | 0.949       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0879     |\n",
      "|    mean_step_reward   | 0.048486955 |\n",
      "|    n_updates          | 76/128      |\n",
      "|    policyGradLoss     | -0.0193     |\n",
      "|    value_loss         | 0.174       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 738         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 233         |\n",
      "|    total_timesteps    | 40804352    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018331058 |\n",
      "|    entropy_loss       | -2.18       |\n",
      "|    explained_variance | 0.926       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0772     |\n",
      "|    mean_step_reward   | 0.041623898 |\n",
      "|    n_updates          | 80/128      |\n",
      "|    policyGradLoss     | -0.0189     |\n",
      "|    value_loss         | 0.274       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 738         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 244         |\n",
      "|    total_timesteps    | 40812544    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021371266 |\n",
      "|    entropy_loss       | -2.19       |\n",
      "|    explained_variance | 0.842       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.094      |\n",
      "|    mean_step_reward   | 0.025009166 |\n",
      "|    n_updates          | 84/128      |\n",
      "|    policyGradLoss     | -0.024      |\n",
      "|    value_loss         | 0.239       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 736         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 255         |\n",
      "|    total_timesteps    | 40820736    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022340445 |\n",
      "|    entropy_loss       | -2.14       |\n",
      "|    explained_variance | 0.92        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0632     |\n",
      "|    mean_step_reward   | 0.050763182 |\n",
      "|    n_updates          | 88/128      |\n",
      "|    policyGradLoss     | -0.0184     |\n",
      "|    value_loss         | 0.295       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 735         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 267         |\n",
      "|    total_timesteps    | 40828928    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016678082 |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.876       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0481     |\n",
      "|    mean_step_reward   | 0.02698449  |\n",
      "|    n_updates          | 92/128      |\n",
      "|    policyGradLoss     | -0.0191     |\n",
      "|    value_loss         | 0.276       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 734         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 278         |\n",
      "|    total_timesteps    | 40837120    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021049779 |\n",
      "|    entropy_loss       | -2.17       |\n",
      "|    explained_variance | 0.957       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0901     |\n",
      "|    mean_step_reward   | 0.053027138 |\n",
      "|    n_updates          | 96/128      |\n",
      "|    policyGradLoss     | -0.0183     |\n",
      "|    value_loss         | 0.186       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 738         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 288         |\n",
      "|    total_timesteps    | 40845312    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017113166 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.931       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0688     |\n",
      "|    mean_step_reward   | 0.024434038 |\n",
      "|    n_updates          | 100/128     |\n",
      "|    policyGradLoss     | -0.0155     |\n",
      "|    value_loss         | 0.178       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 743         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 297         |\n",
      "|    total_timesteps    | 40853504    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017713886 |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.958       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.101      |\n",
      "|    mean_step_reward   | 0.02258878  |\n",
      "|    n_updates          | 104/128     |\n",
      "|    policyGradLoss     | -0.019      |\n",
      "|    value_loss         | 0.0831      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 747         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 306         |\n",
      "|    total_timesteps    | 40861696    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020325739 |\n",
      "|    entropy_loss       | -2.2        |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.103      |\n",
      "|    mean_step_reward   | 0.043990247 |\n",
      "|    n_updates          | 108/128     |\n",
      "|    policyGradLoss     | -0.0176     |\n",
      "|    value_loss         | 0.114       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 748         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 317         |\n",
      "|    total_timesteps    | 40869888    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025762957 |\n",
      "|    entropy_loss       | -2.18       |\n",
      "|    explained_variance | 0.818       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0523     |\n",
      "|    mean_step_reward   | 0.024061028 |\n",
      "|    n_updates          | 112/128     |\n",
      "|    policyGradLoss     | -0.0131     |\n",
      "|    value_loss         | 0.346       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 748         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 328         |\n",
      "|    total_timesteps    | 40878080    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019369286 |\n",
      "|    entropy_loss       | -2.14       |\n",
      "|    explained_variance | 0.936       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0304     |\n",
      "|    mean_step_reward   | 0.067650825 |\n",
      "|    n_updates          | 116/128     |\n",
      "|    policyGradLoss     | -0.0119     |\n",
      "|    value_loss         | 0.295       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 747         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 339         |\n",
      "|    total_timesteps    | 40886272    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016975738 |\n",
      "|    entropy_loss       | -2.16       |\n",
      "|    explained_variance | 0.793       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.032      |\n",
      "|    mean_step_reward   | 0.04309272  |\n",
      "|    n_updates          | 120/128     |\n",
      "|    policyGradLoss     | -0.00683    |\n",
      "|    value_loss         | 0.678       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 745         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 351         |\n",
      "|    total_timesteps    | 40894464    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018223219 |\n",
      "|    entropy_loss       | -2.17       |\n",
      "|    explained_variance | 0.954       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0832     |\n",
      "|    mean_step_reward   | 0.046041355 |\n",
      "|    n_updates          | 124/128     |\n",
      "|    policyGradLoss     | -0.0175     |\n",
      "|    value_loss         | 0.16        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/NoArti_155.zip\n",
      "[EVAL] Mean Return: 130.640, Best Return: 133.240\n",
      "Saved video to ./runs_smw/videos/NoArti/NoArti_155_130.64.mp4\n",
      "\n",
      "=== Round 157 | Learn 262144 steps (Total trained: 40894464) ===\n",
      "Logging to ./runs_smw/tb/NoArti_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1167     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 40902656 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 903         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 40910848    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021097202 |\n",
      "|    entropy_loss       | -2.11       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0665     |\n",
      "|    mean_step_reward   | 0.07280897  |\n",
      "|    n_updates          | 4/128       |\n",
      "|    policyGradLoss     | -0.0216     |\n",
      "|    value_loss         | 0.201       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 832         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 29          |\n",
      "|    total_timesteps    | 40919040    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026012216 |\n",
      "|    entropy_loss       | -2.08       |\n",
      "|    explained_variance | 0.941       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0481     |\n",
      "|    mean_step_reward   | 0.051523194 |\n",
      "|    n_updates          | 8/128       |\n",
      "|    policyGradLoss     | -0.0174     |\n",
      "|    value_loss         | 0.308       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 794         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 41          |\n",
      "|    total_timesteps    | 40927232    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021468882 |\n",
      "|    entropy_loss       | -2.16       |\n",
      "|    explained_variance | 0.952       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0366     |\n",
      "|    mean_step_reward   | 0.054003228 |\n",
      "|    n_updates          | 12/128      |\n",
      "|    policyGradLoss     | -0.0176     |\n",
      "|    value_loss         | 0.276       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 52          |\n",
      "|    total_timesteps    | 40935424    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016310794 |\n",
      "|    entropy_loss       | -2.13       |\n",
      "|    explained_variance | 0.952       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0197     |\n",
      "|    mean_step_reward   | 0.05367603  |\n",
      "|    n_updates          | 16/128      |\n",
      "|    policyGradLoss     | -0.0176     |\n",
      "|    value_loss         | 0.276       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 63          |\n",
      "|    total_timesteps    | 40943616    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025111008 |\n",
      "|    entropy_loss       | -2.09       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0763     |\n",
      "|    mean_step_reward   | 0.062060468 |\n",
      "|    n_updates          | 20/128      |\n",
      "|    policyGradLoss     | -0.0286     |\n",
      "|    value_loss         | 0.173       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 74          |\n",
      "|    total_timesteps    | 40951808    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021942265 |\n",
      "|    entropy_loss       | -2.07       |\n",
      "|    explained_variance | 0.94        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0296     |\n",
      "|    mean_step_reward   | 0.060901076 |\n",
      "|    n_updates          | 24/128      |\n",
      "|    policyGradLoss     | -0.0181     |\n",
      "|    value_loss         | 0.457       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 763         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 85          |\n",
      "|    total_timesteps    | 40960000    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01858627  |\n",
      "|    entropy_loss       | -2.09       |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0652     |\n",
      "|    mean_step_reward   | 0.061500125 |\n",
      "|    n_updates          | 28/128      |\n",
      "|    policyGradLoss     | -0.019      |\n",
      "|    value_loss         | 0.283       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 757         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 97          |\n",
      "|    total_timesteps    | 40968192    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028528864 |\n",
      "|    entropy_loss       | -2.07       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0417     |\n",
      "|    mean_step_reward   | 0.072963014 |\n",
      "|    n_updates          | 32/128      |\n",
      "|    policyGradLoss     | -0.0217     |\n",
      "|    value_loss         | 0.194       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 751         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 109         |\n",
      "|    total_timesteps    | 40976384    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023393389 |\n",
      "|    entropy_loss       | -2.12       |\n",
      "|    explained_variance | 0.95        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0547     |\n",
      "|    mean_step_reward   | 0.054200854 |\n",
      "|    n_updates          | 36/128      |\n",
      "|    policyGradLoss     | -0.0154     |\n",
      "|    value_loss         | 0.288       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 748         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 120         |\n",
      "|    total_timesteps    | 40984576    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023341734 |\n",
      "|    entropy_loss       | -2.19       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0751     |\n",
      "|    mean_step_reward   | 0.04825987  |\n",
      "|    n_updates          | 40/128      |\n",
      "|    policyGradLoss     | -0.0222     |\n",
      "|    value_loss         | 0.122       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 747         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 131         |\n",
      "|    total_timesteps    | 40992768    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022317598 |\n",
      "|    entropy_loss       | -2.16       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0858     |\n",
      "|    mean_step_reward   | 0.053245075 |\n",
      "|    n_updates          | 44/128      |\n",
      "|    policyGradLoss     | -0.02       |\n",
      "|    value_loss         | 0.0841      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 746         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 142         |\n",
      "|    total_timesteps    | 41000960    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020003896 |\n",
      "|    entropy_loss       | -2.18       |\n",
      "|    explained_variance | 0.93        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0377     |\n",
      "|    mean_step_reward   | 0.041137703 |\n",
      "|    n_updates          | 48/128      |\n",
      "|    policyGradLoss     | -0.00817    |\n",
      "|    value_loss         | 0.33        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 743         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 154         |\n",
      "|    total_timesteps    | 41009152    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021347776 |\n",
      "|    entropy_loss       | -2.1        |\n",
      "|    explained_variance | 0.957       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0911     |\n",
      "|    mean_step_reward   | 0.05429287  |\n",
      "|    n_updates          | 52/128      |\n",
      "|    policyGradLoss     | -0.0206     |\n",
      "|    value_loss         | 0.178       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 740         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 165         |\n",
      "|    total_timesteps    | 41017344    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028773453 |\n",
      "|    entropy_loss       | -2.07       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0611     |\n",
      "|    mean_step_reward   | 0.07691508  |\n",
      "|    n_updates          | 56/128      |\n",
      "|    policyGradLoss     | -0.0217     |\n",
      "|    value_loss         | 0.153       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 738         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 177         |\n",
      "|    total_timesteps    | 41025536    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021286126 |\n",
      "|    entropy_loss       | -2.04       |\n",
      "|    explained_variance | 0.941       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.064      |\n",
      "|    mean_step_reward   | 0.04738198  |\n",
      "|    n_updates          | 60/128      |\n",
      "|    policyGradLoss     | -0.0154     |\n",
      "|    value_loss         | 0.33        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 738         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 188         |\n",
      "|    total_timesteps    | 41033728    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028241362 |\n",
      "|    entropy_loss       | -1.98       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0391     |\n",
      "|    mean_step_reward   | 0.08932816  |\n",
      "|    n_updates          | 64/128      |\n",
      "|    policyGradLoss     | -0.0178     |\n",
      "|    value_loss         | 0.28        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 739         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 199         |\n",
      "|    total_timesteps    | 41041920    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017198615 |\n",
      "|    entropy_loss       | -2.08       |\n",
      "|    explained_variance | 0.932       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0404     |\n",
      "|    mean_step_reward   | 0.064872734 |\n",
      "|    n_updates          | 68/128      |\n",
      "|    policyGradLoss     | -0.0127     |\n",
      "|    value_loss         | 0.504       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 739         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 210         |\n",
      "|    total_timesteps    | 41050112    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023182783 |\n",
      "|    entropy_loss       | -2.07       |\n",
      "|    explained_variance | 0.928       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.000765   |\n",
      "|    mean_step_reward   | 0.05943884  |\n",
      "|    n_updates          | 72/128      |\n",
      "|    policyGradLoss     | -0.0171     |\n",
      "|    value_loss         | 0.301       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 737         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 222         |\n",
      "|    total_timesteps    | 41058304    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020896591 |\n",
      "|    entropy_loss       | -1.98       |\n",
      "|    explained_variance | 0.914       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0335     |\n",
      "|    mean_step_reward   | 0.0948147   |\n",
      "|    n_updates          | 76/128      |\n",
      "|    policyGradLoss     | -0.00999    |\n",
      "|    value_loss         | 0.319       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 736         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 233         |\n",
      "|    total_timesteps    | 41066496    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024653913 |\n",
      "|    entropy_loss       | -2.11       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0387     |\n",
      "|    mean_step_reward   | 0.06309201  |\n",
      "|    n_updates          | 80/128      |\n",
      "|    policyGradLoss     | -0.0196     |\n",
      "|    value_loss         | 0.203       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 734         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 245         |\n",
      "|    total_timesteps    | 41074688    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020412356 |\n",
      "|    entropy_loss       | -2.06       |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0124      |\n",
      "|    mean_step_reward   | 0.0720786   |\n",
      "|    n_updates          | 84/128      |\n",
      "|    policyGradLoss     | -0.0191     |\n",
      "|    value_loss         | 0.251       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 734         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 256         |\n",
      "|    total_timesteps    | 41082880    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024695791 |\n",
      "|    entropy_loss       | -2          |\n",
      "|    explained_variance | 0.947       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0114     |\n",
      "|    mean_step_reward   | 0.07880783  |\n",
      "|    n_updates          | 88/128      |\n",
      "|    policyGradLoss     | -0.0183     |\n",
      "|    value_loss         | 0.461       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 741        |\n",
      "|    iterations         | 24         |\n",
      "|    time_elapsed       | 265        |\n",
      "|    total_timesteps    | 41091072   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02546307 |\n",
      "|    entropy_loss       | -2.07      |\n",
      "|    explained_variance | 0.95       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0411    |\n",
      "|    mean_step_reward   | 0.06080583 |\n",
      "|    n_updates          | 92/128     |\n",
      "|    policyGradLoss     | -0.0196    |\n",
      "|    value_loss         | 0.279      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 745         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 274         |\n",
      "|    total_timesteps    | 41099264    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021096757 |\n",
      "|    entropy_loss       | -2.12       |\n",
      "|    explained_variance | 0.914       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0858     |\n",
      "|    mean_step_reward   | 0.04827193  |\n",
      "|    n_updates          | 96/128      |\n",
      "|    policyGradLoss     | -0.0155     |\n",
      "|    value_loss         | 0.302       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 750        |\n",
      "|    iterations         | 26         |\n",
      "|    time_elapsed       | 283        |\n",
      "|    total_timesteps    | 41107456   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02303408 |\n",
      "|    entropy_loss       | -2.12      |\n",
      "|    explained_variance | 0.934      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0721    |\n",
      "|    mean_step_reward   | 0.04554374 |\n",
      "|    n_updates          | 100/128    |\n",
      "|    policyGradLoss     | -0.0173    |\n",
      "|    value_loss         | 0.231      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 750        |\n",
      "|    iterations         | 27         |\n",
      "|    time_elapsed       | 294        |\n",
      "|    total_timesteps    | 41115648   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01839495 |\n",
      "|    entropy_loss       | -2.17      |\n",
      "|    explained_variance | 0.928      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0354    |\n",
      "|    mean_step_reward   | 0.05278969 |\n",
      "|    n_updates          | 104/128    |\n",
      "|    policyGradLoss     | -0.0107    |\n",
      "|    value_loss         | 0.34       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 748         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 306         |\n",
      "|    total_timesteps    | 41123840    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028257474 |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.954       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0856     |\n",
      "|    mean_step_reward   | 0.032831445 |\n",
      "|    n_updates          | 108/128     |\n",
      "|    policyGradLoss     | -0.0192     |\n",
      "|    value_loss         | 0.14        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 746         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 318         |\n",
      "|    total_timesteps    | 41132032    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014249178 |\n",
      "|    entropy_loss       | -2.2        |\n",
      "|    explained_variance | 0.918       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0338     |\n",
      "|    mean_step_reward   | 0.02308171  |\n",
      "|    n_updates          | 112/128     |\n",
      "|    policyGradLoss     | -0.014      |\n",
      "|    value_loss         | 0.272       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 745         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 329         |\n",
      "|    total_timesteps    | 41140224    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01405764  |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.924       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0324     |\n",
      "|    mean_step_reward   | 0.034577433 |\n",
      "|    n_updates          | 116/128     |\n",
      "|    policyGradLoss     | -0.0141     |\n",
      "|    value_loss         | 0.247       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 745         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 340         |\n",
      "|    total_timesteps    | 41148416    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017415205 |\n",
      "|    entropy_loss       | -2.12       |\n",
      "|    explained_variance | 0.944       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0763     |\n",
      "|    mean_step_reward   | 0.048705634 |\n",
      "|    n_updates          | 120/128     |\n",
      "|    policyGradLoss     | -0.0169     |\n",
      "|    value_loss         | 0.227       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 745         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 351         |\n",
      "|    total_timesteps    | 41156608    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017572075 |\n",
      "|    entropy_loss       | -2.13       |\n",
      "|    explained_variance | 0.94        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0666     |\n",
      "|    mean_step_reward   | 0.039325517 |\n",
      "|    n_updates          | 124/128     |\n",
      "|    policyGradLoss     | -0.0176     |\n",
      "|    value_loss         | 0.315       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/NoArti_156.zip\n",
      "[EVAL] Mean Return: 134.077, Best Return: 136.677\n",
      "Saved video to ./runs_smw/videos/NoArti/NoArti_156_134.08.mp4\n",
      "\n",
      "=== Round 158 | Learn 262144 steps (Total trained: 41156608) ===\n",
      "Logging to ./runs_smw/tb/NoArti_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1072     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 41164800 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 855         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 19          |\n",
      "|    total_timesteps    | 41172992    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.031176385 |\n",
      "|    entropy_loss       | -2.19       |\n",
      "|    explained_variance | 0.935       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.107      |\n",
      "|    mean_step_reward   | 0.031384543 |\n",
      "|    n_updates          | 4/128       |\n",
      "|    policyGradLoss     | -0.0213     |\n",
      "|    value_loss         | 0.173       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 804         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 30          |\n",
      "|    total_timesteps    | 41181184    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026272597 |\n",
      "|    entropy_loss       | -2.14       |\n",
      "|    explained_variance | 0.926       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0894     |\n",
      "|    mean_step_reward   | 0.037391648 |\n",
      "|    n_updates          | 8/128       |\n",
      "|    policyGradLoss     | -0.021      |\n",
      "|    value_loss         | 0.187       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 41          |\n",
      "|    total_timesteps    | 41189376    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019433443 |\n",
      "|    entropy_loss       | -2.13       |\n",
      "|    explained_variance | 0.939       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0342     |\n",
      "|    mean_step_reward   | 0.05567412  |\n",
      "|    n_updates          | 12/128      |\n",
      "|    policyGradLoss     | -0.0203     |\n",
      "|    value_loss         | 0.337       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 52          |\n",
      "|    total_timesteps    | 41197568    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.0202884   |\n",
      "|    entropy_loss       | -2.14       |\n",
      "|    explained_variance | 0.92        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0653     |\n",
      "|    mean_step_reward   | 0.046522915 |\n",
      "|    n_updates          | 16/128      |\n",
      "|    policyGradLoss     | -0.0186     |\n",
      "|    value_loss         | 0.26        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 764         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 64          |\n",
      "|    total_timesteps    | 41205760    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020364365 |\n",
      "|    entropy_loss       | -2.13       |\n",
      "|    explained_variance | 0.942       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0647     |\n",
      "|    mean_step_reward   | 0.05201854  |\n",
      "|    n_updates          | 20/128      |\n",
      "|    policyGradLoss     | -0.0199     |\n",
      "|    value_loss         | 0.311       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 753         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 76          |\n",
      "|    total_timesteps    | 41213952    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017964967 |\n",
      "|    entropy_loss       | -2.11       |\n",
      "|    explained_variance | 0.891       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.015       |\n",
      "|    mean_step_reward   | 0.046909608 |\n",
      "|    n_updates          | 24/128      |\n",
      "|    policyGradLoss     | -0.0169     |\n",
      "|    value_loss         | 0.499       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 749        |\n",
      "|    iterations         | 8          |\n",
      "|    time_elapsed       | 87         |\n",
      "|    total_timesteps    | 41222144   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02677605 |\n",
      "|    entropy_loss       | -2.08      |\n",
      "|    explained_variance | 0.92       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0672    |\n",
      "|    mean_step_reward   | 0.04862753 |\n",
      "|    n_updates          | 28/128     |\n",
      "|    policyGradLoss     | -0.0169    |\n",
      "|    value_loss         | 0.42       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 748         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 98          |\n",
      "|    total_timesteps    | 41230336    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024203982 |\n",
      "|    entropy_loss       | -2.07       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0596     |\n",
      "|    mean_step_reward   | 0.06811588  |\n",
      "|    n_updates          | 32/128      |\n",
      "|    policyGradLoss     | -0.0219     |\n",
      "|    value_loss         | 0.167       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 747         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 109         |\n",
      "|    total_timesteps    | 41238528    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018121947 |\n",
      "|    entropy_loss       | -2.15       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0954     |\n",
      "|    mean_step_reward   | 0.04384722  |\n",
      "|    n_updates          | 36/128      |\n",
      "|    policyGradLoss     | -0.0223     |\n",
      "|    value_loss         | 0.131       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 743         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 121         |\n",
      "|    total_timesteps    | 41246720    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022939265 |\n",
      "|    entropy_loss       | -2.13       |\n",
      "|    explained_variance | 0.922       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0332     |\n",
      "|    mean_step_reward   | 0.04132168  |\n",
      "|    n_updates          | 40/128      |\n",
      "|    policyGradLoss     | -0.0188     |\n",
      "|    value_loss         | 0.273       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 740         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 132         |\n",
      "|    total_timesteps    | 41254912    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.033576712 |\n",
      "|    entropy_loss       | -2.13       |\n",
      "|    explained_variance | 0.937       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00627     |\n",
      "|    mean_step_reward   | 0.042459633 |\n",
      "|    n_updates          | 44/128      |\n",
      "|    policyGradLoss     | -0.0211     |\n",
      "|    value_loss         | 0.386       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 737         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 144         |\n",
      "|    total_timesteps    | 41263104    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.034674354 |\n",
      "|    entropy_loss       | -2.1        |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0983     |\n",
      "|    mean_step_reward   | 0.050484106 |\n",
      "|    n_updates          | 48/128      |\n",
      "|    policyGradLoss     | -0.0269     |\n",
      "|    value_loss         | 0.11        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 737        |\n",
      "|    iterations         | 14         |\n",
      "|    time_elapsed       | 155        |\n",
      "|    total_timesteps    | 41271296   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01720257 |\n",
      "|    entropy_loss       | -2.11      |\n",
      "|    explained_variance | 0.924      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.0606     |\n",
      "|    mean_step_reward   | 0.06696199 |\n",
      "|    n_updates          | 52/128     |\n",
      "|    policyGradLoss     | -0.0151    |\n",
      "|    value_loss         | 0.6        |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 736         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 166         |\n",
      "|    total_timesteps    | 41279488    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019713514 |\n",
      "|    entropy_loss       | -2.08       |\n",
      "|    explained_variance | 0.876       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0303     |\n",
      "|    mean_step_reward   | 0.051281855 |\n",
      "|    n_updates          | 56/128      |\n",
      "|    policyGradLoss     | -0.0146     |\n",
      "|    value_loss         | 0.506       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 736         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 178         |\n",
      "|    total_timesteps    | 41287680    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023295218 |\n",
      "|    entropy_loss       | -2.08       |\n",
      "|    explained_variance | 0.879       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0233     |\n",
      "|    mean_step_reward   | 0.05624798  |\n",
      "|    n_updates          | 60/128      |\n",
      "|    policyGradLoss     | -0.014      |\n",
      "|    value_loss         | 0.604       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 735         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 189         |\n",
      "|    total_timesteps    | 41295872    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.032052383 |\n",
      "|    entropy_loss       | -2.1        |\n",
      "|    explained_variance | 0.947       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0847     |\n",
      "|    mean_step_reward   | 0.049384743 |\n",
      "|    n_updates          | 64/128      |\n",
      "|    policyGradLoss     | -0.0238     |\n",
      "|    value_loss         | 0.136       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 733         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 201         |\n",
      "|    total_timesteps    | 41304064    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028816871 |\n",
      "|    entropy_loss       | -2.1        |\n",
      "|    explained_variance | 0.93        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0681     |\n",
      "|    mean_step_reward   | 0.043225907 |\n",
      "|    n_updates          | 68/128      |\n",
      "|    policyGradLoss     | -0.0184     |\n",
      "|    value_loss         | 0.288       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 732        |\n",
      "|    iterations         | 19         |\n",
      "|    time_elapsed       | 212        |\n",
      "|    total_timesteps    | 41312256   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03380961 |\n",
      "|    entropy_loss       | -2.18      |\n",
      "|    explained_variance | 0.953      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.112     |\n",
      "|    mean_step_reward   | 0.03604172 |\n",
      "|    n_updates          | 72/128     |\n",
      "|    policyGradLoss     | -0.0276    |\n",
      "|    value_loss         | 0.116      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 733         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 223         |\n",
      "|    total_timesteps    | 41320448    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020768495 |\n",
      "|    entropy_loss       | -2.16       |\n",
      "|    explained_variance | 0.942       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0597     |\n",
      "|    mean_step_reward   | 0.060184956 |\n",
      "|    n_updates          | 76/128      |\n",
      "|    policyGradLoss     | -0.0123     |\n",
      "|    value_loss         | 0.306       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 739         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 232         |\n",
      "|    total_timesteps    | 41328640    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02019988  |\n",
      "|    entropy_loss       | -2.13       |\n",
      "|    explained_variance | 0.931       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0165     |\n",
      "|    mean_step_reward   | 0.046415426 |\n",
      "|    n_updates          | 80/128      |\n",
      "|    policyGradLoss     | -0.0146     |\n",
      "|    value_loss         | 0.291       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 744         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 242         |\n",
      "|    total_timesteps    | 41336832    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025503617 |\n",
      "|    entropy_loss       | -2.14       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0892     |\n",
      "|    mean_step_reward   | 0.051516257 |\n",
      "|    n_updates          | 84/128      |\n",
      "|    policyGradLoss     | -0.0267     |\n",
      "|    value_loss         | 0.131       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 748         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 251         |\n",
      "|    total_timesteps    | 41345024    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029870022 |\n",
      "|    entropy_loss       | -2.14       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0792     |\n",
      "|    mean_step_reward   | 0.051444374 |\n",
      "|    n_updates          | 88/128      |\n",
      "|    policyGradLoss     | -0.0217     |\n",
      "|    value_loss         | 0.158       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 749         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 262         |\n",
      "|    total_timesteps    | 41353216    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022342414 |\n",
      "|    entropy_loss       | -2.13       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0603     |\n",
      "|    mean_step_reward   | 0.051117048 |\n",
      "|    n_updates          | 92/128      |\n",
      "|    policyGradLoss     | -0.0209     |\n",
      "|    value_loss         | 0.236       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 748         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 273         |\n",
      "|    total_timesteps    | 41361408    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02032344  |\n",
      "|    entropy_loss       | -2.12       |\n",
      "|    explained_variance | 0.903       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0696     |\n",
      "|    mean_step_reward   | 0.046092466 |\n",
      "|    n_updates          | 96/128      |\n",
      "|    policyGradLoss     | -0.0143     |\n",
      "|    value_loss         | 0.417       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 746         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 285         |\n",
      "|    total_timesteps    | 41369600    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028839888 |\n",
      "|    entropy_loss       | -2.16       |\n",
      "|    explained_variance | 0.932       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0403     |\n",
      "|    mean_step_reward   | 0.04327408  |\n",
      "|    n_updates          | 100/128     |\n",
      "|    policyGradLoss     | -0.0211     |\n",
      "|    value_loss         | 0.202       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 745        |\n",
      "|    iterations         | 27         |\n",
      "|    time_elapsed       | 296        |\n",
      "|    total_timesteps    | 41377792   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02360025 |\n",
      "|    entropy_loss       | -2.17      |\n",
      "|    explained_variance | 0.957      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0506    |\n",
      "|    mean_step_reward   | 0.03612562 |\n",
      "|    n_updates          | 104/128    |\n",
      "|    policyGradLoss     | -0.0221    |\n",
      "|    value_loss         | 0.238      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 744        |\n",
      "|    iterations         | 28         |\n",
      "|    time_elapsed       | 308        |\n",
      "|    total_timesteps    | 41385984   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02464747 |\n",
      "|    entropy_loss       | -2.19      |\n",
      "|    explained_variance | 0.864      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0653    |\n",
      "|    mean_step_reward   | 0.02671056 |\n",
      "|    n_updates          | 108/128    |\n",
      "|    policyGradLoss     | -0.0181    |\n",
      "|    value_loss         | 0.285      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 744         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 319         |\n",
      "|    total_timesteps    | 41394176    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02999831  |\n",
      "|    entropy_loss       | -2.19       |\n",
      "|    explained_variance | 0.947       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0962     |\n",
      "|    mean_step_reward   | 0.035748925 |\n",
      "|    n_updates          | 112/128     |\n",
      "|    policyGradLoss     | -0.0231     |\n",
      "|    value_loss         | 0.122       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 743         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 330         |\n",
      "|    total_timesteps    | 41402368    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025648184 |\n",
      "|    entropy_loss       | -2.14       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0861     |\n",
      "|    mean_step_reward   | 0.060179833 |\n",
      "|    n_updates          | 116/128     |\n",
      "|    policyGradLoss     | -0.0182     |\n",
      "|    value_loss         | 0.175       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 742         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 341         |\n",
      "|    total_timesteps    | 41410560    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028685894 |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.904       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0938     |\n",
      "|    mean_step_reward   | 0.02734401  |\n",
      "|    n_updates          | 120/128     |\n",
      "|    policyGradLoss     | -0.0199     |\n",
      "|    value_loss         | 0.124       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 741         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 353         |\n",
      "|    total_timesteps    | 41418752    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023249436 |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.947       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0976     |\n",
      "|    mean_step_reward   | 0.040074773 |\n",
      "|    n_updates          | 124/128     |\n",
      "|    policyGradLoss     | -0.0181     |\n",
      "|    value_loss         | 0.207       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/NoArti_157.zip\n",
      "[EVAL] Mean Return: 133.541, Best Return: 135.941\n",
      "Saved video to ./runs_smw/videos/NoArti/NoArti_157_133.54.mp4\n",
      "\n",
      "=== Round 159 | Learn 262144 steps (Total trained: 41418752) ===\n",
      "Logging to ./runs_smw/tb/NoArti_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1181     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 41426944 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 899         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 41435136    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027427636 |\n",
      "|    entropy_loss       | -2.13       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0966     |\n",
      "|    mean_step_reward   | 0.054117806 |\n",
      "|    n_updates          | 4/128       |\n",
      "|    policyGradLoss     | -0.0224     |\n",
      "|    value_loss         | 0.177       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 833         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 29          |\n",
      "|    total_timesteps    | 41443328    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020380598 |\n",
      "|    entropy_loss       | -2.14       |\n",
      "|    explained_variance | 0.878       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00694    |\n",
      "|    mean_step_reward   | 0.039823215 |\n",
      "|    n_updates          | 8/128       |\n",
      "|    policyGradLoss     | -0.02       |\n",
      "|    value_loss         | 0.416       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 794         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 41          |\n",
      "|    total_timesteps    | 41451520    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027595533 |\n",
      "|    entropy_loss       | -2.14       |\n",
      "|    explained_variance | 0.945       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0588     |\n",
      "|    mean_step_reward   | 0.046326518 |\n",
      "|    n_updates          | 12/128      |\n",
      "|    policyGradLoss     | -0.0215     |\n",
      "|    value_loss         | 0.202       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 52          |\n",
      "|    total_timesteps    | 41459712    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023556441 |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0846     |\n",
      "|    mean_step_reward   | 0.042574495 |\n",
      "|    n_updates          | 16/128      |\n",
      "|    policyGradLoss     | -0.0211     |\n",
      "|    value_loss         | 0.129       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 63          |\n",
      "|    total_timesteps    | 41467904    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018770367 |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.895       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0289     |\n",
      "|    mean_step_reward   | 0.021666475 |\n",
      "|    n_updates          | 20/128      |\n",
      "|    policyGradLoss     | -0.0166     |\n",
      "|    value_loss         | 0.267       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 763         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 75          |\n",
      "|    total_timesteps    | 41476096    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022553064 |\n",
      "|    entropy_loss       | -2.19       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0953     |\n",
      "|    mean_step_reward   | 0.046535812 |\n",
      "|    n_updates          | 24/128      |\n",
      "|    policyGradLoss     | -0.0166     |\n",
      "|    value_loss         | 0.121       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 759        |\n",
      "|    iterations         | 8          |\n",
      "|    time_elapsed       | 86         |\n",
      "|    total_timesteps    | 41484288   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02666089 |\n",
      "|    entropy_loss       | -2.17      |\n",
      "|    explained_variance | 0.908      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0242    |\n",
      "|    mean_step_reward   | 0.03645702 |\n",
      "|    n_updates          | 28/128     |\n",
      "|    policyGradLoss     | -0.0134    |\n",
      "|    value_loss         | 0.379      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 754         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 97          |\n",
      "|    total_timesteps    | 41492480    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01779677  |\n",
      "|    entropy_loss       | -2.19       |\n",
      "|    explained_variance | 0.928       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0261     |\n",
      "|    mean_step_reward   | 0.040362824 |\n",
      "|    n_updates          | 32/128      |\n",
      "|    policyGradLoss     | -0.0129     |\n",
      "|    value_loss         | 0.3         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 749         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 109         |\n",
      "|    total_timesteps    | 41500672    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01379253  |\n",
      "|    entropy_loss       | -2.11       |\n",
      "|    explained_variance | 0.941       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0397     |\n",
      "|    mean_step_reward   | 0.055335462 |\n",
      "|    n_updates          | 36/128      |\n",
      "|    policyGradLoss     | -0.015      |\n",
      "|    value_loss         | 0.294       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 746         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 120         |\n",
      "|    total_timesteps    | 41508864    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023415111 |\n",
      "|    entropy_loss       | -2.06       |\n",
      "|    explained_variance | 0.925       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.057      |\n",
      "|    mean_step_reward   | 0.06133248  |\n",
      "|    n_updates          | 40/128      |\n",
      "|    policyGradLoss     | -0.0188     |\n",
      "|    value_loss         | 0.301       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 746         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 131         |\n",
      "|    total_timesteps    | 41517056    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028038811 |\n",
      "|    entropy_loss       | -2.08       |\n",
      "|    explained_variance | 0.944       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0745     |\n",
      "|    mean_step_reward   | 0.056427278 |\n",
      "|    n_updates          | 44/128      |\n",
      "|    policyGradLoss     | -0.0166     |\n",
      "|    value_loss         | 0.237       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 746         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 142         |\n",
      "|    total_timesteps    | 41525248    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020681757 |\n",
      "|    entropy_loss       | -2.13       |\n",
      "|    explained_variance | 0.935       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0524     |\n",
      "|    mean_step_reward   | 0.05797164  |\n",
      "|    n_updates          | 48/128      |\n",
      "|    policyGradLoss     | -0.0115     |\n",
      "|    value_loss         | 0.327       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 745         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 153         |\n",
      "|    total_timesteps    | 41533440    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027306559 |\n",
      "|    entropy_loss       | -2.14       |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0564     |\n",
      "|    mean_step_reward   | 0.04749056  |\n",
      "|    n_updates          | 52/128      |\n",
      "|    policyGradLoss     | -0.0182     |\n",
      "|    value_loss         | 0.135       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 742         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 165         |\n",
      "|    total_timesteps    | 41541632    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028624479 |\n",
      "|    entropy_loss       | -2.17       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.103      |\n",
      "|    mean_step_reward   | 0.04709156  |\n",
      "|    n_updates          | 56/128      |\n",
      "|    policyGradLoss     | -0.0225     |\n",
      "|    value_loss         | 0.105       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 739         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 177         |\n",
      "|    total_timesteps    | 41549824    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.03383068  |\n",
      "|    entropy_loss       | -2.19       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.107      |\n",
      "|    mean_step_reward   | 0.030738376 |\n",
      "|    n_updates          | 60/128      |\n",
      "|    policyGradLoss     | -0.025      |\n",
      "|    value_loss         | 0.114       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 739         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 188         |\n",
      "|    total_timesteps    | 41558016    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020525172 |\n",
      "|    entropy_loss       | -2.15       |\n",
      "|    explained_variance | 0.955       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0454     |\n",
      "|    mean_step_reward   | 0.043091565 |\n",
      "|    n_updates          | 64/128      |\n",
      "|    policyGradLoss     | -0.0155     |\n",
      "|    value_loss         | 0.264       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 739         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 199         |\n",
      "|    total_timesteps    | 41566208    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021395065 |\n",
      "|    entropy_loss       | -2.15       |\n",
      "|    explained_variance | 0.925       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00802    |\n",
      "|    mean_step_reward   | 0.04678444  |\n",
      "|    n_updates          | 68/128      |\n",
      "|    policyGradLoss     | -0.0166     |\n",
      "|    value_loss         | 0.333       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 747         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 208         |\n",
      "|    total_timesteps    | 41574400    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02220693  |\n",
      "|    entropy_loss       | -2.12       |\n",
      "|    explained_variance | 0.952       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0486     |\n",
      "|    mean_step_reward   | 0.057312995 |\n",
      "|    n_updates          | 72/128      |\n",
      "|    policyGradLoss     | -0.0202     |\n",
      "|    value_loss         | 0.196       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 752         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 217         |\n",
      "|    total_timesteps    | 41582592    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024477102 |\n",
      "|    entropy_loss       | -2.1        |\n",
      "|    explained_variance | 0.952       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00325    |\n",
      "|    mean_step_reward   | 0.05346732  |\n",
      "|    n_updates          | 76/128      |\n",
      "|    policyGradLoss     | -0.0178     |\n",
      "|    value_loss         | 0.288       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 757         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 227         |\n",
      "|    total_timesteps    | 41590784    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021715594 |\n",
      "|    entropy_loss       | -2.02       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0783     |\n",
      "|    mean_step_reward   | 0.080375314 |\n",
      "|    n_updates          | 80/128      |\n",
      "|    policyGradLoss     | -0.0202     |\n",
      "|    value_loss         | 0.183       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 756         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 238         |\n",
      "|    total_timesteps    | 41598976    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020111186 |\n",
      "|    entropy_loss       | -2.05       |\n",
      "|    explained_variance | 0.949       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0235     |\n",
      "|    mean_step_reward   | 0.06063828  |\n",
      "|    n_updates          | 84/128      |\n",
      "|    policyGradLoss     | -0.0185     |\n",
      "|    value_loss         | 0.374       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 753         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 250         |\n",
      "|    total_timesteps    | 41607168    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022925235 |\n",
      "|    entropy_loss       | -2.1        |\n",
      "|    explained_variance | 0.957       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0663     |\n",
      "|    mean_step_reward   | 0.06146688  |\n",
      "|    n_updates          | 88/128      |\n",
      "|    policyGradLoss     | -0.0213     |\n",
      "|    value_loss         | 0.192       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 752         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 261         |\n",
      "|    total_timesteps    | 41615360    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026305942 |\n",
      "|    entropy_loss       | -2.11       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0876     |\n",
      "|    mean_step_reward   | 0.06497013  |\n",
      "|    n_updates          | 92/128      |\n",
      "|    policyGradLoss     | -0.0227     |\n",
      "|    value_loss         | 0.13        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 751         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 272         |\n",
      "|    total_timesteps    | 41623552    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019897465 |\n",
      "|    entropy_loss       | -2.1        |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0621     |\n",
      "|    mean_step_reward   | 0.064563215 |\n",
      "|    n_updates          | 96/128      |\n",
      "|    policyGradLoss     | -0.0182     |\n",
      "|    value_loss         | 0.16        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 750         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 283         |\n",
      "|    total_timesteps    | 41631744    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01996674  |\n",
      "|    entropy_loss       | -2.09       |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.058      |\n",
      "|    mean_step_reward   | 0.066310816 |\n",
      "|    n_updates          | 100/128     |\n",
      "|    policyGradLoss     | -0.0166     |\n",
      "|    value_loss         | 0.247       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 750         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 294         |\n",
      "|    total_timesteps    | 41639936    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024093669 |\n",
      "|    entropy_loss       | -2.03       |\n",
      "|    explained_variance | 0.928       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0497     |\n",
      "|    mean_step_reward   | 0.069126494 |\n",
      "|    n_updates          | 104/128     |\n",
      "|    policyGradLoss     | -0.0108     |\n",
      "|    value_loss         | 0.522       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 749         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 306         |\n",
      "|    total_timesteps    | 41648128    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023781525 |\n",
      "|    entropy_loss       | -2.08       |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0409     |\n",
      "|    mean_step_reward   | 0.06146872  |\n",
      "|    n_updates          | 108/128     |\n",
      "|    policyGradLoss     | -0.0178     |\n",
      "|    value_loss         | 0.326       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 747         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 317         |\n",
      "|    total_timesteps    | 41656320    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020834826 |\n",
      "|    entropy_loss       | -2.06       |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00177    |\n",
      "|    mean_step_reward   | 0.07214642  |\n",
      "|    n_updates          | 112/128     |\n",
      "|    policyGradLoss     | -0.0178     |\n",
      "|    value_loss         | 0.297       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 746         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 329         |\n",
      "|    total_timesteps    | 41664512    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024984682 |\n",
      "|    entropy_loss       | -2.04       |\n",
      "|    explained_variance | 0.892       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0293     |\n",
      "|    mean_step_reward   | 0.06007944  |\n",
      "|    n_updates          | 116/128     |\n",
      "|    policyGradLoss     | -0.0115     |\n",
      "|    value_loss         | 0.539       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 745         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 340         |\n",
      "|    total_timesteps    | 41672704    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016424846 |\n",
      "|    entropy_loss       | -2.13       |\n",
      "|    explained_variance | 0.921       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0365     |\n",
      "|    mean_step_reward   | 0.062174704 |\n",
      "|    n_updates          | 120/128     |\n",
      "|    policyGradLoss     | -0.0132     |\n",
      "|    value_loss         | 0.298       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 744         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 351         |\n",
      "|    total_timesteps    | 41680896    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02136283  |\n",
      "|    entropy_loss       | -2.12       |\n",
      "|    explained_variance | 0.937       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.048      |\n",
      "|    mean_step_reward   | 0.056935236 |\n",
      "|    n_updates          | 124/128     |\n",
      "|    policyGradLoss     | -0.0134     |\n",
      "|    value_loss         | 0.309       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/NoArti_158.zip\n",
      "[EVAL] Mean Return: 3.929, Best Return: 5.737\n",
      "Saved video to ./runs_smw/videos/NoArti/NoArti_158_3.93.mp4\n",
      "\n",
      "=== Round 160 | Learn 262144 steps (Total trained: 41680896) ===\n",
      "Logging to ./runs_smw/tb/NoArti_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1129     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 41689088 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 865         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 41697280    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.0188803   |\n",
      "|    entropy_loss       | -2.16       |\n",
      "|    explained_variance | 0.895       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0668     |\n",
      "|    mean_step_reward   | 0.039294396 |\n",
      "|    n_updates          | 4/128       |\n",
      "|    policyGradLoss     | -0.0131     |\n",
      "|    value_loss         | 0.305       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 809        |\n",
      "|    iterations         | 3          |\n",
      "|    time_elapsed       | 30         |\n",
      "|    total_timesteps    | 41705472   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02297247 |\n",
      "|    entropy_loss       | -2.05      |\n",
      "|    explained_variance | 0.873      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.195      |\n",
      "|    mean_step_reward   | 0.06211729 |\n",
      "|    n_updates          | 8/128      |\n",
      "|    policyGradLoss     | -0.0106    |\n",
      "|    value_loss         | 0.625      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 792         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 41          |\n",
      "|    total_timesteps    | 41713664    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021517072 |\n",
      "|    entropy_loss       | -2.09       |\n",
      "|    explained_variance | 0.945       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0318     |\n",
      "|    mean_step_reward   | 0.06921757  |\n",
      "|    n_updates          | 12/128      |\n",
      "|    policyGradLoss     | -0.0196     |\n",
      "|    value_loss         | 0.213       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 52          |\n",
      "|    total_timesteps    | 41721856    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018953571 |\n",
      "|    entropy_loss       | -2.11       |\n",
      "|    explained_variance | 0.95        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0184     |\n",
      "|    mean_step_reward   | 0.061741192 |\n",
      "|    n_updates          | 16/128      |\n",
      "|    policyGradLoss     | -0.0175     |\n",
      "|    value_loss         | 0.323       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 63          |\n",
      "|    total_timesteps    | 41730048    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025876118 |\n",
      "|    entropy_loss       | -2.16       |\n",
      "|    explained_variance | 0.958       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0995     |\n",
      "|    mean_step_reward   | 0.04860896  |\n",
      "|    n_updates          | 20/128      |\n",
      "|    policyGradLoss     | -0.0209     |\n",
      "|    value_loss         | 0.134       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 74          |\n",
      "|    total_timesteps    | 41738240    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01928852  |\n",
      "|    entropy_loss       | -2.14       |\n",
      "|    explained_variance | 0.895       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0468     |\n",
      "|    mean_step_reward   | 0.044865556 |\n",
      "|    n_updates          | 24/128      |\n",
      "|    policyGradLoss     | -0.0163     |\n",
      "|    value_loss         | 0.458       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 760         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 86          |\n",
      "|    total_timesteps    | 41746432    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015980544 |\n",
      "|    entropy_loss       | -2.08       |\n",
      "|    explained_variance | 0.897       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0267     |\n",
      "|    mean_step_reward   | 0.063982144 |\n",
      "|    n_updates          | 28/128      |\n",
      "|    policyGradLoss     | -0.0122     |\n",
      "|    value_loss         | 0.366       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 756         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 97          |\n",
      "|    total_timesteps    | 41754624    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023585372 |\n",
      "|    entropy_loss       | -2.08       |\n",
      "|    explained_variance | 0.922       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0799     |\n",
      "|    mean_step_reward   | 0.06580711  |\n",
      "|    n_updates          | 32/128      |\n",
      "|    policyGradLoss     | -0.0146     |\n",
      "|    value_loss         | 0.2         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 754         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 108         |\n",
      "|    total_timesteps    | 41762816    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020997839 |\n",
      "|    entropy_loss       | -2.13       |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0434     |\n",
      "|    mean_step_reward   | 0.064247444 |\n",
      "|    n_updates          | 36/128      |\n",
      "|    policyGradLoss     | -0.0143     |\n",
      "|    value_loss         | 0.297       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 754        |\n",
      "|    iterations         | 11         |\n",
      "|    time_elapsed       | 119        |\n",
      "|    total_timesteps    | 41771008   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02400555 |\n",
      "|    entropy_loss       | -2.11      |\n",
      "|    explained_variance | 0.948      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0445    |\n",
      "|    mean_step_reward   | 0.05485931 |\n",
      "|    n_updates          | 40/128     |\n",
      "|    policyGradLoss     | -0.0216    |\n",
      "|    value_loss         | 0.244      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 763         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 128         |\n",
      "|    total_timesteps    | 41779200    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023814024 |\n",
      "|    entropy_loss       | -2.11       |\n",
      "|    explained_variance | 0.932       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0406     |\n",
      "|    mean_step_reward   | 0.049777042 |\n",
      "|    n_updates          | 44/128      |\n",
      "|    policyGradLoss     | -0.0159     |\n",
      "|    value_loss         | 0.369       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 138         |\n",
      "|    total_timesteps    | 41787392    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024950897 |\n",
      "|    entropy_loss       | -2.09       |\n",
      "|    explained_variance | 0.958       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0467     |\n",
      "|    mean_step_reward   | 0.065621674 |\n",
      "|    n_updates          | 48/128      |\n",
      "|    policyGradLoss     | -0.022      |\n",
      "|    value_loss         | 0.181       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 147         |\n",
      "|    total_timesteps    | 41795584    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02175394  |\n",
      "|    entropy_loss       | -2.09       |\n",
      "|    explained_variance | 0.936       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0225      |\n",
      "|    mean_step_reward   | 0.060343802 |\n",
      "|    n_updates          | 52/128      |\n",
      "|    policyGradLoss     | -0.0163     |\n",
      "|    value_loss         | 0.54        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 158         |\n",
      "|    total_timesteps    | 41803776    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018431293 |\n",
      "|    entropy_loss       | -2.08       |\n",
      "|    explained_variance | 0.856       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.055       |\n",
      "|    mean_step_reward   | 0.06337522  |\n",
      "|    n_updates          | 56/128      |\n",
      "|    policyGradLoss     | -0.0141     |\n",
      "|    value_loss         | 0.469       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 771        |\n",
      "|    iterations         | 16         |\n",
      "|    time_elapsed       | 169        |\n",
      "|    total_timesteps    | 41811968   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02448747 |\n",
      "|    entropy_loss       | -2.07      |\n",
      "|    explained_variance | 0.923      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.031     |\n",
      "|    mean_step_reward   | 0.07220769 |\n",
      "|    n_updates          | 60/128     |\n",
      "|    policyGradLoss     | -0.0156    |\n",
      "|    value_loss         | 0.519      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 181         |\n",
      "|    total_timesteps    | 41820160    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021923894 |\n",
      "|    entropy_loss       | -2.1        |\n",
      "|    explained_variance | 0.867       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.193       |\n",
      "|    mean_step_reward   | 0.045589715 |\n",
      "|    n_updates          | 64/128      |\n",
      "|    policyGradLoss     | -0.0126     |\n",
      "|    value_loss         | 0.615       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 767        |\n",
      "|    iterations         | 18         |\n",
      "|    time_elapsed       | 192        |\n",
      "|    total_timesteps    | 41828352   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02057889 |\n",
      "|    entropy_loss       | -2.06      |\n",
      "|    explained_variance | 0.933      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.0168     |\n",
      "|    mean_step_reward   | 0.07095542 |\n",
      "|    n_updates          | 68/128     |\n",
      "|    policyGradLoss     | -0.0151    |\n",
      "|    value_loss         | 0.418      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 765         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 203         |\n",
      "|    total_timesteps    | 41836544    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016006237 |\n",
      "|    entropy_loss       | -2.09       |\n",
      "|    explained_variance | 0.856       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0446     |\n",
      "|    mean_step_reward   | 0.05476031  |\n",
      "|    n_updates          | 72/128      |\n",
      "|    policyGradLoss     | -0.0154     |\n",
      "|    value_loss         | 0.552       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 764         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 214         |\n",
      "|    total_timesteps    | 41844736    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018757889 |\n",
      "|    entropy_loss       | -2.15       |\n",
      "|    explained_variance | 0.828       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00392    |\n",
      "|    mean_step_reward   | 0.04589005  |\n",
      "|    n_updates          | 76/128      |\n",
      "|    policyGradLoss     | -0.0143     |\n",
      "|    value_loss         | 0.587       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 761         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 225         |\n",
      "|    total_timesteps    | 41852928    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020147294 |\n",
      "|    entropy_loss       | -2.15       |\n",
      "|    explained_variance | 0.826       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0476     |\n",
      "|    mean_step_reward   | 0.038707055 |\n",
      "|    n_updates          | 80/128      |\n",
      "|    policyGradLoss     | -0.012      |\n",
      "|    value_loss         | 0.379       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 758         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 237         |\n",
      "|    total_timesteps    | 41861120    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019239616 |\n",
      "|    entropy_loss       | -2.13       |\n",
      "|    explained_variance | 0.776       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.059      |\n",
      "|    mean_step_reward   | 0.048200116 |\n",
      "|    n_updates          | 84/128      |\n",
      "|    policyGradLoss     | -0.0154     |\n",
      "|    value_loss         | 0.553       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 757         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 248         |\n",
      "|    total_timesteps    | 41869312    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017819982 |\n",
      "|    entropy_loss       | -2.16       |\n",
      "|    explained_variance | 0.829       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.057      |\n",
      "|    mean_step_reward   | 0.03771173  |\n",
      "|    n_updates          | 88/128      |\n",
      "|    policyGradLoss     | -0.0152     |\n",
      "|    value_loss         | 0.329       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 757         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 259         |\n",
      "|    total_timesteps    | 41877504    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02069419  |\n",
      "|    entropy_loss       | -2.08       |\n",
      "|    explained_variance | 0.857       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0118     |\n",
      "|    mean_step_reward   | 0.059838876 |\n",
      "|    n_updates          | 92/128      |\n",
      "|    policyGradLoss     | -0.0117     |\n",
      "|    value_loss         | 0.54        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 757         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 270         |\n",
      "|    total_timesteps    | 41885696    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023071665 |\n",
      "|    entropy_loss       | -2.11       |\n",
      "|    explained_variance | 0.899       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0296     |\n",
      "|    mean_step_reward   | 0.0655884   |\n",
      "|    n_updates          | 96/128      |\n",
      "|    policyGradLoss     | -0.0136     |\n",
      "|    value_loss         | 0.37        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 755         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 281         |\n",
      "|    total_timesteps    | 41893888    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030979872 |\n",
      "|    entropy_loss       | -2.15       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0941     |\n",
      "|    mean_step_reward   | 0.05042771  |\n",
      "|    n_updates          | 100/128     |\n",
      "|    policyGradLoss     | -0.0208     |\n",
      "|    value_loss         | 0.114       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 753         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 293         |\n",
      "|    total_timesteps    | 41902080    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017963849 |\n",
      "|    entropy_loss       | -2.15       |\n",
      "|    explained_variance | 0.952       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.042      |\n",
      "|    mean_step_reward   | 0.04513494  |\n",
      "|    n_updates          | 104/128     |\n",
      "|    policyGradLoss     | -0.016      |\n",
      "|    value_loss         | 0.231       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 751         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 305         |\n",
      "|    total_timesteps    | 41910272    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016449314 |\n",
      "|    entropy_loss       | -2.13       |\n",
      "|    explained_variance | 0.89        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0284     |\n",
      "|    mean_step_reward   | 0.0667689   |\n",
      "|    n_updates          | 108/128     |\n",
      "|    policyGradLoss     | -0.0112     |\n",
      "|    value_loss         | 0.457       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 752         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 315         |\n",
      "|    total_timesteps    | 41918464    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023975566 |\n",
      "|    entropy_loss       | -2.14       |\n",
      "|    explained_variance | 0.941       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0544     |\n",
      "|    mean_step_reward   | 0.049294017 |\n",
      "|    n_updates          | 112/128     |\n",
      "|    policyGradLoss     | -0.0177     |\n",
      "|    value_loss         | 0.234       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 751         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 326         |\n",
      "|    total_timesteps    | 41926656    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017396789 |\n",
      "|    entropy_loss       | -2.11       |\n",
      "|    explained_variance | 0.904       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0676     |\n",
      "|    mean_step_reward   | 0.06303905  |\n",
      "|    n_updates          | 116/128     |\n",
      "|    policyGradLoss     | -0.0147     |\n",
      "|    value_loss         | 0.48        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 750         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 338         |\n",
      "|    total_timesteps    | 41934848    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022229288 |\n",
      "|    entropy_loss       | -2.08       |\n",
      "|    explained_variance | 0.957       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0812     |\n",
      "|    mean_step_reward   | 0.061331585 |\n",
      "|    n_updates          | 120/128     |\n",
      "|    policyGradLoss     | -0.021      |\n",
      "|    value_loss         | 0.215       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 749         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 349         |\n",
      "|    total_timesteps    | 41943040    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021934982 |\n",
      "|    entropy_loss       | -2.07       |\n",
      "|    explained_variance | 0.949       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0596     |\n",
      "|    mean_step_reward   | 0.06264225  |\n",
      "|    n_updates          | 124/128     |\n",
      "|    policyGradLoss     | -0.0165     |\n",
      "|    value_loss         | 0.278       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/NoArti_159.zip\n",
      "[EVAL] Mean Return: 132.828, Best Return: 135.428\n",
      "Saved video to ./runs_smw/videos/NoArti/NoArti_159_132.83.mp4\n",
      "\n",
      "=== Round 161 | Learn 262144 steps (Total trained: 41943040) ===\n",
      "Logging to ./runs_smw/tb/NoArti_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1160     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 41951232 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 898         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 41959424    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023676105 |\n",
      "|    entropy_loss       | -2.1        |\n",
      "|    explained_variance | 0.868       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0684     |\n",
      "|    mean_step_reward   | 0.036877878 |\n",
      "|    n_updates          | 4/128       |\n",
      "|    policyGradLoss     | -0.0204     |\n",
      "|    value_loss         | 0.304       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 843        |\n",
      "|    iterations         | 3          |\n",
      "|    time_elapsed       | 29         |\n",
      "|    total_timesteps    | 41967616   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02426407 |\n",
      "|    entropy_loss       | -2.07      |\n",
      "|    explained_variance | 0.952      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0649    |\n",
      "|    mean_step_reward   | 0.06558718 |\n",
      "|    n_updates          | 8/128      |\n",
      "|    policyGradLoss     | -0.0221    |\n",
      "|    value_loss         | 0.213      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 809         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 40          |\n",
      "|    total_timesteps    | 41975808    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019317985 |\n",
      "|    entropy_loss       | -2.08       |\n",
      "|    explained_variance | 0.958       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00388    |\n",
      "|    mean_step_reward   | 0.07133949  |\n",
      "|    n_updates          | 12/128      |\n",
      "|    policyGradLoss     | -0.0162     |\n",
      "|    value_loss         | 0.351       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 52          |\n",
      "|    total_timesteps    | 41984000    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027694916 |\n",
      "|    entropy_loss       | -2.05       |\n",
      "|    explained_variance | 0.944       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.043      |\n",
      "|    mean_step_reward   | 0.05893843  |\n",
      "|    n_updates          | 16/128      |\n",
      "|    policyGradLoss     | -0.0173     |\n",
      "|    value_loss         | 0.291       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 63          |\n",
      "|    total_timesteps    | 41992192    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02286223  |\n",
      "|    entropy_loss       | -2.15       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.077      |\n",
      "|    mean_step_reward   | 0.059507202 |\n",
      "|    n_updates          | 20/128      |\n",
      "|    policyGradLoss     | -0.0183     |\n",
      "|    value_loss         | 0.22        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 74          |\n",
      "|    total_timesteps    | 42000384    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015125939 |\n",
      "|    entropy_loss       | -2.2        |\n",
      "|    explained_variance | 0.928       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0414     |\n",
      "|    mean_step_reward   | 0.037166182 |\n",
      "|    n_updates          | 24/128      |\n",
      "|    policyGradLoss     | -0.0182     |\n",
      "|    value_loss         | 0.223       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 763         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 85          |\n",
      "|    total_timesteps    | 42008576    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025395263 |\n",
      "|    entropy_loss       | -2.14       |\n",
      "|    explained_variance | 0.955       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0585     |\n",
      "|    mean_step_reward   | 0.0550597   |\n",
      "|    n_updates          | 28/128      |\n",
      "|    policyGradLoss     | -0.0185     |\n",
      "|    value_loss         | 0.228       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 759         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 97          |\n",
      "|    total_timesteps    | 42016768    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019216761 |\n",
      "|    entropy_loss       | -2.16       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.081      |\n",
      "|    mean_step_reward   | 0.05175984  |\n",
      "|    n_updates          | 32/128      |\n",
      "|    policyGradLoss     | -0.0213     |\n",
      "|    value_loss         | 0.179       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 106         |\n",
      "|    total_timesteps    | 42024960    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020018622 |\n",
      "|    entropy_loss       | -2.12       |\n",
      "|    explained_variance | 0.941       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0259      |\n",
      "|    mean_step_reward   | 0.057014868 |\n",
      "|    n_updates          | 36/128      |\n",
      "|    policyGradLoss     | -0.0162     |\n",
      "|    value_loss         | 0.43        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 115         |\n",
      "|    total_timesteps    | 42033152    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023323368 |\n",
      "|    entropy_loss       | -2.09       |\n",
      "|    explained_variance | 0.927       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0662     |\n",
      "|    mean_step_reward   | 0.0508388   |\n",
      "|    n_updates          | 40/128      |\n",
      "|    policyGradLoss     | -0.021      |\n",
      "|    value_loss         | 0.266       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 788         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 124         |\n",
      "|    total_timesteps    | 42041344    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018937534 |\n",
      "|    entropy_loss       | -2.2        |\n",
      "|    explained_variance | 0.944       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0503     |\n",
      "|    mean_step_reward   | 0.05091782  |\n",
      "|    n_updates          | 44/128      |\n",
      "|    policyGradLoss     | -0.011      |\n",
      "|    value_loss         | 0.396       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 789         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 134         |\n",
      "|    total_timesteps    | 42049536    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019574545 |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.921       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0645     |\n",
      "|    mean_step_reward   | 0.036069565 |\n",
      "|    n_updates          | 48/128      |\n",
      "|    policyGradLoss     | -0.0138     |\n",
      "|    value_loss         | 0.246       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 145         |\n",
      "|    total_timesteps    | 42057728    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022737961 |\n",
      "|    entropy_loss       | -2.09       |\n",
      "|    explained_variance | 0.954       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0809     |\n",
      "|    mean_step_reward   | 0.06346832  |\n",
      "|    n_updates          | 52/128      |\n",
      "|    policyGradLoss     | -0.0193     |\n",
      "|    value_loss         | 0.255       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 157         |\n",
      "|    total_timesteps    | 42065920    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021947749 |\n",
      "|    entropy_loss       | -2.1        |\n",
      "|    explained_variance | 0.958       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0186     |\n",
      "|    mean_step_reward   | 0.066917464 |\n",
      "|    n_updates          | 56/128      |\n",
      "|    policyGradLoss     | -0.0193     |\n",
      "|    value_loss         | 0.305       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 168         |\n",
      "|    total_timesteps    | 42074112    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024414998 |\n",
      "|    entropy_loss       | -2.13       |\n",
      "|    explained_variance | 0.924       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.081      |\n",
      "|    mean_step_reward   | 0.040641353 |\n",
      "|    n_updates          | 60/128      |\n",
      "|    policyGradLoss     | -0.0227     |\n",
      "|    value_loss         | 0.233       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 180         |\n",
      "|    total_timesteps    | 42082304    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019278375 |\n",
      "|    entropy_loss       | -2.13       |\n",
      "|    explained_variance | 0.899       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0767     |\n",
      "|    mean_step_reward   | 0.034176037 |\n",
      "|    n_updates          | 64/128      |\n",
      "|    policyGradLoss     | -0.0186     |\n",
      "|    value_loss         | 0.294       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 191         |\n",
      "|    total_timesteps    | 42090496    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01536488  |\n",
      "|    entropy_loss       | -2.15       |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0247     |\n",
      "|    mean_step_reward   | 0.081948176 |\n",
      "|    n_updates          | 68/128      |\n",
      "|    policyGradLoss     | -0.0109     |\n",
      "|    value_loss         | 0.313       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 202         |\n",
      "|    total_timesteps    | 42098688    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018845828 |\n",
      "|    entropy_loss       | -2.15       |\n",
      "|    explained_variance | 0.955       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0785     |\n",
      "|    mean_step_reward   | 0.041264623 |\n",
      "|    n_updates          | 72/128      |\n",
      "|    policyGradLoss     | -0.0196     |\n",
      "|    value_loss         | 0.165       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 213         |\n",
      "|    total_timesteps    | 42106880    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014674874 |\n",
      "|    entropy_loss       | -2.14       |\n",
      "|    explained_variance | 0.848       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.159       |\n",
      "|    mean_step_reward   | 0.043839477 |\n",
      "|    n_updates          | 76/128      |\n",
      "|    policyGradLoss     | -0.0144     |\n",
      "|    value_loss         | 0.572       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 765         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 224         |\n",
      "|    total_timesteps    | 42115072    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020723373 |\n",
      "|    entropy_loss       | -2.11       |\n",
      "|    explained_variance | 0.955       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0492     |\n",
      "|    mean_step_reward   | 0.060295366 |\n",
      "|    n_updates          | 80/128      |\n",
      "|    policyGradLoss     | -0.0204     |\n",
      "|    value_loss         | 0.276       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 762         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 236         |\n",
      "|    total_timesteps    | 42123264    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024794772 |\n",
      "|    entropy_loss       | -2.17       |\n",
      "|    explained_variance | 0.957       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0616     |\n",
      "|    mean_step_reward   | 0.05397755  |\n",
      "|    n_updates          | 84/128      |\n",
      "|    policyGradLoss     | -0.0246     |\n",
      "|    value_loss         | 0.137       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 759         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 247         |\n",
      "|    total_timesteps    | 42131456    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020605993 |\n",
      "|    entropy_loss       | -2.18       |\n",
      "|    explained_variance | 0.892       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.032      |\n",
      "|    mean_step_reward   | 0.033839524 |\n",
      "|    n_updates          | 88/128      |\n",
      "|    policyGradLoss     | -0.0134     |\n",
      "|    value_loss         | 0.349       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 758         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 259         |\n",
      "|    total_timesteps    | 42139648    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021636125 |\n",
      "|    entropy_loss       | -2.18       |\n",
      "|    explained_variance | 0.958       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0772     |\n",
      "|    mean_step_reward   | 0.045658022 |\n",
      "|    n_updates          | 92/128      |\n",
      "|    policyGradLoss     | -0.0187     |\n",
      "|    value_loss         | 0.202       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 758         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 270         |\n",
      "|    total_timesteps    | 42147840    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019149277 |\n",
      "|    entropy_loss       | -2.15       |\n",
      "|    explained_variance | 0.945       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0446     |\n",
      "|    mean_step_reward   | 0.049538665 |\n",
      "|    n_updates          | 96/128      |\n",
      "|    policyGradLoss     | -0.0172     |\n",
      "|    value_loss         | 0.277       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 757         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 281         |\n",
      "|    total_timesteps    | 42156032    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01750423  |\n",
      "|    entropy_loss       | -2.13       |\n",
      "|    explained_variance | 0.865       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0663     |\n",
      "|    mean_step_reward   | 0.047551617 |\n",
      "|    n_updates          | 100/128     |\n",
      "|    policyGradLoss     | -0.0143     |\n",
      "|    value_loss         | 0.402       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 756         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 292         |\n",
      "|    total_timesteps    | 42164224    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026866455 |\n",
      "|    entropy_loss       | -2.1        |\n",
      "|    explained_variance | 0.925       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0753      |\n",
      "|    mean_step_reward   | 0.058430426 |\n",
      "|    n_updates          | 104/128     |\n",
      "|    policyGradLoss     | -0.0218     |\n",
      "|    value_loss         | 0.36        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 754         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 304         |\n",
      "|    total_timesteps    | 42172416    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015710788 |\n",
      "|    entropy_loss       | -2.13       |\n",
      "|    explained_variance | 0.931       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0396      |\n",
      "|    mean_step_reward   | 0.057641752 |\n",
      "|    n_updates          | 108/128     |\n",
      "|    policyGradLoss     | -0.0191     |\n",
      "|    value_loss         | 0.525       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 752         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 315         |\n",
      "|    total_timesteps    | 42180608    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024857018 |\n",
      "|    entropy_loss       | -2.16       |\n",
      "|    explained_variance | 0.931       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0912     |\n",
      "|    mean_step_reward   | 0.039868824 |\n",
      "|    n_updates          | 112/128     |\n",
      "|    policyGradLoss     | -0.0238     |\n",
      "|    value_loss         | 0.17        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 751         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 327         |\n",
      "|    total_timesteps    | 42188800    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025359966 |\n",
      "|    entropy_loss       | -2.12       |\n",
      "|    explained_variance | 0.946       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0521     |\n",
      "|    mean_step_reward   | 0.048564434 |\n",
      "|    n_updates          | 116/128     |\n",
      "|    policyGradLoss     | -0.0234     |\n",
      "|    value_loss         | 0.252       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 751         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 337         |\n",
      "|    total_timesteps    | 42196992    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019176994 |\n",
      "|    entropy_loss       | -2.15       |\n",
      "|    explained_variance | 0.952       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0407     |\n",
      "|    mean_step_reward   | 0.06208649  |\n",
      "|    n_updates          | 120/128     |\n",
      "|    policyGradLoss     | -0.0177     |\n",
      "|    value_loss         | 0.278       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 750         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 349         |\n",
      "|    total_timesteps    | 42205184    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019645    |\n",
      "|    entropy_loss       | -2.09       |\n",
      "|    explained_variance | 0.944       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0559     |\n",
      "|    mean_step_reward   | 0.050989658 |\n",
      "|    n_updates          | 124/128     |\n",
      "|    policyGradLoss     | -0.019      |\n",
      "|    value_loss         | 0.303       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/NoArti_160.zip\n",
      "[EVAL] Mean Return: 73.647, Best Return: 75.647\n",
      "Saved video to ./runs_smw/videos/NoArti/NoArti_160_73.65.mp4\n",
      "\n",
      "=== Round 162 | Learn 262144 steps (Total trained: 42205184) ===\n",
      "Logging to ./runs_smw/tb/NoArti_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1196     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 42213376 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 900         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 42221568    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026592143 |\n",
      "|    entropy_loss       | -2.03       |\n",
      "|    explained_variance | 0.932       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0878     |\n",
      "|    mean_step_reward   | 0.06209737  |\n",
      "|    n_updates          | 4/128       |\n",
      "|    policyGradLoss     | -0.022      |\n",
      "|    value_loss         | 0.228       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 869        |\n",
      "|    iterations         | 3          |\n",
      "|    time_elapsed       | 28         |\n",
      "|    total_timesteps    | 42229760   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02270838 |\n",
      "|    entropy_loss       | -2.08      |\n",
      "|    explained_variance | 0.96       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.0634     |\n",
      "|    mean_step_reward   | 0.07545381 |\n",
      "|    n_updates          | 8/128      |\n",
      "|    policyGradLoss     | -0.0185    |\n",
      "|    value_loss         | 0.321      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 874         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 37          |\n",
      "|    total_timesteps    | 42237952    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022927634 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0836     |\n",
      "|    mean_step_reward   | 0.036187746 |\n",
      "|    n_updates          | 12/128      |\n",
      "|    policyGradLoss     | -0.0162     |\n",
      "|    value_loss         | 0.171       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 876         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 46          |\n",
      "|    total_timesteps    | 42246144    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020941127 |\n",
      "|    entropy_loss       | -2.16       |\n",
      "|    explained_variance | 0.929       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0837     |\n",
      "|    mean_step_reward   | 0.0388355   |\n",
      "|    n_updates          | 16/128      |\n",
      "|    policyGradLoss     | -0.0191     |\n",
      "|    value_loss         | 0.244       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 861         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 57          |\n",
      "|    total_timesteps    | 42254336    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022537358 |\n",
      "|    entropy_loss       | -2.15       |\n",
      "|    explained_variance | 0.946       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0633     |\n",
      "|    mean_step_reward   | 0.052821428 |\n",
      "|    n_updates          | 20/128      |\n",
      "|    policyGradLoss     | -0.0196     |\n",
      "|    value_loss         | 0.214       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 837         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 68          |\n",
      "|    total_timesteps    | 42262528    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020521162 |\n",
      "|    entropy_loss       | -2.13       |\n",
      "|    explained_variance | 0.916       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00654     |\n",
      "|    mean_step_reward   | 0.03808161  |\n",
      "|    n_updates          | 24/128      |\n",
      "|    policyGradLoss     | -0.0182     |\n",
      "|    value_loss         | 0.41        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 824         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 79          |\n",
      "|    total_timesteps    | 42270720    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020616103 |\n",
      "|    entropy_loss       | -2.16       |\n",
      "|    explained_variance | 0.908       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0115     |\n",
      "|    mean_step_reward   | 0.04828988  |\n",
      "|    n_updates          | 28/128      |\n",
      "|    policyGradLoss     | -0.0166     |\n",
      "|    value_loss         | 0.357       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 90          |\n",
      "|    total_timesteps    | 42278912    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022013709 |\n",
      "|    entropy_loss       | -2.13       |\n",
      "|    explained_variance | 0.899       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0662     |\n",
      "|    mean_step_reward   | 0.042250477 |\n",
      "|    n_updates          | 32/128      |\n",
      "|    policyGradLoss     | -0.0178     |\n",
      "|    value_loss         | 0.342       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 803         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 101         |\n",
      "|    total_timesteps    | 42287104    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02589168  |\n",
      "|    entropy_loss       | -2.15       |\n",
      "|    explained_variance | 0.934       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0935     |\n",
      "|    mean_step_reward   | 0.036070302 |\n",
      "|    n_updates          | 36/128      |\n",
      "|    policyGradLoss     | -0.0231     |\n",
      "|    value_loss         | 0.226       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 793         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 113         |\n",
      "|    total_timesteps    | 42295296    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025096584 |\n",
      "|    entropy_loss       | -2.13       |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0843     |\n",
      "|    mean_step_reward   | 0.052716937 |\n",
      "|    n_updates          | 40/128      |\n",
      "|    policyGradLoss     | -0.0195     |\n",
      "|    value_loss         | 0.164       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 125         |\n",
      "|    total_timesteps    | 42303488    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.033165894 |\n",
      "|    entropy_loss       | -2.19       |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0764     |\n",
      "|    mean_step_reward   | 0.04249595  |\n",
      "|    n_updates          | 44/128      |\n",
      "|    policyGradLoss     | -0.0216     |\n",
      "|    value_loss         | 0.163       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 136         |\n",
      "|    total_timesteps    | 42311680    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019840853 |\n",
      "|    entropy_loss       | -2.27       |\n",
      "|    explained_variance | 0.957       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0862     |\n",
      "|    mean_step_reward   | 0.033074506 |\n",
      "|    n_updates          | 48/128      |\n",
      "|    policyGradLoss     | -0.0151     |\n",
      "|    value_loss         | 0.176       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 147         |\n",
      "|    total_timesteps    | 42319872    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01873925  |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.888       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.079      |\n",
      "|    mean_step_reward   | 0.012304417 |\n",
      "|    n_updates          | 52/128      |\n",
      "|    policyGradLoss     | -0.0161     |\n",
      "|    value_loss         | 0.276       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 158         |\n",
      "|    total_timesteps    | 42328064    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020870127 |\n",
      "|    entropy_loss       | -2.2        |\n",
      "|    explained_variance | 0.911       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0581     |\n",
      "|    mean_step_reward   | 0.02789037  |\n",
      "|    n_updates          | 56/128      |\n",
      "|    policyGradLoss     | -0.0193     |\n",
      "|    value_loss         | 0.295       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 170         |\n",
      "|    total_timesteps    | 42336256    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019397203 |\n",
      "|    entropy_loss       | -2.19       |\n",
      "|    explained_variance | 0.95        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0837     |\n",
      "|    mean_step_reward   | 0.023151854 |\n",
      "|    n_updates          | 60/128      |\n",
      "|    policyGradLoss     | -0.0221     |\n",
      "|    value_loss         | 0.191       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 181         |\n",
      "|    total_timesteps    | 42344448    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01940941  |\n",
      "|    entropy_loss       | -2.19       |\n",
      "|    explained_variance | 0.874       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0474     |\n",
      "|    mean_step_reward   | 0.038154617 |\n",
      "|    n_updates          | 64/128      |\n",
      "|    policyGradLoss     | -0.0124     |\n",
      "|    value_loss         | 0.399       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 764         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 192         |\n",
      "|    total_timesteps    | 42352640    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028377425 |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.903       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0821     |\n",
      "|    mean_step_reward   | 0.023523971 |\n",
      "|    n_updates          | 68/128      |\n",
      "|    policyGradLoss     | -0.0206     |\n",
      "|    value_loss         | 0.186       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 763          |\n",
      "|    iterations         | 19           |\n",
      "|    time_elapsed       | 203          |\n",
      "|    total_timesteps    | 42360832     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.023289353  |\n",
      "|    entropy_loss       | -2.29        |\n",
      "|    explained_variance | 0.743        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.104       |\n",
      "|    mean_step_reward   | 0.0076040337 |\n",
      "|    n_updates          | 72/128       |\n",
      "|    policyGradLoss     | -0.00146     |\n",
      "|    value_loss         | 0.192        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 762         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 214         |\n",
      "|    total_timesteps    | 42369024    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016523212 |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.856       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0366     |\n",
      "|    mean_step_reward   | 0.01564245  |\n",
      "|    n_updates          | 76/128      |\n",
      "|    policyGradLoss     | -0.015      |\n",
      "|    value_loss         | 0.407       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 760         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 226         |\n",
      "|    total_timesteps    | 42377216    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02476052  |\n",
      "|    entropy_loss       | -2.16       |\n",
      "|    explained_variance | 0.904       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0202     |\n",
      "|    mean_step_reward   | 0.019892478 |\n",
      "|    n_updates          | 80/128      |\n",
      "|    policyGradLoss     | -0.0137     |\n",
      "|    value_loss         | 0.346       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 757         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 237         |\n",
      "|    total_timesteps    | 42385408    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017531477 |\n",
      "|    entropy_loss       | -2.13       |\n",
      "|    explained_variance | 0.914       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0161     |\n",
      "|    mean_step_reward   | 0.026909083 |\n",
      "|    n_updates          | 84/128      |\n",
      "|    policyGradLoss     | -0.0153     |\n",
      "|    value_loss         | 0.474       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 755         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 249         |\n",
      "|    total_timesteps    | 42393600    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022533292 |\n",
      "|    entropy_loss       | -2.13       |\n",
      "|    explained_variance | 0.895       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0755     |\n",
      "|    mean_step_reward   | 0.042449612 |\n",
      "|    n_updates          | 88/128      |\n",
      "|    policyGradLoss     | -0.0191     |\n",
      "|    value_loss         | 0.242       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 754         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 260         |\n",
      "|    total_timesteps    | 42401792    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021369474 |\n",
      "|    entropy_loss       | -2.17       |\n",
      "|    explained_variance | 0.886       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0797     |\n",
      "|    mean_step_reward   | 0.034146264 |\n",
      "|    n_updates          | 92/128      |\n",
      "|    policyGradLoss     | -0.0143     |\n",
      "|    value_loss         | 0.355       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 754         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 271         |\n",
      "|    total_timesteps    | 42409984    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023678202 |\n",
      "|    entropy_loss       | -2.17       |\n",
      "|    explained_variance | 0.883       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0762     |\n",
      "|    mean_step_reward   | 0.030470263 |\n",
      "|    n_updates          | 96/128      |\n",
      "|    policyGradLoss     | -0.0195     |\n",
      "|    value_loss         | 0.226       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 753         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 282         |\n",
      "|    total_timesteps    | 42418176    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025596369 |\n",
      "|    entropy_loss       | -2.16       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.102      |\n",
      "|    mean_step_reward   | 0.050089598 |\n",
      "|    n_updates          | 100/128     |\n",
      "|    policyGradLoss     | -0.0247     |\n",
      "|    value_loss         | 0.126       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 751         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 294         |\n",
      "|    total_timesteps    | 42426368    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026264591 |\n",
      "|    entropy_loss       | -2.16       |\n",
      "|    explained_variance | 0.929       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.09       |\n",
      "|    mean_step_reward   | 0.035377935 |\n",
      "|    n_updates          | 104/128     |\n",
      "|    policyGradLoss     | -0.0172     |\n",
      "|    value_loss         | 0.218       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 750         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 305         |\n",
      "|    total_timesteps    | 42434560    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019319393 |\n",
      "|    entropy_loss       | -2.2        |\n",
      "|    explained_variance | 0.922       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0318     |\n",
      "|    mean_step_reward   | 0.02098348  |\n",
      "|    n_updates          | 108/128     |\n",
      "|    policyGradLoss     | -0.0209     |\n",
      "|    value_loss         | 0.275       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 749         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 316         |\n",
      "|    total_timesteps    | 42442752    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02817643  |\n",
      "|    entropy_loss       | -2.15       |\n",
      "|    explained_variance | 0.936       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0793     |\n",
      "|    mean_step_reward   | 0.043957077 |\n",
      "|    n_updates          | 112/128     |\n",
      "|    policyGradLoss     | -0.0209     |\n",
      "|    value_loss         | 0.244       |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 749       |\n",
      "|    iterations         | 30        |\n",
      "|    time_elapsed       | 327       |\n",
      "|    total_timesteps    | 42450944  |\n",
      "| train/                |           |\n",
      "|    approx_kl          | 0.019107  |\n",
      "|    entropy_loss       | -2.18     |\n",
      "|    explained_variance | 0.956     |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    loss               | -0.0729   |\n",
      "|    mean_step_reward   | 0.0364977 |\n",
      "|    n_updates          | 116/128   |\n",
      "|    policyGradLoss     | -0.018    |\n",
      "|    value_loss         | 0.13      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 748         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 339         |\n",
      "|    total_timesteps    | 42459136    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021710569 |\n",
      "|    entropy_loss       | -2.19       |\n",
      "|    explained_variance | 0.945       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0589     |\n",
      "|    mean_step_reward   | 0.046062894 |\n",
      "|    n_updates          | 120/128     |\n",
      "|    policyGradLoss     | -0.0147     |\n",
      "|    value_loss         | 0.23        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 748        |\n",
      "|    iterations         | 32         |\n",
      "|    time_elapsed       | 350        |\n",
      "|    total_timesteps    | 42467328   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.0210771  |\n",
      "|    entropy_loss       | -2.15      |\n",
      "|    explained_variance | 0.899      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0182    |\n",
      "|    mean_step_reward   | 0.03527047 |\n",
      "|    n_updates          | 124/128    |\n",
      "|    policyGradLoss     | -0.0127    |\n",
      "|    value_loss         | 0.387      |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/NoArti_161.zip\n",
      "[EVAL] Mean Return: 134.075, Best Return: 136.675\n",
      "Saved video to ./runs_smw/videos/NoArti/NoArti_161_134.08.mp4\n",
      "\n",
      "=== Round 163 | Learn 262144 steps (Total trained: 42467328) ===\n",
      "Logging to ./runs_smw/tb/NoArti_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1543     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 42475520 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 1148        |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 14          |\n",
      "|    total_timesteps    | 42483712    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025016516 |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0609     |\n",
      "|    mean_step_reward   | 0.039973788 |\n",
      "|    n_updates          | 4/128       |\n",
      "|    policyGradLoss     | -0.018      |\n",
      "|    value_loss         | 0.195       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 1037        |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 23          |\n",
      "|    total_timesteps    | 42491904    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022606444 |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.104      |\n",
      "|    mean_step_reward   | 0.028829709 |\n",
      "|    n_updates          | 8/128       |\n",
      "|    policyGradLoss     | -0.0247     |\n",
      "|    value_loss         | 0.0988      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 982         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 33          |\n",
      "|    total_timesteps    | 42500096    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025164653 |\n",
      "|    entropy_loss       | -2.17       |\n",
      "|    explained_variance | 0.905       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.028      |\n",
      "|    mean_step_reward   | 0.031699058 |\n",
      "|    n_updates          | 12/128      |\n",
      "|    policyGradLoss     | -0.0183     |\n",
      "|    value_loss         | 0.299       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 914         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 44          |\n",
      "|    total_timesteps    | 42508288    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024686918 |\n",
      "|    entropy_loss       | -2.17       |\n",
      "|    explained_variance | 0.957       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0843     |\n",
      "|    mean_step_reward   | 0.04594061  |\n",
      "|    n_updates          | 16/128      |\n",
      "|    policyGradLoss     | -0.0171     |\n",
      "|    value_loss         | 0.206       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 880         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 55          |\n",
      "|    total_timesteps    | 42516480    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01923927  |\n",
      "|    entropy_loss       | -2.18       |\n",
      "|    explained_variance | 0.928       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0464     |\n",
      "|    mean_step_reward   | 0.034804456 |\n",
      "|    n_updates          | 20/128      |\n",
      "|    policyGradLoss     | -0.0157     |\n",
      "|    value_loss         | 0.288       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 858        |\n",
      "|    iterations         | 7          |\n",
      "|    time_elapsed       | 66         |\n",
      "|    total_timesteps    | 42524672   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01778333 |\n",
      "|    entropy_loss       | -2.19      |\n",
      "|    explained_variance | 0.834      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0776    |\n",
      "|    mean_step_reward   | 0.03199754 |\n",
      "|    n_updates          | 24/128     |\n",
      "|    policyGradLoss     | -0.0132    |\n",
      "|    value_loss         | 0.333      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 843         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 77          |\n",
      "|    total_timesteps    | 42532864    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013974797 |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.843       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00914    |\n",
      "|    mean_step_reward   | 0.033343    |\n",
      "|    n_updates          | 28/128      |\n",
      "|    policyGradLoss     | -0.0126     |\n",
      "|    value_loss         | 0.508       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 827         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 89          |\n",
      "|    total_timesteps    | 42541056    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016652707 |\n",
      "|    entropy_loss       | -2.19       |\n",
      "|    explained_variance | 0.844       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0537      |\n",
      "|    mean_step_reward   | 0.03498675  |\n",
      "|    n_updates          | 32/128      |\n",
      "|    policyGradLoss     | -0.0157     |\n",
      "|    value_loss         | 0.401       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 100         |\n",
      "|    total_timesteps    | 42549248    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018021435 |\n",
      "|    entropy_loss       | -2.19       |\n",
      "|    explained_variance | 0.859       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0638     |\n",
      "|    mean_step_reward   | 0.035113726 |\n",
      "|    n_updates          | 36/128      |\n",
      "|    policyGradLoss     | -0.0138     |\n",
      "|    value_loss         | 0.417       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 802         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 112         |\n",
      "|    total_timesteps    | 42557440    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015924005 |\n",
      "|    entropy_loss       | -2.2        |\n",
      "|    explained_variance | 0.825       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00353    |\n",
      "|    mean_step_reward   | 0.025137983 |\n",
      "|    n_updates          | 40/128      |\n",
      "|    policyGradLoss     | -0.0141     |\n",
      "|    value_loss         | 0.64        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 796         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 123         |\n",
      "|    total_timesteps    | 42565632    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024504917 |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.932       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.104      |\n",
      "|    mean_step_reward   | 0.03332708  |\n",
      "|    n_updates          | 44/128      |\n",
      "|    policyGradLoss     | -0.0195     |\n",
      "|    value_loss         | 0.146       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 793         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 134         |\n",
      "|    total_timesteps    | 42573824    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01854089  |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.909       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0904     |\n",
      "|    mean_step_reward   | 0.021094594 |\n",
      "|    n_updates          | 48/128      |\n",
      "|    policyGradLoss     | -0.0182     |\n",
      "|    value_loss         | 0.198       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 788         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 145         |\n",
      "|    total_timesteps    | 42582016    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01761191  |\n",
      "|    entropy_loss       | -2.2        |\n",
      "|    explained_variance | 0.93        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0517     |\n",
      "|    mean_step_reward   | 0.048468553 |\n",
      "|    n_updates          | 52/128      |\n",
      "|    policyGradLoss     | -0.0121     |\n",
      "|    value_loss         | 0.313       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 157         |\n",
      "|    total_timesteps    | 42590208    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016495127 |\n",
      "|    entropy_loss       | -2.16       |\n",
      "|    explained_variance | 0.907       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0124      |\n",
      "|    mean_step_reward   | 0.037867796 |\n",
      "|    n_updates          | 56/128      |\n",
      "|    policyGradLoss     | -0.0165     |\n",
      "|    value_loss         | 0.365       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 168         |\n",
      "|    total_timesteps    | 42598400    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019760339 |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.947       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0865     |\n",
      "|    mean_step_reward   | 0.0481549   |\n",
      "|    n_updates          | 60/128      |\n",
      "|    policyGradLoss     | -0.016      |\n",
      "|    value_loss         | 0.191       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 179         |\n",
      "|    total_timesteps    | 42606592    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013197422 |\n",
      "|    entropy_loss       | -2.18       |\n",
      "|    explained_variance | 0.864       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0737      |\n",
      "|    mean_step_reward   | 0.016976012 |\n",
      "|    n_updates          | 64/128      |\n",
      "|    policyGradLoss     | -0.0129     |\n",
      "|    value_loss         | 0.564       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 190         |\n",
      "|    total_timesteps    | 42614784    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023662483 |\n",
      "|    entropy_loss       | -2.16       |\n",
      "|    explained_variance | 0.946       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0934     |\n",
      "|    mean_step_reward   | 0.0459959   |\n",
      "|    n_updates          | 68/128      |\n",
      "|    policyGradLoss     | -0.0193     |\n",
      "|    value_loss         | 0.225       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 201         |\n",
      "|    total_timesteps    | 42622976    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021146663 |\n",
      "|    entropy_loss       | -2.19       |\n",
      "|    explained_variance | 0.909       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0898     |\n",
      "|    mean_step_reward   | 0.0464215   |\n",
      "|    n_updates          | 72/128      |\n",
      "|    policyGradLoss     | -0.0167     |\n",
      "|    value_loss         | 0.204       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 213         |\n",
      "|    total_timesteps    | 42631168    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016410906 |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.774       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0664     |\n",
      "|    mean_step_reward   | 0.025228264 |\n",
      "|    n_updates          | 76/128      |\n",
      "|    policyGradLoss     | -0.00909    |\n",
      "|    value_loss         | 0.672       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 765         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 224         |\n",
      "|    total_timesteps    | 42639360    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01709333  |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.896       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0809     |\n",
      "|    mean_step_reward   | 0.019095292 |\n",
      "|    n_updates          | 80/128      |\n",
      "|    policyGradLoss     | -0.0157     |\n",
      "|    value_loss         | 0.238       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 764         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 235         |\n",
      "|    total_timesteps    | 42647552    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019338261 |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.829       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0419     |\n",
      "|    mean_step_reward   | 0.023246676 |\n",
      "|    n_updates          | 84/128      |\n",
      "|    policyGradLoss     | -0.0189     |\n",
      "|    value_loss         | 0.277       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 763         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 246         |\n",
      "|    total_timesteps    | 42655744    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016489843 |\n",
      "|    entropy_loss       | -2.18       |\n",
      "|    explained_variance | 0.902       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0617     |\n",
      "|    mean_step_reward   | 0.030736543 |\n",
      "|    n_updates          | 88/128      |\n",
      "|    policyGradLoss     | -0.0177     |\n",
      "|    value_loss         | 0.273       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 762         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 257         |\n",
      "|    total_timesteps    | 42663936    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017280366 |\n",
      "|    entropy_loss       | -2.17       |\n",
      "|    explained_variance | 0.717       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0137      |\n",
      "|    mean_step_reward   | 0.03255397  |\n",
      "|    n_updates          | 92/128      |\n",
      "|    policyGradLoss     | -0.01       |\n",
      "|    value_loss         | 0.885       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 760         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 269         |\n",
      "|    total_timesteps    | 42672128    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028110437 |\n",
      "|    entropy_loss       | -2.2        |\n",
      "|    explained_variance | 0.901       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.107      |\n",
      "|    mean_step_reward   | 0.03181069  |\n",
      "|    n_updates          | 96/128      |\n",
      "|    policyGradLoss     | -0.0221     |\n",
      "|    value_loss         | 0.123       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 758        |\n",
      "|    iterations         | 26         |\n",
      "|    time_elapsed       | 280        |\n",
      "|    total_timesteps    | 42680320   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01851213 |\n",
      "|    entropy_loss       | -2.25      |\n",
      "|    explained_variance | 0.875      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0515    |\n",
      "|    mean_step_reward   | 0.03588385 |\n",
      "|    n_updates          | 100/128    |\n",
      "|    policyGradLoss     | -0.0124    |\n",
      "|    value_loss         | 0.335      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 756         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 292         |\n",
      "|    total_timesteps    | 42688512    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017282315 |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.675       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0879     |\n",
      "|    mean_step_reward   | 0.015064409 |\n",
      "|    n_updates          | 104/128     |\n",
      "|    policyGradLoss     | -0.0111     |\n",
      "|    value_loss         | 0.327       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 756         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 303         |\n",
      "|    total_timesteps    | 42696704    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016036658 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.784       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0691     |\n",
      "|    mean_step_reward   | 0.025491444 |\n",
      "|    n_updates          | 108/128     |\n",
      "|    policyGradLoss     | -0.00975    |\n",
      "|    value_loss         | 0.443       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 755         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 314         |\n",
      "|    total_timesteps    | 42704896    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016630523 |\n",
      "|    entropy_loss       | -2.2        |\n",
      "|    explained_variance | 0.669       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.1         |\n",
      "|    mean_step_reward   | 0.007299955 |\n",
      "|    n_updates          | 112/128     |\n",
      "|    policyGradLoss     | -0.0122     |\n",
      "|    value_loss         | 0.613       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 755         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 325         |\n",
      "|    total_timesteps    | 42713088    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01673131  |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.659       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0713     |\n",
      "|    mean_step_reward   | 0.020252202 |\n",
      "|    n_updates          | 116/128     |\n",
      "|    policyGradLoss     | -0.014      |\n",
      "|    value_loss         | 0.326       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 754         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 336         |\n",
      "|    total_timesteps    | 42721280    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013666129 |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.599       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0847     |\n",
      "|    mean_step_reward   | 0.015426304 |\n",
      "|    n_updates          | 120/128     |\n",
      "|    policyGradLoss     | -0.0111     |\n",
      "|    value_loss         | 0.433       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 752          |\n",
      "|    iterations         | 32           |\n",
      "|    time_elapsed       | 348          |\n",
      "|    total_timesteps    | 42729472     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.021557868  |\n",
      "|    entropy_loss       | -2.3         |\n",
      "|    explained_variance | 0.691        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.107       |\n",
      "|    mean_step_reward   | 0.0070196576 |\n",
      "|    n_updates          | 124/128      |\n",
      "|    policyGradLoss     | -0.0224      |\n",
      "|    value_loss         | 0.131        |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/NoArti_162.zip\n",
      "[EVAL] Mean Return: 31.925, Best Return: 32.525\n",
      "Saved video to ./runs_smw/videos/NoArti/NoArti_162_31.93.mp4\n",
      "\n",
      "=== Round 164 | Learn 262144 steps (Total trained: 42729472) ===\n",
      "Logging to ./runs_smw/tb/NoArti_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1188     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 42737664 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 901         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 42745856    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014647765 |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.731       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0696     |\n",
      "|    mean_step_reward   | 0.0347292   |\n",
      "|    n_updates          | 4/128       |\n",
      "|    policyGradLoss     | -0.00955    |\n",
      "|    value_loss         | 0.362       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 825          |\n",
      "|    iterations         | 3            |\n",
      "|    time_elapsed       | 29           |\n",
      "|    total_timesteps    | 42754048     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.01179205   |\n",
      "|    entropy_loss       | -2.27        |\n",
      "|    explained_variance | 0.788        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0703      |\n",
      "|    mean_step_reward   | 0.0110601485 |\n",
      "|    n_updates          | 8/128        |\n",
      "|    policyGradLoss     | -0.0153      |\n",
      "|    value_loss         | 0.356        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 797         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 41          |\n",
      "|    total_timesteps    | 42762240    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017734848 |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.618       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0666     |\n",
      "|    mean_step_reward   | 0.009631388 |\n",
      "|    n_updates          | 12/128      |\n",
      "|    policyGradLoss     | -0.0185     |\n",
      "|    value_loss         | 0.385       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 52          |\n",
      "|    total_timesteps    | 42770432    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017591704 |\n",
      "|    entropy_loss       | -2.27       |\n",
      "|    explained_variance | 0.798       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0783     |\n",
      "|    mean_step_reward   | 0.02346853  |\n",
      "|    n_updates          | 16/128      |\n",
      "|    policyGradLoss     | -0.0151     |\n",
      "|    value_loss         | 0.308       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 63          |\n",
      "|    total_timesteps    | 42778624    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019640457 |\n",
      "|    entropy_loss       | -2.28       |\n",
      "|    explained_variance | 0.825       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.093      |\n",
      "|    mean_step_reward   | 0.00960784  |\n",
      "|    n_updates          | 20/128      |\n",
      "|    policyGradLoss     | -0.0198     |\n",
      "|    value_loss         | 0.232       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 74          |\n",
      "|    total_timesteps    | 42786816    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018637959 |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.756       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0664     |\n",
      "|    mean_step_reward   | 0.006283489 |\n",
      "|    n_updates          | 24/128      |\n",
      "|    policyGradLoss     | -0.0163     |\n",
      "|    value_loss         | 0.395       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 762         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 85          |\n",
      "|    total_timesteps    | 42795008    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01536868  |\n",
      "|    entropy_loss       | -2.28       |\n",
      "|    explained_variance | 0.742       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.032       |\n",
      "|    mean_step_reward   | 0.011158928 |\n",
      "|    n_updates          | 28/128      |\n",
      "|    policyGradLoss     | -0.0168     |\n",
      "|    value_loss         | 0.407       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 755         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 97          |\n",
      "|    total_timesteps    | 42803200    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021421984 |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.884       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0761     |\n",
      "|    mean_step_reward   | 0.028464537 |\n",
      "|    n_updates          | 32/128      |\n",
      "|    policyGradLoss     | -0.02       |\n",
      "|    value_loss         | 0.294       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 752         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 108         |\n",
      "|    total_timesteps    | 42811392    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013378839 |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.802       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0796     |\n",
      "|    mean_step_reward   | 0.024028502 |\n",
      "|    n_updates          | 36/128      |\n",
      "|    policyGradLoss     | -0.0159     |\n",
      "|    value_loss         | 0.468       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 750         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 119         |\n",
      "|    total_timesteps    | 42819584    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022049544 |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.594       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0738     |\n",
      "|    mean_step_reward   | 0.006030004 |\n",
      "|    n_updates          | 40/128      |\n",
      "|    policyGradLoss     | -0.0191     |\n",
      "|    value_loss         | 0.474       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 750         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 130         |\n",
      "|    total_timesteps    | 42827776    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021723982 |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.738       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0862     |\n",
      "|    mean_step_reward   | 0.010107306 |\n",
      "|    n_updates          | 44/128      |\n",
      "|    policyGradLoss     | -0.0168     |\n",
      "|    value_loss         | 0.305       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 747         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 142         |\n",
      "|    total_timesteps    | 42835968    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026172604 |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.836       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0847     |\n",
      "|    mean_step_reward   | 0.030372724 |\n",
      "|    n_updates          | 48/128      |\n",
      "|    policyGradLoss     | -0.0189     |\n",
      "|    value_loss         | 0.197       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 744         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 154         |\n",
      "|    total_timesteps    | 42844160    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025070999 |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.938       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.092      |\n",
      "|    mean_step_reward   | 0.031143736 |\n",
      "|    n_updates          | 52/128      |\n",
      "|    policyGradLoss     | -0.0243     |\n",
      "|    value_loss         | 0.212       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 742         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 165         |\n",
      "|    total_timesteps    | 42852352    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026729476 |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.887       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0997     |\n",
      "|    mean_step_reward   | 0.027250612 |\n",
      "|    n_updates          | 56/128      |\n",
      "|    policyGradLoss     | -0.0201     |\n",
      "|    value_loss         | 0.189       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 742         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 176         |\n",
      "|    total_timesteps    | 42860544    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019248653 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.688       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0533      |\n",
      "|    mean_step_reward   | 0.012307693 |\n",
      "|    n_updates          | 60/128      |\n",
      "|    policyGradLoss     | -0.0141     |\n",
      "|    value_loss         | 0.392       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 743         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 187         |\n",
      "|    total_timesteps    | 42868736    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017337328 |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.881       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0661     |\n",
      "|    mean_step_reward   | 0.017847512 |\n",
      "|    n_updates          | 64/128      |\n",
      "|    policyGradLoss     | -0.0173     |\n",
      "|    value_loss         | 0.28        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 743         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 198         |\n",
      "|    total_timesteps    | 42876928    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016796796 |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.723       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.141       |\n",
      "|    mean_step_reward   | 0.013337604 |\n",
      "|    n_updates          | 68/128      |\n",
      "|    policyGradLoss     | -0.0152     |\n",
      "|    value_loss         | 0.677       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 741         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 209         |\n",
      "|    total_timesteps    | 42885120    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022959204 |\n",
      "|    entropy_loss       | -2.19       |\n",
      "|    explained_variance | 0.81        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0512     |\n",
      "|    mean_step_reward   | 0.029511837 |\n",
      "|    n_updates          | 72/128      |\n",
      "|    policyGradLoss     | -0.0184     |\n",
      "|    value_loss         | 0.323       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 739         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 221         |\n",
      "|    total_timesteps    | 42893312    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016919607 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.831       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0461     |\n",
      "|    mean_step_reward   | 0.027598655 |\n",
      "|    n_updates          | 76/128      |\n",
      "|    policyGradLoss     | -0.0129     |\n",
      "|    value_loss         | 0.439       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 739         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 232         |\n",
      "|    total_timesteps    | 42901504    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02322451  |\n",
      "|    entropy_loss       | -2.27       |\n",
      "|    explained_variance | 0.851       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.114      |\n",
      "|    mean_step_reward   | 0.014871335 |\n",
      "|    n_updates          | 80/128      |\n",
      "|    policyGradLoss     | -0.0246     |\n",
      "|    value_loss         | 0.12        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 739         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 243         |\n",
      "|    total_timesteps    | 42909696    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021673292 |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.884       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0664     |\n",
      "|    mean_step_reward   | 0.027798388 |\n",
      "|    n_updates          | 84/128      |\n",
      "|    policyGradLoss     | -0.0147     |\n",
      "|    value_loss         | 0.257       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 739         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 254         |\n",
      "|    total_timesteps    | 42917888    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022162236 |\n",
      "|    entropy_loss       | -2.19       |\n",
      "|    explained_variance | 0.853       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.068      |\n",
      "|    mean_step_reward   | 0.018207822 |\n",
      "|    n_updates          | 88/128      |\n",
      "|    policyGradLoss     | -0.016      |\n",
      "|    value_loss         | 0.416       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 738         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 266         |\n",
      "|    total_timesteps    | 42926080    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022051077 |\n",
      "|    entropy_loss       | -2.17       |\n",
      "|    explained_variance | 0.861       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0629     |\n",
      "|    mean_step_reward   | 0.031995088 |\n",
      "|    n_updates          | 92/128      |\n",
      "|    policyGradLoss     | -0.0155     |\n",
      "|    value_loss         | 0.377       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 737         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 277         |\n",
      "|    total_timesteps    | 42934272    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025354216 |\n",
      "|    entropy_loss       | -2.19       |\n",
      "|    explained_variance | 0.909       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.054      |\n",
      "|    mean_step_reward   | 0.038985237 |\n",
      "|    n_updates          | 96/128      |\n",
      "|    policyGradLoss     | -0.0199     |\n",
      "|    value_loss         | 0.291       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 736         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 289         |\n",
      "|    total_timesteps    | 42942464    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029838057 |\n",
      "|    entropy_loss       | -2.19       |\n",
      "|    explained_variance | 0.938       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0923     |\n",
      "|    mean_step_reward   | 0.035944957 |\n",
      "|    n_updates          | 100/128     |\n",
      "|    policyGradLoss     | -0.0225     |\n",
      "|    value_loss         | 0.174       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 735         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 300         |\n",
      "|    total_timesteps    | 42950656    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019360106 |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.912       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.076      |\n",
      "|    mean_step_reward   | 0.027881648 |\n",
      "|    n_updates          | 104/128     |\n",
      "|    policyGradLoss     | -0.0154     |\n",
      "|    value_loss         | 0.214       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 736         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 311         |\n",
      "|    total_timesteps    | 42958848    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019910444 |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.838       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0663     |\n",
      "|    mean_step_reward   | 0.019662026 |\n",
      "|    n_updates          | 108/128     |\n",
      "|    policyGradLoss     | -0.0153     |\n",
      "|    value_loss         | 0.425       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 739         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 321         |\n",
      "|    total_timesteps    | 42967040    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018625893 |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.92        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0801     |\n",
      "|    mean_step_reward   | 0.028299967 |\n",
      "|    n_updates          | 112/128     |\n",
      "|    policyGradLoss     | -0.0181     |\n",
      "|    value_loss         | 0.285       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 744         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 330         |\n",
      "|    total_timesteps    | 42975232    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019929308 |\n",
      "|    entropy_loss       | -2.19       |\n",
      "|    explained_variance | 0.936       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0515     |\n",
      "|    mean_step_reward   | 0.027438667 |\n",
      "|    n_updates          | 116/128     |\n",
      "|    policyGradLoss     | -0.0186     |\n",
      "|    value_loss         | 0.19        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 747         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 339         |\n",
      "|    total_timesteps    | 42983424    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023633305 |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.89        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0791     |\n",
      "|    mean_step_reward   | 0.025221376 |\n",
      "|    n_updates          | 120/128     |\n",
      "|    policyGradLoss     | -0.0172     |\n",
      "|    value_loss         | 0.212       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 749         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 349         |\n",
      "|    total_timesteps    | 42991616    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022510767 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.863       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0437     |\n",
      "|    mean_step_reward   | 0.021173878 |\n",
      "|    n_updates          | 124/128     |\n",
      "|    policyGradLoss     | -0.0149     |\n",
      "|    value_loss         | 0.346       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/NoArti_163.zip\n",
      "[EVAL] Mean Return: -6.596, Best Return: -4.988\n",
      "Saved video to ./runs_smw/videos/NoArti/NoArti_163_-6.60.mp4\n",
      "\n",
      "=== Round 165 | Learn 262144 steps (Total trained: 42991616) ===\n",
      "Logging to ./runs_smw/tb/NoArti_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1091     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 42999808 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 869         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 43008000    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027234478 |\n",
      "|    entropy_loss       | -2.27       |\n",
      "|    explained_variance | 0.942       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0942     |\n",
      "|    mean_step_reward   | 0.029827932 |\n",
      "|    n_updates          | 4/128       |\n",
      "|    policyGradLoss     | -0.0225     |\n",
      "|    value_loss         | 0.136       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 822         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 29          |\n",
      "|    total_timesteps    | 43016192    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02690758  |\n",
      "|    entropy_loss       | -2.31       |\n",
      "|    explained_variance | 0.914       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.106      |\n",
      "|    mean_step_reward   | 0.011735463 |\n",
      "|    n_updates          | 8/128       |\n",
      "|    policyGradLoss     | -0.0157     |\n",
      "|    value_loss         | 0.0908      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 797         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 41          |\n",
      "|    total_timesteps    | 43024384    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02486417  |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.884       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0999     |\n",
      "|    mean_step_reward   | 0.017695688 |\n",
      "|    n_updates          | 12/128      |\n",
      "|    policyGradLoss     | -0.0177     |\n",
      "|    value_loss         | 0.155       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 780        |\n",
      "|    iterations         | 5          |\n",
      "|    time_elapsed       | 52         |\n",
      "|    total_timesteps    | 43032576   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01858382 |\n",
      "|    entropy_loss       | -2.21      |\n",
      "|    explained_variance | 0.861      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.0238     |\n",
      "|    mean_step_reward   | 0.01742487 |\n",
      "|    n_updates          | 16/128     |\n",
      "|    policyGradLoss     | -0.0122    |\n",
      "|    value_loss         | 0.466      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 765         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 64          |\n",
      "|    total_timesteps    | 43040768    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023575716 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.846       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0897     |\n",
      "|    mean_step_reward   | 0.020484619 |\n",
      "|    n_updates          | 20/128      |\n",
      "|    policyGradLoss     | -0.0178     |\n",
      "|    value_loss         | 0.24        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 758         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 75          |\n",
      "|    total_timesteps    | 43048960    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019720707 |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.933       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0911     |\n",
      "|    mean_step_reward   | 0.031160578 |\n",
      "|    n_updates          | 24/128      |\n",
      "|    policyGradLoss     | -0.0184     |\n",
      "|    value_loss         | 0.228       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 755         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 86          |\n",
      "|    total_timesteps    | 43057152    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023401972 |\n",
      "|    entropy_loss       | -2.17       |\n",
      "|    explained_variance | 0.935       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0735     |\n",
      "|    mean_step_reward   | 0.03980771  |\n",
      "|    n_updates          | 28/128      |\n",
      "|    policyGradLoss     | -0.0174     |\n",
      "|    value_loss         | 0.217       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 754         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 97          |\n",
      "|    total_timesteps    | 43065344    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02361156  |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.941       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0125     |\n",
      "|    mean_step_reward   | 0.036182225 |\n",
      "|    n_updates          | 32/128      |\n",
      "|    policyGradLoss     | -0.0209     |\n",
      "|    value_loss         | 0.182       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 752         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 108         |\n",
      "|    total_timesteps    | 43073536    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021389492 |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.875       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0397     |\n",
      "|    mean_step_reward   | 0.022821486 |\n",
      "|    n_updates          | 36/128      |\n",
      "|    policyGradLoss     | -0.0174     |\n",
      "|    value_loss         | 0.428       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 746         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 120         |\n",
      "|    total_timesteps    | 43081728    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02173219  |\n",
      "|    entropy_loss       | -2.27       |\n",
      "|    explained_variance | 0.709       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0736     |\n",
      "|    mean_step_reward   | 0.014045147 |\n",
      "|    n_updates          | 40/128      |\n",
      "|    policyGradLoss     | -0.018      |\n",
      "|    value_loss         | 0.271       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 742         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 132         |\n",
      "|    total_timesteps    | 43089920    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015857313 |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.896       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0783     |\n",
      "|    mean_step_reward   | 0.021570908 |\n",
      "|    n_updates          | 44/128      |\n",
      "|    policyGradLoss     | -0.0171     |\n",
      "|    value_loss         | 0.313       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 741         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 143         |\n",
      "|    total_timesteps    | 43098112    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02183033  |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.9         |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0896     |\n",
      "|    mean_step_reward   | 0.022545438 |\n",
      "|    n_updates          | 48/128      |\n",
      "|    policyGradLoss     | -0.0211     |\n",
      "|    value_loss         | 0.157       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 740         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 154         |\n",
      "|    total_timesteps    | 43106304    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019892134 |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.852       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.022       |\n",
      "|    mean_step_reward   | 0.02749236  |\n",
      "|    n_updates          | 52/128      |\n",
      "|    policyGradLoss     | -0.0138     |\n",
      "|    value_loss         | 0.386       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 741         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 165         |\n",
      "|    total_timesteps    | 43114496    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01362815  |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.794       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0563     |\n",
      "|    mean_step_reward   | 0.020968223 |\n",
      "|    n_updates          | 56/128      |\n",
      "|    policyGradLoss     | -0.0103     |\n",
      "|    value_loss         | 0.431       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 740         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 177         |\n",
      "|    total_timesteps    | 43122688    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01873995  |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.828       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0784     |\n",
      "|    mean_step_reward   | 0.019932115 |\n",
      "|    n_updates          | 60/128      |\n",
      "|    policyGradLoss     | -0.0133     |\n",
      "|    value_loss         | 0.383       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 737         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 188         |\n",
      "|    total_timesteps    | 43130880    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021990389 |\n",
      "|    entropy_loss       | -2.27       |\n",
      "|    explained_variance | 0.794       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0841     |\n",
      "|    mean_step_reward   | 0.02271811  |\n",
      "|    n_updates          | 64/128      |\n",
      "|    policyGradLoss     | -0.0154     |\n",
      "|    value_loss         | 0.245       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 736         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 200         |\n",
      "|    total_timesteps    | 43139072    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019485839 |\n",
      "|    entropy_loss       | -2.3        |\n",
      "|    explained_variance | 0.794       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0789     |\n",
      "|    mean_step_reward   | 0.019444492 |\n",
      "|    n_updates          | 68/128      |\n",
      "|    policyGradLoss     | -0.0135     |\n",
      "|    value_loss         | 0.294       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 736         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 211         |\n",
      "|    total_timesteps    | 43147264    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014407484 |\n",
      "|    entropy_loss       | -2.27       |\n",
      "|    explained_variance | 0.903       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.072      |\n",
      "|    mean_step_reward   | 0.023087613 |\n",
      "|    n_updates          | 72/128      |\n",
      "|    policyGradLoss     | -0.0152     |\n",
      "|    value_loss         | 0.209       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 737         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 222         |\n",
      "|    total_timesteps    | 43155456    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01715039  |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.735       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.022      |\n",
      "|    mean_step_reward   | 0.015831336 |\n",
      "|    n_updates          | 76/128      |\n",
      "|    policyGradLoss     | -0.0156     |\n",
      "|    value_loss         | 0.375       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 736         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 233         |\n",
      "|    total_timesteps    | 43163648    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016574785 |\n",
      "|    entropy_loss       | -2.28       |\n",
      "|    explained_variance | 0.911       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.105      |\n",
      "|    mean_step_reward   | 0.022573017 |\n",
      "|    n_updates          | 80/128      |\n",
      "|    policyGradLoss     | -0.0168     |\n",
      "|    value_loss         | 0.21        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 735         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 245         |\n",
      "|    total_timesteps    | 43171840    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01773803  |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.714       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0604     |\n",
      "|    mean_step_reward   | 0.012333939 |\n",
      "|    n_updates          | 84/128      |\n",
      "|    policyGradLoss     | -0.0152     |\n",
      "|    value_loss         | 0.345       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 739         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 254         |\n",
      "|    total_timesteps    | 43180032    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019774007 |\n",
      "|    entropy_loss       | -2.17       |\n",
      "|    explained_variance | 0.814       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0643     |\n",
      "|    mean_step_reward   | 0.02282032  |\n",
      "|    n_updates          | 88/128      |\n",
      "|    policyGradLoss     | -0.0176     |\n",
      "|    value_loss         | 0.4         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 744         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 264         |\n",
      "|    total_timesteps    | 43188224    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018047148 |\n",
      "|    entropy_loss       | -2.15       |\n",
      "|    explained_variance | 0.878       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0704     |\n",
      "|    mean_step_reward   | 0.041247718 |\n",
      "|    n_updates          | 92/128      |\n",
      "|    policyGradLoss     | -0.0135     |\n",
      "|    value_loss         | 0.398       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 749         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 273         |\n",
      "|    total_timesteps    | 43196416    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020821273 |\n",
      "|    entropy_loss       | -2.16       |\n",
      "|    explained_variance | 0.816       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0886     |\n",
      "|    mean_step_reward   | 0.029579265 |\n",
      "|    n_updates          | 96/128      |\n",
      "|    policyGradLoss     | -0.02       |\n",
      "|    value_loss         | 0.286       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 750         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 283         |\n",
      "|    total_timesteps    | 43204608    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022286512 |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.88        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0873     |\n",
      "|    mean_step_reward   | 0.05050956  |\n",
      "|    n_updates          | 100/128     |\n",
      "|    policyGradLoss     | -0.0199     |\n",
      "|    value_loss         | 0.355       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 749         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 294         |\n",
      "|    total_timesteps    | 43212800    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020067953 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.825       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0857     |\n",
      "|    mean_step_reward   | 0.020624254 |\n",
      "|    n_updates          | 104/128     |\n",
      "|    policyGradLoss     | -0.0166     |\n",
      "|    value_loss         | 0.332       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 749         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 306         |\n",
      "|    total_timesteps    | 43220992    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01699058  |\n",
      "|    entropy_loss       | -2.2        |\n",
      "|    explained_variance | 0.832       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0453     |\n",
      "|    mean_step_reward   | 0.036236078 |\n",
      "|    n_updates          | 108/128     |\n",
      "|    policyGradLoss     | -0.0135     |\n",
      "|    value_loss         | 0.411       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 748         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 317         |\n",
      "|    total_timesteps    | 43229184    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016185742 |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.764       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0556     |\n",
      "|    mean_step_reward   | 0.023740277 |\n",
      "|    n_updates          | 112/128     |\n",
      "|    policyGradLoss     | -0.00989    |\n",
      "|    value_loss         | 0.52        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 747         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 328         |\n",
      "|    total_timesteps    | 43237376    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015608437 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.87        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0556     |\n",
      "|    mean_step_reward   | 0.024208086 |\n",
      "|    n_updates          | 116/128     |\n",
      "|    policyGradLoss     | -0.0158     |\n",
      "|    value_loss         | 0.26        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 746         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 340         |\n",
      "|    total_timesteps    | 43245568    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016922247 |\n",
      "|    entropy_loss       | -2.16       |\n",
      "|    explained_variance | 0.853       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00163    |\n",
      "|    mean_step_reward   | 0.031319477 |\n",
      "|    n_updates          | 120/128     |\n",
      "|    policyGradLoss     | -0.00916    |\n",
      "|    value_loss         | 0.522       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 745         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 351         |\n",
      "|    total_timesteps    | 43253760    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014776514 |\n",
      "|    entropy_loss       | -2.2        |\n",
      "|    explained_variance | 0.773       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0145     |\n",
      "|    mean_step_reward   | 0.04578412  |\n",
      "|    n_updates          | 124/128     |\n",
      "|    policyGradLoss     | -0.00645    |\n",
      "|    value_loss         | 0.683       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/NoArti_164.zip\n",
      "[EVAL] Mean Return: 44.276, Best Return: 46.076\n",
      "Saved video to ./runs_smw/videos/NoArti/NoArti_164_44.28.mp4\n",
      "\n",
      "=== Round 166 | Learn 262144 steps (Total trained: 43253760) ===\n",
      "Logging to ./runs_smw/tb/NoArti_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1125     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 43261952 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 895         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 43270144    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024470601 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.916       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0978     |\n",
      "|    mean_step_reward   | 0.032188132 |\n",
      "|    n_updates          | 4/128       |\n",
      "|    policyGradLoss     | -0.0206     |\n",
      "|    value_loss         | 0.204       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 840         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 29          |\n",
      "|    total_timesteps    | 43278336    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024996007 |\n",
      "|    entropy_loss       | -2.28       |\n",
      "|    explained_variance | 0.868       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.107      |\n",
      "|    mean_step_reward   | 0.018423907 |\n",
      "|    n_updates          | 8/128       |\n",
      "|    policyGradLoss     | -0.0213     |\n",
      "|    value_loss         | 0.175       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 811         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 40          |\n",
      "|    total_timesteps    | 43286528    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020518536 |\n",
      "|    entropy_loss       | -2.28       |\n",
      "|    explained_variance | 0.922       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0877     |\n",
      "|    mean_step_reward   | 0.016567726 |\n",
      "|    n_updates          | 12/128      |\n",
      "|    policyGradLoss     | -0.0189     |\n",
      "|    value_loss         | 0.137       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 52          |\n",
      "|    total_timesteps    | 43294720    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015398951 |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.783       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0902     |\n",
      "|    mean_step_reward   | 0.018235222 |\n",
      "|    n_updates          | 16/128      |\n",
      "|    policyGradLoss     | -0.0134     |\n",
      "|    value_loss         | 0.264       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 63          |\n",
      "|    total_timesteps    | 43302912    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017718367 |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.866       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.041      |\n",
      "|    mean_step_reward   | 0.024582017 |\n",
      "|    n_updates          | 20/128      |\n",
      "|    policyGradLoss     | -0.0125     |\n",
      "|    value_loss         | 0.369       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 74          |\n",
      "|    total_timesteps    | 43311104    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024341803 |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.916       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0766     |\n",
      "|    mean_step_reward   | 0.027140947 |\n",
      "|    n_updates          | 24/128      |\n",
      "|    policyGradLoss     | -0.0231     |\n",
      "|    value_loss         | 0.153       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 85          |\n",
      "|    total_timesteps    | 43319296    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021872256 |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.945       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0963     |\n",
      "|    mean_step_reward   | 0.02704017  |\n",
      "|    n_updates          | 28/128      |\n",
      "|    policyGradLoss     | -0.0216     |\n",
      "|    value_loss         | 0.119       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 763         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 96          |\n",
      "|    total_timesteps    | 43327488    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021351807 |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.924       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0941     |\n",
      "|    mean_step_reward   | 0.02304358  |\n",
      "|    n_updates          | 32/128      |\n",
      "|    policyGradLoss     | -0.0205     |\n",
      "|    value_loss         | 0.158       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 759         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 107         |\n",
      "|    total_timesteps    | 43335680    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022678854 |\n",
      "|    entropy_loss       | -2.28       |\n",
      "|    explained_variance | 0.904       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.111      |\n",
      "|    mean_step_reward   | 0.01488451  |\n",
      "|    n_updates          | 36/128      |\n",
      "|    policyGradLoss     | -0.0196     |\n",
      "|    value_loss         | 0.111       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 752         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 119         |\n",
      "|    total_timesteps    | 43343872    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018339263 |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.771       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0742     |\n",
      "|    mean_step_reward   | 0.01968984  |\n",
      "|    n_updates          | 40/128      |\n",
      "|    policyGradLoss     | -0.0177     |\n",
      "|    value_loss         | 0.217       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 749         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 131         |\n",
      "|    total_timesteps    | 43352064    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016513787 |\n",
      "|    entropy_loss       | -2.15       |\n",
      "|    explained_variance | 0.859       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00193     |\n",
      "|    mean_step_reward   | 0.016242567 |\n",
      "|    n_updates          | 44/128      |\n",
      "|    policyGradLoss     | -0.0177     |\n",
      "|    value_loss         | 0.467       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 747         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 142         |\n",
      "|    total_timesteps    | 43360256    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020634426 |\n",
      "|    entropy_loss       | -2.16       |\n",
      "|    explained_variance | 0.844       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0137     |\n",
      "|    mean_step_reward   | 0.045504898 |\n",
      "|    n_updates          | 48/128      |\n",
      "|    policyGradLoss     | -0.0134     |\n",
      "|    value_loss         | 0.285       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 748         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 153         |\n",
      "|    total_timesteps    | 43368448    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021812368 |\n",
      "|    entropy_loss       | -2.15       |\n",
      "|    explained_variance | 0.879       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0757     |\n",
      "|    mean_step_reward   | 0.037168793 |\n",
      "|    n_updates          | 52/128      |\n",
      "|    policyGradLoss     | -0.0166     |\n",
      "|    value_loss         | 0.295       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 747         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 164         |\n",
      "|    total_timesteps    | 43376640    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020999216 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.838       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0972     |\n",
      "|    mean_step_reward   | 0.018781053 |\n",
      "|    n_updates          | 56/128      |\n",
      "|    policyGradLoss     | -0.02       |\n",
      "|    value_loss         | 0.204       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 744         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 176         |\n",
      "|    total_timesteps    | 43384832    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023207856 |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.921       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0909     |\n",
      "|    mean_step_reward   | 0.03012846  |\n",
      "|    n_updates          | 60/128      |\n",
      "|    policyGradLoss     | -0.0159     |\n",
      "|    value_loss         | 0.195       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 742         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 187         |\n",
      "|    total_timesteps    | 43393024    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021706758 |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.774       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0853     |\n",
      "|    mean_step_reward   | 0.022457894 |\n",
      "|    n_updates          | 64/128      |\n",
      "|    policyGradLoss     | -0.0103     |\n",
      "|    value_loss         | 0.256       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 742         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 198         |\n",
      "|    total_timesteps    | 43401216    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017701067 |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.882       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0808     |\n",
      "|    mean_step_reward   | 0.026255637 |\n",
      "|    n_updates          | 68/128      |\n",
      "|    policyGradLoss     | -0.0127     |\n",
      "|    value_loss         | 0.324       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 741         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 209         |\n",
      "|    total_timesteps    | 43409408    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019208234 |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.948       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0985     |\n",
      "|    mean_step_reward   | 0.028844802 |\n",
      "|    n_updates          | 72/128      |\n",
      "|    policyGradLoss     | -0.0217     |\n",
      "|    value_loss         | 0.1         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 741         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 220         |\n",
      "|    total_timesteps    | 43417600    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022236409 |\n",
      "|    entropy_loss       | -2.27       |\n",
      "|    explained_variance | 0.91        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0926     |\n",
      "|    mean_step_reward   | 0.01810762  |\n",
      "|    n_updates          | 76/128      |\n",
      "|    policyGradLoss     | -0.0183     |\n",
      "|    value_loss         | 0.141       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 746         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 230         |\n",
      "|    total_timesteps    | 43425792    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010787405 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.879       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0451     |\n",
      "|    mean_step_reward   | 0.030193664 |\n",
      "|    n_updates          | 80/128      |\n",
      "|    policyGradLoss     | -0.0131     |\n",
      "|    value_loss         | 0.369       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 751         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 239         |\n",
      "|    total_timesteps    | 43433984    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022558909 |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.927       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0892     |\n",
      "|    mean_step_reward   | 0.029789953 |\n",
      "|    n_updates          | 84/128      |\n",
      "|    policyGradLoss     | -0.0206     |\n",
      "|    value_loss         | 0.188       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 755         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 249         |\n",
      "|    total_timesteps    | 43442176    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01678707  |\n",
      "|    entropy_loss       | -2.3        |\n",
      "|    explained_variance | 0.917       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0947     |\n",
      "|    mean_step_reward   | 0.010844533 |\n",
      "|    n_updates          | 88/128      |\n",
      "|    policyGradLoss     | -0.0144     |\n",
      "|    value_loss         | 0.197       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 756         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 259         |\n",
      "|    total_timesteps    | 43450368    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.0191676   |\n",
      "|    entropy_loss       | -2.28       |\n",
      "|    explained_variance | 0.587       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0568     |\n",
      "|    mean_step_reward   | 0.011599135 |\n",
      "|    n_updates          | 92/128      |\n",
      "|    policyGradLoss     | -0.0117     |\n",
      "|    value_loss         | 0.396       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 754         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 271         |\n",
      "|    total_timesteps    | 43458560    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018077558 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.932       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0727     |\n",
      "|    mean_step_reward   | 0.031607084 |\n",
      "|    n_updates          | 96/128      |\n",
      "|    policyGradLoss     | -0.0159     |\n",
      "|    value_loss         | 0.218       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 753         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 282         |\n",
      "|    total_timesteps    | 43466752    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018088773 |\n",
      "|    entropy_loss       | -2.3        |\n",
      "|    explained_variance | 0.908       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0827     |\n",
      "|    mean_step_reward   | 0.029516855 |\n",
      "|    n_updates          | 100/128     |\n",
      "|    policyGradLoss     | -0.0112     |\n",
      "|    value_loss         | 0.138       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 752          |\n",
      "|    iterations         | 27           |\n",
      "|    time_elapsed       | 293          |\n",
      "|    total_timesteps    | 43474944     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.01161486   |\n",
      "|    entropy_loss       | -2.3         |\n",
      "|    explained_variance | 0.765        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0526      |\n",
      "|    mean_step_reward   | 0.0012051866 |\n",
      "|    n_updates          | 104/128      |\n",
      "|    policyGradLoss     | -0.0129      |\n",
      "|    value_loss         | 0.353        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 751         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 305         |\n",
      "|    total_timesteps    | 43483136    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021241909 |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.947       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.108      |\n",
      "|    mean_step_reward   | 0.032947887 |\n",
      "|    n_updates          | 108/128     |\n",
      "|    policyGradLoss     | -0.0195     |\n",
      "|    value_loss         | 0.105       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 750         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 316         |\n",
      "|    total_timesteps    | 43491328    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017164089 |\n",
      "|    entropy_loss       | -2.31       |\n",
      "|    explained_variance | 0.873       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0796     |\n",
      "|    mean_step_reward   | 0.021915138 |\n",
      "|    n_updates          | 112/128     |\n",
      "|    policyGradLoss     | -0.0125     |\n",
      "|    value_loss         | 0.221       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 749         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 328         |\n",
      "|    total_timesteps    | 43499520    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013802668 |\n",
      "|    entropy_loss       | -2.28       |\n",
      "|    explained_variance | 0.873       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0172     |\n",
      "|    mean_step_reward   | 0.013192162 |\n",
      "|    n_updates          | 116/128     |\n",
      "|    policyGradLoss     | -0.0123     |\n",
      "|    value_loss         | 0.338       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 748         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 339         |\n",
      "|    total_timesteps    | 43507712    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014740063 |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.908       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.103      |\n",
      "|    mean_step_reward   | 0.015527921 |\n",
      "|    n_updates          | 120/128     |\n",
      "|    policyGradLoss     | -0.0182     |\n",
      "|    value_loss         | 0.192       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 748         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 350         |\n",
      "|    total_timesteps    | 43515904    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020870708 |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.918       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0902     |\n",
      "|    mean_step_reward   | 0.037945867 |\n",
      "|    n_updates          | 124/128     |\n",
      "|    policyGradLoss     | -0.0169     |\n",
      "|    value_loss         | 0.164       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/NoArti_165.zip\n",
      "[EVAL] Mean Return: 85.266, Best Return: 87.266\n",
      "Saved video to ./runs_smw/videos/NoArti/NoArti_165_85.27.mp4\n",
      "\n",
      "=== Round 167 | Learn 262144 steps (Total trained: 43515904) ===\n",
      "Logging to ./runs_smw/tb/NoArti_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1061     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 43524096 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 849         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 19          |\n",
      "|    total_timesteps    | 43532288    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024751732 |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.946       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0997     |\n",
      "|    mean_step_reward   | 0.04055915  |\n",
      "|    n_updates          | 4/128       |\n",
      "|    policyGradLoss     | -0.022      |\n",
      "|    value_loss         | 0.141       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 804         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 30          |\n",
      "|    total_timesteps    | 43540480    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017443761 |\n",
      "|    entropy_loss       | -2.2        |\n",
      "|    explained_variance | 0.87        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0195     |\n",
      "|    mean_step_reward   | 0.023035081 |\n",
      "|    n_updates          | 8/128       |\n",
      "|    policyGradLoss     | -0.014      |\n",
      "|    value_loss         | 0.492       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 794         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 41          |\n",
      "|    total_timesteps    | 43548672    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02121289  |\n",
      "|    entropy_loss       | -2.16       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.086      |\n",
      "|    mean_step_reward   | 0.049533993 |\n",
      "|    n_updates          | 12/128      |\n",
      "|    policyGradLoss     | -0.0229     |\n",
      "|    value_loss         | 0.147       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 52          |\n",
      "|    total_timesteps    | 43556864    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020200916 |\n",
      "|    entropy_loss       | -2.17       |\n",
      "|    explained_variance | 0.786       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0371     |\n",
      "|    mean_step_reward   | 0.01844679  |\n",
      "|    n_updates          | 16/128      |\n",
      "|    policyGradLoss     | -0.0124     |\n",
      "|    value_loss         | 0.609       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 765         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 64          |\n",
      "|    total_timesteps    | 43565056    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022736706 |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.922       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.105      |\n",
      "|    mean_step_reward   | 0.028913882 |\n",
      "|    n_updates          | 20/128      |\n",
      "|    policyGradLoss     | -0.0226     |\n",
      "|    value_loss         | 0.0979      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 755         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 75          |\n",
      "|    total_timesteps    | 43573248    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019275676 |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.941       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0975     |\n",
      "|    mean_step_reward   | 0.027657032 |\n",
      "|    n_updates          | 24/128      |\n",
      "|    policyGradLoss     | -0.0158     |\n",
      "|    value_loss         | 0.173       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 752         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 87          |\n",
      "|    total_timesteps    | 43581440    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013214872 |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.894       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0785     |\n",
      "|    mean_step_reward   | 0.024986554 |\n",
      "|    n_updates          | 28/128      |\n",
      "|    policyGradLoss     | -0.0132     |\n",
      "|    value_loss         | 0.216       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 750         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 98          |\n",
      "|    total_timesteps    | 43589632    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021072945 |\n",
      "|    entropy_loss       | -2.28       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.107      |\n",
      "|    mean_step_reward   | 0.023074554 |\n",
      "|    n_updates          | 32/128      |\n",
      "|    policyGradLoss     | -0.0208     |\n",
      "|    value_loss         | 0.0662      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 749         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 109         |\n",
      "|    total_timesteps    | 43597824    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011407537 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.859       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0798     |\n",
      "|    mean_step_reward   | 0.011998513 |\n",
      "|    n_updates          | 36/128      |\n",
      "|    policyGradLoss     | -0.0104     |\n",
      "|    value_loss         | 0.293       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 747         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 120         |\n",
      "|    total_timesteps    | 43606016    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01800137  |\n",
      "|    entropy_loss       | -2.19       |\n",
      "|    explained_variance | 0.948       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.079      |\n",
      "|    mean_step_reward   | 0.024267348 |\n",
      "|    n_updates          | 40/128      |\n",
      "|    policyGradLoss     | -0.0168     |\n",
      "|    value_loss         | 0.148       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 742         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 132         |\n",
      "|    total_timesteps    | 43614208    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014256764 |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.805       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0884      |\n",
      "|    mean_step_reward   | 0.030782182 |\n",
      "|    n_updates          | 44/128      |\n",
      "|    policyGradLoss     | -0.0115     |\n",
      "|    value_loss         | 0.537       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 740         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 143         |\n",
      "|    total_timesteps    | 43622400    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02036852  |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.871       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0634     |\n",
      "|    mean_step_reward   | 0.019449174 |\n",
      "|    n_updates          | 48/128      |\n",
      "|    policyGradLoss     | -0.0122     |\n",
      "|    value_loss         | 0.257       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 739         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 155         |\n",
      "|    total_timesteps    | 43630592    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016525088 |\n",
      "|    entropy_loss       | -2.16       |\n",
      "|    explained_variance | 0.88        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0569     |\n",
      "|    mean_step_reward   | 0.04623305  |\n",
      "|    n_updates          | 52/128      |\n",
      "|    policyGradLoss     | -0.00853    |\n",
      "|    value_loss         | 0.328       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 739         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 166         |\n",
      "|    total_timesteps    | 43638784    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023346078 |\n",
      "|    entropy_loss       | -2.18       |\n",
      "|    explained_variance | 0.95        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.103      |\n",
      "|    mean_step_reward   | 0.035373047 |\n",
      "|    n_updates          | 56/128      |\n",
      "|    policyGradLoss     | -0.0188     |\n",
      "|    value_loss         | 0.173       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 738         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 177         |\n",
      "|    total_timesteps    | 43646976    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018029619 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.876       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0823     |\n",
      "|    mean_step_reward   | 0.023443315 |\n",
      "|    n_updates          | 60/128      |\n",
      "|    policyGradLoss     | -0.0147     |\n",
      "|    value_loss         | 0.248       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 737         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 188         |\n",
      "|    total_timesteps    | 43655168    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02273873  |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.899       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0777     |\n",
      "|    mean_step_reward   | 0.021504432 |\n",
      "|    n_updates          | 64/128      |\n",
      "|    policyGradLoss     | -0.0184     |\n",
      "|    value_loss         | 0.235       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 735         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 200         |\n",
      "|    total_timesteps    | 43663360    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018187229 |\n",
      "|    entropy_loss       | -2.32       |\n",
      "|    explained_variance | 0.876       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.105      |\n",
      "|    mean_step_reward   | 0.018231634 |\n",
      "|    n_updates          | 68/128      |\n",
      "|    policyGradLoss     | -0.0156     |\n",
      "|    value_loss         | 0.102       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 742          |\n",
      "|    iterations         | 19           |\n",
      "|    time_elapsed       | 209          |\n",
      "|    total_timesteps    | 43671552     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.014057834  |\n",
      "|    entropy_loss       | -2.34        |\n",
      "|    explained_variance | 0.815        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.075       |\n",
      "|    mean_step_reward   | 0.0013305154 |\n",
      "|    n_updates          | 72/128       |\n",
      "|    policyGradLoss     | -0.0101      |\n",
      "|    value_loss         | 0.326        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 749         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 218         |\n",
      "|    total_timesteps    | 43679744    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016795954 |\n",
      "|    entropy_loss       | -2.2        |\n",
      "|    explained_variance | 0.899       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00427     |\n",
      "|    mean_step_reward   | 0.02351873  |\n",
      "|    n_updates          | 76/128      |\n",
      "|    policyGradLoss     | -0.0104     |\n",
      "|    value_loss         | 0.518       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 754         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 228         |\n",
      "|    total_timesteps    | 43687936    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025558189 |\n",
      "|    entropy_loss       | -2.18       |\n",
      "|    explained_variance | 0.929       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0799     |\n",
      "|    mean_step_reward   | 0.037364185 |\n",
      "|    n_updates          | 80/128      |\n",
      "|    policyGradLoss     | -0.0174     |\n",
      "|    value_loss         | 0.186       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 757         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 237         |\n",
      "|    total_timesteps    | 43696128    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019091006 |\n",
      "|    entropy_loss       | -2.16       |\n",
      "|    explained_variance | 0.823       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0103      |\n",
      "|    mean_step_reward   | 0.025817245 |\n",
      "|    n_updates          | 84/128      |\n",
      "|    policyGradLoss     | -0.0122     |\n",
      "|    value_loss         | 0.436       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 755         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 249         |\n",
      "|    total_timesteps    | 43704320    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021234766 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.886       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0904     |\n",
      "|    mean_step_reward   | 0.02865929  |\n",
      "|    n_updates          | 88/128      |\n",
      "|    policyGradLoss     | -0.0151     |\n",
      "|    value_loss         | 0.257       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 753         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 260         |\n",
      "|    total_timesteps    | 43712512    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020021979 |\n",
      "|    entropy_loss       | -2.3        |\n",
      "|    explained_variance | 0.914       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.101      |\n",
      "|    mean_step_reward   | 0.023335753 |\n",
      "|    n_updates          | 92/128      |\n",
      "|    policyGradLoss     | -0.0134     |\n",
      "|    value_loss         | 0.149       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 752         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 272         |\n",
      "|    total_timesteps    | 43720704    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024374671 |\n",
      "|    entropy_loss       | -2.27       |\n",
      "|    explained_variance | 0.886       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.107      |\n",
      "|    mean_step_reward   | 0.018249113 |\n",
      "|    n_updates          | 96/128      |\n",
      "|    policyGradLoss     | -0.0188     |\n",
      "|    value_loss         | 0.155       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 753        |\n",
      "|    iterations         | 26         |\n",
      "|    time_elapsed       | 282        |\n",
      "|    total_timesteps    | 43728896   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01589487 |\n",
      "|    entropy_loss       | -2.21      |\n",
      "|    explained_variance | 0.912      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.072     |\n",
      "|    mean_step_reward   | 0.0391313  |\n",
      "|    n_updates          | 100/128    |\n",
      "|    policyGradLoss     | -0.00931   |\n",
      "|    value_loss         | 0.408      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 752         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 293         |\n",
      "|    total_timesteps    | 43737088    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025875658 |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.857       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0914     |\n",
      "|    mean_step_reward   | 0.022227455 |\n",
      "|    n_updates          | 104/128     |\n",
      "|    policyGradLoss     | -0.0166     |\n",
      "|    value_loss         | 0.21        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 750         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 305         |\n",
      "|    total_timesteps    | 43745280    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01972456  |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.921       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0676     |\n",
      "|    mean_step_reward   | 0.026625462 |\n",
      "|    n_updates          | 108/128     |\n",
      "|    policyGradLoss     | -0.0179     |\n",
      "|    value_loss         | 0.254       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 748         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 317         |\n",
      "|    total_timesteps    | 43753472    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027372401 |\n",
      "|    entropy_loss       | -2.27       |\n",
      "|    explained_variance | 0.952       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.1        |\n",
      "|    mean_step_reward   | 0.03195291  |\n",
      "|    n_updates          | 112/128     |\n",
      "|    policyGradLoss     | -0.0245     |\n",
      "|    value_loss         | 0.0967      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 748         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 328         |\n",
      "|    total_timesteps    | 43761664    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023611402 |\n",
      "|    entropy_loss       | -2.28       |\n",
      "|    explained_variance | 0.941       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0803     |\n",
      "|    mean_step_reward   | 0.021240793 |\n",
      "|    n_updates          | 116/128     |\n",
      "|    policyGradLoss     | -0.0168     |\n",
      "|    value_loss         | 0.152       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 748         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 339         |\n",
      "|    total_timesteps    | 43769856    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019893903 |\n",
      "|    entropy_loss       | -2.33       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.109      |\n",
      "|    mean_step_reward   | 0.013756532 |\n",
      "|    n_updates          | 120/128     |\n",
      "|    policyGradLoss     | -0.0174     |\n",
      "|    value_loss         | 0.0764      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 748         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 350         |\n",
      "|    total_timesteps    | 43778048    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013246793 |\n",
      "|    entropy_loss       | -2.32       |\n",
      "|    explained_variance | 0.833       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.081      |\n",
      "|    mean_step_reward   | -0.00392799 |\n",
      "|    n_updates          | 124/128     |\n",
      "|    policyGradLoss     | -0.0116     |\n",
      "|    value_loss         | 0.21        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/NoArti_166.zip\n",
      "[EVAL] Mean Return: 10.313, Best Return: 10.713\n",
      "Saved video to ./runs_smw/videos/NoArti/NoArti_166_10.31.mp4\n",
      "\n",
      "=== Round 168 | Learn 262144 steps (Total trained: 43778048) ===\n",
      "Logging to ./runs_smw/tb/NoArti_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1106     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 43786240 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 887         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 43794432    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030906681 |\n",
      "|    entropy_loss       | -2.14       |\n",
      "|    explained_variance | 0.889       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0707     |\n",
      "|    mean_step_reward   | 0.032457814 |\n",
      "|    n_updates          | 4/128       |\n",
      "|    policyGradLoss     | -0.0166     |\n",
      "|    value_loss         | 0.321       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 837         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 29          |\n",
      "|    total_timesteps    | 43802624    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01994865  |\n",
      "|    entropy_loss       | -2.17       |\n",
      "|    explained_variance | 0.878       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0672     |\n",
      "|    mean_step_reward   | 0.031910174 |\n",
      "|    n_updates          | 8/128       |\n",
      "|    policyGradLoss     | -0.0129     |\n",
      "|    value_loss         | 0.342       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 809         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 40          |\n",
      "|    total_timesteps    | 43810816    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02438125  |\n",
      "|    entropy_loss       | -2.18       |\n",
      "|    explained_variance | 0.928       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0497     |\n",
      "|    mean_step_reward   | 0.041476496 |\n",
      "|    n_updates          | 12/128      |\n",
      "|    policyGradLoss     | -0.0168     |\n",
      "|    value_loss         | 0.268       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 788         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 51          |\n",
      "|    total_timesteps    | 43819008    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019202664 |\n",
      "|    entropy_loss       | -2.19       |\n",
      "|    explained_variance | 0.949       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0898     |\n",
      "|    mean_step_reward   | 0.03880935  |\n",
      "|    n_updates          | 16/128      |\n",
      "|    policyGradLoss     | -0.0165     |\n",
      "|    value_loss         | 0.174       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 63          |\n",
      "|    total_timesteps    | 43827200    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022668216 |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.889       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0737     |\n",
      "|    mean_step_reward   | 0.015269791 |\n",
      "|    n_updates          | 20/128      |\n",
      "|    policyGradLoss     | -0.0152     |\n",
      "|    value_loss         | 0.175       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 765         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 74          |\n",
      "|    total_timesteps    | 43835392    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02246893  |\n",
      "|    entropy_loss       | -2.32       |\n",
      "|    explained_variance | 0.863       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0937     |\n",
      "|    mean_step_reward   | 0.016543198 |\n",
      "|    n_updates          | 24/128      |\n",
      "|    policyGradLoss     | -0.0139     |\n",
      "|    value_loss         | 0.287       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 761         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 86          |\n",
      "|    total_timesteps    | 43843584    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010701895 |\n",
      "|    entropy_loss       | -2.27       |\n",
      "|    explained_variance | 0.679       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0498     |\n",
      "|    mean_step_reward   | 0.012997467 |\n",
      "|    n_updates          | 28/128      |\n",
      "|    policyGradLoss     | -0.00501    |\n",
      "|    value_loss         | 0.646       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 758        |\n",
      "|    iterations         | 9          |\n",
      "|    time_elapsed       | 97         |\n",
      "|    total_timesteps    | 43851776   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01626012 |\n",
      "|    entropy_loss       | -2.24      |\n",
      "|    explained_variance | 0.902      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.046     |\n",
      "|    mean_step_reward   | 0.01928881 |\n",
      "|    n_updates          | 32/128     |\n",
      "|    policyGradLoss     | -0.0177    |\n",
      "|    value_loss         | 0.326      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 754         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 108         |\n",
      "|    total_timesteps    | 43859968    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019016214 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.853       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0851     |\n",
      "|    mean_step_reward   | 0.022187892 |\n",
      "|    n_updates          | 36/128      |\n",
      "|    policyGradLoss     | -0.0207     |\n",
      "|    value_loss         | 0.171       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 751         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 119         |\n",
      "|    total_timesteps    | 43868160    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013380378 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.902       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0791     |\n",
      "|    mean_step_reward   | 0.017400967 |\n",
      "|    n_updates          | 40/128      |\n",
      "|    policyGradLoss     | -0.013      |\n",
      "|    value_loss         | 0.293       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 746          |\n",
      "|    iterations         | 12           |\n",
      "|    time_elapsed       | 131          |\n",
      "|    total_timesteps    | 43876352     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.018178472  |\n",
      "|    entropy_loss       | -2.25        |\n",
      "|    explained_variance | 0.743        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0473      |\n",
      "|    mean_step_reward   | 0.0077388813 |\n",
      "|    n_updates          | 44/128       |\n",
      "|    policyGradLoss     | -0.0156      |\n",
      "|    value_loss         | 0.348        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 744         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 142         |\n",
      "|    total_timesteps    | 43884544    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01450161  |\n",
      "|    entropy_loss       | -2.27       |\n",
      "|    explained_variance | 0.86        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0506     |\n",
      "|    mean_step_reward   | 0.027634354 |\n",
      "|    n_updates          | 48/128      |\n",
      "|    policyGradLoss     | -0.0134     |\n",
      "|    value_loss         | 0.35        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 744         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 154         |\n",
      "|    total_timesteps    | 43892736    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027449224 |\n",
      "|    entropy_loss       | -2.27       |\n",
      "|    explained_variance | 0.938       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.115      |\n",
      "|    mean_step_reward   | 0.015396185 |\n",
      "|    n_updates          | 52/128      |\n",
      "|    policyGradLoss     | -0.0211     |\n",
      "|    value_loss         | 0.088       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 745         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 164         |\n",
      "|    total_timesteps    | 43900928    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018471275 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.913       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0558     |\n",
      "|    mean_step_reward   | 0.019871341 |\n",
      "|    n_updates          | 56/128      |\n",
      "|    policyGradLoss     | -0.0143     |\n",
      "|    value_loss         | 0.26        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 743         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 176         |\n",
      "|    total_timesteps    | 43909120    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023998903 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.92        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0895     |\n",
      "|    mean_step_reward   | 0.012071151 |\n",
      "|    n_updates          | 60/128      |\n",
      "|    policyGradLoss     | -0.0205     |\n",
      "|    value_loss         | 0.15        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 740         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 188         |\n",
      "|    total_timesteps    | 43917312    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022383645 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.928       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.099      |\n",
      "|    mean_step_reward   | 0.026954532 |\n",
      "|    n_updates          | 64/128      |\n",
      "|    policyGradLoss     | -0.0186     |\n",
      "|    value_loss         | 0.154       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 742         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 198         |\n",
      "|    total_timesteps    | 43925504    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013933929 |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.739       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.05       |\n",
      "|    mean_step_reward   | 0.025234627 |\n",
      "|    n_updates          | 68/128      |\n",
      "|    policyGradLoss     | -0.00981    |\n",
      "|    value_loss         | 0.473       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 750        |\n",
      "|    iterations         | 19         |\n",
      "|    time_elapsed       | 207        |\n",
      "|    total_timesteps    | 43933696   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02420538 |\n",
      "|    entropy_loss       | -2.13      |\n",
      "|    explained_variance | 0.835      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0547    |\n",
      "|    mean_step_reward   | 0.03577214 |\n",
      "|    n_updates          | 72/128     |\n",
      "|    policyGradLoss     | -0.0137    |\n",
      "|    value_loss         | 0.459      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 755        |\n",
      "|    iterations         | 20         |\n",
      "|    time_elapsed       | 216        |\n",
      "|    total_timesteps    | 43941888   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02090839 |\n",
      "|    entropy_loss       | -2.16      |\n",
      "|    explained_variance | 0.944      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0866    |\n",
      "|    mean_step_reward   | 0.04794629 |\n",
      "|    n_updates          | 76/128     |\n",
      "|    policyGradLoss     | -0.0224    |\n",
      "|    value_loss         | 0.206      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 760         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 226         |\n",
      "|    total_timesteps    | 43950080    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019104257 |\n",
      "|    entropy_loss       | -2.2        |\n",
      "|    explained_variance | 0.847       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0418     |\n",
      "|    mean_step_reward   | 0.029475758 |\n",
      "|    n_updates          | 80/128      |\n",
      "|    policyGradLoss     | -0.0118     |\n",
      "|    value_loss         | 0.452       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 759         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 237         |\n",
      "|    total_timesteps    | 43958272    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021942765 |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.875       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0794     |\n",
      "|    mean_step_reward   | 0.024121918 |\n",
      "|    n_updates          | 84/128      |\n",
      "|    policyGradLoss     | -0.0149     |\n",
      "|    value_loss         | 0.186       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 758         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 248         |\n",
      "|    total_timesteps    | 43966464    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021182481 |\n",
      "|    entropy_loss       | -2.19       |\n",
      "|    explained_variance | 0.9         |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0118     |\n",
      "|    mean_step_reward   | 0.040649712 |\n",
      "|    n_updates          | 88/128      |\n",
      "|    policyGradLoss     | -0.0125     |\n",
      "|    value_loss         | 0.494       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 755         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 260         |\n",
      "|    total_timesteps    | 43974656    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022099746 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.824       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0929     |\n",
      "|    mean_step_reward   | 0.023390844 |\n",
      "|    n_updates          | 92/128      |\n",
      "|    policyGradLoss     | -0.0151     |\n",
      "|    value_loss         | 0.255       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 753         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 271         |\n",
      "|    total_timesteps    | 43982848    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012286585 |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.902       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0841     |\n",
      "|    mean_step_reward   | 0.03345316  |\n",
      "|    n_updates          | 96/128      |\n",
      "|    policyGradLoss     | -0.0108     |\n",
      "|    value_loss         | 0.244       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 752         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 282         |\n",
      "|    total_timesteps    | 43991040    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020025577 |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.896       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.088      |\n",
      "|    mean_step_reward   | 0.023566764 |\n",
      "|    n_updates          | 100/128     |\n",
      "|    policyGradLoss     | -0.0154     |\n",
      "|    value_loss         | 0.193       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 752         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 293         |\n",
      "|    total_timesteps    | 43999232    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017646011 |\n",
      "|    entropy_loss       | -2.31       |\n",
      "|    explained_variance | 0.778       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0263     |\n",
      "|    mean_step_reward   | 0.005351324 |\n",
      "|    n_updates          | 104/128     |\n",
      "|    policyGradLoss     | -0.0122     |\n",
      "|    value_loss         | 0.284       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 752         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 304         |\n",
      "|    total_timesteps    | 44007424    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014316242 |\n",
      "|    entropy_loss       | -2.28       |\n",
      "|    explained_variance | 0.807       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0436     |\n",
      "|    mean_step_reward   | 0.013192345 |\n",
      "|    n_updates          | 108/128     |\n",
      "|    policyGradLoss     | -0.0102     |\n",
      "|    value_loss         | 0.431       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 751         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 316         |\n",
      "|    total_timesteps    | 44015616    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.04256805  |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.919       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.106      |\n",
      "|    mean_step_reward   | 0.030666422 |\n",
      "|    n_updates          | 112/128     |\n",
      "|    policyGradLoss     | -0.0223     |\n",
      "|    value_loss         | 0.0937      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 748         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 328         |\n",
      "|    total_timesteps    | 44023808    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018251494 |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0985     |\n",
      "|    mean_step_reward   | 0.028645026 |\n",
      "|    n_updates          | 116/128     |\n",
      "|    policyGradLoss     | -0.0201     |\n",
      "|    value_loss         | 0.135       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 747         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 339         |\n",
      "|    total_timesteps    | 44032000    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019968966 |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.942       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0926     |\n",
      "|    mean_step_reward   | 0.035222445 |\n",
      "|    n_updates          | 120/128     |\n",
      "|    policyGradLoss     | -0.0204     |\n",
      "|    value_loss         | 0.157       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 747          |\n",
      "|    iterations         | 32           |\n",
      "|    time_elapsed       | 350          |\n",
      "|    total_timesteps    | 44040192     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.01693723   |\n",
      "|    entropy_loss       | -2.25        |\n",
      "|    explained_variance | 0.849        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0127      |\n",
      "|    mean_step_reward   | 0.0053013936 |\n",
      "|    n_updates          | 124/128      |\n",
      "|    policyGradLoss     | -0.0126      |\n",
      "|    value_loss         | 0.477        |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/NoArti_167.zip\n",
      "[EVAL] Mean Return: 75.705, Best Return: 77.705\n",
      "Saved video to ./runs_smw/videos/NoArti/NoArti_167_75.71.mp4\n",
      "\n",
      "=== Round 169 | Learn 262144 steps (Total trained: 44040192) ===\n",
      "Logging to ./runs_smw/tb/NoArti_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1075     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 44048384 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 867         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 44056576    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012946571 |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.817       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0259      |\n",
      "|    mean_step_reward   | 0.020793986 |\n",
      "|    n_updates          | 4/128       |\n",
      "|    policyGradLoss     | -0.0117     |\n",
      "|    value_loss         | 0.419       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 822         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 29          |\n",
      "|    total_timesteps    | 44064768    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013398411 |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.84        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0591     |\n",
      "|    mean_step_reward   | 0.013071849 |\n",
      "|    n_updates          | 8/128       |\n",
      "|    policyGradLoss     | -0.0127     |\n",
      "|    value_loss         | 0.371       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 802         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 40          |\n",
      "|    total_timesteps    | 44072960    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020736307 |\n",
      "|    entropy_loss       | -2.29       |\n",
      "|    explained_variance | 0.908       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0745     |\n",
      "|    mean_step_reward   | 0.03142038  |\n",
      "|    n_updates          | 12/128      |\n",
      "|    policyGradLoss     | -0.0188     |\n",
      "|    value_loss         | 0.197       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 788         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 51          |\n",
      "|    total_timesteps    | 44081152    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016116206 |\n",
      "|    entropy_loss       | -2.29       |\n",
      "|    explained_variance | 0.867       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0968     |\n",
      "|    mean_step_reward   | 0.009586167 |\n",
      "|    n_updates          | 16/128      |\n",
      "|    policyGradLoss     | -0.0158     |\n",
      "|    value_loss         | 0.186       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 63          |\n",
      "|    total_timesteps    | 44089344    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027049206 |\n",
      "|    entropy_loss       | -2.29       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.11       |\n",
      "|    mean_step_reward   | 0.02129164  |\n",
      "|    n_updates          | 20/128      |\n",
      "|    policyGradLoss     | -0.0215     |\n",
      "|    value_loss         | 0.0622      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 761         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 75          |\n",
      "|    total_timesteps    | 44097536    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015594443 |\n",
      "|    entropy_loss       | -2.27       |\n",
      "|    explained_variance | 0.891       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0755     |\n",
      "|    mean_step_reward   | 0.007581066 |\n",
      "|    n_updates          | 24/128      |\n",
      "|    policyGradLoss     | -0.0145     |\n",
      "|    value_loss         | 0.238       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 756         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 86          |\n",
      "|    total_timesteps    | 44105728    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01725321  |\n",
      "|    entropy_loss       | -2.3        |\n",
      "|    explained_variance | 0.868       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0739     |\n",
      "|    mean_step_reward   | 0.019158278 |\n",
      "|    n_updates          | 28/128      |\n",
      "|    policyGradLoss     | -0.0131     |\n",
      "|    value_loss         | 0.213       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 757         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 97          |\n",
      "|    total_timesteps    | 44113920    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012838198 |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.928       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.048      |\n",
      "|    mean_step_reward   | 0.020885639 |\n",
      "|    n_updates          | 32/128      |\n",
      "|    policyGradLoss     | -0.0163     |\n",
      "|    value_loss         | 0.284       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 753        |\n",
      "|    iterations         | 10         |\n",
      "|    time_elapsed       | 108        |\n",
      "|    total_timesteps    | 44122112   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02091623 |\n",
      "|    entropy_loss       | -2.17      |\n",
      "|    explained_variance | 0.898      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0283    |\n",
      "|    mean_step_reward   | 0.03422278 |\n",
      "|    n_updates          | 36/128     |\n",
      "|    policyGradLoss     | -0.0158    |\n",
      "|    value_loss         | 0.39       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 749         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 120         |\n",
      "|    total_timesteps    | 44130304    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020397775 |\n",
      "|    entropy_loss       | -2.16       |\n",
      "|    explained_variance | 0.943       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0814     |\n",
      "|    mean_step_reward   | 0.038405586 |\n",
      "|    n_updates          | 40/128      |\n",
      "|    policyGradLoss     | -0.019      |\n",
      "|    value_loss         | 0.221       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 745         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 131         |\n",
      "|    total_timesteps    | 44138496    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020142218 |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.877       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0872     |\n",
      "|    mean_step_reward   | 0.024017334 |\n",
      "|    n_updates          | 44/128      |\n",
      "|    policyGradLoss     | -0.0158     |\n",
      "|    value_loss         | 0.245       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 742         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 143         |\n",
      "|    total_timesteps    | 44146688    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.06740773  |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.11       |\n",
      "|    mean_step_reward   | 0.026540037 |\n",
      "|    n_updates          | 48/128      |\n",
      "|    policyGradLoss     | -0.0187     |\n",
      "|    value_loss         | 0.0661      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 740         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 154         |\n",
      "|    total_timesteps    | 44154880    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017393297 |\n",
      "|    entropy_loss       | -2.31       |\n",
      "|    explained_variance | 0.752       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0922     |\n",
      "|    mean_step_reward   | 0.009126132 |\n",
      "|    n_updates          | 52/128      |\n",
      "|    policyGradLoss     | -0.0119     |\n",
      "|    value_loss         | 0.273       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 740         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 165         |\n",
      "|    total_timesteps    | 44163072    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019663885 |\n",
      "|    entropy_loss       | -2.29       |\n",
      "|    explained_variance | 0.912       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.11       |\n",
      "|    mean_step_reward   | 0.015797703 |\n",
      "|    n_updates          | 56/128      |\n",
      "|    policyGradLoss     | -0.0207     |\n",
      "|    value_loss         | 0.0807      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 746         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 175         |\n",
      "|    total_timesteps    | 44171264    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011527752 |\n",
      "|    entropy_loss       | -2.29       |\n",
      "|    explained_variance | 0.695       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0736     |\n",
      "|    mean_step_reward   | 0.023048397 |\n",
      "|    n_updates          | 60/128      |\n",
      "|    policyGradLoss     | -0.00728    |\n",
      "|    value_loss         | 0.463       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 754         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 184         |\n",
      "|    total_timesteps    | 44179456    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01340407  |\n",
      "|    entropy_loss       | -2.29       |\n",
      "|    explained_variance | 0.819       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0846     |\n",
      "|    mean_step_reward   | 0.013425269 |\n",
      "|    n_updates          | 64/128      |\n",
      "|    policyGradLoss     | -0.0135     |\n",
      "|    value_loss         | 0.284       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 760         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 193         |\n",
      "|    total_timesteps    | 44187648    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013457251 |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.87        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0624     |\n",
      "|    mean_step_reward   | 0.022130134 |\n",
      "|    n_updates          | 68/128      |\n",
      "|    policyGradLoss     | -0.0132     |\n",
      "|    value_loss         | 0.36        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 765         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 203         |\n",
      "|    total_timesteps    | 44195840    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022981718 |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.936       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0794     |\n",
      "|    mean_step_reward   | 0.027728591 |\n",
      "|    n_updates          | 72/128      |\n",
      "|    policyGradLoss     | -0.0216     |\n",
      "|    value_loss         | 0.148       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 765         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 213         |\n",
      "|    total_timesteps    | 44204032    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015393689 |\n",
      "|    entropy_loss       | -2.29       |\n",
      "|    explained_variance | 0.855       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0898     |\n",
      "|    mean_step_reward   | 0.03206276  |\n",
      "|    n_updates          | 76/128      |\n",
      "|    policyGradLoss     | -0.0139     |\n",
      "|    value_loss         | 0.219       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 764         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 225         |\n",
      "|    total_timesteps    | 44212224    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017442618 |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.801       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.042      |\n",
      "|    mean_step_reward   | 0.01642983  |\n",
      "|    n_updates          | 80/128      |\n",
      "|    policyGradLoss     | -0.0145     |\n",
      "|    value_loss         | 0.423       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 762         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 236         |\n",
      "|    total_timesteps    | 44220416    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026590984 |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.101      |\n",
      "|    mean_step_reward   | 0.055727582 |\n",
      "|    n_updates          | 84/128      |\n",
      "|    policyGradLoss     | -0.0281     |\n",
      "|    value_loss         | 0.102       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 759         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 248         |\n",
      "|    total_timesteps    | 44228608    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.0306646   |\n",
      "|    entropy_loss       | -2.31       |\n",
      "|    explained_variance | 0.935       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.107      |\n",
      "|    mean_step_reward   | 0.013101226 |\n",
      "|    n_updates          | 88/128      |\n",
      "|    policyGradLoss     | -0.0185     |\n",
      "|    value_loss         | 0.0804      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 757         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 259         |\n",
      "|    total_timesteps    | 44236800    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014699702 |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.907       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0589     |\n",
      "|    mean_step_reward   | 0.02262039  |\n",
      "|    n_updates          | 92/128      |\n",
      "|    policyGradLoss     | -0.0133     |\n",
      "|    value_loss         | 0.311       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 756         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 270         |\n",
      "|    total_timesteps    | 44244992    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018036652 |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.895       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0778     |\n",
      "|    mean_step_reward   | 0.036982782 |\n",
      "|    n_updates          | 96/128      |\n",
      "|    policyGradLoss     | -0.0194     |\n",
      "|    value_loss         | 0.344       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 756         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 281         |\n",
      "|    total_timesteps    | 44253184    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025697872 |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.939       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0687     |\n",
      "|    mean_step_reward   | 0.03221109  |\n",
      "|    n_updates          | 100/128     |\n",
      "|    policyGradLoss     | -0.0227     |\n",
      "|    value_loss         | 0.246       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 754         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 293         |\n",
      "|    total_timesteps    | 44261376    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02356502  |\n",
      "|    entropy_loss       | -2.32       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.12       |\n",
      "|    mean_step_reward   | 0.017501045 |\n",
      "|    n_updates          | 104/128     |\n",
      "|    policyGradLoss     | -0.0204     |\n",
      "|    value_loss         | 0.0666      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 753         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 304         |\n",
      "|    total_timesteps    | 44269568    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01839324  |\n",
      "|    entropy_loss       | -2.34       |\n",
      "|    explained_variance | 0.84        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0859     |\n",
      "|    mean_step_reward   | 0.005288256 |\n",
      "|    n_updates          | 108/128     |\n",
      "|    policyGradLoss     | -0.0105     |\n",
      "|    value_loss         | 0.104       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 751         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 316         |\n",
      "|    total_timesteps    | 44277760    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02445116  |\n",
      "|    entropy_loss       | -2.32       |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.117      |\n",
      "|    mean_step_reward   | 0.017308896 |\n",
      "|    n_updates          | 112/128     |\n",
      "|    policyGradLoss     | -0.0176     |\n",
      "|    value_loss         | 0.0596      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 750         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 327         |\n",
      "|    total_timesteps    | 44285952    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016300358 |\n",
      "|    entropy_loss       | -2.3        |\n",
      "|    explained_variance | 0.868       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0552     |\n",
      "|    mean_step_reward   | 0.02042764  |\n",
      "|    n_updates          | 116/128     |\n",
      "|    policyGradLoss     | -0.0145     |\n",
      "|    value_loss         | 0.243       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 750          |\n",
      "|    iterations         | 31           |\n",
      "|    time_elapsed       | 338          |\n",
      "|    total_timesteps    | 44294144     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.013065935  |\n",
      "|    entropy_loss       | -2.24        |\n",
      "|    explained_variance | 0.855        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0286      |\n",
      "|    mean_step_reward   | 0.0057631945 |\n",
      "|    n_updates          | 120/128      |\n",
      "|    policyGradLoss     | -0.00874     |\n",
      "|    value_loss         | 0.499        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 749         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 349         |\n",
      "|    total_timesteps    | 44302336    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021214005 |\n",
      "|    entropy_loss       | -2.19       |\n",
      "|    explained_variance | 0.955       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0973     |\n",
      "|    mean_step_reward   | 0.035703436 |\n",
      "|    n_updates          | 124/128     |\n",
      "|    policyGradLoss     | -0.0173     |\n",
      "|    value_loss         | 0.182       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/NoArti_168.zip\n",
      "[EVAL] Mean Return: 129.243, Best Return: 131.843\n",
      "Saved video to ./runs_smw/videos/NoArti/NoArti_168_129.24.mp4\n",
      "\n",
      "=== Round 170 | Learn 262144 steps (Total trained: 44302336) ===\n",
      "Logging to ./runs_smw/tb/NoArti_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1166     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 44310528 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 876         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 44318720    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020769034 |\n",
      "|    entropy_loss       | -2.34       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.107      |\n",
      "|    mean_step_reward   | 0.023562469 |\n",
      "|    n_updates          | 4/128       |\n",
      "|    policyGradLoss     | -0.0146     |\n",
      "|    value_loss         | 0.0532      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 809           |\n",
      "|    iterations         | 3             |\n",
      "|    time_elapsed       | 30            |\n",
      "|    total_timesteps    | 44326912      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.019167956   |\n",
      "|    entropy_loss       | -2.39         |\n",
      "|    explained_variance | 0.844         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0319       |\n",
      "|    mean_step_reward   | 0.00032108443 |\n",
      "|    n_updates          | 8/128         |\n",
      "|    policyGradLoss     | -0.0137       |\n",
      "|    value_loss         | 0.0865        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 41          |\n",
      "|    total_timesteps    | 44335104    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02096678  |\n",
      "|    entropy_loss       | -2.38       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.117      |\n",
      "|    mean_step_reward   | 0.010249565 |\n",
      "|    n_updates          | 12/128      |\n",
      "|    policyGradLoss     | -0.0168     |\n",
      "|    value_loss         | 0.0268      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 774           |\n",
      "|    iterations         | 5             |\n",
      "|    time_elapsed       | 52            |\n",
      "|    total_timesteps    | 44343296      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.01172233    |\n",
      "|    entropy_loss       | -2.34         |\n",
      "|    explained_variance | 0.795         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0951       |\n",
      "|    mean_step_reward   | -0.0076611554 |\n",
      "|    n_updates          | 16/128        |\n",
      "|    policyGradLoss     | -0.0111       |\n",
      "|    value_loss         | 0.221         |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 63          |\n",
      "|    total_timesteps    | 44351488    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017201941 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.924       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0771     |\n",
      "|    mean_step_reward   | 0.011502154 |\n",
      "|    n_updates          | 20/128      |\n",
      "|    policyGradLoss     | -0.0186     |\n",
      "|    value_loss         | 0.163       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 761         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 75          |\n",
      "|    total_timesteps    | 44359680    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018401586 |\n",
      "|    entropy_loss       | -2.17       |\n",
      "|    explained_variance | 0.945       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0647     |\n",
      "|    mean_step_reward   | 0.05128887  |\n",
      "|    n_updates          | 24/128      |\n",
      "|    policyGradLoss     | -0.0163     |\n",
      "|    value_loss         | 0.206       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 753         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 87          |\n",
      "|    total_timesteps    | 44367872    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017115429 |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.942       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0806     |\n",
      "|    mean_step_reward   | 0.028952435 |\n",
      "|    n_updates          | 28/128      |\n",
      "|    policyGradLoss     | -0.0206     |\n",
      "|    value_loss         | 0.213       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 748         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 98          |\n",
      "|    total_timesteps    | 44376064    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022462536 |\n",
      "|    entropy_loss       | -2.27       |\n",
      "|    explained_variance | 0.917       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.102      |\n",
      "|    mean_step_reward   | 0.0227543   |\n",
      "|    n_updates          | 32/128      |\n",
      "|    policyGradLoss     | -0.0192     |\n",
      "|    value_loss         | 0.148       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 746         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 109         |\n",
      "|    total_timesteps    | 44384256    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016016629 |\n",
      "|    entropy_loss       | -2.28       |\n",
      "|    explained_variance | 0.725       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.094      |\n",
      "|    mean_step_reward   | 0.019004097 |\n",
      "|    n_updates          | 36/128      |\n",
      "|    policyGradLoss     | -0.0095     |\n",
      "|    value_loss         | 0.193       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 747         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 120         |\n",
      "|    total_timesteps    | 44392448    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014960837 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.832       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0363     |\n",
      "|    mean_step_reward   | 0.030441808 |\n",
      "|    n_updates          | 40/128      |\n",
      "|    policyGradLoss     | -0.0148     |\n",
      "|    value_loss         | 0.497       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 746         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 131         |\n",
      "|    total_timesteps    | 44400640    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021125495 |\n",
      "|    entropy_loss       | -2.18       |\n",
      "|    explained_variance | 0.937       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0614     |\n",
      "|    mean_step_reward   | 0.04224546  |\n",
      "|    n_updates          | 44/128      |\n",
      "|    policyGradLoss     | -0.0164     |\n",
      "|    value_loss         | 0.23        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 743         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 143         |\n",
      "|    total_timesteps    | 44408832    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012519212 |\n",
      "|    entropy_loss       | -2.16       |\n",
      "|    explained_variance | 0.895       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0735     |\n",
      "|    mean_step_reward   | 0.035148323 |\n",
      "|    n_updates          | 48/128      |\n",
      "|    policyGradLoss     | -0.0118     |\n",
      "|    value_loss         | 0.396       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 749         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 153         |\n",
      "|    total_timesteps    | 44417024    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025873585 |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.936       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.11       |\n",
      "|    mean_step_reward   | 0.030593954 |\n",
      "|    n_updates          | 52/128      |\n",
      "|    policyGradLoss     | -0.0273     |\n",
      "|    value_loss         | 0.0966      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 759         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 161         |\n",
      "|    total_timesteps    | 44425216    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024466848 |\n",
      "|    entropy_loss       | -2.27       |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0971     |\n",
      "|    mean_step_reward   | 0.029776972 |\n",
      "|    n_updates          | 56/128      |\n",
      "|    policyGradLoss     | -0.0187     |\n",
      "|    value_loss         | 0.0856      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 764         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 171         |\n",
      "|    total_timesteps    | 44433408    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028881198 |\n",
      "|    entropy_loss       | -2.34       |\n",
      "|    explained_variance | 0.939       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.118      |\n",
      "|    mean_step_reward   | 0.009507386 |\n",
      "|    n_updates          | 60/128      |\n",
      "|    policyGradLoss     | -0.0238     |\n",
      "|    value_loss         | 0.0308      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 180         |\n",
      "|    total_timesteps    | 44441600    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02011246  |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.889       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0774     |\n",
      "|    mean_step_reward   | 0.022354953 |\n",
      "|    n_updates          | 64/128      |\n",
      "|    policyGradLoss     | -0.0137     |\n",
      "|    value_loss         | 0.242       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 191         |\n",
      "|    total_timesteps    | 44449792    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013778662 |\n",
      "|    entropy_loss       | -2.29       |\n",
      "|    explained_variance | 0.912       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0771     |\n",
      "|    mean_step_reward   | 0.009844661 |\n",
      "|    n_updates          | 68/128      |\n",
      "|    policyGradLoss     | -0.0143     |\n",
      "|    value_loss         | 0.184       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 764         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 203         |\n",
      "|    total_timesteps    | 44457984    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.0153562   |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.948       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0774     |\n",
      "|    mean_step_reward   | 0.025743151 |\n",
      "|    n_updates          | 72/128      |\n",
      "|    policyGradLoss     | -0.0155     |\n",
      "|    value_loss         | 0.248       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 762         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 214         |\n",
      "|    total_timesteps    | 44466176    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025833804 |\n",
      "|    entropy_loss       | -2.2        |\n",
      "|    explained_variance | 0.922       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0885     |\n",
      "|    mean_step_reward   | 0.031951245 |\n",
      "|    n_updates          | 76/128      |\n",
      "|    policyGradLoss     | -0.0153     |\n",
      "|    value_loss         | 0.252       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 760         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 226         |\n",
      "|    total_timesteps    | 44474368    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029177628 |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0929     |\n",
      "|    mean_step_reward   | 0.026590293 |\n",
      "|    n_updates          | 80/128      |\n",
      "|    policyGradLoss     | -0.0142     |\n",
      "|    value_loss         | 0.136       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 759         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 237         |\n",
      "|    total_timesteps    | 44482560    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02262223  |\n",
      "|    entropy_loss       | -2.27       |\n",
      "|    explained_variance | 0.918       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0552     |\n",
      "|    mean_step_reward   | 0.017357863 |\n",
      "|    n_updates          | 84/128      |\n",
      "|    policyGradLoss     | -0.019      |\n",
      "|    value_loss         | 0.264       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 758         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 248         |\n",
      "|    total_timesteps    | 44490752    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029844444 |\n",
      "|    entropy_loss       | -2.2        |\n",
      "|    explained_variance | 0.941       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0416     |\n",
      "|    mean_step_reward   | 0.023383025 |\n",
      "|    n_updates          | 88/128      |\n",
      "|    policyGradLoss     | -0.0181     |\n",
      "|    value_loss         | 0.195       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 756         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 259         |\n",
      "|    total_timesteps    | 44498944    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028097339 |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0861     |\n",
      "|    mean_step_reward   | 0.0384612   |\n",
      "|    n_updates          | 92/128      |\n",
      "|    policyGradLoss     | -0.0229     |\n",
      "|    value_loss         | 0.125       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 754         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 271         |\n",
      "|    total_timesteps    | 44507136    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027435448 |\n",
      "|    entropy_loss       | -2.29       |\n",
      "|    explained_variance | 0.943       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0809     |\n",
      "|    mean_step_reward   | 0.019320302 |\n",
      "|    n_updates          | 96/128      |\n",
      "|    policyGradLoss     | -0.0168     |\n",
      "|    value_loss         | 0.153       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 752          |\n",
      "|    iterations         | 26           |\n",
      "|    time_elapsed       | 282          |\n",
      "|    total_timesteps    | 44515328     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.021977887  |\n",
      "|    entropy_loss       | -2.32        |\n",
      "|    explained_variance | 0.862        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.089       |\n",
      "|    mean_step_reward   | 0.0100083295 |\n",
      "|    n_updates          | 100/128      |\n",
      "|    policyGradLoss     | -0.0162      |\n",
      "|    value_loss         | 0.136        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 753          |\n",
      "|    iterations         | 27           |\n",
      "|    time_elapsed       | 293          |\n",
      "|    total_timesteps    | 44523520     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.017504197  |\n",
      "|    entropy_loss       | -2.28        |\n",
      "|    explained_variance | 0.77         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0874      |\n",
      "|    mean_step_reward   | 0.0074290168 |\n",
      "|    n_updates          | 104/128      |\n",
      "|    policyGradLoss     | -0.012       |\n",
      "|    value_loss         | 0.23         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 753         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 304         |\n",
      "|    total_timesteps    | 44531712    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025952809 |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.948       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.097      |\n",
      "|    mean_step_reward   | 0.023368264 |\n",
      "|    n_updates          | 108/128     |\n",
      "|    policyGradLoss     | -0.0217     |\n",
      "|    value_loss         | 0.119       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 751         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 316         |\n",
      "|    total_timesteps    | 44539904    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020489473 |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.947       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0759     |\n",
      "|    mean_step_reward   | 0.019106261 |\n",
      "|    n_updates          | 112/128     |\n",
      "|    policyGradLoss     | -0.0164     |\n",
      "|    value_loss         | 0.187       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 749         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 327         |\n",
      "|    total_timesteps    | 44548096    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019399516 |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.871       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0572     |\n",
      "|    mean_step_reward   | 0.019482303 |\n",
      "|    n_updates          | 116/128     |\n",
      "|    policyGradLoss     | -0.0111     |\n",
      "|    value_loss         | 0.365       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 748         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 339         |\n",
      "|    total_timesteps    | 44556288    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016081858 |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.778       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0884     |\n",
      "|    mean_step_reward   | 0.022535224 |\n",
      "|    n_updates          | 120/128     |\n",
      "|    policyGradLoss     | -0.0144     |\n",
      "|    value_loss         | 0.263       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 748         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 350         |\n",
      "|    total_timesteps    | 44564480    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020586781 |\n",
      "|    entropy_loss       | -2.27       |\n",
      "|    explained_variance | 0.783       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0752     |\n",
      "|    mean_step_reward   | 0.02167426  |\n",
      "|    n_updates          | 124/128     |\n",
      "|    policyGradLoss     | -0.0107     |\n",
      "|    value_loss         | 0.283       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/NoArti_169.zip\n",
      "[EVAL] Mean Return: 6.674, Best Return: 8.290\n",
      "Saved video to ./runs_smw/videos/NoArti/NoArti_169_6.67.mp4\n",
      "\n",
      "=== Round 171 | Learn 262144 steps (Total trained: 44564480) ===\n",
      "Logging to ./runs_smw/tb/NoArti_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1139     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 44572672 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 881         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 44580864    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01481922  |\n",
      "|    entropy_loss       | -2.32       |\n",
      "|    explained_variance | 0.845       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.107      |\n",
      "|    mean_step_reward   | 0.021545582 |\n",
      "|    n_updates          | 4/128       |\n",
      "|    policyGradLoss     | -0.015      |\n",
      "|    value_loss         | 0.157       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 812          |\n",
      "|    iterations         | 3            |\n",
      "|    time_elapsed       | 30           |\n",
      "|    total_timesteps    | 44589056     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.020061972  |\n",
      "|    entropy_loss       | -2.35        |\n",
      "|    explained_variance | 0.915        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.104       |\n",
      "|    mean_step_reward   | 0.0058671106 |\n",
      "|    n_updates          | 8/128        |\n",
      "|    policyGradLoss     | -0.015       |\n",
      "|    value_loss         | 0.0703       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 781          |\n",
      "|    iterations         | 4            |\n",
      "|    time_elapsed       | 41           |\n",
      "|    total_timesteps    | 44597248     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.011577133  |\n",
      "|    entropy_loss       | -2.31        |\n",
      "|    explained_variance | 0.927        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.104       |\n",
      "|    mean_step_reward   | 0.0056571164 |\n",
      "|    n_updates          | 12/128       |\n",
      "|    policyGradLoss     | -0.0134      |\n",
      "|    value_loss         | 0.196        |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 769        |\n",
      "|    iterations         | 5          |\n",
      "|    time_elapsed       | 53         |\n",
      "|    total_timesteps    | 44605440   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02371708 |\n",
      "|    entropy_loss       | -2.25      |\n",
      "|    explained_variance | 0.943      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.102     |\n",
      "|    mean_step_reward   | 0.02085178 |\n",
      "|    n_updates          | 16/128     |\n",
      "|    policyGradLoss     | -0.0187    |\n",
      "|    value_loss         | 0.127      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 64          |\n",
      "|    total_timesteps    | 44613632    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016637135 |\n",
      "|    entropy_loss       | -2.27       |\n",
      "|    explained_variance | 0.822       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0717     |\n",
      "|    mean_step_reward   | 0.027962478 |\n",
      "|    n_updates          | 20/128      |\n",
      "|    policyGradLoss     | -0.0107     |\n",
      "|    value_loss         | 0.284       |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 766           |\n",
      "|    iterations         | 7             |\n",
      "|    time_elapsed       | 74            |\n",
      "|    total_timesteps    | 44621824      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.014272606   |\n",
      "|    entropy_loss       | -2.21         |\n",
      "|    explained_variance | 0.653         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0228       |\n",
      "|    mean_step_reward   | -0.0013066591 |\n",
      "|    n_updates          | 24/128        |\n",
      "|    policyGradLoss     | -0.00985      |\n",
      "|    value_loss         | 0.726         |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 84          |\n",
      "|    total_timesteps    | 44630016    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022946231 |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.871       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0789     |\n",
      "|    mean_step_reward   | 0.037542447 |\n",
      "|    n_updates          | 28/128      |\n",
      "|    policyGradLoss     | -0.0183     |\n",
      "|    value_loss         | 0.224       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 790         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 93          |\n",
      "|    total_timesteps    | 44638208    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024695773 |\n",
      "|    entropy_loss       | -2.2        |\n",
      "|    explained_variance | 0.957       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0901     |\n",
      "|    mean_step_reward   | 0.048493702 |\n",
      "|    n_updates          | 32/128      |\n",
      "|    policyGradLoss     | -0.0188     |\n",
      "|    value_loss         | 0.137       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 797         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 102         |\n",
      "|    total_timesteps    | 44646400    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.033789508 |\n",
      "|    entropy_loss       | -2.28       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.102      |\n",
      "|    mean_step_reward   | 0.02734946  |\n",
      "|    n_updates          | 36/128      |\n",
      "|    policyGradLoss     | -0.0166     |\n",
      "|    value_loss         | 0.0662      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 803         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 112         |\n",
      "|    total_timesteps    | 44654592    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019928701 |\n",
      "|    entropy_loss       | -2.29       |\n",
      "|    explained_variance | 0.899       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0847     |\n",
      "|    mean_step_reward   | 0.011530148 |\n",
      "|    n_updates          | 40/128      |\n",
      "|    policyGradLoss     | -0.0155     |\n",
      "|    value_loss         | 0.201       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 798         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 123         |\n",
      "|    total_timesteps    | 44662784    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.033022508 |\n",
      "|    entropy_loss       | -2.18       |\n",
      "|    explained_variance | 0.922       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0257      |\n",
      "|    mean_step_reward   | 0.031087425 |\n",
      "|    n_updates          | 44/128      |\n",
      "|    policyGradLoss     | -0.0192     |\n",
      "|    value_loss         | 0.201       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 793         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 134         |\n",
      "|    total_timesteps    | 44670976    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014791863 |\n",
      "|    entropy_loss       | -2.19       |\n",
      "|    explained_variance | 0.893       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0803     |\n",
      "|    mean_step_reward   | 0.04668843  |\n",
      "|    n_updates          | 48/128      |\n",
      "|    policyGradLoss     | -0.0114     |\n",
      "|    value_loss         | 0.382       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 788         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 145         |\n",
      "|    total_timesteps    | 44679168    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019473422 |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.909       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0106      |\n",
      "|    mean_step_reward   | 0.028222652 |\n",
      "|    n_updates          | 52/128      |\n",
      "|    policyGradLoss     | -0.012      |\n",
      "|    value_loss         | 0.32        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 157         |\n",
      "|    total_timesteps    | 44687360    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022669904 |\n",
      "|    entropy_loss       | -2.33       |\n",
      "|    explained_variance | 0.917       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0756     |\n",
      "|    mean_step_reward   | 0.014770145 |\n",
      "|    n_updates          | 56/128      |\n",
      "|    policyGradLoss     | -0.0144     |\n",
      "|    value_loss         | 0.141       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 168         |\n",
      "|    total_timesteps    | 44695552    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02830271  |\n",
      "|    entropy_loss       | -2.3        |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0915     |\n",
      "|    mean_step_reward   | 0.028112683 |\n",
      "|    n_updates          | 60/128      |\n",
      "|    policyGradLoss     | -0.0181     |\n",
      "|    value_loss         | 0.0726      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 773          |\n",
      "|    iterations         | 17           |\n",
      "|    time_elapsed       | 179          |\n",
      "|    total_timesteps    | 44703744     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.015221011  |\n",
      "|    entropy_loss       | -2.38        |\n",
      "|    explained_variance | 0.927        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.104       |\n",
      "|    mean_step_reward   | 0.0034805073 |\n",
      "|    n_updates          | 64/128       |\n",
      "|    policyGradLoss     | -0.0133      |\n",
      "|    value_loss         | 0.0799       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 191         |\n",
      "|    total_timesteps    | 44711936    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012632756 |\n",
      "|    entropy_loss       | -2.32       |\n",
      "|    explained_variance | 0.945       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.103      |\n",
      "|    mean_step_reward   | 0.010319421 |\n",
      "|    n_updates          | 68/128      |\n",
      "|    policyGradLoss     | -0.0165     |\n",
      "|    value_loss         | 0.148       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 768          |\n",
      "|    iterations         | 19           |\n",
      "|    time_elapsed       | 202          |\n",
      "|    total_timesteps    | 44720128     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.015467798  |\n",
      "|    entropy_loss       | -2.27        |\n",
      "|    explained_variance | 0.849        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0694      |\n",
      "|    mean_step_reward   | 0.0096422685 |\n",
      "|    n_updates          | 72/128       |\n",
      "|    policyGradLoss     | -0.0164      |\n",
      "|    value_loss         | 0.276        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 765         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 213         |\n",
      "|    total_timesteps    | 44728320    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.0160565   |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.901       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0351      |\n",
      "|    mean_step_reward   | 0.014333898 |\n",
      "|    n_updates          | 76/128      |\n",
      "|    policyGradLoss     | -0.0164     |\n",
      "|    value_loss         | 0.443       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 762         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 225         |\n",
      "|    total_timesteps    | 44736512    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016301315 |\n",
      "|    entropy_loss       | -2.27       |\n",
      "|    explained_variance | 0.939       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0967     |\n",
      "|    mean_step_reward   | 0.021147022 |\n",
      "|    n_updates          | 80/128      |\n",
      "|    policyGradLoss     | -0.0198     |\n",
      "|    value_loss         | 0.159       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 760         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 236         |\n",
      "|    total_timesteps    | 44744704    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014843298 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.91        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0509     |\n",
      "|    mean_step_reward   | 0.021994239 |\n",
      "|    n_updates          | 84/128      |\n",
      "|    policyGradLoss     | -0.0143     |\n",
      "|    value_loss         | 0.343       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 758         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 248         |\n",
      "|    total_timesteps    | 44752896    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02076873  |\n",
      "|    entropy_loss       | -2.3        |\n",
      "|    explained_variance | 0.897       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.107      |\n",
      "|    mean_step_reward   | 0.016615262 |\n",
      "|    n_updates          | 88/128      |\n",
      "|    policyGradLoss     | -0.0202     |\n",
      "|    value_loss         | 0.11        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 758         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 259         |\n",
      "|    total_timesteps    | 44761088    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014682844 |\n",
      "|    entropy_loss       | -2.3        |\n",
      "|    explained_variance | 0.877       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0837     |\n",
      "|    mean_step_reward   | 0.018407393 |\n",
      "|    n_updates          | 92/128      |\n",
      "|    policyGradLoss     | -0.0147     |\n",
      "|    value_loss         | 0.233       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 756         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 270         |\n",
      "|    total_timesteps    | 44769280    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017615147 |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.751       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0699     |\n",
      "|    mean_step_reward   | 0.023446511 |\n",
      "|    n_updates          | 96/128      |\n",
      "|    policyGradLoss     | -0.0106     |\n",
      "|    value_loss         | 0.456       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 754         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 282         |\n",
      "|    total_timesteps    | 44777472    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021385666 |\n",
      "|    entropy_loss       | -2.28       |\n",
      "|    explained_variance | 0.8         |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0752     |\n",
      "|    mean_step_reward   | 0.010180156 |\n",
      "|    n_updates          | 100/128     |\n",
      "|    policyGradLoss     | -0.0197     |\n",
      "|    value_loss         | 0.223       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 752          |\n",
      "|    iterations         | 27           |\n",
      "|    time_elapsed       | 293          |\n",
      "|    total_timesteps    | 44785664     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0139048295 |\n",
      "|    entropy_loss       | -2.22        |\n",
      "|    explained_variance | 0.875        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0555      |\n",
      "|    mean_step_reward   | 0.03362515   |\n",
      "|    n_updates          | 104/128      |\n",
      "|    policyGradLoss     | -0.0163      |\n",
      "|    value_loss         | 0.357        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 751         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 305         |\n",
      "|    total_timesteps    | 44793856    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014329528 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.892       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0676     |\n",
      "|    mean_step_reward   | 0.026444238 |\n",
      "|    n_updates          | 108/128     |\n",
      "|    policyGradLoss     | -0.0152     |\n",
      "|    value_loss         | 0.236       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 751         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 316         |\n",
      "|    total_timesteps    | 44802048    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017242428 |\n",
      "|    entropy_loss       | -2.2        |\n",
      "|    explained_variance | 0.695       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.057      |\n",
      "|    mean_step_reward   | 0.018296313 |\n",
      "|    n_updates          | 112/128     |\n",
      "|    policyGradLoss     | -0.0165     |\n",
      "|    value_loss         | 0.478       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 750         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 327         |\n",
      "|    total_timesteps    | 44810240    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02109139  |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.896       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0922     |\n",
      "|    mean_step_reward   | 0.032066844 |\n",
      "|    n_updates          | 116/128     |\n",
      "|    policyGradLoss     | -0.0147     |\n",
      "|    value_loss         | 0.188       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 749         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 338         |\n",
      "|    total_timesteps    | 44818432    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02003661  |\n",
      "|    entropy_loss       | -2.28       |\n",
      "|    explained_variance | 0.907       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0918     |\n",
      "|    mean_step_reward   | 0.016168049 |\n",
      "|    n_updates          | 120/128     |\n",
      "|    policyGradLoss     | -0.0205     |\n",
      "|    value_loss         | 0.143       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 747          |\n",
      "|    iterations         | 32           |\n",
      "|    time_elapsed       | 350          |\n",
      "|    total_timesteps    | 44826624     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0138638085 |\n",
      "|    entropy_loss       | -2.24        |\n",
      "|    explained_variance | 0.815        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0758      |\n",
      "|    mean_step_reward   | 0.024476327  |\n",
      "|    n_updates          | 124/128      |\n",
      "|    policyGradLoss     | -0.012       |\n",
      "|    value_loss         | 0.421        |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/NoArti_170.zip\n",
      "[EVAL] Mean Return: 40.096, Best Return: 42.096\n",
      "Saved video to ./runs_smw/videos/NoArti/NoArti_170_40.10.mp4\n",
      "\n",
      "=== Round 172 | Learn 262144 steps (Total trained: 44826624) ===\n",
      "Logging to ./runs_smw/tb/NoArti_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1180     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 44834816 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 897         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 44843008    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016490314 |\n",
      "|    entropy_loss       | -2.27       |\n",
      "|    explained_variance | 0.909       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0781     |\n",
      "|    mean_step_reward   | 0.017266354 |\n",
      "|    n_updates          | 4/128       |\n",
      "|    policyGradLoss     | -0.0152     |\n",
      "|    value_loss         | 0.259       |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 821            |\n",
      "|    iterations         | 3              |\n",
      "|    time_elapsed       | 29             |\n",
      "|    total_timesteps    | 44851200       |\n",
      "| train/                |                |\n",
      "|    approx_kl          | 0.013537072    |\n",
      "|    entropy_loss       | -2.26          |\n",
      "|    explained_variance | 0.56           |\n",
      "|    learning_rate      | 0.0001         |\n",
      "|    loss               | 0.0417         |\n",
      "|    mean_step_reward   | -5.5020675e-05 |\n",
      "|    n_updates          | 8/128          |\n",
      "|    policyGradLoss     | -0.0109        |\n",
      "|    value_loss         | 0.59           |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 790         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 41          |\n",
      "|    total_timesteps    | 44859392    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01646863  |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.923       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0875     |\n",
      "|    mean_step_reward   | 0.029253103 |\n",
      "|    n_updates          | 12/128      |\n",
      "|    policyGradLoss     | -0.0179     |\n",
      "|    value_loss         | 0.216       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 52          |\n",
      "|    total_timesteps    | 44867584    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016567677 |\n",
      "|    entropy_loss       | -2.27       |\n",
      "|    explained_variance | 0.866       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0704     |\n",
      "|    mean_step_reward   | 0.011947949 |\n",
      "|    n_updates          | 16/128      |\n",
      "|    policyGradLoss     | -0.0127     |\n",
      "|    value_loss         | 0.269       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 63          |\n",
      "|    total_timesteps    | 44875776    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014923809 |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.833       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0877     |\n",
      "|    mean_step_reward   | 0.024343403 |\n",
      "|    n_updates          | 20/128      |\n",
      "|    policyGradLoss     | -0.012      |\n",
      "|    value_loss         | 0.31        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 765         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 74          |\n",
      "|    total_timesteps    | 44883968    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016883895 |\n",
      "|    entropy_loss       | -2.27       |\n",
      "|    explained_variance | 0.869       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0847     |\n",
      "|    mean_step_reward   | 0.03287217  |\n",
      "|    n_updates          | 24/128      |\n",
      "|    policyGradLoss     | -0.0129     |\n",
      "|    value_loss         | 0.211       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 84          |\n",
      "|    total_timesteps    | 44892160    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017653715 |\n",
      "|    entropy_loss       | -2.27       |\n",
      "|    explained_variance | 0.94        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0967     |\n",
      "|    mean_step_reward   | 0.026205894 |\n",
      "|    n_updates          | 28/128      |\n",
      "|    policyGradLoss     | -0.0185     |\n",
      "|    value_loss         | 0.241       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 791          |\n",
      "|    iterations         | 9            |\n",
      "|    time_elapsed       | 93           |\n",
      "|    total_timesteps    | 44900352     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0135100465 |\n",
      "|    entropy_loss       | -2.27        |\n",
      "|    explained_variance | 0.854        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.00647      |\n",
      "|    mean_step_reward   | 0.01816932   |\n",
      "|    n_updates          | 32/128       |\n",
      "|    policyGradLoss     | -0.0141      |\n",
      "|    value_loss         | 0.358        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 799         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 102         |\n",
      "|    total_timesteps    | 44908544    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01204687  |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.926       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0732     |\n",
      "|    mean_step_reward   | 0.015030464 |\n",
      "|    n_updates          | 36/128      |\n",
      "|    policyGradLoss     | -0.0158     |\n",
      "|    value_loss         | 0.217       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 805         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 111         |\n",
      "|    total_timesteps    | 44916736    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018743115 |\n",
      "|    entropy_loss       | -2.29       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0796     |\n",
      "|    mean_step_reward   | 0.02110369  |\n",
      "|    n_updates          | 40/128      |\n",
      "|    policyGradLoss     | -0.0194     |\n",
      "|    value_loss         | 0.113       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 799         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 122         |\n",
      "|    total_timesteps    | 44924928    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029995855 |\n",
      "|    entropy_loss       | -2.32       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.115      |\n",
      "|    mean_step_reward   | 0.020021867 |\n",
      "|    n_updates          | 44/128      |\n",
      "|    policyGradLoss     | -0.0188     |\n",
      "|    value_loss         | 0.0331      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 792         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 134         |\n",
      "|    total_timesteps    | 44933120    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012554137 |\n",
      "|    entropy_loss       | -2.29       |\n",
      "|    explained_variance | 0.933       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0816     |\n",
      "|    mean_step_reward   | 0.001554531 |\n",
      "|    n_updates          | 48/128      |\n",
      "|    policyGradLoss     | -0.0156     |\n",
      "|    value_loss         | 0.179       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 146         |\n",
      "|    total_timesteps    | 44941312    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017800458 |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.753       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0722      |\n",
      "|    mean_step_reward   | 0.02092435  |\n",
      "|    n_updates          | 52/128      |\n",
      "|    policyGradLoss     | -0.0142     |\n",
      "|    value_loss         | 0.431       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 157         |\n",
      "|    total_timesteps    | 44949504    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014386682 |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.777       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0129     |\n",
      "|    mean_step_reward   | 0.019762069 |\n",
      "|    n_updates          | 56/128      |\n",
      "|    policyGradLoss     | -0.0115     |\n",
      "|    value_loss         | 0.505       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 168         |\n",
      "|    total_timesteps    | 44957696    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023143811 |\n",
      "|    entropy_loss       | -2.2        |\n",
      "|    explained_variance | 0.906       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0998     |\n",
      "|    mean_step_reward   | 0.03622912  |\n",
      "|    n_updates          | 60/128      |\n",
      "|    policyGradLoss     | -0.0131     |\n",
      "|    value_loss         | 0.152       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 179         |\n",
      "|    total_timesteps    | 44965888    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023557048 |\n",
      "|    entropy_loss       | -2.27       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.104      |\n",
      "|    mean_step_reward   | 0.028742414 |\n",
      "|    n_updates          | 64/128      |\n",
      "|    policyGradLoss     | -0.018      |\n",
      "|    value_loss         | 0.135       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 191         |\n",
      "|    total_timesteps    | 44974080    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02219775  |\n",
      "|    entropy_loss       | -2.28       |\n",
      "|    explained_variance | 0.797       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0964     |\n",
      "|    mean_step_reward   | 0.013780752 |\n",
      "|    n_updates          | 68/128      |\n",
      "|    policyGradLoss     | -0.0152     |\n",
      "|    value_loss         | 0.223       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 202         |\n",
      "|    total_timesteps    | 44982272    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017474942 |\n",
      "|    entropy_loss       | -2.28       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.101      |\n",
      "|    mean_step_reward   | 0.021873396 |\n",
      "|    n_updates          | 72/128      |\n",
      "|    policyGradLoss     | -0.0191     |\n",
      "|    value_loss         | 0.104       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 764         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 214         |\n",
      "|    total_timesteps    | 44990464    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01684232  |\n",
      "|    entropy_loss       | -2.27       |\n",
      "|    explained_variance | 0.897       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0889     |\n",
      "|    mean_step_reward   | 0.014430848 |\n",
      "|    n_updates          | 76/128      |\n",
      "|    policyGradLoss     | -0.0149     |\n",
      "|    value_loss         | 0.222       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 762         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 225         |\n",
      "|    total_timesteps    | 44998656    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020314734 |\n",
      "|    entropy_loss       | -2.27       |\n",
      "|    explained_variance | 0.917       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.086      |\n",
      "|    mean_step_reward   | 0.025632259 |\n",
      "|    n_updates          | 80/128      |\n",
      "|    policyGradLoss     | -0.015      |\n",
      "|    value_loss         | 0.16        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 761         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 236         |\n",
      "|    total_timesteps    | 45006848    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014746232 |\n",
      "|    entropy_loss       | -2.31       |\n",
      "|    explained_variance | 0.814       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0778     |\n",
      "|    mean_step_reward   | 0.010149119 |\n",
      "|    n_updates          | 84/128      |\n",
      "|    policyGradLoss     | -0.0153     |\n",
      "|    value_loss         | 0.281       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 759         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 247         |\n",
      "|    total_timesteps    | 45015040    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018983133 |\n",
      "|    entropy_loss       | -2.27       |\n",
      "|    explained_variance | 0.865       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0745     |\n",
      "|    mean_step_reward   | 0.013278119 |\n",
      "|    n_updates          | 88/128      |\n",
      "|    policyGradLoss     | -0.0175     |\n",
      "|    value_loss         | 0.236       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 758         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 259         |\n",
      "|    total_timesteps    | 45023232    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016166558 |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.898       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.059      |\n",
      "|    mean_step_reward   | 0.004115002 |\n",
      "|    n_updates          | 92/128      |\n",
      "|    policyGradLoss     | -0.0147     |\n",
      "|    value_loss         | 0.252       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 756         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 270         |\n",
      "|    total_timesteps    | 45031424    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018627893 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.937       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0796     |\n",
      "|    mean_step_reward   | 0.02939625  |\n",
      "|    n_updates          | 96/128      |\n",
      "|    policyGradLoss     | -0.0197     |\n",
      "|    value_loss         | 0.149       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 754         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 282         |\n",
      "|    total_timesteps    | 45039616    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019407535 |\n",
      "|    entropy_loss       | -2.18       |\n",
      "|    explained_variance | 0.906       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0201     |\n",
      "|    mean_step_reward   | 0.032924436 |\n",
      "|    n_updates          | 100/128     |\n",
      "|    policyGradLoss     | -0.0158     |\n",
      "|    value_loss         | 0.344       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 753         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 293         |\n",
      "|    total_timesteps    | 45047808    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015571471 |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.92        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0788     |\n",
      "|    mean_step_reward   | 0.025444705 |\n",
      "|    n_updates          | 104/128     |\n",
      "|    policyGradLoss     | -0.0179     |\n",
      "|    value_loss         | 0.209       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 753         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 304         |\n",
      "|    total_timesteps    | 45056000    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018728286 |\n",
      "|    entropy_loss       | -2.19       |\n",
      "|    explained_variance | 0.883       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.066      |\n",
      "|    mean_step_reward   | 0.028744033 |\n",
      "|    n_updates          | 108/128     |\n",
      "|    policyGradLoss     | -0.0188     |\n",
      "|    value_loss         | 0.3         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 753         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 315         |\n",
      "|    total_timesteps    | 45064192    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02509173  |\n",
      "|    entropy_loss       | -2.28       |\n",
      "|    explained_variance | 0.921       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.107      |\n",
      "|    mean_step_reward   | 0.020899186 |\n",
      "|    n_updates          | 112/128     |\n",
      "|    policyGradLoss     | -0.0218     |\n",
      "|    value_loss         | 0.106       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 751         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 326         |\n",
      "|    total_timesteps    | 45072384    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017215434 |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.823       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0837     |\n",
      "|    mean_step_reward   | 0.033354744 |\n",
      "|    n_updates          | 116/128     |\n",
      "|    policyGradLoss     | -0.0134     |\n",
      "|    value_loss         | 0.243       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 750         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 338         |\n",
      "|    total_timesteps    | 45080576    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012816144 |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.835       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0472     |\n",
      "|    mean_step_reward   | 0.03938456  |\n",
      "|    n_updates          | 120/128     |\n",
      "|    policyGradLoss     | -0.0107     |\n",
      "|    value_loss         | 0.433       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 749         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 349         |\n",
      "|    total_timesteps    | 45088768    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022229813 |\n",
      "|    entropy_loss       | -2.17       |\n",
      "|    explained_variance | 0.931       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0987     |\n",
      "|    mean_step_reward   | 0.048771217 |\n",
      "|    n_updates          | 124/128     |\n",
      "|    policyGradLoss     | -0.017      |\n",
      "|    value_loss         | 0.162       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/NoArti_171.zip\n",
      "[EVAL] Mean Return: 132.140, Best Return: 134.740\n",
      "Saved video to ./runs_smw/videos/NoArti/NoArti_171_132.14.mp4\n",
      "\n",
      "=== Round 173 | Learn 262144 steps (Total trained: 45088768) ===\n",
      "Logging to ./runs_smw/tb/NoArti_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1163     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 45096960 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 905         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 45105152    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018828973 |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.933       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0121      |\n",
      "|    mean_step_reward   | 0.027327776 |\n",
      "|    n_updates          | 4/128       |\n",
      "|    policyGradLoss     | -0.0148     |\n",
      "|    value_loss         | 0.352       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 828         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 29          |\n",
      "|    total_timesteps    | 45113344    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022972468 |\n",
      "|    entropy_loss       | -2.15       |\n",
      "|    explained_variance | 0.943       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0626     |\n",
      "|    mean_step_reward   | 0.049875204 |\n",
      "|    n_updates          | 8/128       |\n",
      "|    policyGradLoss     | -0.0214     |\n",
      "|    value_loss         | 0.244       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 792         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 41          |\n",
      "|    total_timesteps    | 45121536    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01995255  |\n",
      "|    entropy_loss       | -2.18       |\n",
      "|    explained_variance | 0.925       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0653     |\n",
      "|    mean_step_reward   | 0.035865016 |\n",
      "|    n_updates          | 12/128      |\n",
      "|    policyGradLoss     | -0.0185     |\n",
      "|    value_loss         | 0.314       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 52          |\n",
      "|    total_timesteps    | 45129728    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023789428 |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.929       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0489     |\n",
      "|    mean_step_reward   | 0.030711425 |\n",
      "|    n_updates          | 16/128      |\n",
      "|    policyGradLoss     | -0.0157     |\n",
      "|    value_loss         | 0.245       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 792         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 62          |\n",
      "|    total_timesteps    | 45137920    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020879436 |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.921       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.108      |\n",
      "|    mean_step_reward   | 0.026683744 |\n",
      "|    n_updates          | 20/128      |\n",
      "|    policyGradLoss     | -0.0188     |\n",
      "|    value_loss         | 0.144       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 808         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 70          |\n",
      "|    total_timesteps    | 45146112    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023488738 |\n",
      "|    entropy_loss       | -2.27       |\n",
      "|    explained_variance | 0.95        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0755     |\n",
      "|    mean_step_reward   | 0.029615473 |\n",
      "|    n_updates          | 24/128      |\n",
      "|    policyGradLoss     | -0.0191     |\n",
      "|    value_loss         | 0.166       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 815          |\n",
      "|    iterations         | 8            |\n",
      "|    time_elapsed       | 80           |\n",
      "|    total_timesteps    | 45154304     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0136879645 |\n",
      "|    entropy_loss       | -2.32        |\n",
      "|    explained_variance | 0.923        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0957      |\n",
      "|    mean_step_reward   | 0.007874599  |\n",
      "|    n_updates          | 28/128       |\n",
      "|    policyGradLoss     | -0.019       |\n",
      "|    value_loss         | 0.101        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 820         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 89          |\n",
      "|    total_timesteps    | 45162496    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023770047 |\n",
      "|    entropy_loss       | -2.31       |\n",
      "|    explained_variance | 0.791       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0965     |\n",
      "|    mean_step_reward   | 0.009535367 |\n",
      "|    n_updates          | 32/128      |\n",
      "|    policyGradLoss     | -0.0187     |\n",
      "|    value_loss         | 0.123       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 809         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 101         |\n",
      "|    total_timesteps    | 45170688    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019730775 |\n",
      "|    entropy_loss       | -2.28       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0908     |\n",
      "|    mean_step_reward   | 0.022612644 |\n",
      "|    n_updates          | 36/128      |\n",
      "|    policyGradLoss     | -0.0171     |\n",
      "|    value_loss         | 0.121       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 802         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 112         |\n",
      "|    total_timesteps    | 45178880    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020152308 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.91        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0339      |\n",
      "|    mean_step_reward   | 0.024089672 |\n",
      "|    n_updates          | 40/128      |\n",
      "|    policyGradLoss     | -0.0182     |\n",
      "|    value_loss         | 0.209       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 796         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 123         |\n",
      "|    total_timesteps    | 45187072    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017363826 |\n",
      "|    entropy_loss       | -2.2        |\n",
      "|    explained_variance | 0.918       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0253     |\n",
      "|    mean_step_reward   | 0.03795502  |\n",
      "|    n_updates          | 44/128      |\n",
      "|    policyGradLoss     | -0.0142     |\n",
      "|    value_loss         | 0.389       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 792         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 134         |\n",
      "|    total_timesteps    | 45195264    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020111313 |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.902       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0762     |\n",
      "|    mean_step_reward   | 0.02594172  |\n",
      "|    n_updates          | 48/128      |\n",
      "|    policyGradLoss     | -0.0131     |\n",
      "|    value_loss         | 0.32        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 146         |\n",
      "|    total_timesteps    | 45203456    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02222037  |\n",
      "|    entropy_loss       | -2.2        |\n",
      "|    explained_variance | 0.938       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0637     |\n",
      "|    mean_step_reward   | 0.026118971 |\n",
      "|    n_updates          | 52/128      |\n",
      "|    policyGradLoss     | -0.0172     |\n",
      "|    value_loss         | 0.212       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 157         |\n",
      "|    total_timesteps    | 45211648    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018409982 |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.921       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.084      |\n",
      "|    mean_step_reward   | 0.03322784  |\n",
      "|    n_updates          | 56/128      |\n",
      "|    policyGradLoss     | -0.0164     |\n",
      "|    value_loss         | 0.244       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 169         |\n",
      "|    total_timesteps    | 45219840    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026345039 |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.943       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.111      |\n",
      "|    mean_step_reward   | 0.025639806 |\n",
      "|    n_updates          | 60/128      |\n",
      "|    policyGradLoss     | -0.0217     |\n",
      "|    value_loss         | 0.0973      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 180         |\n",
      "|    total_timesteps    | 45228032    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022428907 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.861       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0744     |\n",
      "|    mean_step_reward   | 0.017283633 |\n",
      "|    n_updates          | 64/128      |\n",
      "|    policyGradLoss     | -0.0153     |\n",
      "|    value_loss         | 0.259       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 191         |\n",
      "|    total_timesteps    | 45236224    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022862576 |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0487     |\n",
      "|    mean_step_reward   | 0.045628563 |\n",
      "|    n_updates          | 68/128      |\n",
      "|    policyGradLoss     | -0.0142     |\n",
      "|    value_loss         | 0.223       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 202         |\n",
      "|    total_timesteps    | 45244416    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027559392 |\n",
      "|    entropy_loss       | -2.27       |\n",
      "|    explained_variance | 0.942       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0785     |\n",
      "|    mean_step_reward   | 0.021185936 |\n",
      "|    n_updates          | 72/128      |\n",
      "|    policyGradLoss     | -0.019      |\n",
      "|    value_loss         | 0.13        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 764         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 214         |\n",
      "|    total_timesteps    | 45252608    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019656029 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.941       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0168      |\n",
      "|    mean_step_reward   | 0.011055391 |\n",
      "|    n_updates          | 76/128      |\n",
      "|    policyGradLoss     | -0.0165     |\n",
      "|    value_loss         | 0.236       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 761         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 225         |\n",
      "|    total_timesteps    | 45260800    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.0259187   |\n",
      "|    entropy_loss       | -2.29       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.11       |\n",
      "|    mean_step_reward   | 0.028031927 |\n",
      "|    n_updates          | 80/128      |\n",
      "|    policyGradLoss     | -0.0195     |\n",
      "|    value_loss         | 0.0949      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 760          |\n",
      "|    iterations         | 22           |\n",
      "|    time_elapsed       | 236          |\n",
      "|    total_timesteps    | 45268992     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.021381188  |\n",
      "|    entropy_loss       | -2.33        |\n",
      "|    explained_variance | 0.852        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.099       |\n",
      "|    mean_step_reward   | 0.0037726094 |\n",
      "|    n_updates          | 84/128       |\n",
      "|    policyGradLoss     | -0.0152      |\n",
      "|    value_loss         | 0.132        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 759         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 248         |\n",
      "|    total_timesteps    | 45277184    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019675294 |\n",
      "|    entropy_loss       | -2.31       |\n",
      "|    explained_variance | 0.936       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0971     |\n",
      "|    mean_step_reward   | 0.020415882 |\n",
      "|    n_updates          | 88/128      |\n",
      "|    policyGradLoss     | -0.0163     |\n",
      "|    value_loss         | 0.137       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 758         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 259         |\n",
      "|    total_timesteps    | 45285376    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014112635 |\n",
      "|    entropy_loss       | -2.31       |\n",
      "|    explained_variance | 0.947       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0898     |\n",
      "|    mean_step_reward   | 0.015533974 |\n",
      "|    n_updates          | 92/128      |\n",
      "|    policyGradLoss     | -0.0175     |\n",
      "|    value_loss         | 0.123       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 756          |\n",
      "|    iterations         | 25           |\n",
      "|    time_elapsed       | 270          |\n",
      "|    total_timesteps    | 45293568     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.016643478  |\n",
      "|    entropy_loss       | -2.28        |\n",
      "|    explained_variance | 0.935        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0989      |\n",
      "|    mean_step_reward   | 0.0131042525 |\n",
      "|    n_updates          | 96/128       |\n",
      "|    policyGradLoss     | -0.0196      |\n",
      "|    value_loss         | 0.132        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 754         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 282         |\n",
      "|    total_timesteps    | 45301760    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022875164 |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0757     |\n",
      "|    mean_step_reward   | 0.02417502  |\n",
      "|    n_updates          | 100/128     |\n",
      "|    policyGradLoss     | -0.0216     |\n",
      "|    value_loss         | 0.105       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 752         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 293         |\n",
      "|    total_timesteps    | 45309952    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015683193 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.877       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0456     |\n",
      "|    mean_step_reward   | 0.010959832 |\n",
      "|    n_updates          | 104/128     |\n",
      "|    policyGradLoss     | -0.0122     |\n",
      "|    value_loss         | 0.315       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 752        |\n",
      "|    iterations         | 28         |\n",
      "|    time_elapsed       | 304        |\n",
      "|    total_timesteps    | 45318144   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02411497 |\n",
      "|    entropy_loss       | -2.28      |\n",
      "|    explained_variance | 0.971      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.12      |\n",
      "|    mean_step_reward   | 0.02182586 |\n",
      "|    n_updates          | 108/128    |\n",
      "|    policyGradLoss     | -0.0199    |\n",
      "|    value_loss         | 0.0625     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 752         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 315         |\n",
      "|    total_timesteps    | 45326336    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017499277 |\n",
      "|    entropy_loss       | -2.32       |\n",
      "|    explained_variance | 0.873       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.1        |\n",
      "|    mean_step_reward   | 0.017038863 |\n",
      "|    n_updates          | 112/128     |\n",
      "|    policyGradLoss     | -0.017      |\n",
      "|    value_loss         | 0.165       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 751          |\n",
      "|    iterations         | 30           |\n",
      "|    time_elapsed       | 326          |\n",
      "|    total_timesteps    | 45334528     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.01799439   |\n",
      "|    entropy_loss       | -2.33        |\n",
      "|    explained_variance | 0.952        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0686      |\n",
      "|    mean_step_reward   | 0.0063308096 |\n",
      "|    n_updates          | 116/128      |\n",
      "|    policyGradLoss     | -0.0194      |\n",
      "|    value_loss         | 0.0929       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 750         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 338         |\n",
      "|    total_timesteps    | 45342720    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017384669 |\n",
      "|    entropy_loss       | -2.2        |\n",
      "|    explained_variance | 0.951       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.095      |\n",
      "|    mean_step_reward   | 0.019571831 |\n",
      "|    n_updates          | 120/128     |\n",
      "|    policyGradLoss     | -0.0145     |\n",
      "|    value_loss         | 0.154       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 748         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 350         |\n",
      "|    total_timesteps    | 45350912    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021918852 |\n",
      "|    entropy_loss       | -2.19       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0891     |\n",
      "|    mean_step_reward   | 0.045269273 |\n",
      "|    n_updates          | 124/128     |\n",
      "|    policyGradLoss     | -0.0185     |\n",
      "|    value_loss         | 0.108       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/NoArti_172.zip\n",
      "[EVAL] Mean Return: 114.769, Best Return: 117.169\n",
      "Saved video to ./runs_smw/videos/NoArti/NoArti_172_114.77.mp4\n",
      "\n",
      "=== Round 174 | Learn 262144 steps (Total trained: 45350912) ===\n",
      "Logging to ./runs_smw/tb/NoArti_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1048     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 45359104 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 891         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 45367296    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02586947  |\n",
      "|    entropy_loss       | -2.19       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.106      |\n",
      "|    mean_step_reward   | 0.038351834 |\n",
      "|    n_updates          | 4/128       |\n",
      "|    policyGradLoss     | -0.0198     |\n",
      "|    value_loss         | 0.133       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 900         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 27          |\n",
      "|    total_timesteps    | 45375488    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023726612 |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.108      |\n",
      "|    mean_step_reward   | 0.03313645  |\n",
      "|    n_updates          | 8/128       |\n",
      "|    policyGradLoss     | -0.0164     |\n",
      "|    value_loss         | 0.0817      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 891         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 36          |\n",
      "|    total_timesteps    | 45383680    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020753335 |\n",
      "|    entropy_loss       | -2.28       |\n",
      "|    explained_variance | 0.908       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0961     |\n",
      "|    mean_step_reward   | 0.017393613 |\n",
      "|    n_updates          | 12/128      |\n",
      "|    policyGradLoss     | -0.0162     |\n",
      "|    value_loss         | 0.151       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 887         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 46          |\n",
      "|    total_timesteps    | 45391872    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021975126 |\n",
      "|    entropy_loss       | -2.28       |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.108      |\n",
      "|    mean_step_reward   | 0.016749442 |\n",
      "|    n_updates          | 16/128      |\n",
      "|    policyGradLoss     | -0.0227     |\n",
      "|    value_loss         | 0.0738      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 858         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 57          |\n",
      "|    total_timesteps    | 45400064    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013342654 |\n",
      "|    entropy_loss       | -2.2        |\n",
      "|    explained_variance | 0.833       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0148     |\n",
      "|    mean_step_reward   | 0.037141986 |\n",
      "|    n_updates          | 20/128      |\n",
      "|    policyGradLoss     | -0.00996    |\n",
      "|    value_loss         | 0.65        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 831         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 69          |\n",
      "|    total_timesteps    | 45408256    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017042879 |\n",
      "|    entropy_loss       | -2.17       |\n",
      "|    explained_variance | 0.946       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0688     |\n",
      "|    mean_step_reward   | 0.046422444 |\n",
      "|    n_updates          | 24/128      |\n",
      "|    policyGradLoss     | -0.0154     |\n",
      "|    value_loss         | 0.258       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 814         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 80          |\n",
      "|    total_timesteps    | 45416448    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025629982 |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.948       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0699     |\n",
      "|    mean_step_reward   | 0.027046654 |\n",
      "|    n_updates          | 28/128      |\n",
      "|    policyGradLoss     | -0.0193     |\n",
      "|    value_loss         | 0.111       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 804         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 91          |\n",
      "|    total_timesteps    | 45424640    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014664545 |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.729       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0563      |\n",
      "|    mean_step_reward   | 0.017885791 |\n",
      "|    n_updates          | 32/128      |\n",
      "|    policyGradLoss     | -0.0107     |\n",
      "|    value_loss         | 0.611       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 798         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 102         |\n",
      "|    total_timesteps    | 45432832    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019653823 |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.874       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.062      |\n",
      "|    mean_step_reward   | 0.024833363 |\n",
      "|    n_updates          | 36/128      |\n",
      "|    policyGradLoss     | -0.0163     |\n",
      "|    value_loss         | 0.199       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 790         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 113         |\n",
      "|    total_timesteps    | 45441024    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024849674 |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.955       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.094      |\n",
      "|    mean_step_reward   | 0.04165799  |\n",
      "|    n_updates          | 40/128      |\n",
      "|    policyGradLoss     | -0.0191     |\n",
      "|    value_loss         | 0.171       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 125         |\n",
      "|    total_timesteps    | 45449216    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022787957 |\n",
      "|    entropy_loss       | -2.29       |\n",
      "|    explained_variance | 0.94        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.083      |\n",
      "|    mean_step_reward   | 0.014046197 |\n",
      "|    n_updates          | 44/128      |\n",
      "|    policyGradLoss     | -0.0156     |\n",
      "|    value_loss         | 0.13        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 137         |\n",
      "|    total_timesteps    | 45457408    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017057866 |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.843       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0884     |\n",
      "|    mean_step_reward   | 0.013856682 |\n",
      "|    n_updates          | 48/128      |\n",
      "|    policyGradLoss     | -0.0145     |\n",
      "|    value_loss         | 0.301       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 148         |\n",
      "|    total_timesteps    | 45465600    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021900134 |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.815       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0603     |\n",
      "|    mean_step_reward   | 0.027047785 |\n",
      "|    n_updates          | 52/128      |\n",
      "|    policyGradLoss     | -0.0175     |\n",
      "|    value_loss         | 0.337       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 159         |\n",
      "|    total_timesteps    | 45473792    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02429389  |\n",
      "|    entropy_loss       | -2.19       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.101      |\n",
      "|    mean_step_reward   | 0.053886548 |\n",
      "|    n_updates          | 56/128      |\n",
      "|    policyGradLoss     | -0.0244     |\n",
      "|    value_loss         | 0.118       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 170         |\n",
      "|    total_timesteps    | 45481984    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02101257  |\n",
      "|    entropy_loss       | -2.28       |\n",
      "|    explained_variance | 0.935       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.106      |\n",
      "|    mean_step_reward   | 0.019676406 |\n",
      "|    n_updates          | 60/128      |\n",
      "|    policyGradLoss     | -0.0178     |\n",
      "|    value_loss         | 0.125       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 181         |\n",
      "|    total_timesteps    | 45490176    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021119852 |\n",
      "|    entropy_loss       | -2.27       |\n",
      "|    explained_variance | 0.806       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0502     |\n",
      "|    mean_step_reward   | 0.004020648 |\n",
      "|    n_updates          | 64/128      |\n",
      "|    policyGradLoss     | -0.0177     |\n",
      "|    value_loss         | 0.299       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 762         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 193         |\n",
      "|    total_timesteps    | 45498368    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018763825 |\n",
      "|    entropy_loss       | -2.2        |\n",
      "|    explained_variance | 0.905       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0549     |\n",
      "|    mean_step_reward   | 0.03660357  |\n",
      "|    n_updates          | 68/128      |\n",
      "|    policyGradLoss     | -0.0194     |\n",
      "|    value_loss         | 0.254       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 759         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 204         |\n",
      "|    total_timesteps    | 45506560    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025335636 |\n",
      "|    entropy_loss       | -2.2        |\n",
      "|    explained_variance | 0.93        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0739     |\n",
      "|    mean_step_reward   | 0.03183426  |\n",
      "|    n_updates          | 72/128      |\n",
      "|    policyGradLoss     | -0.0209     |\n",
      "|    value_loss         | 0.283       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 758        |\n",
      "|    iterations         | 20         |\n",
      "|    time_elapsed       | 216        |\n",
      "|    total_timesteps    | 45514752   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.020641   |\n",
      "|    entropy_loss       | -2.23      |\n",
      "|    explained_variance | 0.833      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0457    |\n",
      "|    mean_step_reward   | 0.02166852 |\n",
      "|    n_updates          | 76/128     |\n",
      "|    policyGradLoss     | -0.0135    |\n",
      "|    value_loss         | 0.377      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 757         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 227         |\n",
      "|    total_timesteps    | 45522944    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022776762 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.94        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0249     |\n",
      "|    mean_step_reward   | 0.030034523 |\n",
      "|    n_updates          | 80/128      |\n",
      "|    policyGradLoss     | -0.0194     |\n",
      "|    value_loss         | 0.202       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 756         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 238         |\n",
      "|    total_timesteps    | 45531136    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022975843 |\n",
      "|    entropy_loss       | -2.28       |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.108      |\n",
      "|    mean_step_reward   | 0.018388178 |\n",
      "|    n_updates          | 84/128      |\n",
      "|    policyGradLoss     | -0.0209     |\n",
      "|    value_loss         | 0.0927      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 754         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 249         |\n",
      "|    total_timesteps    | 45539328    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02687308  |\n",
      "|    entropy_loss       | -2.27       |\n",
      "|    explained_variance | 0.95        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.105      |\n",
      "|    mean_step_reward   | 0.018829245 |\n",
      "|    n_updates          | 88/128      |\n",
      "|    policyGradLoss     | -0.0208     |\n",
      "|    value_loss         | 0.0928      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 752         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 261         |\n",
      "|    total_timesteps    | 45547520    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020873843 |\n",
      "|    entropy_loss       | -2.2        |\n",
      "|    explained_variance | 0.946       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0381     |\n",
      "|    mean_step_reward   | 0.025115442 |\n",
      "|    n_updates          | 92/128      |\n",
      "|    policyGradLoss     | -0.015      |\n",
      "|    value_loss         | 0.138       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 751         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 272         |\n",
      "|    total_timesteps    | 45555712    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01954804  |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.884       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0728     |\n",
      "|    mean_step_reward   | 0.032343104 |\n",
      "|    n_updates          | 96/128      |\n",
      "|    policyGradLoss     | -0.0133     |\n",
      "|    value_loss         | 0.318       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 751         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 283         |\n",
      "|    total_timesteps    | 45563904    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017355138 |\n",
      "|    entropy_loss       | -2.18       |\n",
      "|    explained_variance | 0.897       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0635     |\n",
      "|    mean_step_reward   | 0.014099498 |\n",
      "|    n_updates          | 100/128     |\n",
      "|    policyGradLoss     | -0.0154     |\n",
      "|    value_loss         | 0.363       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 750         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 294         |\n",
      "|    total_timesteps    | 45572096    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028850626 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.123      |\n",
      "|    mean_step_reward   | 0.023898497 |\n",
      "|    n_updates          | 104/128     |\n",
      "|    policyGradLoss     | -0.0248     |\n",
      "|    value_loss         | 0.0845      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 749         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 306         |\n",
      "|    total_timesteps    | 45580288    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023832323 |\n",
      "|    entropy_loss       | -2.28       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.107      |\n",
      "|    mean_step_reward   | 0.026423236 |\n",
      "|    n_updates          | 108/128     |\n",
      "|    policyGradLoss     | -0.017      |\n",
      "|    value_loss         | 0.0813      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 747         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 317         |\n",
      "|    total_timesteps    | 45588480    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01698457  |\n",
      "|    entropy_loss       | -2.3        |\n",
      "|    explained_variance | 0.93        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0927     |\n",
      "|    mean_step_reward   | 0.011619679 |\n",
      "|    n_updates          | 112/128     |\n",
      "|    policyGradLoss     | -0.0129     |\n",
      "|    value_loss         | 0.147       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 746         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 329         |\n",
      "|    total_timesteps    | 45596672    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020915743 |\n",
      "|    entropy_loss       | -2.18       |\n",
      "|    explained_variance | 0.901       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0629     |\n",
      "|    mean_step_reward   | 0.031260457 |\n",
      "|    n_updates          | 116/128     |\n",
      "|    policyGradLoss     | -0.014      |\n",
      "|    value_loss         | 0.323       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 746         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 340         |\n",
      "|    total_timesteps    | 45604864    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023900405 |\n",
      "|    entropy_loss       | -2.2        |\n",
      "|    explained_variance | 0.938       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0787     |\n",
      "|    mean_step_reward   | 0.033108357 |\n",
      "|    n_updates          | 120/128     |\n",
      "|    policyGradLoss     | -0.0183     |\n",
      "|    value_loss         | 0.154       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 745         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 351         |\n",
      "|    total_timesteps    | 45613056    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022274032 |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.957       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0104     |\n",
      "|    mean_step_reward   | 0.02401117  |\n",
      "|    n_updates          | 124/128     |\n",
      "|    policyGradLoss     | -0.0198     |\n",
      "|    value_loss         | 0.223       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/NoArti_173.zip\n",
      "[EVAL] Mean Return: 48.534, Best Return: 50.534\n",
      "Saved video to ./runs_smw/videos/NoArti/NoArti_173_48.53.mp4\n",
      "\n",
      "=== Round 175 | Learn 262144 steps (Total trained: 45613056) ===\n",
      "Logging to ./runs_smw/tb/NoArti_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1173     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 45621248 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 903         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 45629440    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020317096 |\n",
      "|    entropy_loss       | -2.16       |\n",
      "|    explained_variance | 0.94        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0798     |\n",
      "|    mean_step_reward   | 0.045171443 |\n",
      "|    n_updates          | 4/128       |\n",
      "|    policyGradLoss     | -0.0189     |\n",
      "|    value_loss         | 0.226       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 826         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 29          |\n",
      "|    total_timesteps    | 45637632    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022115149 |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.949       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.079      |\n",
      "|    mean_step_reward   | 0.026828345 |\n",
      "|    n_updates          | 8/128       |\n",
      "|    policyGradLoss     | -0.0165     |\n",
      "|    value_loss         | 0.153       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 789         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 41          |\n",
      "|    total_timesteps    | 45645824    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026004303 |\n",
      "|    entropy_loss       | -2.29       |\n",
      "|    explained_variance | 0.91        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.103      |\n",
      "|    mean_step_reward   | 0.02286243  |\n",
      "|    n_updates          | 12/128      |\n",
      "|    policyGradLoss     | -0.0199     |\n",
      "|    value_loss         | 0.0909      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 769        |\n",
      "|    iterations         | 5          |\n",
      "|    time_elapsed       | 53         |\n",
      "|    total_timesteps    | 45654016   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02833953 |\n",
      "|    entropy_loss       | -2.26      |\n",
      "|    explained_variance | 0.954      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.101     |\n",
      "|    mean_step_reward   | 0.02657735 |\n",
      "|    n_updates          | 16/128     |\n",
      "|    policyGradLoss     | -0.0176    |\n",
      "|    value_loss         | 0.123      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 761         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 64          |\n",
      "|    total_timesteps    | 45662208    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018383022 |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.861       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0727     |\n",
      "|    mean_step_reward   | 0.01985424  |\n",
      "|    n_updates          | 20/128      |\n",
      "|    policyGradLoss     | -0.0166     |\n",
      "|    value_loss         | 0.217       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 756         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 75          |\n",
      "|    total_timesteps    | 45670400    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019491185 |\n",
      "|    entropy_loss       | -2.2        |\n",
      "|    explained_variance | 0.916       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.068      |\n",
      "|    mean_step_reward   | 0.027652489 |\n",
      "|    n_updates          | 24/128      |\n",
      "|    policyGradLoss     | -0.0166     |\n",
      "|    value_loss         | 0.212       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 755        |\n",
      "|    iterations         | 8          |\n",
      "|    time_elapsed       | 86         |\n",
      "|    total_timesteps    | 45678592   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01623281 |\n",
      "|    entropy_loss       | -2.14      |\n",
      "|    explained_variance | 0.932      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0745    |\n",
      "|    mean_step_reward   | 0.04878397 |\n",
      "|    n_updates          | 28/128     |\n",
      "|    policyGradLoss     | -0.0193    |\n",
      "|    value_loss         | 0.282      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 751         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 98          |\n",
      "|    total_timesteps    | 45686784    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023737354 |\n",
      "|    entropy_loss       | -2.14       |\n",
      "|    explained_variance | 0.936       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0444     |\n",
      "|    mean_step_reward   | 0.035682186 |\n",
      "|    n_updates          | 32/128      |\n",
      "|    policyGradLoss     | -0.015      |\n",
      "|    value_loss         | 0.362       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 745         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 109         |\n",
      "|    total_timesteps    | 45694976    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026557235 |\n",
      "|    entropy_loss       | -2.19       |\n",
      "|    explained_variance | 0.943       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0879     |\n",
      "|    mean_step_reward   | 0.039885245 |\n",
      "|    n_updates          | 36/128      |\n",
      "|    policyGradLoss     | -0.0168     |\n",
      "|    value_loss         | 0.157       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 742         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 121         |\n",
      "|    total_timesteps    | 45703168    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019402094 |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.932       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0698     |\n",
      "|    mean_step_reward   | 0.026528206 |\n",
      "|    n_updates          | 40/128      |\n",
      "|    policyGradLoss     | -0.00886    |\n",
      "|    value_loss         | 0.246       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 740         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 132         |\n",
      "|    total_timesteps    | 45711360    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01904212  |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.901       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0636     |\n",
      "|    mean_step_reward   | 0.035646163 |\n",
      "|    n_updates          | 44/128      |\n",
      "|    policyGradLoss     | -0.0154     |\n",
      "|    value_loss         | 0.286       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 739         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 143         |\n",
      "|    total_timesteps    | 45719552    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017482555 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.927       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0929     |\n",
      "|    mean_step_reward   | 0.02630837  |\n",
      "|    n_updates          | 48/128      |\n",
      "|    policyGradLoss     | -0.0155     |\n",
      "|    value_loss         | 0.153       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 738         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 155         |\n",
      "|    total_timesteps    | 45727744    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018416435 |\n",
      "|    entropy_loss       | -2.13       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0632     |\n",
      "|    mean_step_reward   | 0.05373514  |\n",
      "|    n_updates          | 52/128      |\n",
      "|    policyGradLoss     | -0.0182     |\n",
      "|    value_loss         | 0.199       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 736         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 166         |\n",
      "|    total_timesteps    | 45735936    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020779077 |\n",
      "|    entropy_loss       | -2.14       |\n",
      "|    explained_variance | 0.95        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0763     |\n",
      "|    mean_step_reward   | 0.05495511  |\n",
      "|    n_updates          | 56/128      |\n",
      "|    policyGradLoss     | -0.0147     |\n",
      "|    value_loss         | 0.34        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 733         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 178         |\n",
      "|    total_timesteps    | 45744128    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027889773 |\n",
      "|    entropy_loss       | -2.19       |\n",
      "|    explained_variance | 0.921       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0844     |\n",
      "|    mean_step_reward   | 0.030171257 |\n",
      "|    n_updates          | 60/128      |\n",
      "|    policyGradLoss     | -0.0177     |\n",
      "|    value_loss         | 0.228       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 732         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 190         |\n",
      "|    total_timesteps    | 45752320    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024476416 |\n",
      "|    entropy_loss       | -2.2        |\n",
      "|    explained_variance | 0.925       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0929     |\n",
      "|    mean_step_reward   | 0.031165395 |\n",
      "|    n_updates          | 64/128      |\n",
      "|    policyGradLoss     | -0.0164     |\n",
      "|    value_loss         | 0.222       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 732         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 201         |\n",
      "|    total_timesteps    | 45760512    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021267008 |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.939       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0865     |\n",
      "|    mean_step_reward   | 0.02828741  |\n",
      "|    n_updates          | 68/128      |\n",
      "|    policyGradLoss     | -0.0182     |\n",
      "|    value_loss         | 0.15        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 732         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 212         |\n",
      "|    total_timesteps    | 45768704    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022802375 |\n",
      "|    entropy_loss       | -2.27       |\n",
      "|    explained_variance | 0.928       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0993     |\n",
      "|    mean_step_reward   | 0.02348207  |\n",
      "|    n_updates          | 72/128      |\n",
      "|    policyGradLoss     | -0.0176     |\n",
      "|    value_loss         | 0.134       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 732         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 223         |\n",
      "|    total_timesteps    | 45776896    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018218072 |\n",
      "|    entropy_loss       | -2.2        |\n",
      "|    explained_variance | 0.902       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0575     |\n",
      "|    mean_step_reward   | 0.014813347 |\n",
      "|    n_updates          | 76/128      |\n",
      "|    policyGradLoss     | -0.0171     |\n",
      "|    value_loss         | 0.228       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 731        |\n",
      "|    iterations         | 21         |\n",
      "|    time_elapsed       | 235        |\n",
      "|    total_timesteps    | 45785088   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02002281 |\n",
      "|    entropy_loss       | -2.17      |\n",
      "|    explained_variance | 0.95       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0733    |\n",
      "|    mean_step_reward   | 0.04301779 |\n",
      "|    n_updates          | 80/128     |\n",
      "|    policyGradLoss     | -0.014     |\n",
      "|    value_loss         | 0.185      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 730         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 246         |\n",
      "|    total_timesteps    | 45793280    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029677415 |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.106      |\n",
      "|    mean_step_reward   | 0.0333908   |\n",
      "|    n_updates          | 84/128      |\n",
      "|    policyGradLoss     | -0.0202     |\n",
      "|    value_loss         | 0.102       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 729        |\n",
      "|    iterations         | 23         |\n",
      "|    time_elapsed       | 258        |\n",
      "|    total_timesteps    | 45801472   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02115508 |\n",
      "|    entropy_loss       | -2.27      |\n",
      "|    explained_variance | 0.948      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0387    |\n",
      "|    mean_step_reward   | 0.01967946 |\n",
      "|    n_updates          | 88/128     |\n",
      "|    policyGradLoss     | -0.0158    |\n",
      "|    value_loss         | 0.12       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 729         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 269         |\n",
      "|    total_timesteps    | 45809664    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.0207382   |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.102      |\n",
      "|    mean_step_reward   | 0.016694732 |\n",
      "|    n_updates          | 92/128      |\n",
      "|    policyGradLoss     | -0.0199     |\n",
      "|    value_loss         | 0.0762      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 730         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 280         |\n",
      "|    total_timesteps    | 45817856    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027625035 |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.103      |\n",
      "|    mean_step_reward   | 0.024592837 |\n",
      "|    n_updates          | 96/128      |\n",
      "|    policyGradLoss     | -0.0195     |\n",
      "|    value_loss         | 0.0722      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 729         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 291         |\n",
      "|    total_timesteps    | 45826048    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019158918 |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.846       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0825     |\n",
      "|    mean_step_reward   | 0.017373826 |\n",
      "|    n_updates          | 100/128     |\n",
      "|    policyGradLoss     | -0.0138     |\n",
      "|    value_loss         | 0.309       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 728         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 303         |\n",
      "|    total_timesteps    | 45834240    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020652466 |\n",
      "|    entropy_loss       | -2.16       |\n",
      "|    explained_variance | 0.919       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0383     |\n",
      "|    mean_step_reward   | 0.0421774   |\n",
      "|    n_updates          | 104/128     |\n",
      "|    policyGradLoss     | -0.0137     |\n",
      "|    value_loss         | 0.429       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 727         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 315         |\n",
      "|    total_timesteps    | 45842432    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016703054 |\n",
      "|    entropy_loss       | -2.14       |\n",
      "|    explained_variance | 0.772       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0224     |\n",
      "|    mean_step_reward   | 0.032589935 |\n",
      "|    n_updates          | 108/128     |\n",
      "|    policyGradLoss     | -0.0118     |\n",
      "|    value_loss         | 0.57        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 730         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 325         |\n",
      "|    total_timesteps    | 45850624    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022817021 |\n",
      "|    entropy_loss       | -2.17       |\n",
      "|    explained_variance | 0.873       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0543     |\n",
      "|    mean_step_reward   | 0.042124853 |\n",
      "|    n_updates          | 112/128     |\n",
      "|    policyGradLoss     | -0.0205     |\n",
      "|    value_loss         | 0.233       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 735         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 334         |\n",
      "|    total_timesteps    | 45858816    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019079182 |\n",
      "|    entropy_loss       | -2.17       |\n",
      "|    explained_variance | 0.884       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0313     |\n",
      "|    mean_step_reward   | 0.031389438 |\n",
      "|    n_updates          | 116/128     |\n",
      "|    policyGradLoss     | -0.0156     |\n",
      "|    value_loss         | 0.445       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 739         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 343         |\n",
      "|    total_timesteps    | 45867008    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022859635 |\n",
      "|    entropy_loss       | -2.14       |\n",
      "|    explained_variance | 0.914       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.071      |\n",
      "|    mean_step_reward   | 0.03913903  |\n",
      "|    n_updates          | 120/128     |\n",
      "|    policyGradLoss     | -0.02       |\n",
      "|    value_loss         | 0.263       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 742         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 352         |\n",
      "|    total_timesteps    | 45875200    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022521403 |\n",
      "|    entropy_loss       | -2.15       |\n",
      "|    explained_variance | 0.954       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0929     |\n",
      "|    mean_step_reward   | 0.04370861  |\n",
      "|    n_updates          | 124/128     |\n",
      "|    policyGradLoss     | -0.0207     |\n",
      "|    value_loss         | 0.143       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/NoArti_174.zip\n",
      "[EVAL] Mean Return: 131.738, Best Return: 134.338\n",
      "Saved video to ./runs_smw/videos/NoArti/NoArti_174_131.74.mp4\n",
      "\n",
      "=== Round 176 | Learn 262144 steps (Total trained: 45875200) ===\n",
      "Logging to ./runs_smw/tb/NoArti_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1110     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 45883392 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 893         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 45891584    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021832865 |\n",
      "|    entropy_loss       | -2.14       |\n",
      "|    explained_variance | 0.904       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0508     |\n",
      "|    mean_step_reward   | 0.037336282 |\n",
      "|    n_updates          | 4/128       |\n",
      "|    policyGradLoss     | -0.0188     |\n",
      "|    value_loss         | 0.418       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 840         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 29          |\n",
      "|    total_timesteps    | 45899776    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025611322 |\n",
      "|    entropy_loss       | -2.18       |\n",
      "|    explained_variance | 0.948       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0732     |\n",
      "|    mean_step_reward   | 0.04623536  |\n",
      "|    n_updates          | 8/128       |\n",
      "|    policyGradLoss     | -0.0174     |\n",
      "|    value_loss         | 0.163       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 808         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 40          |\n",
      "|    total_timesteps    | 45907968    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021495711 |\n",
      "|    entropy_loss       | -2.17       |\n",
      "|    explained_variance | 0.943       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0781     |\n",
      "|    mean_step_reward   | 0.03117752  |\n",
      "|    n_updates          | 12/128      |\n",
      "|    policyGradLoss     | -0.0166     |\n",
      "|    value_loss         | 0.287       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 52          |\n",
      "|    total_timesteps    | 45916160    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021506827 |\n",
      "|    entropy_loss       | -2.12       |\n",
      "|    explained_variance | 0.938       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0471     |\n",
      "|    mean_step_reward   | 0.043289326 |\n",
      "|    n_updates          | 16/128      |\n",
      "|    policyGradLoss     | -0.0188     |\n",
      "|    value_loss         | 0.292       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 63          |\n",
      "|    total_timesteps    | 45924352    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024818566 |\n",
      "|    entropy_loss       | -2.15       |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0749     |\n",
      "|    mean_step_reward   | 0.04350101  |\n",
      "|    n_updates          | 20/128      |\n",
      "|    policyGradLoss     | -0.0179     |\n",
      "|    value_loss         | 0.267       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 760         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 75          |\n",
      "|    total_timesteps    | 45932544    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027289513 |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.886       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.097      |\n",
      "|    mean_step_reward   | 0.023753066 |\n",
      "|    n_updates          | 24/128      |\n",
      "|    policyGradLoss     | -0.0218     |\n",
      "|    value_loss         | 0.164       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 756         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 86          |\n",
      "|    total_timesteps    | 45940736    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021824785 |\n",
      "|    entropy_loss       | -2.2        |\n",
      "|    explained_variance | 0.915       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0889     |\n",
      "|    mean_step_reward   | 0.028158765 |\n",
      "|    n_updates          | 28/128      |\n",
      "|    policyGradLoss     | -0.0183     |\n",
      "|    value_loss         | 0.276       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 753         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 97          |\n",
      "|    total_timesteps    | 45948928    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.034750476 |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.926       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.124      |\n",
      "|    mean_step_reward   | 0.018661626 |\n",
      "|    n_updates          | 32/128      |\n",
      "|    policyGradLoss     | -0.0263     |\n",
      "|    value_loss         | 0.0981      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 751         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 109         |\n",
      "|    total_timesteps    | 45957120    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01942492  |\n",
      "|    entropy_loss       | -2.18       |\n",
      "|    explained_variance | 0.92        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0291     |\n",
      "|    mean_step_reward   | 0.014507646 |\n",
      "|    n_updates          | 36/128      |\n",
      "|    policyGradLoss     | -0.0137     |\n",
      "|    value_loss         | 0.324       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 746         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 120         |\n",
      "|    total_timesteps    | 45965312    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026423406 |\n",
      "|    entropy_loss       | -2.13       |\n",
      "|    explained_variance | 0.949       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0123     |\n",
      "|    mean_step_reward   | 0.033085212 |\n",
      "|    n_updates          | 40/128      |\n",
      "|    policyGradLoss     | -0.0234     |\n",
      "|    value_loss         | 0.264       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 742         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 132         |\n",
      "|    total_timesteps    | 45973504    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026946526 |\n",
      "|    entropy_loss       | -2.1        |\n",
      "|    explained_variance | 0.904       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0629     |\n",
      "|    mean_step_reward   | 0.047162127 |\n",
      "|    n_updates          | 44/128      |\n",
      "|    policyGradLoss     | -0.0195     |\n",
      "|    value_loss         | 0.376       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 740        |\n",
      "|    iterations         | 13         |\n",
      "|    time_elapsed       | 143        |\n",
      "|    total_timesteps    | 45981696   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03127124 |\n",
      "|    entropy_loss       | -2.16      |\n",
      "|    explained_variance | 0.976      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.111     |\n",
      "|    mean_step_reward   | 0.05371888 |\n",
      "|    n_updates          | 48/128     |\n",
      "|    policyGradLoss     | -0.027     |\n",
      "|    value_loss         | 0.0988     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 741         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 154         |\n",
      "|    total_timesteps    | 45989888    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020787423 |\n",
      "|    entropy_loss       | -2.27       |\n",
      "|    explained_variance | 0.901       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0928     |\n",
      "|    mean_step_reward   | 0.013294207 |\n",
      "|    n_updates          | 52/128      |\n",
      "|    policyGradLoss     | -0.0144     |\n",
      "|    value_loss         | 0.164       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 740        |\n",
      "|    iterations         | 15         |\n",
      "|    time_elapsed       | 165        |\n",
      "|    total_timesteps    | 45998080   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03243405 |\n",
      "|    entropy_loss       | -2.3       |\n",
      "|    explained_variance | 0.949      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.122     |\n",
      "|    mean_step_reward   | 0.01435487 |\n",
      "|    n_updates          | 56/128     |\n",
      "|    policyGradLoss     | -0.0238    |\n",
      "|    value_loss         | 0.0333     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 739         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 177         |\n",
      "|    total_timesteps    | 46006272    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013985964 |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.106      |\n",
      "|    mean_step_reward   | 0.007867679 |\n",
      "|    n_updates          | 60/128      |\n",
      "|    policyGradLoss     | -0.0165     |\n",
      "|    value_loss         | 0.101       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 737         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 188         |\n",
      "|    total_timesteps    | 46014464    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02211697  |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0486     |\n",
      "|    mean_step_reward   | 0.020646926 |\n",
      "|    n_updates          | 64/128      |\n",
      "|    policyGradLoss     | -0.0233     |\n",
      "|    value_loss         | 0.143       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 735         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 200         |\n",
      "|    total_timesteps    | 46022656    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02496247  |\n",
      "|    entropy_loss       | -2.12       |\n",
      "|    explained_variance | 0.949       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0668     |\n",
      "|    mean_step_reward   | 0.028045146 |\n",
      "|    n_updates          | 68/128      |\n",
      "|    policyGradLoss     | -0.0177     |\n",
      "|    value_loss         | 0.365       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 734         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 211         |\n",
      "|    total_timesteps    | 46030848    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.049035206 |\n",
      "|    entropy_loss       | -2.14       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.101      |\n",
      "|    mean_step_reward   | 0.052738663 |\n",
      "|    n_updates          | 72/128      |\n",
      "|    policyGradLoss     | -0.0212     |\n",
      "|    value_loss         | 0.151       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 735         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 222         |\n",
      "|    total_timesteps    | 46039040    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021206351 |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.932       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.105      |\n",
      "|    mean_step_reward   | 0.013597967 |\n",
      "|    n_updates          | 76/128      |\n",
      "|    policyGradLoss     | -0.0168     |\n",
      "|    value_loss         | 0.143       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 735         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 233         |\n",
      "|    total_timesteps    | 46047232    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021352665 |\n",
      "|    entropy_loss       | -2.27       |\n",
      "|    explained_variance | 0.877       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0801     |\n",
      "|    mean_step_reward   | 0.014981754 |\n",
      "|    n_updates          | 80/128      |\n",
      "|    policyGradLoss     | -0.0195     |\n",
      "|    value_loss         | 0.126       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 734         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 245         |\n",
      "|    total_timesteps    | 46055424    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028938357 |\n",
      "|    entropy_loss       | -2.27       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.116      |\n",
      "|    mean_step_reward   | 0.024961773 |\n",
      "|    n_updates          | 84/128      |\n",
      "|    policyGradLoss     | -0.0257     |\n",
      "|    value_loss         | 0.047       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 732         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 257         |\n",
      "|    total_timesteps    | 46063616    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018343952 |\n",
      "|    entropy_loss       | -2.28       |\n",
      "|    explained_variance | 0.948       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0925     |\n",
      "|    mean_step_reward   | 0.010421079 |\n",
      "|    n_updates          | 88/128      |\n",
      "|    policyGradLoss     | -0.0159     |\n",
      "|    value_loss         | 0.133       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 731         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 268         |\n",
      "|    total_timesteps    | 46071808    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018566335 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.092      |\n",
      "|    mean_step_reward   | 0.014719141 |\n",
      "|    n_updates          | 92/128      |\n",
      "|    policyGradLoss     | -0.0217     |\n",
      "|    value_loss         | 0.0991      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 731         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 279         |\n",
      "|    total_timesteps    | 46080000    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017769303 |\n",
      "|    entropy_loss       | -2.18       |\n",
      "|    explained_variance | 0.922       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0441     |\n",
      "|    mean_step_reward   | 0.045971557 |\n",
      "|    n_updates          | 96/128      |\n",
      "|    policyGradLoss     | -0.012      |\n",
      "|    value_loss         | 0.342       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 731         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 291         |\n",
      "|    total_timesteps    | 46088192    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027201554 |\n",
      "|    entropy_loss       | -2.18       |\n",
      "|    explained_variance | 0.867       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0866     |\n",
      "|    mean_step_reward   | 0.02365896  |\n",
      "|    n_updates          | 100/128     |\n",
      "|    policyGradLoss     | -0.0216     |\n",
      "|    value_loss         | 0.223       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 736         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 300         |\n",
      "|    total_timesteps    | 46096384    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021002455 |\n",
      "|    entropy_loss       | -2.17       |\n",
      "|    explained_variance | 0.879       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0567     |\n",
      "|    mean_step_reward   | 0.02829674  |\n",
      "|    n_updates          | 104/128     |\n",
      "|    policyGradLoss     | -0.0208     |\n",
      "|    value_loss         | 0.395       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 741         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 309         |\n",
      "|    total_timesteps    | 46104576    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020369723 |\n",
      "|    entropy_loss       | -2.15       |\n",
      "|    explained_variance | 0.949       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.09       |\n",
      "|    mean_step_reward   | 0.04786592  |\n",
      "|    n_updates          | 108/128     |\n",
      "|    policyGradLoss     | -0.0199     |\n",
      "|    value_loss         | 0.183       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 745         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 318         |\n",
      "|    total_timesteps    | 46112768    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020163812 |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.924       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.043      |\n",
      "|    mean_step_reward   | 0.026026778 |\n",
      "|    n_updates          | 112/128     |\n",
      "|    policyGradLoss     | -0.0181     |\n",
      "|    value_loss         | 0.196       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 748         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 328         |\n",
      "|    total_timesteps    | 46120960    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030206705 |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.11       |\n",
      "|    mean_step_reward   | 0.029677253 |\n",
      "|    n_updates          | 116/128     |\n",
      "|    policyGradLoss     | -0.022      |\n",
      "|    value_loss         | 0.0782      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 747         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 339         |\n",
      "|    total_timesteps    | 46129152    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027992759 |\n",
      "|    entropy_loss       | -2.29       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.115      |\n",
      "|    mean_step_reward   | 0.015394527 |\n",
      "|    n_updates          | 120/128     |\n",
      "|    policyGradLoss     | -0.0249     |\n",
      "|    value_loss         | 0.03        |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 747           |\n",
      "|    iterations         | 32            |\n",
      "|    time_elapsed       | 350           |\n",
      "|    total_timesteps    | 46137344      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.017558476   |\n",
      "|    entropy_loss       | -2.26         |\n",
      "|    explained_variance | 0.929         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0828       |\n",
      "|    mean_step_reward   | -0.0022068263 |\n",
      "|    n_updates          | 124/128       |\n",
      "|    policyGradLoss     | -0.0109       |\n",
      "|    value_loss         | 0.175         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/NoArti_175.zip\n",
      "[EVAL] Mean Return: -9.930, Best Return: -9.930\n",
      "Saved video to ./runs_smw/videos/NoArti/NoArti_175_-9.93.mp4\n",
      "\n",
      "=== Round 177 | Learn 262144 steps (Total trained: 46137344) ===\n",
      "Logging to ./runs_smw/tb/NoArti_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1158     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 46145536 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 893         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 46153728    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024339985 |\n",
      "|    entropy_loss       | -2.2        |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.107      |\n",
      "|    mean_step_reward   | 0.037791606 |\n",
      "|    n_updates          | 4/128       |\n",
      "|    policyGradLoss     | -0.0187     |\n",
      "|    value_loss         | 0.11        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 820          |\n",
      "|    iterations         | 3            |\n",
      "|    time_elapsed       | 29           |\n",
      "|    total_timesteps    | 46161920     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.015024813  |\n",
      "|    entropy_loss       | -2.26        |\n",
      "|    explained_variance | 0.883        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0527      |\n",
      "|    mean_step_reward   | 0.0078661665 |\n",
      "|    n_updates          | 8/128        |\n",
      "|    policyGradLoss     | -0.0132      |\n",
      "|    value_loss         | 0.361        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 789         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 41          |\n",
      "|    total_timesteps    | 46170112    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025479538 |\n",
      "|    entropy_loss       | -2.31       |\n",
      "|    explained_variance | 0.944       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.109      |\n",
      "|    mean_step_reward   | 0.014713997 |\n",
      "|    n_updates          | 12/128      |\n",
      "|    policyGradLoss     | -0.0204     |\n",
      "|    value_loss         | 0.0431      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 52          |\n",
      "|    total_timesteps    | 46178304    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026692808 |\n",
      "|    entropy_loss       | -2.28       |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0565     |\n",
      "|    mean_step_reward   | 0.02747938  |\n",
      "|    n_updates          | 16/128      |\n",
      "|    policyGradLoss     | -0.0154     |\n",
      "|    value_loss         | 0.172       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 63          |\n",
      "|    total_timesteps    | 46186496    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013233576 |\n",
      "|    entropy_loss       | -2.28       |\n",
      "|    explained_variance | 0.943       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0929     |\n",
      "|    mean_step_reward   | 0.004132053 |\n",
      "|    n_updates          | 20/128      |\n",
      "|    policyGradLoss     | -0.0131     |\n",
      "|    value_loss         | 0.127       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 74          |\n",
      "|    total_timesteps    | 46194688    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023262551 |\n",
      "|    entropy_loss       | -2.18       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0988     |\n",
      "|    mean_step_reward   | 0.039394498 |\n",
      "|    n_updates          | 24/128      |\n",
      "|    policyGradLoss     | -0.0211     |\n",
      "|    value_loss         | 0.131       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 762         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 85          |\n",
      "|    total_timesteps    | 46202880    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014658902 |\n",
      "|    entropy_loss       | -2.18       |\n",
      "|    explained_variance | 0.899       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0771     |\n",
      "|    mean_step_reward   | 0.02605735  |\n",
      "|    n_updates          | 28/128      |\n",
      "|    policyGradLoss     | -0.0112     |\n",
      "|    value_loss         | 0.294       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 755         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 97          |\n",
      "|    total_timesteps    | 46211072    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027180541 |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.939       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0748     |\n",
      "|    mean_step_reward   | 0.021243328 |\n",
      "|    n_updates          | 32/128      |\n",
      "|    policyGradLoss     | -0.0174     |\n",
      "|    value_loss         | 0.118       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 750         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 109         |\n",
      "|    total_timesteps    | 46219264    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02037139  |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.923       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0801     |\n",
      "|    mean_step_reward   | 0.013413186 |\n",
      "|    n_updates          | 36/128      |\n",
      "|    policyGradLoss     | -0.0174     |\n",
      "|    value_loss         | 0.183       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 748         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 120         |\n",
      "|    total_timesteps    | 46227456    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019391388 |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.903       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.072      |\n",
      "|    mean_step_reward   | 0.01456146  |\n",
      "|    n_updates          | 40/128      |\n",
      "|    policyGradLoss     | -0.017      |\n",
      "|    value_loss         | 0.273       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 747         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 131         |\n",
      "|    total_timesteps    | 46235648    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013329843 |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.845       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0589     |\n",
      "|    mean_step_reward   | 0.017881706 |\n",
      "|    n_updates          | 44/128      |\n",
      "|    policyGradLoss     | -0.0144     |\n",
      "|    value_loss         | 0.55        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 746         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 142         |\n",
      "|    total_timesteps    | 46243840    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019589527 |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.923       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0966     |\n",
      "|    mean_step_reward   | 0.017423363 |\n",
      "|    n_updates          | 48/128      |\n",
      "|    policyGradLoss     | -0.0171     |\n",
      "|    value_loss         | 0.14        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 744         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 154         |\n",
      "|    total_timesteps    | 46252032    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014547264 |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.894       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0298     |\n",
      "|    mean_step_reward   | 0.026101526 |\n",
      "|    n_updates          | 52/128      |\n",
      "|    policyGradLoss     | -0.0156     |\n",
      "|    value_loss         | 0.32        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 741         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 165         |\n",
      "|    total_timesteps    | 46260224    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01927818  |\n",
      "|    entropy_loss       | -2.19       |\n",
      "|    explained_variance | 0.94        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0922     |\n",
      "|    mean_step_reward   | 0.033066608 |\n",
      "|    n_updates          | 56/128      |\n",
      "|    policyGradLoss     | -0.0165     |\n",
      "|    value_loss         | 0.21        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 739         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 177         |\n",
      "|    total_timesteps    | 46268416    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021126162 |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.925       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0505     |\n",
      "|    mean_step_reward   | 0.021151822 |\n",
      "|    n_updates          | 60/128      |\n",
      "|    policyGradLoss     | -0.0165     |\n",
      "|    value_loss         | 0.216       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 740         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 188         |\n",
      "|    total_timesteps    | 46276608    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021968968 |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.904       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0865     |\n",
      "|    mean_step_reward   | 0.029738504 |\n",
      "|    n_updates          | 64/128      |\n",
      "|    policyGradLoss     | -0.0173     |\n",
      "|    value_loss         | 0.138       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 740         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 199         |\n",
      "|    total_timesteps    | 46284800    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017139107 |\n",
      "|    entropy_loss       | -2.28       |\n",
      "|    explained_variance | 0.868       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0526     |\n",
      "|    mean_step_reward   | 0.015783187 |\n",
      "|    n_updates          | 68/128      |\n",
      "|    policyGradLoss     | -0.0119     |\n",
      "|    value_loss         | 0.366       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 739         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 210         |\n",
      "|    total_timesteps    | 46292992    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021931574 |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.888       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0878     |\n",
      "|    mean_step_reward   | 0.028511722 |\n",
      "|    n_updates          | 72/128      |\n",
      "|    policyGradLoss     | -0.0173     |\n",
      "|    value_loss         | 0.208       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 737         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 222         |\n",
      "|    total_timesteps    | 46301184    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017003976 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.896       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0681     |\n",
      "|    mean_step_reward   | 0.03629738  |\n",
      "|    n_updates          | 76/128      |\n",
      "|    policyGradLoss     | -0.0146     |\n",
      "|    value_loss         | 0.326       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 735         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 233         |\n",
      "|    total_timesteps    | 46309376    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020653885 |\n",
      "|    entropy_loss       | -2.19       |\n",
      "|    explained_variance | 0.903       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0706     |\n",
      "|    mean_step_reward   | 0.02124206  |\n",
      "|    n_updates          | 80/128      |\n",
      "|    policyGradLoss     | -0.0167     |\n",
      "|    value_loss         | 0.214       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 734         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 245         |\n",
      "|    total_timesteps    | 46317568    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016257007 |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.807       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0199      |\n",
      "|    mean_step_reward   | 0.022803405 |\n",
      "|    n_updates          | 84/128      |\n",
      "|    policyGradLoss     | -0.014      |\n",
      "|    value_loss         | 0.472       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 735         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 256         |\n",
      "|    total_timesteps    | 46325760    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025195066 |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.809       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.104      |\n",
      "|    mean_step_reward   | 0.016911104 |\n",
      "|    n_updates          | 88/128      |\n",
      "|    policyGradLoss     | -0.0187     |\n",
      "|    value_loss         | 0.2         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 735         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 267         |\n",
      "|    total_timesteps    | 46333952    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.031192211 |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.108      |\n",
      "|    mean_step_reward   | 0.032345816 |\n",
      "|    n_updates          | 92/128      |\n",
      "|    policyGradLoss     | -0.0222     |\n",
      "|    value_loss         | 0.0576      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 734         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 278         |\n",
      "|    total_timesteps    | 46342144    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013941925 |\n",
      "|    entropy_loss       | -2.34       |\n",
      "|    explained_variance | 0.897       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0986     |\n",
      "|    mean_step_reward   | 0.011809281 |\n",
      "|    n_updates          | 96/128      |\n",
      "|    policyGradLoss     | -0.01       |\n",
      "|    value_loss         | 0.135       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 733         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 290         |\n",
      "|    total_timesteps    | 46350336    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02155164  |\n",
      "|    entropy_loss       | -2.32       |\n",
      "|    explained_variance | 0.912       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.112      |\n",
      "|    mean_step_reward   | 0.014334395 |\n",
      "|    n_updates          | 100/128     |\n",
      "|    policyGradLoss     | -0.0147     |\n",
      "|    value_loss         | 0.113       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 739         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 299         |\n",
      "|    total_timesteps    | 46358528    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020309929 |\n",
      "|    entropy_loss       | -2.27       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.104      |\n",
      "|    mean_step_reward   | 0.014385559 |\n",
      "|    n_updates          | 104/128     |\n",
      "|    policyGradLoss     | -0.0198     |\n",
      "|    value_loss         | 0.0819      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 743          |\n",
      "|    iterations         | 28           |\n",
      "|    time_elapsed       | 308          |\n",
      "|    total_timesteps    | 46366720     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.015369574  |\n",
      "|    entropy_loss       | -2.31        |\n",
      "|    explained_variance | 0.821        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0761      |\n",
      "|    mean_step_reward   | 0.0025824478 |\n",
      "|    n_updates          | 108/128      |\n",
      "|    policyGradLoss     | -0.0159      |\n",
      "|    value_loss         | 0.258        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 747         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 317         |\n",
      "|    total_timesteps    | 46374912    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021536108 |\n",
      "|    entropy_loss       | -2.28       |\n",
      "|    explained_variance | 0.899       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0991     |\n",
      "|    mean_step_reward   | 0.011691559 |\n",
      "|    n_updates          | 112/128     |\n",
      "|    policyGradLoss     | -0.0158     |\n",
      "|    value_loss         | 0.13        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 748         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 328         |\n",
      "|    total_timesteps    | 46383104    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021880284 |\n",
      "|    entropy_loss       | -2.18       |\n",
      "|    explained_variance | 0.88        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0503     |\n",
      "|    mean_step_reward   | 0.018402979 |\n",
      "|    n_updates          | 116/128     |\n",
      "|    policyGradLoss     | -0.017      |\n",
      "|    value_loss         | 0.331       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 749         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 338         |\n",
      "|    total_timesteps    | 46391296    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019547272 |\n",
      "|    entropy_loss       | -2.12       |\n",
      "|    explained_variance | 0.758       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0766     |\n",
      "|    mean_step_reward   | 0.04599505  |\n",
      "|    n_updates          | 120/128     |\n",
      "|    policyGradLoss     | -0.00883    |\n",
      "|    value_loss         | 0.448       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 748         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 350         |\n",
      "|    total_timesteps    | 46399488    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020978019 |\n",
      "|    entropy_loss       | -2.13       |\n",
      "|    explained_variance | 0.897       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0677     |\n",
      "|    mean_step_reward   | 0.037549272 |\n",
      "|    n_updates          | 124/128     |\n",
      "|    policyGradLoss     | -0.0151     |\n",
      "|    value_loss         | 0.417       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/NoArti_176.zip\n",
      "[EVAL] Mean Return: -0.503, Best Return: -0.103\n",
      "Saved video to ./runs_smw/videos/NoArti/NoArti_176_-0.50.mp4\n",
      "\n",
      "=== Round 178 | Learn 262144 steps (Total trained: 46399488) ===\n",
      "Logging to ./runs_smw/tb/NoArti_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1072     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 46407680 |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 857          |\n",
      "|    iterations         | 2            |\n",
      "|    time_elapsed       | 19           |\n",
      "|    total_timesteps    | 46415872     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.018275287  |\n",
      "|    entropy_loss       | -2.38        |\n",
      "|    explained_variance | 0.754        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0798      |\n",
      "|    mean_step_reward   | 0.0051723737 |\n",
      "|    n_updates          | 4/128        |\n",
      "|    policyGradLoss     | -0.00909     |\n",
      "|    value_loss         | 0.152        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 816         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 30          |\n",
      "|    total_timesteps    | 46424064    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018550705 |\n",
      "|    entropy_loss       | -2.35       |\n",
      "|    explained_variance | 0.942       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.106      |\n",
      "|    mean_step_reward   | 0.014393516 |\n",
      "|    n_updates          | 8/128       |\n",
      "|    policyGradLoss     | -0.0132     |\n",
      "|    value_loss         | 0.0731      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 792          |\n",
      "|    iterations         | 4            |\n",
      "|    time_elapsed       | 41           |\n",
      "|    total_timesteps    | 46432256     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.015562875  |\n",
      "|    entropy_loss       | -2.33        |\n",
      "|    explained_variance | 0.802        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.1         |\n",
      "|    mean_step_reward   | 0.0015767295 |\n",
      "|    n_updates          | 12/128       |\n",
      "|    policyGradLoss     | -0.011       |\n",
      "|    value_loss         | 0.243        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 52          |\n",
      "|    total_timesteps    | 46440448    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.0249736   |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.907       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0833     |\n",
      "|    mean_step_reward   | 0.011292881 |\n",
      "|    n_updates          | 16/128      |\n",
      "|    policyGradLoss     | -0.0164     |\n",
      "|    value_loss         | 0.134       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 63          |\n",
      "|    total_timesteps    | 46448640    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017755676 |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.855       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0399     |\n",
      "|    mean_step_reward   | 0.02687074  |\n",
      "|    n_updates          | 20/128      |\n",
      "|    policyGradLoss     | -0.0143     |\n",
      "|    value_loss         | 0.392       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 758         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 75          |\n",
      "|    total_timesteps    | 46456832    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017418053 |\n",
      "|    entropy_loss       | -2.27       |\n",
      "|    explained_variance | 0.848       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0611     |\n",
      "|    mean_step_reward   | 0.019668534 |\n",
      "|    n_updates          | 24/128      |\n",
      "|    policyGradLoss     | -0.0119     |\n",
      "|    value_loss         | 0.293       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 753         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 86          |\n",
      "|    total_timesteps    | 46465024    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019230165 |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.831       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0768     |\n",
      "|    mean_step_reward   | 0.015129387 |\n",
      "|    n_updates          | 28/128      |\n",
      "|    policyGradLoss     | -0.0131     |\n",
      "|    value_loss         | 0.249       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 751         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 98          |\n",
      "|    total_timesteps    | 46473216    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02015673  |\n",
      "|    entropy_loss       | -2.28       |\n",
      "|    explained_variance | 0.815       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0788     |\n",
      "|    mean_step_reward   | 0.013111378 |\n",
      "|    n_updates          | 32/128      |\n",
      "|    policyGradLoss     | -0.0128     |\n",
      "|    value_loss         | 0.227       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 750          |\n",
      "|    iterations         | 10           |\n",
      "|    time_elapsed       | 109          |\n",
      "|    total_timesteps    | 46481408     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.013917875  |\n",
      "|    entropy_loss       | -2.33        |\n",
      "|    explained_variance | 0.824        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0936      |\n",
      "|    mean_step_reward   | 0.0070265178 |\n",
      "|    n_updates          | 36/128       |\n",
      "|    policyGradLoss     | -0.0137      |\n",
      "|    value_loss         | 0.158        |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 748        |\n",
      "|    iterations         | 11         |\n",
      "|    time_elapsed       | 120        |\n",
      "|    total_timesteps    | 46489600   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01524236 |\n",
      "|    entropy_loss       | -2.27      |\n",
      "|    explained_variance | 0.561      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0815    |\n",
      "|    mean_step_reward   | 0.01238187 |\n",
      "|    n_updates          | 40/128     |\n",
      "|    policyGradLoss     | -0.0146    |\n",
      "|    value_loss         | 0.306      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 744         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 132         |\n",
      "|    total_timesteps    | 46497792    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015737321 |\n",
      "|    entropy_loss       | -2.28       |\n",
      "|    explained_variance | 0.787       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0995     |\n",
      "|    mean_step_reward   | 0.017372623 |\n",
      "|    n_updates          | 44/128      |\n",
      "|    policyGradLoss     | -0.0175     |\n",
      "|    value_loss         | 0.263       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 741         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 143         |\n",
      "|    total_timesteps    | 46505984    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017129678 |\n",
      "|    entropy_loss       | -2.28       |\n",
      "|    explained_variance | 0.706       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0171      |\n",
      "|    mean_step_reward   | 0.012025045 |\n",
      "|    n_updates          | 48/128      |\n",
      "|    policyGradLoss     | -0.0135     |\n",
      "|    value_loss         | 0.492       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 739         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 155         |\n",
      "|    total_timesteps    | 46514176    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02300701  |\n",
      "|    entropy_loss       | -2.27       |\n",
      "|    explained_variance | 0.924       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0944     |\n",
      "|    mean_step_reward   | 0.019337315 |\n",
      "|    n_updates          | 52/128      |\n",
      "|    policyGradLoss     | -0.02       |\n",
      "|    value_loss         | 0.125       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 741         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 165         |\n",
      "|    total_timesteps    | 46522368    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016656838 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.746       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0589     |\n",
      "|    mean_step_reward   | 0.016991498 |\n",
      "|    n_updates          | 56/128      |\n",
      "|    policyGradLoss     | -0.00494    |\n",
      "|    value_loss         | 0.343       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 741        |\n",
      "|    iterations         | 16         |\n",
      "|    time_elapsed       | 176        |\n",
      "|    total_timesteps    | 46530560   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02007392 |\n",
      "|    entropy_loss       | -2.31      |\n",
      "|    explained_variance | 0.896      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0916    |\n",
      "|    mean_step_reward   | 0.02341402 |\n",
      "|    n_updates          | 60/128     |\n",
      "|    policyGradLoss     | -0.0148    |\n",
      "|    value_loss         | 0.215      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 740         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 188         |\n",
      "|    total_timesteps    | 46538752    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017484196 |\n",
      "|    entropy_loss       | -2.34       |\n",
      "|    explained_variance | 0.911       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.112      |\n",
      "|    mean_step_reward   | 0.009801108 |\n",
      "|    n_updates          | 64/128      |\n",
      "|    policyGradLoss     | -0.0158     |\n",
      "|    value_loss         | 0.0928      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 737          |\n",
      "|    iterations         | 18           |\n",
      "|    time_elapsed       | 199          |\n",
      "|    total_timesteps    | 46546944     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.016584937  |\n",
      "|    entropy_loss       | -2.37        |\n",
      "|    explained_variance | 0.846        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0907      |\n",
      "|    mean_step_reward   | 0.0027049112 |\n",
      "|    n_updates          | 68/128       |\n",
      "|    policyGradLoss     | -0.0132      |\n",
      "|    value_loss         | 0.159        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 737          |\n",
      "|    iterations         | 19           |\n",
      "|    time_elapsed       | 211          |\n",
      "|    total_timesteps    | 46555136     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.019520156  |\n",
      "|    entropy_loss       | -2.31        |\n",
      "|    explained_variance | 0.93         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.106       |\n",
      "|    mean_step_reward   | 0.0036738503 |\n",
      "|    n_updates          | 72/128       |\n",
      "|    policyGradLoss     | -0.0184      |\n",
      "|    value_loss         | 0.124        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 736         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 222         |\n",
      "|    total_timesteps    | 46563328    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016313305 |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.94        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.101      |\n",
      "|    mean_step_reward   | 0.02518386  |\n",
      "|    n_updates          | 76/128      |\n",
      "|    policyGradLoss     | -0.0189     |\n",
      "|    value_loss         | 0.122       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 744         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 231         |\n",
      "|    total_timesteps    | 46571520    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016626384 |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.867       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0228     |\n",
      "|    mean_step_reward   | 0.016933998 |\n",
      "|    n_updates          | 80/128      |\n",
      "|    policyGradLoss     | -0.0122     |\n",
      "|    value_loss         | 0.26        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 750         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 240         |\n",
      "|    total_timesteps    | 46579712    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018156352 |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.893       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0797     |\n",
      "|    mean_step_reward   | 0.030053182 |\n",
      "|    n_updates          | 84/128      |\n",
      "|    policyGradLoss     | -0.0177     |\n",
      "|    value_loss         | 0.281       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 754         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 249         |\n",
      "|    total_timesteps    | 46587904    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019039106 |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.932       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0894     |\n",
      "|    mean_step_reward   | 0.029389817 |\n",
      "|    n_updates          | 88/128      |\n",
      "|    policyGradLoss     | -0.0194     |\n",
      "|    value_loss         | 0.152       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 756         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 259         |\n",
      "|    total_timesteps    | 46596096    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018246885 |\n",
      "|    entropy_loss       | -2.34       |\n",
      "|    explained_variance | 0.873       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.071      |\n",
      "|    mean_step_reward   | 0.015249804 |\n",
      "|    n_updates          | 92/128      |\n",
      "|    policyGradLoss     | -0.0127     |\n",
      "|    value_loss         | 0.214       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 755         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 271         |\n",
      "|    total_timesteps    | 46604288    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022343088 |\n",
      "|    entropy_loss       | -2.29       |\n",
      "|    explained_variance | 0.884       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0473     |\n",
      "|    mean_step_reward   | 0.012202662 |\n",
      "|    n_updates          | 96/128      |\n",
      "|    policyGradLoss     | -0.0132     |\n",
      "|    value_loss         | 0.171       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 754         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 282         |\n",
      "|    total_timesteps    | 46612480    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016209427 |\n",
      "|    entropy_loss       | -2.29       |\n",
      "|    explained_variance | 0.887       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0328      |\n",
      "|    mean_step_reward   | 0.021248635 |\n",
      "|    n_updates          | 100/128     |\n",
      "|    policyGradLoss     | -0.0122     |\n",
      "|    value_loss         | 0.229       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 753         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 293         |\n",
      "|    total_timesteps    | 46620672    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019727316 |\n",
      "|    entropy_loss       | -2.29       |\n",
      "|    explained_variance | 0.937       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.108      |\n",
      "|    mean_step_reward   | 0.014052657 |\n",
      "|    n_updates          | 104/128     |\n",
      "|    policyGradLoss     | -0.0164     |\n",
      "|    value_loss         | 0.106       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 752          |\n",
      "|    iterations         | 28           |\n",
      "|    time_elapsed       | 305          |\n",
      "|    total_timesteps    | 46628864     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.016687721  |\n",
      "|    entropy_loss       | -2.26        |\n",
      "|    explained_variance | 0.872        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0897      |\n",
      "|    mean_step_reward   | 0.0063218055 |\n",
      "|    n_updates          | 108/128      |\n",
      "|    policyGradLoss     | -0.0141      |\n",
      "|    value_loss         | 0.294        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 750         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 316         |\n",
      "|    total_timesteps    | 46637056    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014257914 |\n",
      "|    entropy_loss       | -2.18       |\n",
      "|    explained_variance | 0.848       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0161      |\n",
      "|    mean_step_reward   | 0.027372738 |\n",
      "|    n_updates          | 112/128     |\n",
      "|    policyGradLoss     | -0.00918    |\n",
      "|    value_loss         | 0.545       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 748         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 328         |\n",
      "|    total_timesteps    | 46645248    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018803328 |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.865       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0831     |\n",
      "|    mean_step_reward   | 0.032368317 |\n",
      "|    n_updates          | 116/128     |\n",
      "|    policyGradLoss     | -0.0163     |\n",
      "|    value_loss         | 0.207       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 748         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 339         |\n",
      "|    total_timesteps    | 46653440    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018473826 |\n",
      "|    entropy_loss       | -2.27       |\n",
      "|    explained_variance | 0.711       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0861     |\n",
      "|    mean_step_reward   | 0.010143808 |\n",
      "|    n_updates          | 120/128     |\n",
      "|    policyGradLoss     | -0.0162     |\n",
      "|    value_loss         | 0.351       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 748         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 350         |\n",
      "|    total_timesteps    | 46661632    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020495543 |\n",
      "|    entropy_loss       | -2.29       |\n",
      "|    explained_variance | 0.68        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0826     |\n",
      "|    mean_step_reward   | 0.010307462 |\n",
      "|    n_updates          | 124/128     |\n",
      "|    policyGradLoss     | -0.0154     |\n",
      "|    value_loss         | 0.261       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/NoArti_177.zip\n",
      "[EVAL] Mean Return: 68.560, Best Return: 70.360\n",
      "Saved video to ./runs_smw/videos/NoArti/NoArti_177_68.56.mp4\n",
      "\n",
      "=== Round 179 | Learn 262144 steps (Total trained: 46661632) ===\n",
      "Logging to ./runs_smw/tb/NoArti_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1067     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 46669824 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 865         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 46678016    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016717248 |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.87        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0129      |\n",
      "|    mean_step_reward   | 0.030299563 |\n",
      "|    n_updates          | 4/128       |\n",
      "|    policyGradLoss     | -0.0136     |\n",
      "|    value_loss         | 0.551       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 816          |\n",
      "|    iterations         | 3            |\n",
      "|    time_elapsed       | 30           |\n",
      "|    total_timesteps    | 46686208     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.019576006  |\n",
      "|    entropy_loss       | -2.26        |\n",
      "|    explained_variance | 0.859        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0868      |\n",
      "|    mean_step_reward   | 0.0026970105 |\n",
      "|    n_updates          | 8/128        |\n",
      "|    policyGradLoss     | -0.0118      |\n",
      "|    value_loss         | 0.233        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 794          |\n",
      "|    iterations         | 4            |\n",
      "|    time_elapsed       | 41           |\n",
      "|    total_timesteps    | 46694400     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.018580804  |\n",
      "|    entropy_loss       | -2.33        |\n",
      "|    explained_variance | 0.762        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.102       |\n",
      "|    mean_step_reward   | 0.0065136375 |\n",
      "|    n_updates          | 12/128       |\n",
      "|    policyGradLoss     | -0.0152      |\n",
      "|    value_loss         | 0.202        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 780          |\n",
      "|    iterations         | 5            |\n",
      "|    time_elapsed       | 52           |\n",
      "|    total_timesteps    | 46702592     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.018586844  |\n",
      "|    entropy_loss       | -2.4         |\n",
      "|    explained_variance | 0.651        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.108       |\n",
      "|    mean_step_reward   | 0.0030745792 |\n",
      "|    n_updates          | 16/128       |\n",
      "|    policyGradLoss     | -0.0132      |\n",
      "|    value_loss         | 0.11         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 767           |\n",
      "|    iterations         | 6             |\n",
      "|    time_elapsed       | 64            |\n",
      "|    total_timesteps    | 46710784      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.017465193   |\n",
      "|    entropy_loss       | -2.34         |\n",
      "|    explained_variance | 0.764         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0608       |\n",
      "|    mean_step_reward   | -0.0043792464 |\n",
      "|    n_updates          | 20/128        |\n",
      "|    policyGradLoss     | -0.0144       |\n",
      "|    value_loss         | 0.286         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 758          |\n",
      "|    iterations         | 7            |\n",
      "|    time_elapsed       | 75           |\n",
      "|    total_timesteps    | 46718976     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.020009644  |\n",
      "|    entropy_loss       | -2.31        |\n",
      "|    explained_variance | 0.762        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0901      |\n",
      "|    mean_step_reward   | 0.0011032046 |\n",
      "|    n_updates          | 24/128       |\n",
      "|    policyGradLoss     | -0.0134      |\n",
      "|    value_loss         | 0.149        |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 756            |\n",
      "|    iterations         | 8              |\n",
      "|    time_elapsed       | 86             |\n",
      "|    total_timesteps    | 46727168       |\n",
      "| train/                |                |\n",
      "|    approx_kl          | 0.014162819    |\n",
      "|    entropy_loss       | -2.25          |\n",
      "|    explained_variance | 0.91           |\n",
      "|    learning_rate      | 0.0001         |\n",
      "|    loss               | -0.0807        |\n",
      "|    mean_step_reward   | -0.00026960438 |\n",
      "|    n_updates          | 28/128         |\n",
      "|    policyGradLoss     | -0.0151        |\n",
      "|    value_loss         | 0.221          |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 754         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 97          |\n",
      "|    total_timesteps    | 46735360    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029899273 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.882       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.107      |\n",
      "|    mean_step_reward   | 0.011139513 |\n",
      "|    n_updates          | 32/128      |\n",
      "|    policyGradLoss     | -0.0217     |\n",
      "|    value_loss         | 0.141       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 751         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 108         |\n",
      "|    total_timesteps    | 46743552    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020429758 |\n",
      "|    entropy_loss       | -2.34       |\n",
      "|    explained_variance | 0.693       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.112      |\n",
      "|    mean_step_reward   | 0.009871958 |\n",
      "|    n_updates          | 36/128      |\n",
      "|    policyGradLoss     | -0.0187     |\n",
      "|    value_loss         | 0.118       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 748          |\n",
      "|    iterations         | 11           |\n",
      "|    time_elapsed       | 120          |\n",
      "|    total_timesteps    | 46751744     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.019421155  |\n",
      "|    entropy_loss       | -2.32        |\n",
      "|    explained_variance | 0.504        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0256      |\n",
      "|    mean_step_reward   | 0.0019564908 |\n",
      "|    n_updates          | 40/128       |\n",
      "|    policyGradLoss     | -0.0171      |\n",
      "|    value_loss         | 0.453        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 743         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 132         |\n",
      "|    total_timesteps    | 46759936    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018384624 |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.718       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.088      |\n",
      "|    mean_step_reward   | 0.014773789 |\n",
      "|    n_updates          | 44/128      |\n",
      "|    policyGradLoss     | -0.0173     |\n",
      "|    value_loss         | 0.389       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 741         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 143         |\n",
      "|    total_timesteps    | 46768128    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020173833 |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.679       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.084      |\n",
      "|    mean_step_reward   | 0.013525404 |\n",
      "|    n_updates          | 48/128      |\n",
      "|    policyGradLoss     | -0.0172     |\n",
      "|    value_loss         | 0.299       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 742         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 154         |\n",
      "|    total_timesteps    | 46776320    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01344805  |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.704       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0528     |\n",
      "|    mean_step_reward   | 0.015338449 |\n",
      "|    n_updates          | 52/128      |\n",
      "|    policyGradLoss     | -0.0135     |\n",
      "|    value_loss         | 0.539       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 741         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 165         |\n",
      "|    total_timesteps    | 46784512    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019936655 |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.777       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.097      |\n",
      "|    mean_step_reward   | 0.01738608  |\n",
      "|    n_updates          | 56/128      |\n",
      "|    policyGradLoss     | -0.0194     |\n",
      "|    value_loss         | 0.194       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 740         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 176         |\n",
      "|    total_timesteps    | 46792704    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018016491 |\n",
      "|    entropy_loss       | -2.33       |\n",
      "|    explained_variance | 0.869       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.119      |\n",
      "|    mean_step_reward   | 0.015509992 |\n",
      "|    n_updates          | 60/128      |\n",
      "|    policyGradLoss     | -0.023      |\n",
      "|    value_loss         | 0.0965      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 738          |\n",
      "|    iterations         | 17           |\n",
      "|    time_elapsed       | 188          |\n",
      "|    total_timesteps    | 46800896     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.012335996  |\n",
      "|    entropy_loss       | -2.3         |\n",
      "|    explained_variance | 0.856        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0914      |\n",
      "|    mean_step_reward   | 0.0073925965 |\n",
      "|    n_updates          | 64/128       |\n",
      "|    policyGradLoss     | -0.0145      |\n",
      "|    value_loss         | 0.177        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 737          |\n",
      "|    iterations         | 18           |\n",
      "|    time_elapsed       | 199          |\n",
      "|    total_timesteps    | 46809088     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.01880168   |\n",
      "|    entropy_loss       | -2.3         |\n",
      "|    explained_variance | 0.805        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0995      |\n",
      "|    mean_step_reward   | 0.0071586017 |\n",
      "|    n_updates          | 68/128       |\n",
      "|    policyGradLoss     | -0.0175      |\n",
      "|    value_loss         | 0.154        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 746         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 208         |\n",
      "|    total_timesteps    | 46817280    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018210255 |\n",
      "|    entropy_loss       | -2.34       |\n",
      "|    explained_variance | 0.834       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0536     |\n",
      "|    mean_step_reward   | 0.001564241 |\n",
      "|    n_updates          | 72/128      |\n",
      "|    policyGradLoss     | -0.0148     |\n",
      "|    value_loss         | 0.236       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 751          |\n",
      "|    iterations         | 20           |\n",
      "|    time_elapsed       | 217          |\n",
      "|    total_timesteps    | 46825472     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.01521413   |\n",
      "|    entropy_loss       | -2.3         |\n",
      "|    explained_variance | 0.722        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0881      |\n",
      "|    mean_step_reward   | 0.0033243995 |\n",
      "|    n_updates          | 76/128       |\n",
      "|    policyGradLoss     | -0.0148      |\n",
      "|    value_loss         | 0.186        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 757         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 227         |\n",
      "|    total_timesteps    | 46833664    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017163616 |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.901       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0763     |\n",
      "|    mean_step_reward   | 0.013314305 |\n",
      "|    n_updates          | 80/128      |\n",
      "|    policyGradLoss     | -0.0154     |\n",
      "|    value_loss         | 0.236       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 758         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 237         |\n",
      "|    total_timesteps    | 46841856    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021206133 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.677       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0712     |\n",
      "|    mean_step_reward   | 0.023637839 |\n",
      "|    n_updates          | 84/128      |\n",
      "|    policyGradLoss     | -0.0143     |\n",
      "|    value_loss         | 0.526       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 756         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 249         |\n",
      "|    total_timesteps    | 46850048    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019301083 |\n",
      "|    entropy_loss       | -2.28       |\n",
      "|    explained_variance | 0.722       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0674     |\n",
      "|    mean_step_reward   | 0.004182743 |\n",
      "|    n_updates          | 88/128      |\n",
      "|    policyGradLoss     | -0.0136     |\n",
      "|    value_loss         | 0.402       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 756         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 259         |\n",
      "|    total_timesteps    | 46858240    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018819982 |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.856       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0527     |\n",
      "|    mean_step_reward   | 0.018673133 |\n",
      "|    n_updates          | 92/128      |\n",
      "|    policyGradLoss     | -0.0178     |\n",
      "|    value_loss         | 0.326       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 755         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 271         |\n",
      "|    total_timesteps    | 46866432    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017052967 |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.861       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0652     |\n",
      "|    mean_step_reward   | 0.033791125 |\n",
      "|    n_updates          | 96/128      |\n",
      "|    policyGradLoss     | -0.0145     |\n",
      "|    value_loss         | 0.399       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 755         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 282         |\n",
      "|    total_timesteps    | 46874624    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01662894  |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.849       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00837     |\n",
      "|    mean_step_reward   | 0.024774108 |\n",
      "|    n_updates          | 100/128     |\n",
      "|    policyGradLoss     | -0.0131     |\n",
      "|    value_loss         | 0.486       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 755         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 292         |\n",
      "|    total_timesteps    | 46882816    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019176625 |\n",
      "|    entropy_loss       | -2.29       |\n",
      "|    explained_variance | 0.875       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.096      |\n",
      "|    mean_step_reward   | 0.013900509 |\n",
      "|    n_updates          | 104/128     |\n",
      "|    policyGradLoss     | -0.0186     |\n",
      "|    value_loss         | 0.142       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 755         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 303         |\n",
      "|    total_timesteps    | 46891008    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021525066 |\n",
      "|    entropy_loss       | -2.27       |\n",
      "|    explained_variance | 0.876       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.101      |\n",
      "|    mean_step_reward   | 0.01911118  |\n",
      "|    n_updates          | 108/128     |\n",
      "|    policyGradLoss     | -0.0212     |\n",
      "|    value_loss         | 0.169       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 756         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 314         |\n",
      "|    total_timesteps    | 46899200    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023375373 |\n",
      "|    entropy_loss       | -2.28       |\n",
      "|    explained_variance | 0.916       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.108      |\n",
      "|    mean_step_reward   | 0.026805304 |\n",
      "|    n_updates          | 112/128     |\n",
      "|    policyGradLoss     | -0.0189     |\n",
      "|    value_loss         | 0.129       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 756         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 324         |\n",
      "|    total_timesteps    | 46907392    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017508954 |\n",
      "|    entropy_loss       | -2.35       |\n",
      "|    explained_variance | 0.94        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.109      |\n",
      "|    mean_step_reward   | 0.011934692 |\n",
      "|    n_updates          | 116/128     |\n",
      "|    policyGradLoss     | -0.0194     |\n",
      "|    value_loss         | 0.084       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 757          |\n",
      "|    iterations         | 31           |\n",
      "|    time_elapsed       | 335          |\n",
      "|    total_timesteps    | 46915584     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.00926392   |\n",
      "|    entropy_loss       | -2.32        |\n",
      "|    explained_variance | 0.843        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0597      |\n",
      "|    mean_step_reward   | 0.0065535856 |\n",
      "|    n_updates          | 120/128      |\n",
      "|    policyGradLoss     | -0.0118      |\n",
      "|    value_loss         | 0.289        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 757         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 346         |\n",
      "|    total_timesteps    | 46923776    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016074901 |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.943       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0892     |\n",
      "|    mean_step_reward   | 0.017527217 |\n",
      "|    n_updates          | 124/128     |\n",
      "|    policyGradLoss     | -0.0155     |\n",
      "|    value_loss         | 0.18        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/NoArti_178.zip\n",
      "[EVAL] Mean Return: -7.632, Best Return: -6.024\n",
      "Saved video to ./runs_smw/videos/NoArti/NoArti_178_-7.63.mp4\n",
      "\n",
      "=== Round 180 | Learn 262144 steps (Total trained: 46923776) ===\n",
      "Logging to ./runs_smw/tb/NoArti_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1096     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 46931968 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 891         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 46940160    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.0168985   |\n",
      "|    entropy_loss       | -2.29       |\n",
      "|    explained_variance | 0.886       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0983     |\n",
      "|    mean_step_reward   | 0.005226384 |\n",
      "|    n_updates          | 4/128       |\n",
      "|    policyGradLoss     | -0.0159     |\n",
      "|    value_loss         | 0.138       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 845         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 29          |\n",
      "|    total_timesteps    | 46948352    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020046448 |\n",
      "|    entropy_loss       | -2.27       |\n",
      "|    explained_variance | 0.86        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0977     |\n",
      "|    mean_step_reward   | 0.01828929  |\n",
      "|    n_updates          | 8/128       |\n",
      "|    policyGradLoss     | -0.0175     |\n",
      "|    value_loss         | 0.196       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 820         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 46956544    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019321077 |\n",
      "|    entropy_loss       | -2.28       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.107      |\n",
      "|    mean_step_reward   | 0.028371893 |\n",
      "|    n_updates          | 12/128      |\n",
      "|    policyGradLoss     | -0.0176     |\n",
      "|    value_loss         | 0.104       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 807         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 50          |\n",
      "|    total_timesteps    | 46964736    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023207244 |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.928       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0845     |\n",
      "|    mean_step_reward   | 0.017000914 |\n",
      "|    n_updates          | 16/128      |\n",
      "|    policyGradLoss     | -0.0156     |\n",
      "|    value_loss         | 0.161       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 798         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 61          |\n",
      "|    total_timesteps    | 46972928    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016066426 |\n",
      "|    entropy_loss       | -2.18       |\n",
      "|    explained_variance | 0.917       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0746     |\n",
      "|    mean_step_reward   | 0.027775243 |\n",
      "|    n_updates          | 20/128      |\n",
      "|    policyGradLoss     | -0.0162     |\n",
      "|    value_loss         | 0.285       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 794         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 72          |\n",
      "|    total_timesteps    | 46981120    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012975669 |\n",
      "|    entropy_loss       | -2.19       |\n",
      "|    explained_variance | 0.857       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0675     |\n",
      "|    mean_step_reward   | 0.04454109  |\n",
      "|    n_updates          | 24/128      |\n",
      "|    policyGradLoss     | -0.0111     |\n",
      "|    value_loss         | 0.5         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 790         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 82          |\n",
      "|    total_timesteps    | 46989312    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017236164 |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.913       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0757     |\n",
      "|    mean_step_reward   | 0.022764072 |\n",
      "|    n_updates          | 28/128      |\n",
      "|    policyGradLoss     | -0.0173     |\n",
      "|    value_loss         | 0.273       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 93          |\n",
      "|    total_timesteps    | 46997504    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023248248 |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.911       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0918     |\n",
      "|    mean_step_reward   | 0.033339657 |\n",
      "|    n_updates          | 32/128      |\n",
      "|    policyGradLoss     | -0.0175     |\n",
      "|    value_loss         | 0.184       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 104         |\n",
      "|    total_timesteps    | 47005696    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020383997 |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.912       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0802     |\n",
      "|    mean_step_reward   | 0.031219698 |\n",
      "|    n_updates          | 36/128      |\n",
      "|    policyGradLoss     | -0.0167     |\n",
      "|    value_loss         | 0.263       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 115         |\n",
      "|    total_timesteps    | 47013888    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01686598  |\n",
      "|    entropy_loss       | -2.28       |\n",
      "|    explained_variance | 0.931       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0981     |\n",
      "|    mean_step_reward   | 0.015058929 |\n",
      "|    n_updates          | 40/128      |\n",
      "|    policyGradLoss     | -0.0207     |\n",
      "|    value_loss         | 0.118       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 125         |\n",
      "|    total_timesteps    | 47022080    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017443392 |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.829       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0838     |\n",
      "|    mean_step_reward   | 0.031236032 |\n",
      "|    n_updates          | 44/128      |\n",
      "|    policyGradLoss     | -0.0116     |\n",
      "|    value_loss         | 0.445       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 136         |\n",
      "|    total_timesteps    | 47030272    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013822891 |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.834       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0571     |\n",
      "|    mean_step_reward   | 0.016109943 |\n",
      "|    n_updates          | 48/128      |\n",
      "|    policyGradLoss     | -0.0126     |\n",
      "|    value_loss         | 0.342       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 147         |\n",
      "|    total_timesteps    | 47038464    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016700618 |\n",
      "|    entropy_loss       | -2.29       |\n",
      "|    explained_variance | 0.895       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0928     |\n",
      "|    mean_step_reward   | 0.016397448 |\n",
      "|    n_updates          | 52/128      |\n",
      "|    policyGradLoss     | -0.0175     |\n",
      "|    value_loss         | 0.153       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 157         |\n",
      "|    total_timesteps    | 47046656    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019595645 |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.957       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0667     |\n",
      "|    mean_step_reward   | 0.027774943 |\n",
      "|    n_updates          | 56/128      |\n",
      "|    policyGradLoss     | -0.0225     |\n",
      "|    value_loss         | 0.136       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 168         |\n",
      "|    total_timesteps    | 47054848    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018167442 |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.886       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0578     |\n",
      "|    mean_step_reward   | 0.03432955  |\n",
      "|    n_updates          | 60/128      |\n",
      "|    policyGradLoss     | -0.0125     |\n",
      "|    value_loss         | 0.278       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 775        |\n",
      "|    iterations         | 17         |\n",
      "|    time_elapsed       | 179        |\n",
      "|    total_timesteps    | 47063040   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02431196 |\n",
      "|    entropy_loss       | -2.24      |\n",
      "|    explained_variance | 0.906      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0635    |\n",
      "|    mean_step_reward   | 0.02375865 |\n",
      "|    n_updates          | 64/128     |\n",
      "|    policyGradLoss     | -0.0156    |\n",
      "|    value_loss         | 0.203      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 190         |\n",
      "|    total_timesteps    | 47071232    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011948001 |\n",
      "|    entropy_loss       | -2.28       |\n",
      "|    explained_variance | 0.939       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0918     |\n",
      "|    mean_step_reward   | 0.018303357 |\n",
      "|    n_updates          | 68/128      |\n",
      "|    policyGradLoss     | -0.0172     |\n",
      "|    value_loss         | 0.202       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 201         |\n",
      "|    total_timesteps    | 47079424    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02120452  |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.952       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0942     |\n",
      "|    mean_step_reward   | 0.025491629 |\n",
      "|    n_updates          | 72/128      |\n",
      "|    policyGradLoss     | -0.0196     |\n",
      "|    value_loss         | 0.15        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 212         |\n",
      "|    total_timesteps    | 47087616    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026187886 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.917       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0998     |\n",
      "|    mean_step_reward   | 0.045414828 |\n",
      "|    n_updates          | 76/128      |\n",
      "|    policyGradLoss     | -0.0108     |\n",
      "|    value_loss         | 0.19        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 222         |\n",
      "|    total_timesteps    | 47095808    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019701213 |\n",
      "|    entropy_loss       | -2.34       |\n",
      "|    explained_variance | 0.943       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.097      |\n",
      "|    mean_step_reward   | 0.006092019 |\n",
      "|    n_updates          | 80/128      |\n",
      "|    policyGradLoss     | -0.0134     |\n",
      "|    value_loss         | 0.112       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 233         |\n",
      "|    total_timesteps    | 47104000    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012478499 |\n",
      "|    entropy_loss       | -2.28       |\n",
      "|    explained_variance | 0.938       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0545     |\n",
      "|    mean_step_reward   | 0.010672294 |\n",
      "|    n_updates          | 84/128      |\n",
      "|    policyGradLoss     | -0.0146     |\n",
      "|    value_loss         | 0.183       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 244         |\n",
      "|    total_timesteps    | 47112192    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023361841 |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.108      |\n",
      "|    mean_step_reward   | 0.03264308  |\n",
      "|    n_updates          | 88/128      |\n",
      "|    policyGradLoss     | -0.0234     |\n",
      "|    value_loss         | 0.111       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 255         |\n",
      "|    total_timesteps    | 47120384    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015805759 |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.864       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0788     |\n",
      "|    mean_step_reward   | 0.029032914 |\n",
      "|    n_updates          | 92/128      |\n",
      "|    policyGradLoss     | -0.0116     |\n",
      "|    value_loss         | 0.295       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 769          |\n",
      "|    iterations         | 25           |\n",
      "|    time_elapsed       | 265          |\n",
      "|    total_timesteps    | 47128576     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.018737674  |\n",
      "|    entropy_loss       | -2.29        |\n",
      "|    explained_variance | 0.864        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.056       |\n",
      "|    mean_step_reward   | 0.0049963016 |\n",
      "|    n_updates          | 96/128       |\n",
      "|    policyGradLoss     | -0.013       |\n",
      "|    value_loss         | 0.217        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 276         |\n",
      "|    total_timesteps    | 47136768    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02252352  |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.943       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0922     |\n",
      "|    mean_step_reward   | 0.021031328 |\n",
      "|    n_updates          | 100/128     |\n",
      "|    policyGradLoss     | -0.0193     |\n",
      "|    value_loss         | 0.126       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 287         |\n",
      "|    total_timesteps    | 47144960    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02850407  |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.954       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0796     |\n",
      "|    mean_step_reward   | 0.038226373 |\n",
      "|    n_updates          | 104/128     |\n",
      "|    policyGradLoss     | -0.0188     |\n",
      "|    value_loss         | 0.154       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 298         |\n",
      "|    total_timesteps    | 47153152    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022910265 |\n",
      "|    entropy_loss       | -2.16       |\n",
      "|    explained_variance | 0.935       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.047      |\n",
      "|    mean_step_reward   | 0.031228226 |\n",
      "|    n_updates          | 108/128     |\n",
      "|    policyGradLoss     | -0.0151     |\n",
      "|    value_loss         | 0.278       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 308         |\n",
      "|    total_timesteps    | 47161344    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024773816 |\n",
      "|    entropy_loss       | -2.18       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.109      |\n",
      "|    mean_step_reward   | 0.036107607 |\n",
      "|    n_updates          | 112/128     |\n",
      "|    policyGradLoss     | -0.0209     |\n",
      "|    value_loss         | 0.128       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 319         |\n",
      "|    total_timesteps    | 47169536    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022863543 |\n",
      "|    entropy_loss       | -2.29       |\n",
      "|    explained_variance | 0.892       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0724     |\n",
      "|    mean_step_reward   | 0.015651945 |\n",
      "|    n_updates          | 116/128     |\n",
      "|    policyGradLoss     | -0.0148     |\n",
      "|    value_loss         | 0.174       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 329         |\n",
      "|    total_timesteps    | 47177728    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01868027  |\n",
      "|    entropy_loss       | -2.35       |\n",
      "|    explained_variance | 0.955       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.112      |\n",
      "|    mean_step_reward   | 0.012354288 |\n",
      "|    n_updates          | 120/128     |\n",
      "|    policyGradLoss     | -0.0167     |\n",
      "|    value_loss         | 0.048       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 340         |\n",
      "|    total_timesteps    | 47185920    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02354876  |\n",
      "|    entropy_loss       | -2.31       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.122      |\n",
      "|    mean_step_reward   | 0.016765505 |\n",
      "|    n_updates          | 124/128     |\n",
      "|    policyGradLoss     | -0.0234     |\n",
      "|    value_loss         | 0.0347      |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/NoArti_179.zip\n",
      "[EVAL] Mean Return: 36.854, Best Return: 38.054\n",
      "Saved video to ./runs_smw/videos/NoArti/NoArti_179_36.85.mp4\n",
      "\n",
      "=== Round 181 | Learn 262144 steps (Total trained: 47185920) ===\n",
      "Logging to ./runs_smw/tb/NoArti_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1105     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 47194112 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 898         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 47202304    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022358393 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.951       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0995     |\n",
      "|    mean_step_reward   | 0.02405408  |\n",
      "|    n_updates          | 4/128       |\n",
      "|    policyGradLoss     | -0.0175     |\n",
      "|    value_loss         | 0.0878      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 852         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 47210496    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025128305 |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.115      |\n",
      "|    mean_step_reward   | 0.03016109  |\n",
      "|    n_updates          | 8/128       |\n",
      "|    policyGradLoss     | -0.0213     |\n",
      "|    value_loss         | 0.0568      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 826         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 47218688    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018704329 |\n",
      "|    entropy_loss       | -2.29       |\n",
      "|    explained_variance | 0.913       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.087      |\n",
      "|    mean_step_reward   | 0.011069624 |\n",
      "|    n_updates          | 12/128      |\n",
      "|    policyGradLoss     | -0.0172     |\n",
      "|    value_loss         | 0.116       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 810         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 50          |\n",
      "|    total_timesteps    | 47226880    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021171343 |\n",
      "|    entropy_loss       | -2.3        |\n",
      "|    explained_variance | 0.903       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0862     |\n",
      "|    mean_step_reward   | 0.013755115 |\n",
      "|    n_updates          | 16/128      |\n",
      "|    policyGradLoss     | -0.0159     |\n",
      "|    value_loss         | 0.201       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 803         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 61          |\n",
      "|    total_timesteps    | 47235072    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020264944 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.923       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0651     |\n",
      "|    mean_step_reward   | 0.01967238  |\n",
      "|    n_updates          | 20/128      |\n",
      "|    policyGradLoss     | -0.0175     |\n",
      "|    value_loss         | 0.176       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 796         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 72          |\n",
      "|    total_timesteps    | 47243264    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023022065 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0877     |\n",
      "|    mean_step_reward   | 0.03579305  |\n",
      "|    n_updates          | 24/128      |\n",
      "|    policyGradLoss     | -0.0188     |\n",
      "|    value_loss         | 0.0805      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 788         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 83          |\n",
      "|    total_timesteps    | 47251456    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021615    |\n",
      "|    entropy_loss       | -2.32       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.108      |\n",
      "|    mean_step_reward   | 0.012984056 |\n",
      "|    n_updates          | 28/128      |\n",
      "|    policyGradLoss     | -0.0209     |\n",
      "|    value_loss         | 0.0401      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 93          |\n",
      "|    total_timesteps    | 47259648    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017614875 |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.862       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0507     |\n",
      "|    mean_step_reward   | 0.018005025 |\n",
      "|    n_updates          | 32/128      |\n",
      "|    policyGradLoss     | -0.00987    |\n",
      "|    value_loss         | 0.39        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 104         |\n",
      "|    total_timesteps    | 47267840    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018434603 |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.927       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.079      |\n",
      "|    mean_step_reward   | 0.018180907 |\n",
      "|    n_updates          | 36/128      |\n",
      "|    policyGradLoss     | -0.014      |\n",
      "|    value_loss         | 0.204       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 114         |\n",
      "|    total_timesteps    | 47276032    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022155095 |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.947       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0978     |\n",
      "|    mean_step_reward   | 0.03746275  |\n",
      "|    n_updates          | 40/128      |\n",
      "|    policyGradLoss     | -0.0194     |\n",
      "|    value_loss         | 0.152       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 125         |\n",
      "|    total_timesteps    | 47284224    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01936022  |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.958       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0632     |\n",
      "|    mean_step_reward   | 0.020474475 |\n",
      "|    n_updates          | 44/128      |\n",
      "|    policyGradLoss     | -0.0192     |\n",
      "|    value_loss         | 0.165       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 136         |\n",
      "|    total_timesteps    | 47292416    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02819989  |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.949       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.102      |\n",
      "|    mean_step_reward   | 0.031741496 |\n",
      "|    n_updates          | 48/128      |\n",
      "|    policyGradLoss     | -0.0196     |\n",
      "|    value_loss         | 0.142       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 147         |\n",
      "|    total_timesteps    | 47300608    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018658575 |\n",
      "|    entropy_loss       | -2.29       |\n",
      "|    explained_variance | 0.908       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0719     |\n",
      "|    mean_step_reward   | 0.019198595 |\n",
      "|    n_updates          | 52/128      |\n",
      "|    policyGradLoss     | -0.00782    |\n",
      "|    value_loss         | 0.221       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 157         |\n",
      "|    total_timesteps    | 47308800    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025587838 |\n",
      "|    entropy_loss       | -2.38       |\n",
      "|    explained_variance | 0.916       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.121      |\n",
      "|    mean_step_reward   | 0.007078496 |\n",
      "|    n_updates          | 56/128      |\n",
      "|    policyGradLoss     | -0.02       |\n",
      "|    value_loss         | 0.0184      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 778          |\n",
      "|    iterations         | 16           |\n",
      "|    time_elapsed       | 168          |\n",
      "|    total_timesteps    | 47316992     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.015636344  |\n",
      "|    entropy_loss       | -2.32        |\n",
      "|    explained_variance | 0.716        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.06        |\n",
      "|    mean_step_reward   | 0.0054357853 |\n",
      "|    n_updates          | 60/128       |\n",
      "|    policyGradLoss     | -0.0112      |\n",
      "|    value_loss         | 0.384        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 179         |\n",
      "|    total_timesteps    | 47325184    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021495461 |\n",
      "|    entropy_loss       | -2.29       |\n",
      "|    explained_variance | 0.924       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.107      |\n",
      "|    mean_step_reward   | 0.015371012 |\n",
      "|    n_updates          | 64/128      |\n",
      "|    policyGradLoss     | -0.0207     |\n",
      "|    value_loss         | 0.115       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 190         |\n",
      "|    total_timesteps    | 47333376    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017285235 |\n",
      "|    entropy_loss       | -2.32       |\n",
      "|    explained_variance | 0.93        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.113      |\n",
      "|    mean_step_reward   | 0.021255571 |\n",
      "|    n_updates          | 68/128      |\n",
      "|    policyGradLoss     | -0.0144     |\n",
      "|    value_loss         | 0.0689      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 200         |\n",
      "|    total_timesteps    | 47341568    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012101272 |\n",
      "|    entropy_loss       | -2.29       |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0675     |\n",
      "|    mean_step_reward   | 0.009490747 |\n",
      "|    n_updates          | 72/128      |\n",
      "|    policyGradLoss     | -0.0145     |\n",
      "|    value_loss         | 0.104       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 211         |\n",
      "|    total_timesteps    | 47349760    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019362649 |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0887     |\n",
      "|    mean_step_reward   | 0.030590411 |\n",
      "|    n_updates          | 76/128      |\n",
      "|    policyGradLoss     | -0.0172     |\n",
      "|    value_loss         | 0.132       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 776        |\n",
      "|    iterations         | 21         |\n",
      "|    time_elapsed       | 221        |\n",
      "|    total_timesteps    | 47357952   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01950394 |\n",
      "|    entropy_loss       | -2.25      |\n",
      "|    explained_variance | 0.916      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0739    |\n",
      "|    mean_step_reward   | 0.01658516 |\n",
      "|    n_updates          | 80/128     |\n",
      "|    policyGradLoss     | -0.0145    |\n",
      "|    value_loss         | 0.215      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 775        |\n",
      "|    iterations         | 22         |\n",
      "|    time_elapsed       | 232        |\n",
      "|    total_timesteps    | 47366144   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02706441 |\n",
      "|    entropy_loss       | -2.28      |\n",
      "|    explained_variance | 0.97       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.101     |\n",
      "|    mean_step_reward   | 0.0290326  |\n",
      "|    n_updates          | 84/128     |\n",
      "|    policyGradLoss     | -0.0184    |\n",
      "|    value_loss         | 0.0712     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 775          |\n",
      "|    iterations         | 23           |\n",
      "|    time_elapsed       | 242          |\n",
      "|    total_timesteps    | 47374336     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.015101343  |\n",
      "|    entropy_loss       | -2.26        |\n",
      "|    explained_variance | 0.955        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0967      |\n",
      "|    mean_step_reward   | 0.0050092125 |\n",
      "|    n_updates          | 88/128       |\n",
      "|    policyGradLoss     | -0.0175      |\n",
      "|    value_loss         | 0.104        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 253         |\n",
      "|    total_timesteps    | 47382528    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028685696 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.922       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0849     |\n",
      "|    mean_step_reward   | 0.025132349 |\n",
      "|    n_updates          | 92/128      |\n",
      "|    policyGradLoss     | -0.0161     |\n",
      "|    value_loss         | 0.0763      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 264         |\n",
      "|    total_timesteps    | 47390720    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018495494 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.928       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0957     |\n",
      "|    mean_step_reward   | 0.029646125 |\n",
      "|    n_updates          | 96/128      |\n",
      "|    policyGradLoss     | -0.0145     |\n",
      "|    value_loss         | 0.162       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 773        |\n",
      "|    iterations         | 26         |\n",
      "|    time_elapsed       | 275        |\n",
      "|    total_timesteps    | 47398912   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01999756 |\n",
      "|    entropy_loss       | -2.16      |\n",
      "|    explained_variance | 0.928      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.0518     |\n",
      "|    mean_step_reward   | 0.02344511 |\n",
      "|    n_updates          | 100/128    |\n",
      "|    policyGradLoss     | -0.0158    |\n",
      "|    value_loss         | 0.303      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 286         |\n",
      "|    total_timesteps    | 47407104    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029109973 |\n",
      "|    entropy_loss       | -2.14       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.102      |\n",
      "|    mean_step_reward   | 0.052955545 |\n",
      "|    n_updates          | 104/128     |\n",
      "|    policyGradLoss     | -0.0212     |\n",
      "|    value_loss         | 0.104       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 296         |\n",
      "|    total_timesteps    | 47415296    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022318225 |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.928       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0615     |\n",
      "|    mean_step_reward   | 0.024677325 |\n",
      "|    n_updates          | 108/128     |\n",
      "|    policyGradLoss     | -0.013      |\n",
      "|    value_loss         | 0.205       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 307         |\n",
      "|    total_timesteps    | 47423488    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030273635 |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.102      |\n",
      "|    mean_step_reward   | 0.031452954 |\n",
      "|    n_updates          | 112/128     |\n",
      "|    policyGradLoss     | -0.0201     |\n",
      "|    value_loss         | 0.0685      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 318         |\n",
      "|    total_timesteps    | 47431680    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023180075 |\n",
      "|    entropy_loss       | -2.28       |\n",
      "|    explained_variance | 0.958       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.101      |\n",
      "|    mean_step_reward   | 0.022014275 |\n",
      "|    n_updates          | 116/128     |\n",
      "|    policyGradLoss     | -0.0182     |\n",
      "|    value_loss         | 0.0722      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 329         |\n",
      "|    total_timesteps    | 47439872    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017783046 |\n",
      "|    entropy_loss       | -2.3        |\n",
      "|    explained_variance | 0.862       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0438     |\n",
      "|    mean_step_reward   | 0.019913416 |\n",
      "|    n_updates          | 120/128     |\n",
      "|    policyGradLoss     | -0.012      |\n",
      "|    value_loss         | 0.239       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 339         |\n",
      "|    total_timesteps    | 47448064    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018102773 |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.882       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0722      |\n",
      "|    mean_step_reward   | 0.015780885 |\n",
      "|    n_updates          | 124/128     |\n",
      "|    policyGradLoss     | -0.0107     |\n",
      "|    value_loss         | 0.348       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/NoArti_180.zip\n",
      "[EVAL] Mean Return: 131.460, Best Return: 134.060\n",
      "Saved video to ./runs_smw/videos/NoArti/NoArti_180_131.46.mp4\n",
      "\n",
      "=== Round 182 | Learn 262144 steps (Total trained: 47448064) ===\n",
      "Logging to ./runs_smw/tb/NoArti_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1076     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 47456256 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 886         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 47464448    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021735588 |\n",
      "|    entropy_loss       | -2.18       |\n",
      "|    explained_variance | 0.958       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0839     |\n",
      "|    mean_step_reward   | 0.03531703  |\n",
      "|    n_updates          | 4/128       |\n",
      "|    policyGradLoss     | -0.0144     |\n",
      "|    value_loss         | 0.155       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 851         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 47472640    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020671535 |\n",
      "|    entropy_loss       | -2.18       |\n",
      "|    explained_variance | 0.927       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0393      |\n",
      "|    mean_step_reward   | 0.032427173 |\n",
      "|    n_updates          | 8/128       |\n",
      "|    policyGradLoss     | -0.0142     |\n",
      "|    value_loss         | 0.348       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 829         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 47480832    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024705075 |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.949       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0674     |\n",
      "|    mean_step_reward   | 0.038016923 |\n",
      "|    n_updates          | 12/128      |\n",
      "|    policyGradLoss     | -0.0178     |\n",
      "|    value_loss         | 0.139       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 816         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 50          |\n",
      "|    total_timesteps    | 47489024    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014242185 |\n",
      "|    entropy_loss       | -2.28       |\n",
      "|    explained_variance | 0.872       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0726     |\n",
      "|    mean_step_reward   | 0.017532846 |\n",
      "|    n_updates          | 16/128      |\n",
      "|    policyGradLoss     | -0.0122     |\n",
      "|    value_loss         | 0.281       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 808         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 60          |\n",
      "|    total_timesteps    | 47497216    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023298452 |\n",
      "|    entropy_loss       | -2.33       |\n",
      "|    explained_variance | 0.913       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.107      |\n",
      "|    mean_step_reward   | 0.014496174 |\n",
      "|    n_updates          | 20/128      |\n",
      "|    policyGradLoss     | -0.0188     |\n",
      "|    value_loss         | 0.0876      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 797         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 71          |\n",
      "|    total_timesteps    | 47505408    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018004905 |\n",
      "|    entropy_loss       | -2.32       |\n",
      "|    explained_variance | 0.955       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0978     |\n",
      "|    mean_step_reward   | 0.013316127 |\n",
      "|    n_updates          | 24/128      |\n",
      "|    policyGradLoss     | -0.0182     |\n",
      "|    value_loss         | 0.076       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 792         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 82          |\n",
      "|    total_timesteps    | 47513600    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015203748 |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.8         |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0748     |\n",
      "|    mean_step_reward   | 0.013005226 |\n",
      "|    n_updates          | 28/128      |\n",
      "|    policyGradLoss     | -0.0139     |\n",
      "|    value_loss         | 0.33        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 786        |\n",
      "|    iterations         | 9          |\n",
      "|    time_elapsed       | 93         |\n",
      "|    total_timesteps    | 47521792   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01882147 |\n",
      "|    entropy_loss       | -2.22      |\n",
      "|    explained_variance | 0.794      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0663    |\n",
      "|    mean_step_reward   | 0.02708166 |\n",
      "|    n_updates          | 32/128     |\n",
      "|    policyGradLoss     | -0.0212    |\n",
      "|    value_loss         | 0.314      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 104         |\n",
      "|    total_timesteps    | 47529984    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014932478 |\n",
      "|    entropy_loss       | -2.28       |\n",
      "|    explained_variance | 0.875       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0926     |\n",
      "|    mean_step_reward   | 0.029408654 |\n",
      "|    n_updates          | 36/128      |\n",
      "|    policyGradLoss     | -0.0142     |\n",
      "|    value_loss         | 0.15        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 115         |\n",
      "|    total_timesteps    | 47538176    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017521493 |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.924       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0868     |\n",
      "|    mean_step_reward   | 0.014476868 |\n",
      "|    n_updates          | 40/128      |\n",
      "|    policyGradLoss     | -0.0173     |\n",
      "|    value_loss         | 0.224       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 125         |\n",
      "|    total_timesteps    | 47546368    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021845572 |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.105      |\n",
      "|    mean_step_reward   | 0.029816447 |\n",
      "|    n_updates          | 44/128      |\n",
      "|    policyGradLoss     | -0.0228     |\n",
      "|    value_loss         | 0.09        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 136         |\n",
      "|    total_timesteps    | 47554560    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017199576 |\n",
      "|    entropy_loss       | -2.27       |\n",
      "|    explained_variance | 0.923       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0771     |\n",
      "|    mean_step_reward   | 0.024228487 |\n",
      "|    n_updates          | 48/128      |\n",
      "|    policyGradLoss     | -0.0151     |\n",
      "|    value_loss         | 0.219       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 147         |\n",
      "|    total_timesteps    | 47562752    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015779965 |\n",
      "|    entropy_loss       | -2.28       |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.109      |\n",
      "|    mean_step_reward   | 0.019655157 |\n",
      "|    n_updates          | 52/128      |\n",
      "|    policyGradLoss     | -0.0189     |\n",
      "|    value_loss         | 0.104       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 158         |\n",
      "|    total_timesteps    | 47570944    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012199234 |\n",
      "|    entropy_loss       | -2.2        |\n",
      "|    explained_variance | 0.778       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0509     |\n",
      "|    mean_step_reward   | 0.02666219  |\n",
      "|    n_updates          | 56/128      |\n",
      "|    policyGradLoss     | -0.0109     |\n",
      "|    value_loss         | 0.385       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 169         |\n",
      "|    total_timesteps    | 47579136    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019331094 |\n",
      "|    entropy_loss       | -2.18       |\n",
      "|    explained_variance | 0.884       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0115     |\n",
      "|    mean_step_reward   | 0.03344622  |\n",
      "|    n_updates          | 60/128      |\n",
      "|    policyGradLoss     | -0.0145     |\n",
      "|    value_loss         | 0.372       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 179         |\n",
      "|    total_timesteps    | 47587328    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024975417 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.095      |\n",
      "|    mean_step_reward   | 0.034591045 |\n",
      "|    n_updates          | 64/128      |\n",
      "|    policyGradLoss     | -0.0216     |\n",
      "|    value_loss         | 0.086       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 775        |\n",
      "|    iterations         | 18         |\n",
      "|    time_elapsed       | 190        |\n",
      "|    total_timesteps    | 47595520   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02481158 |\n",
      "|    entropy_loss       | -2.25      |\n",
      "|    explained_variance | 0.968      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.104     |\n",
      "|    mean_step_reward   | 0.03284549 |\n",
      "|    n_updates          | 68/128     |\n",
      "|    policyGradLoss     | -0.0174    |\n",
      "|    value_loss         | 0.155      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 200         |\n",
      "|    total_timesteps    | 47603712    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016962094 |\n",
      "|    entropy_loss       | -2.31       |\n",
      "|    explained_variance | 0.759       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0914     |\n",
      "|    mean_step_reward   | 0.010925427 |\n",
      "|    n_updates          | 72/128      |\n",
      "|    policyGradLoss     | -0.00819    |\n",
      "|    value_loss         | 0.365       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 773        |\n",
      "|    iterations         | 20         |\n",
      "|    time_elapsed       | 211        |\n",
      "|    total_timesteps    | 47611904   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01670887 |\n",
      "|    entropy_loss       | -2.25      |\n",
      "|    explained_variance | 0.852      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0696    |\n",
      "|    mean_step_reward   | 0.02062698 |\n",
      "|    n_updates          | 76/128     |\n",
      "|    policyGradLoss     | -0.016     |\n",
      "|    value_loss         | 0.288      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 222         |\n",
      "|    total_timesteps    | 47620096    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02539279  |\n",
      "|    entropy_loss       | -2.16       |\n",
      "|    explained_variance | 0.894       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0891     |\n",
      "|    mean_step_reward   | 0.039755784 |\n",
      "|    n_updates          | 80/128      |\n",
      "|    policyGradLoss     | -0.0183     |\n",
      "|    value_loss         | 0.252       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 772        |\n",
      "|    iterations         | 22         |\n",
      "|    time_elapsed       | 233        |\n",
      "|    total_timesteps    | 47628288   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02286499 |\n",
      "|    entropy_loss       | -2.19      |\n",
      "|    explained_variance | 0.923      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0887    |\n",
      "|    mean_step_reward   | 0.04221972 |\n",
      "|    n_updates          | 84/128     |\n",
      "|    policyGradLoss     | -0.0158    |\n",
      "|    value_loss         | 0.255      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 244         |\n",
      "|    total_timesteps    | 47636480    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016513117 |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.896       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0131      |\n",
      "|    mean_step_reward   | 0.026442433 |\n",
      "|    n_updates          | 88/128      |\n",
      "|    policyGradLoss     | -0.0154     |\n",
      "|    value_loss         | 0.316       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 255         |\n",
      "|    total_timesteps    | 47644672    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022232886 |\n",
      "|    entropy_loss       | -2.17       |\n",
      "|    explained_variance | 0.927       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0877     |\n",
      "|    mean_step_reward   | 0.04047447  |\n",
      "|    n_updates          | 92/128      |\n",
      "|    policyGradLoss     | -0.0188     |\n",
      "|    value_loss         | 0.222       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 266         |\n",
      "|    total_timesteps    | 47652864    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017533492 |\n",
      "|    entropy_loss       | -2.28       |\n",
      "|    explained_variance | 0.931       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0986     |\n",
      "|    mean_step_reward   | 0.029867532 |\n",
      "|    n_updates          | 96/128      |\n",
      "|    policyGradLoss     | -0.0167     |\n",
      "|    value_loss         | 0.166       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 769          |\n",
      "|    iterations         | 26           |\n",
      "|    time_elapsed       | 276          |\n",
      "|    total_timesteps    | 47661056     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.017478816  |\n",
      "|    entropy_loss       | -2.23        |\n",
      "|    explained_variance | 0.527        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.06        |\n",
      "|    mean_step_reward   | 0.0088598365 |\n",
      "|    n_updates          | 100/128      |\n",
      "|    policyGradLoss     | -0.0134      |\n",
      "|    value_loss         | 0.44         |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 770        |\n",
      "|    iterations         | 27         |\n",
      "|    time_elapsed       | 287        |\n",
      "|    total_timesteps    | 47669248   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01546262 |\n",
      "|    entropy_loss       | -2.21      |\n",
      "|    explained_variance | 0.822      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.0836     |\n",
      "|    mean_step_reward   | 0.03981097 |\n",
      "|    n_updates          | 104/128    |\n",
      "|    policyGradLoss     | -0.0102    |\n",
      "|    value_loss         | 0.53       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 298         |\n",
      "|    total_timesteps    | 47677440    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018042076 |\n",
      "|    entropy_loss       | -2.2        |\n",
      "|    explained_variance | 0.851       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0285     |\n",
      "|    mean_step_reward   | 0.024843225 |\n",
      "|    n_updates          | 108/128     |\n",
      "|    policyGradLoss     | -0.015      |\n",
      "|    value_loss         | 0.544       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 308         |\n",
      "|    total_timesteps    | 47685632    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02460572  |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.914       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0923     |\n",
      "|    mean_step_reward   | 0.045222268 |\n",
      "|    n_updates          | 112/128     |\n",
      "|    policyGradLoss     | -0.0177     |\n",
      "|    value_loss         | 0.167       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 319         |\n",
      "|    total_timesteps    | 47693824    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021221358 |\n",
      "|    entropy_loss       | -2.19       |\n",
      "|    explained_variance | 0.917       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0436     |\n",
      "|    mean_step_reward   | 0.036338452 |\n",
      "|    n_updates          | 116/128     |\n",
      "|    policyGradLoss     | -0.0143     |\n",
      "|    value_loss         | 0.381       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 330         |\n",
      "|    total_timesteps    | 47702016    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025036257 |\n",
      "|    entropy_loss       | -2.18       |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0904     |\n",
      "|    mean_step_reward   | 0.05145087  |\n",
      "|    n_updates          | 120/128     |\n",
      "|    policyGradLoss     | -0.0205     |\n",
      "|    value_loss         | 0.139       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 341         |\n",
      "|    total_timesteps    | 47710208    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022800937 |\n",
      "|    entropy_loss       | -2.29       |\n",
      "|    explained_variance | 0.945       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.109      |\n",
      "|    mean_step_reward   | 0.027351152 |\n",
      "|    n_updates          | 124/128     |\n",
      "|    policyGradLoss     | -0.0201     |\n",
      "|    value_loss         | 0.0966      |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/NoArti_181.zip\n",
      "[EVAL] Mean Return: -64.756, Best Return: -62.748\n",
      "Saved video to ./runs_smw/videos/NoArti/NoArti_181_-64.76.mp4\n",
      "\n",
      "=== Round 183 | Learn 262144 steps (Total trained: 47710208) ===\n",
      "Logging to ./runs_smw/tb/NoArti_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1104     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 47718400 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 900         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 47726592    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024745742 |\n",
      "|    entropy_loss       | -2.27       |\n",
      "|    explained_variance | 0.949       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.105      |\n",
      "|    mean_step_reward   | 0.02632843  |\n",
      "|    n_updates          | 4/128       |\n",
      "|    policyGradLoss     | -0.0181     |\n",
      "|    value_loss         | 0.0981      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 838         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 29          |\n",
      "|    total_timesteps    | 47734784    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018615099 |\n",
      "|    entropy_loss       | -2.3        |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.106      |\n",
      "|    mean_step_reward   | 0.027760081 |\n",
      "|    n_updates          | 8/128       |\n",
      "|    policyGradLoss     | -0.014      |\n",
      "|    value_loss         | 0.109       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 824          |\n",
      "|    iterations         | 4            |\n",
      "|    time_elapsed       | 39           |\n",
      "|    total_timesteps    | 47742976     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0135086    |\n",
      "|    entropy_loss       | -2.4         |\n",
      "|    explained_variance | 0.742        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.119       |\n",
      "|    mean_step_reward   | 0.0010893932 |\n",
      "|    n_updates          | 12/128       |\n",
      "|    policyGradLoss     | -0.0117      |\n",
      "|    value_loss         | 0.0744       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 805          |\n",
      "|    iterations         | 5            |\n",
      "|    time_elapsed       | 50           |\n",
      "|    total_timesteps    | 47751168     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.010610867  |\n",
      "|    entropy_loss       | -2.38        |\n",
      "|    explained_variance | 0.947        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.105       |\n",
      "|    mean_step_reward   | 0.0050062523 |\n",
      "|    n_updates          | 16/128       |\n",
      "|    policyGradLoss     | -0.0127      |\n",
      "|    value_loss         | 0.0587       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 797          |\n",
      "|    iterations         | 6            |\n",
      "|    time_elapsed       | 61           |\n",
      "|    total_timesteps    | 47759360     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.01681279   |\n",
      "|    entropy_loss       | -2.3         |\n",
      "|    explained_variance | 0.959        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.107       |\n",
      "|    mean_step_reward   | 0.0056389947 |\n",
      "|    n_updates          | 20/128       |\n",
      "|    policyGradLoss     | -0.0186      |\n",
      "|    value_loss         | 0.0977       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 791         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 72          |\n",
      "|    total_timesteps    | 47767552    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02756679  |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.934       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0937     |\n",
      "|    mean_step_reward   | 0.019651318 |\n",
      "|    n_updates          | 24/128      |\n",
      "|    policyGradLoss     | -0.0166     |\n",
      "|    value_loss         | 0.131       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 789         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 83          |\n",
      "|    total_timesteps    | 47775744    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021585643 |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.931       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.087      |\n",
      "|    mean_step_reward   | 0.022872388 |\n",
      "|    n_updates          | 28/128      |\n",
      "|    policyGradLoss     | -0.0185     |\n",
      "|    value_loss         | 0.2         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 93          |\n",
      "|    total_timesteps    | 47783936    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014010405 |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.892       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0706     |\n",
      "|    mean_step_reward   | 0.020638974 |\n",
      "|    n_updates          | 32/128      |\n",
      "|    policyGradLoss     | -0.0126     |\n",
      "|    value_loss         | 0.32        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 105         |\n",
      "|    total_timesteps    | 47792128    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027335748 |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.105      |\n",
      "|    mean_step_reward   | 0.03728181  |\n",
      "|    n_updates          | 36/128      |\n",
      "|    policyGradLoss     | -0.0207     |\n",
      "|    value_loss         | 0.152       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 777          |\n",
      "|    iterations         | 11           |\n",
      "|    time_elapsed       | 115          |\n",
      "|    total_timesteps    | 47800320     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.02059142   |\n",
      "|    entropy_loss       | -2.38        |\n",
      "|    explained_variance | 0.933        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.1         |\n",
      "|    mean_step_reward   | 0.0041806195 |\n",
      "|    n_updates          | 40/128       |\n",
      "|    policyGradLoss     | -0.0138      |\n",
      "|    value_loss         | 0.0761       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 776          |\n",
      "|    iterations         | 12           |\n",
      "|    time_elapsed       | 126          |\n",
      "|    total_timesteps    | 47808512     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.015844055  |\n",
      "|    entropy_loss       | -2.31        |\n",
      "|    explained_variance | 0.95         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0957      |\n",
      "|    mean_step_reward   | 0.0095006125 |\n",
      "|    n_updates          | 44/128       |\n",
      "|    policyGradLoss     | -0.0184      |\n",
      "|    value_loss         | 0.0808       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 137         |\n",
      "|    total_timesteps    | 47816704    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021082604 |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.942       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0949     |\n",
      "|    mean_step_reward   | 0.013780028 |\n",
      "|    n_updates          | 48/128      |\n",
      "|    policyGradLoss     | -0.0164     |\n",
      "|    value_loss         | 0.173       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 147         |\n",
      "|    total_timesteps    | 47824896    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029297244 |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.101      |\n",
      "|    mean_step_reward   | 0.03555815  |\n",
      "|    n_updates          | 52/128      |\n",
      "|    policyGradLoss     | -0.0195     |\n",
      "|    value_loss         | 0.106       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 775          |\n",
      "|    iterations         | 15           |\n",
      "|    time_elapsed       | 158          |\n",
      "|    total_timesteps    | 47833088     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.018250002  |\n",
      "|    entropy_loss       | -2.31        |\n",
      "|    explained_variance | 0.959        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0953      |\n",
      "|    mean_step_reward   | 0.0013779249 |\n",
      "|    n_updates          | 56/128       |\n",
      "|    policyGradLoss     | -0.0166      |\n",
      "|    value_loss         | 0.0975       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 169         |\n",
      "|    total_timesteps    | 47841280    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015964225 |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.936       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0921     |\n",
      "|    mean_step_reward   | 0.017915111 |\n",
      "|    n_updates          | 60/128      |\n",
      "|    policyGradLoss     | -0.0169     |\n",
      "|    value_loss         | 0.178       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 179         |\n",
      "|    total_timesteps    | 47849472    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02821717  |\n",
      "|    entropy_loss       | -2.16       |\n",
      "|    explained_variance | 0.913       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0658     |\n",
      "|    mean_step_reward   | 0.035260655 |\n",
      "|    n_updates          | 64/128      |\n",
      "|    policyGradLoss     | -0.0165     |\n",
      "|    value_loss         | 0.296       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 190         |\n",
      "|    total_timesteps    | 47857664    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02182107  |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.897       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0955     |\n",
      "|    mean_step_reward   | 0.025655469 |\n",
      "|    n_updates          | 68/128      |\n",
      "|    policyGradLoss     | -0.0187     |\n",
      "|    value_loss         | 0.209       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 201         |\n",
      "|    total_timesteps    | 47865856    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02034128  |\n",
      "|    entropy_loss       | -2.29       |\n",
      "|    explained_variance | 0.93        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.112      |\n",
      "|    mean_step_reward   | 0.021477632 |\n",
      "|    n_updates          | 72/128      |\n",
      "|    policyGradLoss     | -0.0223     |\n",
      "|    value_loss         | 0.11        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 772          |\n",
      "|    iterations         | 20           |\n",
      "|    time_elapsed       | 212          |\n",
      "|    total_timesteps    | 47874048     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0140153095 |\n",
      "|    entropy_loss       | -2.25        |\n",
      "|    explained_variance | 0.905        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0644      |\n",
      "|    mean_step_reward   | 0.029467184  |\n",
      "|    n_updates          | 76/128       |\n",
      "|    policyGradLoss     | -0.013       |\n",
      "|    value_loss         | 0.165        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 222         |\n",
      "|    total_timesteps    | 47882240    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023439154 |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.946       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0895     |\n",
      "|    mean_step_reward   | 0.02437103  |\n",
      "|    n_updates          | 80/128      |\n",
      "|    policyGradLoss     | -0.0178     |\n",
      "|    value_loss         | 0.176       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 233         |\n",
      "|    total_timesteps    | 47890432    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015157409 |\n",
      "|    entropy_loss       | -2.27       |\n",
      "|    explained_variance | 0.923       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0929     |\n",
      "|    mean_step_reward   | 0.015873274 |\n",
      "|    n_updates          | 84/128      |\n",
      "|    policyGradLoss     | -0.0169     |\n",
      "|    value_loss         | 0.168       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 244         |\n",
      "|    total_timesteps    | 47898624    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014752081 |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.75        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0289     |\n",
      "|    mean_step_reward   | 0.019038267 |\n",
      "|    n_updates          | 88/128      |\n",
      "|    policyGradLoss     | -0.0109     |\n",
      "|    value_loss         | 0.53        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 255         |\n",
      "|    total_timesteps    | 47906816    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020539477 |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.944       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.106      |\n",
      "|    mean_step_reward   | 0.024220655 |\n",
      "|    n_updates          | 92/128      |\n",
      "|    policyGradLoss     | -0.021      |\n",
      "|    value_loss         | 0.131       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 265         |\n",
      "|    total_timesteps    | 47915008    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019116884 |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.898       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0897     |\n",
      "|    mean_step_reward   | 0.033893652 |\n",
      "|    n_updates          | 96/128      |\n",
      "|    policyGradLoss     | -0.0134     |\n",
      "|    value_loss         | 0.288       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 276         |\n",
      "|    total_timesteps    | 47923200    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020844243 |\n",
      "|    entropy_loss       | -2.29       |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0892     |\n",
      "|    mean_step_reward   | 0.009299178 |\n",
      "|    n_updates          | 100/128     |\n",
      "|    policyGradLoss     | -0.0177     |\n",
      "|    value_loss         | 0.128       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 287         |\n",
      "|    total_timesteps    | 47931392    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01855322  |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.88        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0915     |\n",
      "|    mean_step_reward   | 0.018781595 |\n",
      "|    n_updates          | 104/128     |\n",
      "|    policyGradLoss     | -0.0163     |\n",
      "|    value_loss         | 0.228       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 298         |\n",
      "|    total_timesteps    | 47939584    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028140446 |\n",
      "|    entropy_loss       | -2.28       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.109      |\n",
      "|    mean_step_reward   | 0.025045868 |\n",
      "|    n_updates          | 108/128     |\n",
      "|    policyGradLoss     | -0.0195     |\n",
      "|    value_loss         | 0.0817      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 308         |\n",
      "|    total_timesteps    | 47947776    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016815074 |\n",
      "|    entropy_loss       | -2.34       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0918     |\n",
      "|    mean_step_reward   | 0.009234259 |\n",
      "|    n_updates          | 112/128     |\n",
      "|    policyGradLoss     | -0.015      |\n",
      "|    value_loss         | 0.0621      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 319         |\n",
      "|    total_timesteps    | 47955968    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021233719 |\n",
      "|    entropy_loss       | -2.31       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.114      |\n",
      "|    mean_step_reward   | 0.019175034 |\n",
      "|    n_updates          | 116/128     |\n",
      "|    policyGradLoss     | -0.0183     |\n",
      "|    value_loss         | 0.0664      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 330         |\n",
      "|    total_timesteps    | 47964160    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016030317 |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.844       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0346     |\n",
      "|    mean_step_reward   | 0.004204266 |\n",
      "|    n_updates          | 120/128     |\n",
      "|    policyGradLoss     | -0.0107     |\n",
      "|    value_loss         | 0.404       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 341         |\n",
      "|    total_timesteps    | 47972352    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025094632 |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.938       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0999     |\n",
      "|    mean_step_reward   | 0.03268707  |\n",
      "|    n_updates          | 124/128     |\n",
      "|    policyGradLoss     | -0.0155     |\n",
      "|    value_loss         | 0.124       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/NoArti_182.zip\n",
      "[EVAL] Mean Return: 136.819, Best Return: 139.219\n",
      "Saved video to ./runs_smw/videos/NoArti/NoArti_182_136.82.mp4\n",
      "\n",
      "=== Round 184 | Learn 262144 steps (Total trained: 47972352) ===\n",
      "Logging to ./runs_smw/tb/NoArti_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1068     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 47980544 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 866         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 47988736    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023304807 |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.908       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0849     |\n",
      "|    mean_step_reward   | 0.020475084 |\n",
      "|    n_updates          | 4/128       |\n",
      "|    policyGradLoss     | -0.0173     |\n",
      "|    value_loss         | 0.142       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 830         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 29          |\n",
      "|    total_timesteps    | 47996928    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021935176 |\n",
      "|    entropy_loss       | -2.28       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.106      |\n",
      "|    mean_step_reward   | 0.019490622 |\n",
      "|    n_updates          | 8/128       |\n",
      "|    policyGradLoss     | -0.0197     |\n",
      "|    value_loss         | 0.0695      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 815         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 40          |\n",
      "|    total_timesteps    | 48005120    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02672318  |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.949       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0605     |\n",
      "|    mean_step_reward   | 0.027954882 |\n",
      "|    n_updates          | 12/128      |\n",
      "|    policyGradLoss     | -0.0176     |\n",
      "|    value_loss         | 0.148       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 803         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 50          |\n",
      "|    total_timesteps    | 48013312    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020020975 |\n",
      "|    entropy_loss       | -2.16       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0835     |\n",
      "|    mean_step_reward   | 0.030508578 |\n",
      "|    n_updates          | 16/128      |\n",
      "|    policyGradLoss     | -0.0194     |\n",
      "|    value_loss         | 0.171       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 799        |\n",
      "|    iterations         | 6          |\n",
      "|    time_elapsed       | 61         |\n",
      "|    total_timesteps    | 48021504   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02785441 |\n",
      "|    entropy_loss       | -2.16      |\n",
      "|    explained_variance | 0.985      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.104     |\n",
      "|    mean_step_reward   | 0.04408838 |\n",
      "|    n_updates          | 20/128     |\n",
      "|    policyGradLoss     | -0.0251    |\n",
      "|    value_loss         | 0.082      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 794         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 72          |\n",
      "|    total_timesteps    | 48029696    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027387677 |\n",
      "|    entropy_loss       | -2.29       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.113      |\n",
      "|    mean_step_reward   | 0.027380401 |\n",
      "|    n_updates          | 24/128      |\n",
      "|    policyGradLoss     | -0.0188     |\n",
      "|    value_loss         | 0.0598      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 792         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 82          |\n",
      "|    total_timesteps    | 48037888    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015664335 |\n",
      "|    entropy_loss       | -2.33       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.104      |\n",
      "|    mean_step_reward   | 0.01148478  |\n",
      "|    n_updates          | 28/128      |\n",
      "|    policyGradLoss     | -0.0162     |\n",
      "|    value_loss         | 0.0633      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 789         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 93          |\n",
      "|    total_timesteps    | 48046080    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023804545 |\n",
      "|    entropy_loss       | -2.33       |\n",
      "|    explained_variance | 0.913       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.104      |\n",
      "|    mean_step_reward   | 0.012185698 |\n",
      "|    n_updates          | 32/128      |\n",
      "|    policyGradLoss     | -0.0131     |\n",
      "|    value_loss         | 0.0902      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 785          |\n",
      "|    iterations         | 10           |\n",
      "|    time_elapsed       | 104          |\n",
      "|    total_timesteps    | 48054272     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.016649961  |\n",
      "|    entropy_loss       | -2.34        |\n",
      "|    explained_variance | 0.877        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.104       |\n",
      "|    mean_step_reward   | 0.0054679383 |\n",
      "|    n_updates          | 36/128       |\n",
      "|    policyGradLoss     | -0.0143      |\n",
      "|    value_loss         | 0.0958       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 114         |\n",
      "|    total_timesteps    | 48062464    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025519865 |\n",
      "|    entropy_loss       | -2.27       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.105      |\n",
      "|    mean_step_reward   | 0.018463962 |\n",
      "|    n_updates          | 40/128      |\n",
      "|    policyGradLoss     | -0.0198     |\n",
      "|    value_loss         | 0.056       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 782          |\n",
      "|    iterations         | 12           |\n",
      "|    time_elapsed       | 125          |\n",
      "|    total_timesteps    | 48070656     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0114033045 |\n",
      "|    entropy_loss       | -2.22        |\n",
      "|    explained_variance | 0.96         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0873      |\n",
      "|    mean_step_reward   | 0.018427651  |\n",
      "|    n_updates          | 44/128       |\n",
      "|    policyGradLoss     | -0.0167      |\n",
      "|    value_loss         | 0.154        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 136         |\n",
      "|    total_timesteps    | 48078848    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027367081 |\n",
      "|    entropy_loss       | -2.19       |\n",
      "|    explained_variance | 0.941       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0243     |\n",
      "|    mean_step_reward   | 0.03203322  |\n",
      "|    n_updates          | 48/128      |\n",
      "|    policyGradLoss     | -0.0178     |\n",
      "|    value_loss         | 0.248       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 146         |\n",
      "|    total_timesteps    | 48087040    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021341901 |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0991     |\n",
      "|    mean_step_reward   | 0.040192068 |\n",
      "|    n_updates          | 52/128      |\n",
      "|    policyGradLoss     | -0.0184     |\n",
      "|    value_loss         | 0.0943      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 157         |\n",
      "|    total_timesteps    | 48095232    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026143983 |\n",
      "|    entropy_loss       | -2.36       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.123      |\n",
      "|    mean_step_reward   | 0.01002821  |\n",
      "|    n_updates          | 56/128      |\n",
      "|    policyGradLoss     | -0.0183     |\n",
      "|    value_loss         | 0.0125      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 168         |\n",
      "|    total_timesteps    | 48103424    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.0193657   |\n",
      "|    entropy_loss       | -2.32       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.105      |\n",
      "|    mean_step_reward   | 0.010780973 |\n",
      "|    n_updates          | 60/128      |\n",
      "|    policyGradLoss     | -0.0163     |\n",
      "|    value_loss         | 0.0504      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 179         |\n",
      "|    total_timesteps    | 48111616    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016245672 |\n",
      "|    entropy_loss       | -2.17       |\n",
      "|    explained_variance | 0.86        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0284     |\n",
      "|    mean_step_reward   | 0.024379237 |\n",
      "|    n_updates          | 64/128      |\n",
      "|    policyGradLoss     | -0.00648    |\n",
      "|    value_loss         | 0.356       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 774        |\n",
      "|    iterations         | 18         |\n",
      "|    time_elapsed       | 190        |\n",
      "|    total_timesteps    | 48119808   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02184305 |\n",
      "|    entropy_loss       | -2.08      |\n",
      "|    explained_variance | 0.923      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0611    |\n",
      "|    mean_step_reward   | 0.05864532 |\n",
      "|    n_updates          | 68/128     |\n",
      "|    policyGradLoss     | -0.0135    |\n",
      "|    value_loss         | 0.297      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 201         |\n",
      "|    total_timesteps    | 48128000    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024997834 |\n",
      "|    entropy_loss       | -2.14       |\n",
      "|    explained_variance | 0.937       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0239      |\n",
      "|    mean_step_reward   | 0.03372169  |\n",
      "|    n_updates          | 72/128      |\n",
      "|    policyGradLoss     | -0.0146     |\n",
      "|    value_loss         | 0.323       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 773        |\n",
      "|    iterations         | 20         |\n",
      "|    time_elapsed       | 211        |\n",
      "|    total_timesteps    | 48136192   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01829658 |\n",
      "|    entropy_loss       | -2.16      |\n",
      "|    explained_variance | 0.895      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0529    |\n",
      "|    mean_step_reward   | 0.03852258 |\n",
      "|    n_updates          | 76/128     |\n",
      "|    policyGradLoss     | -0.0136    |\n",
      "|    value_loss         | 0.403      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 772        |\n",
      "|    iterations         | 21         |\n",
      "|    time_elapsed       | 222        |\n",
      "|    total_timesteps    | 48144384   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03239315 |\n",
      "|    entropy_loss       | -2.17      |\n",
      "|    explained_variance | 0.964      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0794    |\n",
      "|    mean_step_reward   | 0.03995631 |\n",
      "|    n_updates          | 80/128     |\n",
      "|    policyGradLoss     | -0.0202    |\n",
      "|    value_loss         | 0.124      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 233         |\n",
      "|    total_timesteps    | 48152576    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021894248 |\n",
      "|    entropy_loss       | -2.2        |\n",
      "|    explained_variance | 0.871       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.039      |\n",
      "|    mean_step_reward   | 0.029561132 |\n",
      "|    n_updates          | 84/128      |\n",
      "|    policyGradLoss     | -0.0144     |\n",
      "|    value_loss         | 0.415       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 773        |\n",
      "|    iterations         | 23         |\n",
      "|    time_elapsed       | 243        |\n",
      "|    total_timesteps    | 48160768   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02080391 |\n",
      "|    entropy_loss       | -2.01      |\n",
      "|    explained_variance | 0.919      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.0382     |\n",
      "|    mean_step_reward   | 0.05582173 |\n",
      "|    n_updates          | 88/128     |\n",
      "|    policyGradLoss     | -0.0128    |\n",
      "|    value_loss         | 0.346      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 254         |\n",
      "|    total_timesteps    | 48168960    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021989036 |\n",
      "|    entropy_loss       | -2.03       |\n",
      "|    explained_variance | 0.954       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0675     |\n",
      "|    mean_step_reward   | 0.09045073  |\n",
      "|    n_updates          | 92/128      |\n",
      "|    policyGradLoss     | -0.0157     |\n",
      "|    value_loss         | 0.282       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 264         |\n",
      "|    total_timesteps    | 48177152    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020188307 |\n",
      "|    entropy_loss       | -2.16       |\n",
      "|    explained_variance | 0.805       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0375     |\n",
      "|    mean_step_reward   | 0.03721603  |\n",
      "|    n_updates          | 96/128      |\n",
      "|    policyGradLoss     | -0.00953    |\n",
      "|    value_loss         | 0.382       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 772        |\n",
      "|    iterations         | 26         |\n",
      "|    time_elapsed       | 275        |\n",
      "|    total_timesteps    | 48185344   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01765645 |\n",
      "|    entropy_loss       | -2.14      |\n",
      "|    explained_variance | 0.906      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0348    |\n",
      "|    mean_step_reward   | 0.05000463 |\n",
      "|    n_updates          | 100/128    |\n",
      "|    policyGradLoss     | -0.0116    |\n",
      "|    value_loss         | 0.392      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 771        |\n",
      "|    iterations         | 27         |\n",
      "|    time_elapsed       | 286        |\n",
      "|    total_timesteps    | 48193536   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02474935 |\n",
      "|    entropy_loss       | -2.12      |\n",
      "|    explained_variance | 0.952      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0888    |\n",
      "|    mean_step_reward   | 0.05014938 |\n",
      "|    n_updates          | 104/128    |\n",
      "|    policyGradLoss     | -0.0202    |\n",
      "|    value_loss         | 0.193      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 297         |\n",
      "|    total_timesteps    | 48201728    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017450519 |\n",
      "|    entropy_loss       | -2.15       |\n",
      "|    explained_variance | 0.914       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0475     |\n",
      "|    mean_step_reward   | 0.042505972 |\n",
      "|    n_updates          | 108/128     |\n",
      "|    policyGradLoss     | -0.0153     |\n",
      "|    value_loss         | 0.261       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 308         |\n",
      "|    total_timesteps    | 48209920    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013416526 |\n",
      "|    entropy_loss       | -2.18       |\n",
      "|    explained_variance | 0.925       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0725     |\n",
      "|    mean_step_reward   | 0.048392978 |\n",
      "|    n_updates          | 112/128     |\n",
      "|    policyGradLoss     | -0.0126     |\n",
      "|    value_loss         | 0.285       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 319         |\n",
      "|    total_timesteps    | 48218112    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019163385 |\n",
      "|    entropy_loss       | -2.17       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.088      |\n",
      "|    mean_step_reward   | 0.04455315  |\n",
      "|    n_updates          | 116/128     |\n",
      "|    policyGradLoss     | -0.017      |\n",
      "|    value_loss         | 0.126       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 329         |\n",
      "|    total_timesteps    | 48226304    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02229755  |\n",
      "|    entropy_loss       | -2.27       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0908     |\n",
      "|    mean_step_reward   | 0.026171539 |\n",
      "|    n_updates          | 120/128     |\n",
      "|    policyGradLoss     | -0.016      |\n",
      "|    value_loss         | 0.114       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 340         |\n",
      "|    total_timesteps    | 48234496    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02201714  |\n",
      "|    entropy_loss       | -2.37       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.12       |\n",
      "|    mean_step_reward   | 0.009107279 |\n",
      "|    n_updates          | 124/128     |\n",
      "|    policyGradLoss     | -0.0227     |\n",
      "|    value_loss         | 0.0224      |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/NoArti_183.zip\n",
      "[EVAL] Mean Return: 61.772, Best Return: 63.572\n",
      "Saved video to ./runs_smw/videos/NoArti/NoArti_183_61.77.mp4\n",
      "\n",
      "=== Round 185 | Learn 262144 steps (Total trained: 48234496) ===\n",
      "Logging to ./runs_smw/tb/NoArti_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1102     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 48242688 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 909         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 48250880    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018614765 |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.104      |\n",
      "|    mean_step_reward   | 0.03108739  |\n",
      "|    n_updates          | 4/128       |\n",
      "|    policyGradLoss     | -0.0184     |\n",
      "|    value_loss         | 0.0758      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 856         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 48259072    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029409006 |\n",
      "|    entropy_loss       | -2.29       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.118      |\n",
      "|    mean_step_reward   | 0.013849704 |\n",
      "|    n_updates          | 8/128       |\n",
      "|    policyGradLoss     | -0.0259     |\n",
      "|    value_loss         | 0.0432      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 821         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 48267264    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016753098 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.945       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0925     |\n",
      "|    mean_step_reward   | 0.0160572   |\n",
      "|    n_updates          | 12/128      |\n",
      "|    policyGradLoss     | -0.0183     |\n",
      "|    value_loss         | 0.146       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 806         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 50          |\n",
      "|    total_timesteps    | 48275456    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019215481 |\n",
      "|    entropy_loss       | -2.18       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0883     |\n",
      "|    mean_step_reward   | 0.0470162   |\n",
      "|    n_updates          | 16/128      |\n",
      "|    policyGradLoss     | -0.0177     |\n",
      "|    value_loss         | 0.153       |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 793       |\n",
      "|    iterations         | 6         |\n",
      "|    time_elapsed       | 61        |\n",
      "|    total_timesteps    | 48283648  |\n",
      "| train/                |           |\n",
      "|    approx_kl          | 0.0171678 |\n",
      "|    entropy_loss       | -2.24     |\n",
      "|    explained_variance | 0.937     |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    loss               | -0.0436   |\n",
      "|    mean_step_reward   | 0.0299215 |\n",
      "|    n_updates          | 20/128    |\n",
      "|    policyGradLoss     | -0.0154   |\n",
      "|    value_loss         | 0.215     |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 72          |\n",
      "|    total_timesteps    | 48291840    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019612728 |\n",
      "|    entropy_loss       | -2.2        |\n",
      "|    explained_variance | 0.888       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0207     |\n",
      "|    mean_step_reward   | 0.02265207  |\n",
      "|    n_updates          | 24/128      |\n",
      "|    policyGradLoss     | -0.015      |\n",
      "|    value_loss         | 0.404       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 83          |\n",
      "|    total_timesteps    | 48300032    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020987812 |\n",
      "|    entropy_loss       | -2.13       |\n",
      "|    explained_variance | 0.919       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0542     |\n",
      "|    mean_step_reward   | 0.03622363  |\n",
      "|    n_updates          | 28/128      |\n",
      "|    policyGradLoss     | -0.0159     |\n",
      "|    value_loss         | 0.344       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 94          |\n",
      "|    total_timesteps    | 48308224    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021843385 |\n",
      "|    entropy_loss       | -2.15       |\n",
      "|    explained_variance | 0.902       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0305     |\n",
      "|    mean_step_reward   | 0.038099483 |\n",
      "|    n_updates          | 32/128      |\n",
      "|    policyGradLoss     | -0.0156     |\n",
      "|    value_loss         | 0.26        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 105         |\n",
      "|    total_timesteps    | 48316416    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019462615 |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0581     |\n",
      "|    mean_step_reward   | 0.02400465  |\n",
      "|    n_updates          | 36/128      |\n",
      "|    policyGradLoss     | -0.0194     |\n",
      "|    value_loss         | 0.176       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 116         |\n",
      "|    total_timesteps    | 48324608    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022937702 |\n",
      "|    entropy_loss       | -2.19       |\n",
      "|    explained_variance | 0.902       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0234     |\n",
      "|    mean_step_reward   | 0.028910644 |\n",
      "|    n_updates          | 40/128      |\n",
      "|    policyGradLoss     | -0.0165     |\n",
      "|    value_loss         | 0.358       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 127         |\n",
      "|    total_timesteps    | 48332800    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02685704  |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0988     |\n",
      "|    mean_step_reward   | 0.035893805 |\n",
      "|    n_updates          | 44/128      |\n",
      "|    policyGradLoss     | -0.0229     |\n",
      "|    value_loss         | 0.0642      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 137         |\n",
      "|    total_timesteps    | 48340992    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019610088 |\n",
      "|    entropy_loss       | -2.31       |\n",
      "|    explained_variance | 0.914       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0949     |\n",
      "|    mean_step_reward   | 0.016403573 |\n",
      "|    n_updates          | 48/128      |\n",
      "|    policyGradLoss     | -0.0129     |\n",
      "|    value_loss         | 0.162       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 148         |\n",
      "|    total_timesteps    | 48349184    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017485626 |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.888       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.000223    |\n",
      "|    mean_step_reward   | 0.01843981  |\n",
      "|    n_updates          | 52/128      |\n",
      "|    policyGradLoss     | -0.0154     |\n",
      "|    value_loss         | 0.384       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 159         |\n",
      "|    total_timesteps    | 48357376    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020817962 |\n",
      "|    entropy_loss       | -2.19       |\n",
      "|    explained_variance | 0.95        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.107      |\n",
      "|    mean_step_reward   | 0.029752739 |\n",
      "|    n_updates          | 56/128      |\n",
      "|    policyGradLoss     | -0.0195     |\n",
      "|    value_loss         | 0.109       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 170         |\n",
      "|    total_timesteps    | 48365568    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021821748 |\n",
      "|    entropy_loss       | -2.16       |\n",
      "|    explained_variance | 0.867       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0557     |\n",
      "|    mean_step_reward   | 0.03175678  |\n",
      "|    n_updates          | 60/128      |\n",
      "|    policyGradLoss     | -0.0128     |\n",
      "|    value_loss         | 0.569       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 180         |\n",
      "|    total_timesteps    | 48373760    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023663215 |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.947       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0862     |\n",
      "|    mean_step_reward   | 0.035921164 |\n",
      "|    n_updates          | 64/128      |\n",
      "|    policyGradLoss     | -0.021      |\n",
      "|    value_loss         | 0.176       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 191         |\n",
      "|    total_timesteps    | 48381952    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023012709 |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.943       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.013      |\n",
      "|    mean_step_reward   | 0.031800024 |\n",
      "|    n_updates          | 68/128      |\n",
      "|    policyGradLoss     | -0.017      |\n",
      "|    value_loss         | 0.266       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 202         |\n",
      "|    total_timesteps    | 48390144    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021412125 |\n",
      "|    entropy_loss       | -2.2        |\n",
      "|    explained_variance | 0.921       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0853     |\n",
      "|    mean_step_reward   | 0.033336792 |\n",
      "|    n_updates          | 72/128      |\n",
      "|    policyGradLoss     | -0.0178     |\n",
      "|    value_loss         | 0.134       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 212         |\n",
      "|    total_timesteps    | 48398336    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011522345 |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.95        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0953     |\n",
      "|    mean_step_reward   | 0.026221927 |\n",
      "|    n_updates          | 76/128      |\n",
      "|    policyGradLoss     | -0.0167     |\n",
      "|    value_loss         | 0.162       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 223         |\n",
      "|    total_timesteps    | 48406528    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026248354 |\n",
      "|    entropy_loss       | -2.18       |\n",
      "|    explained_variance | 0.942       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0893     |\n",
      "|    mean_step_reward   | 0.029243428 |\n",
      "|    n_updates          | 80/128      |\n",
      "|    policyGradLoss     | -0.019      |\n",
      "|    value_loss         | 0.168       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 234         |\n",
      "|    total_timesteps    | 48414720    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024680804 |\n",
      "|    entropy_loss       | -2.2        |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0959     |\n",
      "|    mean_step_reward   | 0.04797168  |\n",
      "|    n_updates          | 84/128      |\n",
      "|    policyGradLoss     | -0.0215     |\n",
      "|    value_loss         | 0.081       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 245         |\n",
      "|    total_timesteps    | 48422912    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02317899  |\n",
      "|    entropy_loss       | -2.19       |\n",
      "|    explained_variance | 0.925       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.104      |\n",
      "|    mean_step_reward   | 0.030324265 |\n",
      "|    n_updates          | 88/128      |\n",
      "|    policyGradLoss     | -0.0144     |\n",
      "|    value_loss         | 0.158       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 255         |\n",
      "|    total_timesteps    | 48431104    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023825908 |\n",
      "|    entropy_loss       | -2.17       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0836     |\n",
      "|    mean_step_reward   | 0.040465847 |\n",
      "|    n_updates          | 92/128      |\n",
      "|    policyGradLoss     | -0.016      |\n",
      "|    value_loss         | 0.171       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 266         |\n",
      "|    total_timesteps    | 48439296    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024665201 |\n",
      "|    entropy_loss       | -2.11       |\n",
      "|    explained_variance | 0.957       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0506     |\n",
      "|    mean_step_reward   | 0.05557808  |\n",
      "|    n_updates          | 96/128      |\n",
      "|    policyGradLoss     | -0.0176     |\n",
      "|    value_loss         | 0.239       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 277         |\n",
      "|    total_timesteps    | 48447488    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023547292 |\n",
      "|    entropy_loss       | -2.13       |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.041      |\n",
      "|    mean_step_reward   | 0.04943622  |\n",
      "|    n_updates          | 100/128     |\n",
      "|    policyGradLoss     | -0.0166     |\n",
      "|    value_loss         | 0.295       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 288         |\n",
      "|    total_timesteps    | 48455680    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013922158 |\n",
      "|    entropy_loss       | -2.14       |\n",
      "|    explained_variance | 0.868       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0236     |\n",
      "|    mean_step_reward   | 0.042867593 |\n",
      "|    n_updates          | 104/128     |\n",
      "|    policyGradLoss     | -0.0168     |\n",
      "|    value_loss         | 0.388       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 299         |\n",
      "|    total_timesteps    | 48463872    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021309698 |\n",
      "|    entropy_loss       | -2.1        |\n",
      "|    explained_variance | 0.923       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0878     |\n",
      "|    mean_step_reward   | 0.05455108  |\n",
      "|    n_updates          | 108/128     |\n",
      "|    policyGradLoss     | -0.0137     |\n",
      "|    value_loss         | 0.253       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 309         |\n",
      "|    total_timesteps    | 48472064    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02398709  |\n",
      "|    entropy_loss       | -2.17       |\n",
      "|    explained_variance | 0.924       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0669     |\n",
      "|    mean_step_reward   | 0.033145748 |\n",
      "|    n_updates          | 112/128     |\n",
      "|    policyGradLoss     | -0.0185     |\n",
      "|    value_loss         | 0.297       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 320         |\n",
      "|    total_timesteps    | 48480256    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020498633 |\n",
      "|    entropy_loss       | -2.11       |\n",
      "|    explained_variance | 0.92        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0628     |\n",
      "|    mean_step_reward   | 0.047475487 |\n",
      "|    n_updates          | 116/128     |\n",
      "|    policyGradLoss     | -0.0162     |\n",
      "|    value_loss         | 0.254       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 331         |\n",
      "|    total_timesteps    | 48488448    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017929167 |\n",
      "|    entropy_loss       | -2.07       |\n",
      "|    explained_variance | 0.924       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0232      |\n",
      "|    mean_step_reward   | 0.05922183  |\n",
      "|    n_updates          | 120/128     |\n",
      "|    policyGradLoss     | -0.0134     |\n",
      "|    value_loss         | 0.539       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 341         |\n",
      "|    total_timesteps    | 48496640    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01978039  |\n",
      "|    entropy_loss       | -2.1        |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0342     |\n",
      "|    mean_step_reward   | 0.066105254 |\n",
      "|    n_updates          | 124/128     |\n",
      "|    policyGradLoss     | -0.019      |\n",
      "|    value_loss         | 0.178       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/NoArti_184.zip\n",
      "[EVAL] Mean Return: -9.905, Best Return: -9.905\n",
      "Saved video to ./runs_smw/videos/NoArti/NoArti_184_-9.91.mp4\n",
      "\n",
      "=== Round 186 | Learn 262144 steps (Total trained: 48496640) ===\n",
      "Logging to ./runs_smw/tb/NoArti_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1109     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 48504832 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 885         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 48513024    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021749636 |\n",
      "|    entropy_loss       | -2.27       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0984     |\n",
      "|    mean_step_reward   | 0.029359695 |\n",
      "|    n_updates          | 4/128       |\n",
      "|    policyGradLoss     | -0.0194     |\n",
      "|    value_loss         | 0.0536      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 835         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 29          |\n",
      "|    total_timesteps    | 48521216    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01933532  |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.832       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0335     |\n",
      "|    mean_step_reward   | 0.023478955 |\n",
      "|    n_updates          | 8/128       |\n",
      "|    policyGradLoss     | -0.0116     |\n",
      "|    value_loss         | 0.314       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 816         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 40          |\n",
      "|    total_timesteps    | 48529408    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022501769 |\n",
      "|    entropy_loss       | -2.07       |\n",
      "|    explained_variance | 0.912       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00545     |\n",
      "|    mean_step_reward   | 0.046022475 |\n",
      "|    n_updates          | 12/128      |\n",
      "|    policyGradLoss     | -0.0149     |\n",
      "|    value_loss         | 0.301       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 800         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 51          |\n",
      "|    total_timesteps    | 48537600    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020709466 |\n",
      "|    entropy_loss       | -2.15       |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0728     |\n",
      "|    mean_step_reward   | 0.052501306 |\n",
      "|    n_updates          | 16/128      |\n",
      "|    policyGradLoss     | -0.0203     |\n",
      "|    value_loss         | 0.199       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 796        |\n",
      "|    iterations         | 6          |\n",
      "|    time_elapsed       | 61         |\n",
      "|    total_timesteps    | 48545792   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02558531 |\n",
      "|    entropy_loss       | -2.2       |\n",
      "|    explained_variance | 0.926      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0449    |\n",
      "|    mean_step_reward   | 0.02932666 |\n",
      "|    n_updates          | 20/128     |\n",
      "|    policyGradLoss     | -0.0153    |\n",
      "|    value_loss         | 0.276      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 791         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 72          |\n",
      "|    total_timesteps    | 48553984    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022315478 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.923       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0816     |\n",
      "|    mean_step_reward   | 0.027681638 |\n",
      "|    n_updates          | 24/128      |\n",
      "|    policyGradLoss     | -0.0154     |\n",
      "|    value_loss         | 0.171       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 83          |\n",
      "|    total_timesteps    | 48562176    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027880754 |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0728     |\n",
      "|    mean_step_reward   | 0.03375788  |\n",
      "|    n_updates          | 28/128      |\n",
      "|    policyGradLoss     | -0.0216     |\n",
      "|    value_loss         | 0.117       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 94          |\n",
      "|    total_timesteps    | 48570368    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021169078 |\n",
      "|    entropy_loss       | -2.17       |\n",
      "|    explained_variance | 0.926       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.077      |\n",
      "|    mean_step_reward   | 0.030303804 |\n",
      "|    n_updates          | 32/128      |\n",
      "|    policyGradLoss     | -0.0182     |\n",
      "|    value_loss         | 0.297       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 105         |\n",
      "|    total_timesteps    | 48578560    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026049308 |\n",
      "|    entropy_loss       | -2.09       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0814     |\n",
      "|    mean_step_reward   | 0.04424587  |\n",
      "|    n_updates          | 36/128      |\n",
      "|    policyGradLoss     | -0.0261     |\n",
      "|    value_loss         | 0.114       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 115         |\n",
      "|    total_timesteps    | 48586752    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021435767 |\n",
      "|    entropy_loss       | -2.11       |\n",
      "|    explained_variance | 0.877       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0021     |\n",
      "|    mean_step_reward   | 0.05645279  |\n",
      "|    n_updates          | 40/128      |\n",
      "|    policyGradLoss     | -0.0135     |\n",
      "|    value_loss         | 0.472       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 126         |\n",
      "|    total_timesteps    | 48594944    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015355604 |\n",
      "|    entropy_loss       | -2.15       |\n",
      "|    explained_variance | 0.916       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0393     |\n",
      "|    mean_step_reward   | 0.046195425 |\n",
      "|    n_updates          | 44/128      |\n",
      "|    policyGradLoss     | -0.0129     |\n",
      "|    value_loss         | 0.337       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 136         |\n",
      "|    total_timesteps    | 48603136    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02578628  |\n",
      "|    entropy_loss       | -2.11       |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0947     |\n",
      "|    mean_step_reward   | 0.057162262 |\n",
      "|    n_updates          | 48/128      |\n",
      "|    policyGradLoss     | -0.0151     |\n",
      "|    value_loss         | 0.139       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 147         |\n",
      "|    total_timesteps    | 48611328    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023764856 |\n",
      "|    entropy_loss       | -2.2        |\n",
      "|    explained_variance | 0.958       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0402     |\n",
      "|    mean_step_reward   | 0.043491255 |\n",
      "|    n_updates          | 52/128      |\n",
      "|    policyGradLoss     | -0.0137     |\n",
      "|    value_loss         | 0.27        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 158         |\n",
      "|    total_timesteps    | 48619520    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023850366 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.94        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0697     |\n",
      "|    mean_step_reward   | 0.01948153  |\n",
      "|    n_updates          | 56/128      |\n",
      "|    policyGradLoss     | -0.014      |\n",
      "|    value_loss         | 0.158       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 169         |\n",
      "|    total_timesteps    | 48627712    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018492226 |\n",
      "|    entropy_loss       | -2.18       |\n",
      "|    explained_variance | 0.915       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0553     |\n",
      "|    mean_step_reward   | 0.045465622 |\n",
      "|    n_updates          | 60/128      |\n",
      "|    policyGradLoss     | -0.0084     |\n",
      "|    value_loss         | 0.257       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 180         |\n",
      "|    total_timesteps    | 48635904    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018828062 |\n",
      "|    entropy_loss       | -2.12       |\n",
      "|    explained_variance | 0.852       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0721     |\n",
      "|    mean_step_reward   | 0.030872468 |\n",
      "|    n_updates          | 64/128      |\n",
      "|    policyGradLoss     | -0.0176     |\n",
      "|    value_loss         | 0.335       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 190         |\n",
      "|    total_timesteps    | 48644096    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030486334 |\n",
      "|    entropy_loss       | -2.04       |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.08       |\n",
      "|    mean_step_reward   | 0.06488812  |\n",
      "|    n_updates          | 68/128      |\n",
      "|    policyGradLoss     | -0.024      |\n",
      "|    value_loss         | 0.19        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 201         |\n",
      "|    total_timesteps    | 48652288    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016951833 |\n",
      "|    entropy_loss       | -2.13       |\n",
      "|    explained_variance | 0.939       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.023      |\n",
      "|    mean_step_reward   | 0.043171737 |\n",
      "|    n_updates          | 72/128      |\n",
      "|    policyGradLoss     | -0.0131     |\n",
      "|    value_loss         | 0.375       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 211         |\n",
      "|    total_timesteps    | 48660480    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026211549 |\n",
      "|    entropy_loss       | -2.14       |\n",
      "|    explained_variance | 0.942       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0859     |\n",
      "|    mean_step_reward   | 0.04245624  |\n",
      "|    n_updates          | 76/128      |\n",
      "|    policyGradLoss     | -0.0195     |\n",
      "|    value_loss         | 0.198       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 222         |\n",
      "|    total_timesteps    | 48668672    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023587594 |\n",
      "|    entropy_loss       | -2.14       |\n",
      "|    explained_variance | 0.729       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0337     |\n",
      "|    mean_step_reward   | 0.032679833 |\n",
      "|    n_updates          | 80/128      |\n",
      "|    policyGradLoss     | -0.0117     |\n",
      "|    value_loss         | 0.525       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 233         |\n",
      "|    total_timesteps    | 48676864    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018867781 |\n",
      "|    entropy_loss       | -2.11       |\n",
      "|    explained_variance | 0.782       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0482      |\n",
      "|    mean_step_reward   | 0.039737005 |\n",
      "|    n_updates          | 84/128      |\n",
      "|    policyGradLoss     | -0.0114     |\n",
      "|    value_loss         | 0.687       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 771        |\n",
      "|    iterations         | 23         |\n",
      "|    time_elapsed       | 244        |\n",
      "|    total_timesteps    | 48685056   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02232752 |\n",
      "|    entropy_loss       | -2.2       |\n",
      "|    explained_variance | 0.961      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0934    |\n",
      "|    mean_step_reward   | 0.03784606 |\n",
      "|    n_updates          | 88/128     |\n",
      "|    policyGradLoss     | -0.0223    |\n",
      "|    value_loss         | 0.0924     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 255         |\n",
      "|    total_timesteps    | 48693248    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018308595 |\n",
      "|    entropy_loss       | -2.19       |\n",
      "|    explained_variance | 0.931       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0118     |\n",
      "|    mean_step_reward   | 0.023581266 |\n",
      "|    n_updates          | 92/128      |\n",
      "|    policyGradLoss     | -0.0117     |\n",
      "|    value_loss         | 0.333       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 265         |\n",
      "|    total_timesteps    | 48701440    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027613925 |\n",
      "|    entropy_loss       | -2.13       |\n",
      "|    explained_variance | 0.869       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0469     |\n",
      "|    mean_step_reward   | 0.041793786 |\n",
      "|    n_updates          | 96/128      |\n",
      "|    policyGradLoss     | -0.0159     |\n",
      "|    value_loss         | 0.417       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 276         |\n",
      "|    total_timesteps    | 48709632    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029291725 |\n",
      "|    entropy_loss       | -2.12       |\n",
      "|    explained_variance | 0.94        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.084      |\n",
      "|    mean_step_reward   | 0.042625558 |\n",
      "|    n_updates          | 100/128     |\n",
      "|    policyGradLoss     | -0.0217     |\n",
      "|    value_loss         | 0.198       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 287         |\n",
      "|    total_timesteps    | 48717824    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025186792 |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.958       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0926     |\n",
      "|    mean_step_reward   | 0.022410367 |\n",
      "|    n_updates          | 104/128     |\n",
      "|    policyGradLoss     | -0.0189     |\n",
      "|    value_loss         | 0.136       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 297         |\n",
      "|    total_timesteps    | 48726016    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021445602 |\n",
      "|    entropy_loss       | -2.29       |\n",
      "|    explained_variance | 0.932       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0904     |\n",
      "|    mean_step_reward   | 0.023201833 |\n",
      "|    n_updates          | 108/128     |\n",
      "|    policyGradLoss     | -0.0165     |\n",
      "|    value_loss         | 0.142       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 308         |\n",
      "|    total_timesteps    | 48734208    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02215252  |\n",
      "|    entropy_loss       | -2.3        |\n",
      "|    explained_variance | 0.955       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.114      |\n",
      "|    mean_step_reward   | 0.014343237 |\n",
      "|    n_updates          | 112/128     |\n",
      "|    policyGradLoss     | -0.0169     |\n",
      "|    value_loss         | 0.12        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 319         |\n",
      "|    total_timesteps    | 48742400    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025336834 |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.933       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.088      |\n",
      "|    mean_step_reward   | 0.012014199 |\n",
      "|    n_updates          | 116/128     |\n",
      "|    policyGradLoss     | -0.0177     |\n",
      "|    value_loss         | 0.148       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 330         |\n",
      "|    total_timesteps    | 48750592    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020643128 |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.948       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0758     |\n",
      "|    mean_step_reward   | 0.03085275  |\n",
      "|    n_updates          | 120/128     |\n",
      "|    policyGradLoss     | -0.0182     |\n",
      "|    value_loss         | 0.13        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 341         |\n",
      "|    total_timesteps    | 48758784    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023924008 |\n",
      "|    entropy_loss       | -2.18       |\n",
      "|    explained_variance | 0.955       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0634     |\n",
      "|    mean_step_reward   | 0.022198785 |\n",
      "|    n_updates          | 124/128     |\n",
      "|    policyGradLoss     | -0.0215     |\n",
      "|    value_loss         | 0.194       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/NoArti_185.zip\n",
      "[EVAL] Mean Return: 132.459, Best Return: 135.059\n",
      "Saved video to ./runs_smw/videos/NoArti/NoArti_185_132.46.mp4\n",
      "\n",
      "=== Round 187 | Learn 262144 steps (Total trained: 48758784) ===\n",
      "Logging to ./runs_smw/tb/NoArti_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1087     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 48766976 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 897         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 48775168    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018649984 |\n",
      "|    entropy_loss       | -2.14       |\n",
      "|    explained_variance | 0.872       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0523     |\n",
      "|    mean_step_reward   | 0.028347079 |\n",
      "|    n_updates          | 4/128       |\n",
      "|    policyGradLoss     | -0.0152     |\n",
      "|    value_loss         | 0.329       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 845         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 29          |\n",
      "|    total_timesteps    | 48783360    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026553676 |\n",
      "|    entropy_loss       | -2.11       |\n",
      "|    explained_variance | 0.935       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00114     |\n",
      "|    mean_step_reward   | 0.04719025  |\n",
      "|    n_updates          | 8/128       |\n",
      "|    policyGradLoss     | -0.0156     |\n",
      "|    value_loss         | 0.327       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 822         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 48791552    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028144762 |\n",
      "|    entropy_loss       | -2.18       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0944     |\n",
      "|    mean_step_reward   | 0.03376717  |\n",
      "|    n_updates          | 12/128      |\n",
      "|    policyGradLoss     | -0.0204     |\n",
      "|    value_loss         | 0.0883      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 811         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 50          |\n",
      "|    total_timesteps    | 48799744    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012384523 |\n",
      "|    entropy_loss       | -2.17       |\n",
      "|    explained_variance | 0.947       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0459     |\n",
      "|    mean_step_reward   | 0.03472031  |\n",
      "|    n_updates          | 16/128      |\n",
      "|    policyGradLoss     | -0.0153     |\n",
      "|    value_loss         | 0.293       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 806         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 60          |\n",
      "|    total_timesteps    | 48807936    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02594703  |\n",
      "|    entropy_loss       | -2.1        |\n",
      "|    explained_variance | 0.931       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0698     |\n",
      "|    mean_step_reward   | 0.050660864 |\n",
      "|    n_updates          | 20/128      |\n",
      "|    policyGradLoss     | -0.0153     |\n",
      "|    value_loss         | 0.393       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 800         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 71          |\n",
      "|    total_timesteps    | 48816128    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02443159  |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.951       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0907     |\n",
      "|    mean_step_reward   | 0.039867565 |\n",
      "|    n_updates          | 24/128      |\n",
      "|    policyGradLoss     | -0.0178     |\n",
      "|    value_loss         | 0.122       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 797         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 82          |\n",
      "|    total_timesteps    | 48824320    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018892262 |\n",
      "|    entropy_loss       | -2.28       |\n",
      "|    explained_variance | 0.907       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0792     |\n",
      "|    mean_step_reward   | 0.021343581 |\n",
      "|    n_updates          | 28/128      |\n",
      "|    policyGradLoss     | -0.00967    |\n",
      "|    value_loss         | 0.172       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 794         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 92          |\n",
      "|    total_timesteps    | 48832512    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014218144 |\n",
      "|    entropy_loss       | -2.29       |\n",
      "|    explained_variance | 0.865       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0977     |\n",
      "|    mean_step_reward   | 0.016564218 |\n",
      "|    n_updates          | 32/128      |\n",
      "|    policyGradLoss     | -0.0147     |\n",
      "|    value_loss         | 0.127       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 791         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 103         |\n",
      "|    total_timesteps    | 48840704    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018130446 |\n",
      "|    entropy_loss       | -2.27       |\n",
      "|    explained_variance | 0.883       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0764     |\n",
      "|    mean_step_reward   | 0.033104226 |\n",
      "|    n_updates          | 36/128      |\n",
      "|    policyGradLoss     | -0.0107     |\n",
      "|    value_loss         | 0.234       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 790         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 113         |\n",
      "|    total_timesteps    | 48848896    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01735945  |\n",
      "|    entropy_loss       | -2.27       |\n",
      "|    explained_variance | 0.932       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0934     |\n",
      "|    mean_step_reward   | 0.018199896 |\n",
      "|    n_updates          | 40/128      |\n",
      "|    policyGradLoss     | -0.0152     |\n",
      "|    value_loss         | 0.121       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 124         |\n",
      "|    total_timesteps    | 48857088    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017437607 |\n",
      "|    entropy_loss       | -2.27       |\n",
      "|    explained_variance | 0.866       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0925     |\n",
      "|    mean_step_reward   | 0.025976194 |\n",
      "|    n_updates          | 44/128      |\n",
      "|    policyGradLoss     | -0.013      |\n",
      "|    value_loss         | 0.298       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 135         |\n",
      "|    total_timesteps    | 48865280    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018207068 |\n",
      "|    entropy_loss       | -2.2        |\n",
      "|    explained_variance | 0.922       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0871     |\n",
      "|    mean_step_reward   | 0.024344262 |\n",
      "|    n_updates          | 48/128      |\n",
      "|    policyGradLoss     | -0.0156     |\n",
      "|    value_loss         | 0.255       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 145         |\n",
      "|    total_timesteps    | 48873472    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030656068 |\n",
      "|    entropy_loss       | -2.19       |\n",
      "|    explained_variance | 0.938       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0957     |\n",
      "|    mean_step_reward   | 0.036546152 |\n",
      "|    n_updates          | 52/128      |\n",
      "|    policyGradLoss     | -0.0174     |\n",
      "|    value_loss         | 0.148       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 156         |\n",
      "|    total_timesteps    | 48881664    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012130364 |\n",
      "|    entropy_loss       | -2.29       |\n",
      "|    explained_variance | 0.846       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0951     |\n",
      "|    mean_step_reward   | 0.027280346 |\n",
      "|    n_updates          | 56/128      |\n",
      "|    policyGradLoss     | -0.00868    |\n",
      "|    value_loss         | 0.369       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 167         |\n",
      "|    total_timesteps    | 48889856    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023882043 |\n",
      "|    entropy_loss       | -2.3        |\n",
      "|    explained_variance | 0.925       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0833     |\n",
      "|    mean_step_reward   | 0.013420373 |\n",
      "|    n_updates          | 60/128      |\n",
      "|    policyGradLoss     | -0.0177     |\n",
      "|    value_loss         | 0.096       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 178         |\n",
      "|    total_timesteps    | 48898048    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022690713 |\n",
      "|    entropy_loss       | -2.28       |\n",
      "|    explained_variance | 0.915       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.055      |\n",
      "|    mean_step_reward   | 0.023795474 |\n",
      "|    n_updates          | 64/128      |\n",
      "|    policyGradLoss     | -0.0174     |\n",
      "|    value_loss         | 0.186       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 188         |\n",
      "|    total_timesteps    | 48906240    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020154633 |\n",
      "|    entropy_loss       | -2.28       |\n",
      "|    explained_variance | 0.925       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0994     |\n",
      "|    mean_step_reward   | 0.013102454 |\n",
      "|    n_updates          | 68/128      |\n",
      "|    policyGradLoss     | -0.0188     |\n",
      "|    value_loss         | 0.123       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 780          |\n",
      "|    iterations         | 19           |\n",
      "|    time_elapsed       | 199          |\n",
      "|    total_timesteps    | 48914432     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.017365115  |\n",
      "|    entropy_loss       | -2.31        |\n",
      "|    explained_variance | 0.833        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0632      |\n",
      "|    mean_step_reward   | 0.0124965785 |\n",
      "|    n_updates          | 72/128       |\n",
      "|    policyGradLoss     | -0.0136      |\n",
      "|    value_loss         | 0.373        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 779          |\n",
      "|    iterations         | 20           |\n",
      "|    time_elapsed       | 210          |\n",
      "|    total_timesteps    | 48922624     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.019744977  |\n",
      "|    entropy_loss       | -2.34        |\n",
      "|    explained_variance | 0.881        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0897      |\n",
      "|    mean_step_reward   | 0.0050771534 |\n",
      "|    n_updates          | 76/128       |\n",
      "|    policyGradLoss     | -0.0164      |\n",
      "|    value_loss         | 0.131        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 220         |\n",
      "|    total_timesteps    | 48930816    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018517222 |\n",
      "|    entropy_loss       | -2.27       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0975     |\n",
      "|    mean_step_reward   | 0.021879848 |\n",
      "|    n_updates          | 80/128      |\n",
      "|    policyGradLoss     | -0.0163     |\n",
      "|    value_loss         | 0.104       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 231         |\n",
      "|    total_timesteps    | 48939008    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015628815 |\n",
      "|    entropy_loss       | -2.28       |\n",
      "|    explained_variance | 0.928       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0819     |\n",
      "|    mean_step_reward   | 0.019941904 |\n",
      "|    n_updates          | 84/128      |\n",
      "|    policyGradLoss     | -0.0125     |\n",
      "|    value_loss         | 0.208       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 242         |\n",
      "|    total_timesteps    | 48947200    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020159567 |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.925       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0626     |\n",
      "|    mean_step_reward   | 0.016253788 |\n",
      "|    n_updates          | 88/128      |\n",
      "|    policyGradLoss     | -0.0147     |\n",
      "|    value_loss         | 0.186       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 253         |\n",
      "|    total_timesteps    | 48955392    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018975321 |\n",
      "|    entropy_loss       | -2.18       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0926     |\n",
      "|    mean_step_reward   | 0.030180953 |\n",
      "|    n_updates          | 92/128      |\n",
      "|    policyGradLoss     | -0.0199     |\n",
      "|    value_loss         | 0.122       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 264         |\n",
      "|    total_timesteps    | 48963584    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027952846 |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0574     |\n",
      "|    mean_step_reward   | 0.041327797 |\n",
      "|    n_updates          | 96/128      |\n",
      "|    policyGradLoss     | -0.0195     |\n",
      "|    value_loss         | 0.107       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 275         |\n",
      "|    total_timesteps    | 48971776    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015803855 |\n",
      "|    entropy_loss       | -2.27       |\n",
      "|    explained_variance | 0.926       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0822     |\n",
      "|    mean_step_reward   | 0.039941143 |\n",
      "|    n_updates          | 100/128     |\n",
      "|    policyGradLoss     | -0.00904    |\n",
      "|    value_loss         | 0.204       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 286         |\n",
      "|    total_timesteps    | 48979968    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.033755615 |\n",
      "|    entropy_loss       | -2.32       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.12       |\n",
      "|    mean_step_reward   | 0.011004074 |\n",
      "|    n_updates          | 104/128     |\n",
      "|    policyGradLoss     | -0.0214     |\n",
      "|    value_loss         | 0.0234      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 297         |\n",
      "|    total_timesteps    | 48988160    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025005875 |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.933       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00529    |\n",
      "|    mean_step_reward   | 0.021670267 |\n",
      "|    n_updates          | 108/128     |\n",
      "|    policyGradLoss     | -0.0105     |\n",
      "|    value_loss         | 0.175       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 307         |\n",
      "|    total_timesteps    | 48996352    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024456361 |\n",
      "|    entropy_loss       | -2.2        |\n",
      "|    explained_variance | 0.938       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0995     |\n",
      "|    mean_step_reward   | 0.02469981  |\n",
      "|    n_updates          | 112/128     |\n",
      "|    policyGradLoss     | -0.0119     |\n",
      "|    value_loss         | 0.165       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 318         |\n",
      "|    total_timesteps    | 49004544    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020250749 |\n",
      "|    entropy_loss       | -2.16       |\n",
      "|    explained_variance | 0.93        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0682     |\n",
      "|    mean_step_reward   | 0.034525286 |\n",
      "|    n_updates          | 116/128     |\n",
      "|    policyGradLoss     | -0.0131     |\n",
      "|    value_loss         | 0.325       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 329         |\n",
      "|    total_timesteps    | 49012736    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021471027 |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.874       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0698     |\n",
      "|    mean_step_reward   | 0.02020089  |\n",
      "|    n_updates          | 120/128     |\n",
      "|    policyGradLoss     | -0.0156     |\n",
      "|    value_loss         | 0.237       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 340         |\n",
      "|    total_timesteps    | 49020928    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01791479  |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.958       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0888     |\n",
      "|    mean_step_reward   | 0.022191577 |\n",
      "|    n_updates          | 124/128     |\n",
      "|    policyGradLoss     | -0.0184     |\n",
      "|    value_loss         | 0.116       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/NoArti_186.zip\n",
      "[EVAL] Mean Return: 129.969, Best Return: 132.169\n",
      "Saved video to ./runs_smw/videos/NoArti/NoArti_186_129.97.mp4\n",
      "\n",
      "=== Round 188 | Learn 262144 steps (Total trained: 49020928) ===\n",
      "Logging to ./runs_smw/tb/NoArti_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1097     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 49029120 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 910         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 49037312    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026590962 |\n",
      "|    entropy_loss       | -2.3        |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0986     |\n",
      "|    mean_step_reward   | 0.02307842  |\n",
      "|    n_updates          | 4/128       |\n",
      "|    policyGradLoss     | -0.022      |\n",
      "|    value_loss         | 0.0493      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 850         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 49045504    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018841365 |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.938       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.104      |\n",
      "|    mean_step_reward   | 0.010230721 |\n",
      "|    n_updates          | 8/128       |\n",
      "|    policyGradLoss     | -0.0156     |\n",
      "|    value_loss         | 0.093       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 824         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 49053696    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024067137 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.101      |\n",
      "|    mean_step_reward   | 0.026547149 |\n",
      "|    n_updates          | 12/128      |\n",
      "|    policyGradLoss     | -0.021      |\n",
      "|    value_loss         | 0.102       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 815         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 50          |\n",
      "|    total_timesteps    | 49061888    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014424367 |\n",
      "|    entropy_loss       | -2.29       |\n",
      "|    explained_variance | 0.919       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0858     |\n",
      "|    mean_step_reward   | 0.015380501 |\n",
      "|    n_updates          | 16/128      |\n",
      "|    policyGradLoss     | -0.0138     |\n",
      "|    value_loss         | 0.126       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 802         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 61          |\n",
      "|    total_timesteps    | 49070080    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018860832 |\n",
      "|    entropy_loss       | -2.3        |\n",
      "|    explained_variance | 0.877       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.111      |\n",
      "|    mean_step_reward   | 0.018836416 |\n",
      "|    n_updates          | 20/128      |\n",
      "|    policyGradLoss     | -0.0137     |\n",
      "|    value_loss         | 0.0583      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 797         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 71          |\n",
      "|    total_timesteps    | 49078272    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023881204 |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.118      |\n",
      "|    mean_step_reward   | 0.0200851   |\n",
      "|    n_updates          | 24/128      |\n",
      "|    policyGradLoss     | -0.0216     |\n",
      "|    value_loss         | 0.0447      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 789         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 83          |\n",
      "|    total_timesteps    | 49086464    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018253446 |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.927       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0727     |\n",
      "|    mean_step_reward   | 0.018672703 |\n",
      "|    n_updates          | 28/128      |\n",
      "|    policyGradLoss     | -0.014      |\n",
      "|    value_loss         | 0.295       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 93          |\n",
      "|    total_timesteps    | 49094656    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018970067 |\n",
      "|    entropy_loss       | -2.09       |\n",
      "|    explained_variance | 0.902       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0184      |\n",
      "|    mean_step_reward   | 0.038206123 |\n",
      "|    n_updates          | 32/128      |\n",
      "|    policyGradLoss     | -0.00971    |\n",
      "|    value_loss         | 0.474       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 104         |\n",
      "|    total_timesteps    | 49102848    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021944158 |\n",
      "|    entropy_loss       | -2.07       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0727     |\n",
      "|    mean_step_reward   | 0.064090535 |\n",
      "|    n_updates          | 36/128      |\n",
      "|    policyGradLoss     | -0.0211     |\n",
      "|    value_loss         | 0.155       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 115         |\n",
      "|    total_timesteps    | 49111040    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024850257 |\n",
      "|    entropy_loss       | -2.13       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0701     |\n",
      "|    mean_step_reward   | 0.053934354 |\n",
      "|    n_updates          | 40/128      |\n",
      "|    policyGradLoss     | -0.0219     |\n",
      "|    value_loss         | 0.132       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 125         |\n",
      "|    total_timesteps    | 49119232    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019679371 |\n",
      "|    entropy_loss       | -2.15       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.072      |\n",
      "|    mean_step_reward   | 0.04866778  |\n",
      "|    n_updates          | 44/128      |\n",
      "|    policyGradLoss     | -0.0179     |\n",
      "|    value_loss         | 0.155       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 136         |\n",
      "|    total_timesteps    | 49127424    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025038986 |\n",
      "|    entropy_loss       | -2.08       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0765     |\n",
      "|    mean_step_reward   | 0.05345817  |\n",
      "|    n_updates          | 48/128      |\n",
      "|    policyGradLoss     | -0.0222     |\n",
      "|    value_loss         | 0.165       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 147         |\n",
      "|    total_timesteps    | 49135616    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022939442 |\n",
      "|    entropy_loss       | -2.12       |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0666     |\n",
      "|    mean_step_reward   | 0.062344685 |\n",
      "|    n_updates          | 52/128      |\n",
      "|    policyGradLoss     | -0.0168     |\n",
      "|    value_loss         | 0.192       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 158         |\n",
      "|    total_timesteps    | 49143808    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020361345 |\n",
      "|    entropy_loss       | -2.07       |\n",
      "|    explained_variance | 0.905       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.108       |\n",
      "|    mean_step_reward   | 0.0414727   |\n",
      "|    n_updates          | 56/128      |\n",
      "|    policyGradLoss     | -0.0144     |\n",
      "|    value_loss         | 0.491       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 169         |\n",
      "|    total_timesteps    | 49152000    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026036594 |\n",
      "|    entropy_loss       | -2.09       |\n",
      "|    explained_variance | 0.906       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.075       |\n",
      "|    mean_step_reward   | 0.045631383 |\n",
      "|    n_updates          | 60/128      |\n",
      "|    policyGradLoss     | -0.0161     |\n",
      "|    value_loss         | 0.451       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 180         |\n",
      "|    total_timesteps    | 49160192    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028962009 |\n",
      "|    entropy_loss       | -2.14       |\n",
      "|    explained_variance | 0.94        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0741     |\n",
      "|    mean_step_reward   | 0.044782527 |\n",
      "|    n_updates          | 64/128      |\n",
      "|    policyGradLoss     | -0.0175     |\n",
      "|    value_loss         | 0.257       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 190         |\n",
      "|    total_timesteps    | 49168384    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02285386  |\n",
      "|    entropy_loss       | -2.19       |\n",
      "|    explained_variance | 0.909       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0801     |\n",
      "|    mean_step_reward   | 0.029287098 |\n",
      "|    n_updates          | 68/128      |\n",
      "|    policyGradLoss     | -0.0138     |\n",
      "|    value_loss         | 0.288       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 772        |\n",
      "|    iterations         | 19         |\n",
      "|    time_elapsed       | 201        |\n",
      "|    total_timesteps    | 49176576   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02654579 |\n",
      "|    entropy_loss       | -2.13      |\n",
      "|    explained_variance | 0.975      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0661    |\n",
      "|    mean_step_reward   | 0.04327513 |\n",
      "|    n_updates          | 72/128     |\n",
      "|    policyGradLoss     | -0.0229    |\n",
      "|    value_loss         | 0.134      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 212         |\n",
      "|    total_timesteps    | 49184768    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016243178 |\n",
      "|    entropy_loss       | -2.18       |\n",
      "|    explained_variance | 0.905       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0724     |\n",
      "|    mean_step_reward   | 0.039732978 |\n",
      "|    n_updates          | 76/128      |\n",
      "|    policyGradLoss     | -0.0119     |\n",
      "|    value_loss         | 0.314       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 223         |\n",
      "|    total_timesteps    | 49192960    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018079298 |\n",
      "|    entropy_loss       | -2.17       |\n",
      "|    explained_variance | 0.947       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0412      |\n",
      "|    mean_step_reward   | 0.032518595 |\n",
      "|    n_updates          | 80/128      |\n",
      "|    policyGradLoss     | -0.0183     |\n",
      "|    value_loss         | 0.237       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 233         |\n",
      "|    total_timesteps    | 49201152    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024796076 |\n",
      "|    entropy_loss       | -2.12       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0641     |\n",
      "|    mean_step_reward   | 0.03895296  |\n",
      "|    n_updates          | 84/128      |\n",
      "|    policyGradLoss     | -0.0221     |\n",
      "|    value_loss         | 0.193       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 244         |\n",
      "|    total_timesteps    | 49209344    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026723994 |\n",
      "|    entropy_loss       | -2.16       |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0161      |\n",
      "|    mean_step_reward   | 0.042521164 |\n",
      "|    n_updates          | 88/128      |\n",
      "|    policyGradLoss     | -0.0196     |\n",
      "|    value_loss         | 0.225       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 255         |\n",
      "|    total_timesteps    | 49217536    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022571333 |\n",
      "|    entropy_loss       | -2.17       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.101      |\n",
      "|    mean_step_reward   | 0.034098826 |\n",
      "|    n_updates          | 92/128      |\n",
      "|    policyGradLoss     | -0.0215     |\n",
      "|    value_loss         | 0.103       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 266         |\n",
      "|    total_timesteps    | 49225728    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028069025 |\n",
      "|    entropy_loss       | -2.18       |\n",
      "|    explained_variance | 0.948       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0868     |\n",
      "|    mean_step_reward   | 0.03963569  |\n",
      "|    n_updates          | 96/128      |\n",
      "|    policyGradLoss     | -0.0185     |\n",
      "|    value_loss         | 0.188       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 277         |\n",
      "|    total_timesteps    | 49233920    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020661447 |\n",
      "|    entropy_loss       | -2.16       |\n",
      "|    explained_variance | 0.954       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0712     |\n",
      "|    mean_step_reward   | 0.029617095 |\n",
      "|    n_updates          | 100/128     |\n",
      "|    policyGradLoss     | -0.0199     |\n",
      "|    value_loss         | 0.255       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 767        |\n",
      "|    iterations         | 27         |\n",
      "|    time_elapsed       | 288        |\n",
      "|    total_timesteps    | 49242112   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03015598 |\n",
      "|    entropy_loss       | -2.05      |\n",
      "|    explained_variance | 0.961      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0763    |\n",
      "|    mean_step_reward   | 0.06358363 |\n",
      "|    n_updates          | 104/128    |\n",
      "|    policyGradLoss     | -0.0217    |\n",
      "|    value_loss         | 0.2        |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 298         |\n",
      "|    total_timesteps    | 49250304    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029066462 |\n",
      "|    entropy_loss       | -2.12       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0857     |\n",
      "|    mean_step_reward   | 0.06049992  |\n",
      "|    n_updates          | 108/128     |\n",
      "|    policyGradLoss     | -0.0241     |\n",
      "|    value_loss         | 0.116       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 309         |\n",
      "|    total_timesteps    | 49258496    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019662019 |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.941       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0709     |\n",
      "|    mean_step_reward   | 0.02200427  |\n",
      "|    n_updates          | 112/128     |\n",
      "|    policyGradLoss     | -0.0168     |\n",
      "|    value_loss         | 0.231       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 320         |\n",
      "|    total_timesteps    | 49266688    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022940837 |\n",
      "|    entropy_loss       | -2.14       |\n",
      "|    explained_variance | 0.89        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.047      |\n",
      "|    mean_step_reward   | 0.039519697 |\n",
      "|    n_updates          | 116/128     |\n",
      "|    policyGradLoss     | -0.014      |\n",
      "|    value_loss         | 0.293       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 331         |\n",
      "|    total_timesteps    | 49274880    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024013601 |\n",
      "|    entropy_loss       | -2.17       |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0946     |\n",
      "|    mean_step_reward   | 0.040735386 |\n",
      "|    n_updates          | 120/128     |\n",
      "|    policyGradLoss     | -0.0201     |\n",
      "|    value_loss         | 0.157       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 342         |\n",
      "|    total_timesteps    | 49283072    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023752691 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.946       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.091      |\n",
      "|    mean_step_reward   | 0.028132632 |\n",
      "|    n_updates          | 124/128     |\n",
      "|    policyGradLoss     | -0.0156     |\n",
      "|    value_loss         | 0.151       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/NoArti_187.zip\n",
      "[EVAL] Mean Return: 130.920, Best Return: 133.520\n",
      "Saved video to ./runs_smw/videos/NoArti/NoArti_187_130.92.mp4\n",
      "\n",
      "=== Round 189 | Learn 262144 steps (Total trained: 49283072) ===\n",
      "Logging to ./runs_smw/tb/NoArti_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1126     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 49291264 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 895         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 49299456    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014667103 |\n",
      "|    entropy_loss       | -2.17       |\n",
      "|    explained_variance | 0.82        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0704     |\n",
      "|    mean_step_reward   | 0.033315446 |\n",
      "|    n_updates          | 4/128       |\n",
      "|    policyGradLoss     | -0.00901    |\n",
      "|    value_loss         | 0.421       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 844         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 29          |\n",
      "|    total_timesteps    | 49307648    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024165902 |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0961     |\n",
      "|    mean_step_reward   | 0.032355145 |\n",
      "|    n_updates          | 8/128       |\n",
      "|    policyGradLoss     | -0.0197     |\n",
      "|    value_loss         | 0.129       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 823         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 49315840    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02193959  |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.879       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0947     |\n",
      "|    mean_step_reward   | 0.013844238 |\n",
      "|    n_updates          | 12/128      |\n",
      "|    policyGradLoss     | -0.0158     |\n",
      "|    value_loss         | 0.19        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 811         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 50          |\n",
      "|    total_timesteps    | 49324032    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01461372  |\n",
      "|    entropy_loss       | -2.19       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0794     |\n",
      "|    mean_step_reward   | 0.044948548 |\n",
      "|    n_updates          | 16/128      |\n",
      "|    policyGradLoss     | -0.0147     |\n",
      "|    value_loss         | 0.184       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 799         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 61          |\n",
      "|    total_timesteps    | 49332224    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02126328  |\n",
      "|    entropy_loss       | -2.15       |\n",
      "|    explained_variance | 0.928       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0729     |\n",
      "|    mean_step_reward   | 0.043623537 |\n",
      "|    n_updates          | 20/128      |\n",
      "|    policyGradLoss     | -0.0153     |\n",
      "|    value_loss         | 0.274       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 789         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 72          |\n",
      "|    total_timesteps    | 49340416    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015027851 |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.863       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0369      |\n",
      "|    mean_step_reward   | 0.030045915 |\n",
      "|    n_updates          | 24/128      |\n",
      "|    policyGradLoss     | -0.00852    |\n",
      "|    value_loss         | 0.475       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 83          |\n",
      "|    total_timesteps    | 49348608    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017228961 |\n",
      "|    entropy_loss       | -2.16       |\n",
      "|    explained_variance | 0.938       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0591     |\n",
      "|    mean_step_reward   | 0.035851803 |\n",
      "|    n_updates          | 28/128      |\n",
      "|    policyGradLoss     | -0.0193     |\n",
      "|    value_loss         | 0.22        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 94          |\n",
      "|    total_timesteps    | 49356800    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025213473 |\n",
      "|    entropy_loss       | -2.14       |\n",
      "|    explained_variance | 0.933       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0705     |\n",
      "|    mean_step_reward   | 0.044655662 |\n",
      "|    n_updates          | 32/128      |\n",
      "|    policyGradLoss     | -0.0194     |\n",
      "|    value_loss         | 0.298       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 105         |\n",
      "|    total_timesteps    | 49364992    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018415036 |\n",
      "|    entropy_loss       | -2.15       |\n",
      "|    explained_variance | 0.914       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0619     |\n",
      "|    mean_step_reward   | 0.05510282  |\n",
      "|    n_updates          | 36/128      |\n",
      "|    policyGradLoss     | -0.0164     |\n",
      "|    value_loss         | 0.284       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 777        |\n",
      "|    iterations         | 11         |\n",
      "|    time_elapsed       | 115        |\n",
      "|    total_timesteps    | 49373184   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02120835 |\n",
      "|    entropy_loss       | -2.17      |\n",
      "|    explained_variance | 0.905      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0616    |\n",
      "|    mean_step_reward   | 0.04727994 |\n",
      "|    n_updates          | 40/128     |\n",
      "|    policyGradLoss     | -0.0132    |\n",
      "|    value_loss         | 0.387      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 126         |\n",
      "|    total_timesteps    | 49381376    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019272065 |\n",
      "|    entropy_loss       | -2.15       |\n",
      "|    explained_variance | 0.901       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0672     |\n",
      "|    mean_step_reward   | 0.03651049  |\n",
      "|    n_updates          | 44/128      |\n",
      "|    policyGradLoss     | -0.0171     |\n",
      "|    value_loss         | 0.45        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 137         |\n",
      "|    total_timesteps    | 49389568    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02440114  |\n",
      "|    entropy_loss       | -2.18       |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.104      |\n",
      "|    mean_step_reward   | 0.041730944 |\n",
      "|    n_updates          | 48/128      |\n",
      "|    policyGradLoss     | -0.0255     |\n",
      "|    value_loss         | 0.149       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 148         |\n",
      "|    total_timesteps    | 49397760    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017485972 |\n",
      "|    entropy_loss       | -2.13       |\n",
      "|    explained_variance | 0.935       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0472      |\n",
      "|    mean_step_reward   | 0.05092082  |\n",
      "|    n_updates          | 52/128      |\n",
      "|    policyGradLoss     | -0.0172     |\n",
      "|    value_loss         | 0.59        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 159         |\n",
      "|    total_timesteps    | 49405952    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.032686267 |\n",
      "|    entropy_loss       | -2.19       |\n",
      "|    explained_variance | 0.935       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0735     |\n",
      "|    mean_step_reward   | 0.03500527  |\n",
      "|    n_updates          | 56/128      |\n",
      "|    policyGradLoss     | -0.0231     |\n",
      "|    value_loss         | 0.188       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 169         |\n",
      "|    total_timesteps    | 49414144    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021112321 |\n",
      "|    entropy_loss       | -2.17       |\n",
      "|    explained_variance | 0.938       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0719     |\n",
      "|    mean_step_reward   | 0.043010585 |\n",
      "|    n_updates          | 60/128      |\n",
      "|    policyGradLoss     | -0.0191     |\n",
      "|    value_loss         | 0.23        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 180         |\n",
      "|    total_timesteps    | 49422336    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02788015  |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.937       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.105      |\n",
      "|    mean_step_reward   | 0.026556488 |\n",
      "|    n_updates          | 64/128      |\n",
      "|    policyGradLoss     | -0.0186     |\n",
      "|    value_loss         | 0.146       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 191         |\n",
      "|    total_timesteps    | 49430528    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022792988 |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.911       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.105      |\n",
      "|    mean_step_reward   | 0.020855632 |\n",
      "|    n_updates          | 68/128      |\n",
      "|    policyGradLoss     | -0.0185     |\n",
      "|    value_loss         | 0.127       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 202         |\n",
      "|    total_timesteps    | 49438720    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022377588 |\n",
      "|    entropy_loss       | -2.19       |\n",
      "|    explained_variance | 0.946       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0854     |\n",
      "|    mean_step_reward   | 0.03788682  |\n",
      "|    n_updates          | 72/128      |\n",
      "|    policyGradLoss     | -0.0188     |\n",
      "|    value_loss         | 0.172       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 213         |\n",
      "|    total_timesteps    | 49446912    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030903608 |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.11       |\n",
      "|    mean_step_reward   | 0.032650836 |\n",
      "|    n_updates          | 76/128      |\n",
      "|    policyGradLoss     | -0.0271     |\n",
      "|    value_loss         | 0.0889      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 223         |\n",
      "|    total_timesteps    | 49455104    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026957612 |\n",
      "|    entropy_loss       | -2.16       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0942     |\n",
      "|    mean_step_reward   | 0.043155313 |\n",
      "|    n_updates          | 80/128      |\n",
      "|    policyGradLoss     | -0.0173     |\n",
      "|    value_loss         | 0.203       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 234         |\n",
      "|    total_timesteps    | 49463296    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018878197 |\n",
      "|    entropy_loss       | -2.2        |\n",
      "|    explained_variance | 0.935       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0308     |\n",
      "|    mean_step_reward   | 0.020692738 |\n",
      "|    n_updates          | 84/128      |\n",
      "|    policyGradLoss     | -0.0211     |\n",
      "|    value_loss         | 0.206       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 245         |\n",
      "|    total_timesteps    | 49471488    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019538188 |\n",
      "|    entropy_loss       | -2.17       |\n",
      "|    explained_variance | 0.919       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0533     |\n",
      "|    mean_step_reward   | 0.048530445 |\n",
      "|    n_updates          | 88/128      |\n",
      "|    policyGradLoss     | -0.0143     |\n",
      "|    value_loss         | 0.355       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 256         |\n",
      "|    total_timesteps    | 49479680    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014051556 |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.842       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00459    |\n",
      "|    mean_step_reward   | 0.035365798 |\n",
      "|    n_updates          | 92/128      |\n",
      "|    policyGradLoss     | -0.00508    |\n",
      "|    value_loss         | 0.301       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 765         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 267         |\n",
      "|    total_timesteps    | 49487872    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016451273 |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.92        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0773     |\n",
      "|    mean_step_reward   | 0.026246306 |\n",
      "|    n_updates          | 96/128      |\n",
      "|    policyGradLoss     | -0.0118     |\n",
      "|    value_loss         | 0.172       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 765        |\n",
      "|    iterations         | 26         |\n",
      "|    time_elapsed       | 278        |\n",
      "|    total_timesteps    | 49496064   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01917483 |\n",
      "|    entropy_loss       | -2.26      |\n",
      "|    explained_variance | 0.97       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0974    |\n",
      "|    mean_step_reward   | 0.03998884 |\n",
      "|    n_updates          | 100/128    |\n",
      "|    policyGradLoss     | -0.0178    |\n",
      "|    value_loss         | 0.147      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 765         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 288         |\n",
      "|    total_timesteps    | 49504256    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027412605 |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.114      |\n",
      "|    mean_step_reward   | 0.024742346 |\n",
      "|    n_updates          | 104/128     |\n",
      "|    policyGradLoss     | -0.0272     |\n",
      "|    value_loss         | 0.0453      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 765          |\n",
      "|    iterations         | 28           |\n",
      "|    time_elapsed       | 299          |\n",
      "|    total_timesteps    | 49512448     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0092705265 |\n",
      "|    entropy_loss       | -2.21        |\n",
      "|    explained_variance | 0.964        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0122      |\n",
      "|    mean_step_reward   | 0.037092723  |\n",
      "|    n_updates          | 108/128      |\n",
      "|    policyGradLoss     | -0.0123      |\n",
      "|    value_loss         | 0.223        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 765         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 310         |\n",
      "|    total_timesteps    | 49520640    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020128455 |\n",
      "|    entropy_loss       | -2.13       |\n",
      "|    explained_variance | 0.949       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0815     |\n",
      "|    mean_step_reward   | 0.048148587 |\n",
      "|    n_updates          | 112/128     |\n",
      "|    policyGradLoss     | -0.0162     |\n",
      "|    value_loss         | 0.251       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 765         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 321         |\n",
      "|    total_timesteps    | 49528832    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021823987 |\n",
      "|    entropy_loss       | -2.1        |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0649     |\n",
      "|    mean_step_reward   | 0.05080814  |\n",
      "|    n_updates          | 116/128     |\n",
      "|    policyGradLoss     | -0.0172     |\n",
      "|    value_loss         | 0.194       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 764         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 332         |\n",
      "|    total_timesteps    | 49537024    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022834314 |\n",
      "|    entropy_loss       | -2.12       |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.099      |\n",
      "|    mean_step_reward   | 0.049249873 |\n",
      "|    n_updates          | 120/128     |\n",
      "|    policyGradLoss     | -0.0171     |\n",
      "|    value_loss         | 0.158       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 763         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 343         |\n",
      "|    total_timesteps    | 49545216    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022980526 |\n",
      "|    entropy_loss       | -2.11       |\n",
      "|    explained_variance | 0.945       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0257      |\n",
      "|    mean_step_reward   | 0.05162749  |\n",
      "|    n_updates          | 124/128     |\n",
      "|    policyGradLoss     | -0.0129     |\n",
      "|    value_loss         | 0.341       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/NoArti_188.zip\n",
      "[EVAL] Mean Return: 132.297, Best Return: 134.897\n",
      "Saved video to ./runs_smw/videos/NoArti/NoArti_188_132.30.mp4\n",
      "\n",
      "=== Round 190 | Learn 262144 steps (Total trained: 49545216) ===\n",
      "Logging to ./runs_smw/tb/NoArti_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1112     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 49553408 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 907         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 49561600    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01777405  |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.891       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0549     |\n",
      "|    mean_step_reward   | 0.022790901 |\n",
      "|    n_updates          | 4/128       |\n",
      "|    policyGradLoss     | -0.0146     |\n",
      "|    value_loss         | 0.289       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 842         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 29          |\n",
      "|    total_timesteps    | 49569792    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022165904 |\n",
      "|    entropy_loss       | -2.19       |\n",
      "|    explained_variance | 0.907       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0196     |\n",
      "|    mean_step_reward   | 0.035604578 |\n",
      "|    n_updates          | 8/128       |\n",
      "|    policyGradLoss     | -0.0175     |\n",
      "|    value_loss         | 0.348       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 817         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 40          |\n",
      "|    total_timesteps    | 49577984    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021395955 |\n",
      "|    entropy_loss       | -2.15       |\n",
      "|    explained_variance | 0.861       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0234      |\n",
      "|    mean_step_reward   | 0.023902444 |\n",
      "|    n_updates          | 12/128      |\n",
      "|    policyGradLoss     | -0.0144     |\n",
      "|    value_loss         | 0.525       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 805         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 50          |\n",
      "|    total_timesteps    | 49586176    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030883417 |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.958       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.108      |\n",
      "|    mean_step_reward   | 0.032773007 |\n",
      "|    n_updates          | 16/128      |\n",
      "|    policyGradLoss     | -0.0241     |\n",
      "|    value_loss         | 0.109       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 802         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 61          |\n",
      "|    total_timesteps    | 49594368    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018631995 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.887       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0662     |\n",
      "|    mean_step_reward   | 0.013952034 |\n",
      "|    n_updates          | 20/128      |\n",
      "|    policyGradLoss     | -0.013      |\n",
      "|    value_loss         | 0.336       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 799         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 71          |\n",
      "|    total_timesteps    | 49602560    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028592207 |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.917       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0936     |\n",
      "|    mean_step_reward   | 0.029120296 |\n",
      "|    n_updates          | 24/128      |\n",
      "|    policyGradLoss     | -0.0221     |\n",
      "|    value_loss         | 0.14        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 792         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 82          |\n",
      "|    total_timesteps    | 49610752    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019986352 |\n",
      "|    entropy_loss       | -2.2        |\n",
      "|    explained_variance | 0.913       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0746     |\n",
      "|    mean_step_reward   | 0.04124838  |\n",
      "|    n_updates          | 28/128      |\n",
      "|    policyGradLoss     | -0.0163     |\n",
      "|    value_loss         | 0.318       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 93          |\n",
      "|    total_timesteps    | 49618944    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026841672 |\n",
      "|    entropy_loss       | -2.28       |\n",
      "|    explained_variance | 0.952       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.118      |\n",
      "|    mean_step_reward   | 0.020528995 |\n",
      "|    n_updates          | 32/128      |\n",
      "|    policyGradLoss     | -0.0218     |\n",
      "|    value_loss         | 0.138       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 104         |\n",
      "|    total_timesteps    | 49627136    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022634802 |\n",
      "|    entropy_loss       | -2.3        |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.107      |\n",
      "|    mean_step_reward   | 0.015856655 |\n",
      "|    n_updates          | 36/128      |\n",
      "|    policyGradLoss     | -0.024      |\n",
      "|    value_loss         | 0.0634      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 115         |\n",
      "|    total_timesteps    | 49635328    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026844766 |\n",
      "|    entropy_loss       | -2.28       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.111      |\n",
      "|    mean_step_reward   | 0.02770888  |\n",
      "|    n_updates          | 40/128      |\n",
      "|    policyGradLoss     | -0.0186     |\n",
      "|    value_loss         | 0.0752      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 126         |\n",
      "|    total_timesteps    | 49643520    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01853731  |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.876       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0444     |\n",
      "|    mean_step_reward   | 0.017274927 |\n",
      "|    n_updates          | 44/128      |\n",
      "|    policyGradLoss     | -0.0149     |\n",
      "|    value_loss         | 0.372       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 775        |\n",
      "|    iterations         | 13         |\n",
      "|    time_elapsed       | 137        |\n",
      "|    total_timesteps    | 49651712   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02801058 |\n",
      "|    entropy_loss       | -2.27      |\n",
      "|    explained_variance | 0.969      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.114     |\n",
      "|    mean_step_reward   | 0.02039621 |\n",
      "|    n_updates          | 48/128     |\n",
      "|    policyGradLoss     | -0.0227    |\n",
      "|    value_loss         | 0.0708     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 148         |\n",
      "|    total_timesteps    | 49659904    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019138565 |\n",
      "|    entropy_loss       | -2.29       |\n",
      "|    explained_variance | 0.87        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0532     |\n",
      "|    mean_step_reward   | 0.011934856 |\n",
      "|    n_updates          | 52/128      |\n",
      "|    policyGradLoss     | -0.0099     |\n",
      "|    value_loss         | 0.325       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 159         |\n",
      "|    total_timesteps    | 49668096    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017880533 |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.925       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0565     |\n",
      "|    mean_step_reward   | 0.024451114 |\n",
      "|    n_updates          | 56/128      |\n",
      "|    policyGradLoss     | -0.0179     |\n",
      "|    value_loss         | 0.252       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 170         |\n",
      "|    total_timesteps    | 49676288    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02362601  |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.933       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.102      |\n",
      "|    mean_step_reward   | 0.018095631 |\n",
      "|    n_updates          | 60/128      |\n",
      "|    policyGradLoss     | -0.02       |\n",
      "|    value_loss         | 0.17        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 181         |\n",
      "|    total_timesteps    | 49684480    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026901692 |\n",
      "|    entropy_loss       | -2.29       |\n",
      "|    explained_variance | 0.934       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0983     |\n",
      "|    mean_step_reward   | 0.01242928  |\n",
      "|    n_updates          | 64/128      |\n",
      "|    policyGradLoss     | -0.0201     |\n",
      "|    value_loss         | 0.126       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 767          |\n",
      "|    iterations         | 18           |\n",
      "|    time_elapsed       | 192          |\n",
      "|    total_timesteps    | 49692672     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.019956673  |\n",
      "|    entropy_loss       | -2.3         |\n",
      "|    explained_variance | 0.891        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0746      |\n",
      "|    mean_step_reward   | 0.0056772004 |\n",
      "|    n_updates          | 68/128       |\n",
      "|    policyGradLoss     | -0.0154      |\n",
      "|    value_loss         | 0.268        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 202         |\n",
      "|    total_timesteps    | 49700864    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025662381 |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.784       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0864     |\n",
      "|    mean_step_reward   | 0.02184218  |\n",
      "|    n_updates          | 72/128      |\n",
      "|    policyGradLoss     | -0.0144     |\n",
      "|    value_loss         | 0.275       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 213         |\n",
      "|    total_timesteps    | 49709056    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018369738 |\n",
      "|    entropy_loss       | -2.27       |\n",
      "|    explained_variance | 0.831       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0566     |\n",
      "|    mean_step_reward   | 0.013338578 |\n",
      "|    n_updates          | 76/128      |\n",
      "|    policyGradLoss     | -0.0131     |\n",
      "|    value_loss         | 0.429       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 224         |\n",
      "|    total_timesteps    | 49717248    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029334135 |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.921       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0904     |\n",
      "|    mean_step_reward   | 0.016990745 |\n",
      "|    n_updates          | 80/128      |\n",
      "|    policyGradLoss     | -0.0185     |\n",
      "|    value_loss         | 0.151       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 235         |\n",
      "|    total_timesteps    | 49725440    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021337735 |\n",
      "|    entropy_loss       | -2.19       |\n",
      "|    explained_variance | 0.933       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0743     |\n",
      "|    mean_step_reward   | 0.04718414  |\n",
      "|    n_updates          | 84/128      |\n",
      "|    policyGradLoss     | -0.0144     |\n",
      "|    value_loss         | 0.169       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 245         |\n",
      "|    total_timesteps    | 49733632    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021589428 |\n",
      "|    entropy_loss       | -2.32       |\n",
      "|    explained_variance | 0.486       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0959     |\n",
      "|    mean_step_reward   | 0.007535588 |\n",
      "|    n_updates          | 88/128      |\n",
      "|    policyGradLoss     | -0.00899    |\n",
      "|    value_loss         | 0.177       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 765         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 256         |\n",
      "|    total_timesteps    | 49741824    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015879527 |\n",
      "|    entropy_loss       | -2.32       |\n",
      "|    explained_variance | 0.881       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0574     |\n",
      "|    mean_step_reward   | 0.006349682 |\n",
      "|    n_updates          | 92/128      |\n",
      "|    policyGradLoss     | -0.0152     |\n",
      "|    value_loss         | 0.215       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 764         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 267         |\n",
      "|    total_timesteps    | 49750016    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021938223 |\n",
      "|    entropy_loss       | -2.28       |\n",
      "|    explained_variance | 0.86        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.066      |\n",
      "|    mean_step_reward   | 0.017522134 |\n",
      "|    n_updates          | 96/128      |\n",
      "|    policyGradLoss     | -0.0131     |\n",
      "|    value_loss         | 0.172       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 764         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 278         |\n",
      "|    total_timesteps    | 49758208    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011472571 |\n",
      "|    entropy_loss       | -2.27       |\n",
      "|    explained_variance | 0.925       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.103      |\n",
      "|    mean_step_reward   | 0.019320197 |\n",
      "|    n_updates          | 100/128     |\n",
      "|    policyGradLoss     | -0.0186     |\n",
      "|    value_loss         | 0.171       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 763         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 289         |\n",
      "|    total_timesteps    | 49766400    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020329019 |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.9         |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0584     |\n",
      "|    mean_step_reward   | 0.016141031 |\n",
      "|    n_updates          | 104/128     |\n",
      "|    policyGradLoss     | -0.0172     |\n",
      "|    value_loss         | 0.246       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 762         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 300         |\n",
      "|    total_timesteps    | 49774592    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023348395 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.931       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0996     |\n",
      "|    mean_step_reward   | 0.02439026  |\n",
      "|    n_updates          | 108/128     |\n",
      "|    policyGradLoss     | -0.0203     |\n",
      "|    value_loss         | 0.123       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 762         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 311         |\n",
      "|    total_timesteps    | 49782784    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017910201 |\n",
      "|    entropy_loss       | -2.27       |\n",
      "|    explained_variance | 0.858       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0795     |\n",
      "|    mean_step_reward   | 0.029036427 |\n",
      "|    n_updates          | 112/128     |\n",
      "|    policyGradLoss     | -0.00911    |\n",
      "|    value_loss         | 0.324       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 762         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 322         |\n",
      "|    total_timesteps    | 49790976    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026073247 |\n",
      "|    entropy_loss       | -2.33       |\n",
      "|    explained_variance | 0.688       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.103      |\n",
      "|    mean_step_reward   | 0.004382383 |\n",
      "|    n_updates          | 116/128     |\n",
      "|    policyGradLoss     | -0.0123     |\n",
      "|    value_loss         | 0.145       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 762         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 332         |\n",
      "|    total_timesteps    | 49799168    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018916603 |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.836       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0166     |\n",
      "|    mean_step_reward   | 0.018648785 |\n",
      "|    n_updates          | 120/128     |\n",
      "|    policyGradLoss     | -0.00876    |\n",
      "|    value_loss         | 0.656       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 762         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 343         |\n",
      "|    total_timesteps    | 49807360    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028633632 |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.895       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0902     |\n",
      "|    mean_step_reward   | 0.025841698 |\n",
      "|    n_updates          | 124/128     |\n",
      "|    policyGradLoss     | -0.0176     |\n",
      "|    value_loss         | 0.149       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/NoArti_189.zip\n",
      "[EVAL] Mean Return: 40.361, Best Return: 40.961\n",
      "Saved video to ./runs_smw/videos/NoArti/NoArti_189_40.36.mp4\n",
      "\n",
      "=== Round 191 | Learn 262144 steps (Total trained: 49807360) ===\n",
      "Logging to ./runs_smw/tb/NoArti_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1095     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 49815552 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 904         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 49823744    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025450103 |\n",
      "|    entropy_loss       | -2.29       |\n",
      "|    explained_variance | 0.845       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0892     |\n",
      "|    mean_step_reward   | 0.012272334 |\n",
      "|    n_updates          | 4/128       |\n",
      "|    policyGradLoss     | -0.0153     |\n",
      "|    value_loss         | 0.241       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 861         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 49831936    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020491887 |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.924       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0514     |\n",
      "|    mean_step_reward   | 0.026495624 |\n",
      "|    n_updates          | 8/128       |\n",
      "|    policyGradLoss     | -0.0154     |\n",
      "|    value_loss         | 0.277       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 837         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 49840128    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028081913 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.925       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.104      |\n",
      "|    mean_step_reward   | 0.03165441  |\n",
      "|    n_updates          | 12/128      |\n",
      "|    policyGradLoss     | -0.0219     |\n",
      "|    value_loss         | 0.143       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 824        |\n",
      "|    iterations         | 5          |\n",
      "|    time_elapsed       | 49         |\n",
      "|    total_timesteps    | 49848320   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02514216 |\n",
      "|    entropy_loss       | -2.25      |\n",
      "|    explained_variance | 0.964      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0925    |\n",
      "|    mean_step_reward   | 0.02675869 |\n",
      "|    n_updates          | 16/128     |\n",
      "|    policyGradLoss     | -0.0198    |\n",
      "|    value_loss         | 0.118      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 810         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 60          |\n",
      "|    total_timesteps    | 49856512    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019070823 |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.94        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0898     |\n",
      "|    mean_step_reward   | 0.010305769 |\n",
      "|    n_updates          | 20/128      |\n",
      "|    policyGradLoss     | -0.0194     |\n",
      "|    value_loss         | 0.173       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 804         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 71          |\n",
      "|    total_timesteps    | 49864704    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019859772 |\n",
      "|    entropy_loss       | -2.19       |\n",
      "|    explained_variance | 0.73        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0415     |\n",
      "|    mean_step_reward   | 0.027424777 |\n",
      "|    n_updates          | 24/128      |\n",
      "|    policyGradLoss     | -0.0123     |\n",
      "|    value_loss         | 0.543       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 795         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 82          |\n",
      "|    total_timesteps    | 49872896    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.0225638   |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.9         |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0929     |\n",
      "|    mean_step_reward   | 0.026021391 |\n",
      "|    n_updates          | 28/128      |\n",
      "|    policyGradLoss     | -0.0184     |\n",
      "|    value_loss         | 0.236       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 793         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 92          |\n",
      "|    total_timesteps    | 49881088    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020148689 |\n",
      "|    entropy_loss       | -2.27       |\n",
      "|    explained_variance | 0.948       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0982     |\n",
      "|    mean_step_reward   | 0.02839596  |\n",
      "|    n_updates          | 32/128      |\n",
      "|    policyGradLoss     | -0.0144     |\n",
      "|    value_loss         | 0.134       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 792         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 103         |\n",
      "|    total_timesteps    | 49889280    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018002573 |\n",
      "|    entropy_loss       | -2.3        |\n",
      "|    explained_variance | 0.905       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.102      |\n",
      "|    mean_step_reward   | 0.01221624  |\n",
      "|    n_updates          | 36/128      |\n",
      "|    policyGradLoss     | -0.0146     |\n",
      "|    value_loss         | 0.168       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 788         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 114         |\n",
      "|    total_timesteps    | 49897472    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01946577  |\n",
      "|    entropy_loss       | -2.28       |\n",
      "|    explained_variance | 0.945       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.11       |\n",
      "|    mean_step_reward   | 0.026347961 |\n",
      "|    n_updates          | 40/128      |\n",
      "|    policyGradLoss     | -0.0173     |\n",
      "|    value_loss         | 0.102       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 124         |\n",
      "|    total_timesteps    | 49905664    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021332778 |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.908       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0695     |\n",
      "|    mean_step_reward   | 0.01894993  |\n",
      "|    n_updates          | 44/128      |\n",
      "|    policyGradLoss     | -0.0182     |\n",
      "|    value_loss         | 0.173       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 135         |\n",
      "|    total_timesteps    | 49913856    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021450896 |\n",
      "|    entropy_loss       | -2.27       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0776     |\n",
      "|    mean_step_reward   | 0.01810554  |\n",
      "|    n_updates          | 48/128      |\n",
      "|    policyGradLoss     | -0.0195     |\n",
      "|    value_loss         | 0.149       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 146         |\n",
      "|    total_timesteps    | 49922048    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015616983 |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.958       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0777     |\n",
      "|    mean_step_reward   | 0.02409663  |\n",
      "|    n_updates          | 52/128      |\n",
      "|    policyGradLoss     | -0.016      |\n",
      "|    value_loss         | 0.153       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 157         |\n",
      "|    total_timesteps    | 49930240    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023349965 |\n",
      "|    entropy_loss       | -2.27       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.112      |\n",
      "|    mean_step_reward   | 0.020375371 |\n",
      "|    n_updates          | 56/128      |\n",
      "|    policyGradLoss     | -0.0212     |\n",
      "|    value_loss         | 0.0686      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 168         |\n",
      "|    total_timesteps    | 49938432    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017449766 |\n",
      "|    entropy_loss       | -2.27       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.09       |\n",
      "|    mean_step_reward   | 0.03355783  |\n",
      "|    n_updates          | 60/128      |\n",
      "|    policyGradLoss     | -0.0149     |\n",
      "|    value_loss         | 0.147       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 178         |\n",
      "|    total_timesteps    | 49946624    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020119604 |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.725       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0161     |\n",
      "|    mean_step_reward   | 0.012712483 |\n",
      "|    n_updates          | 64/128      |\n",
      "|    policyGradLoss     | -0.0127     |\n",
      "|    value_loss         | 0.338       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 189         |\n",
      "|    total_timesteps    | 49954816    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02384719  |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.954       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0977     |\n",
      "|    mean_step_reward   | 0.027638499 |\n",
      "|    n_updates          | 68/128      |\n",
      "|    policyGradLoss     | -0.0184     |\n",
      "|    value_loss         | 0.143       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 777        |\n",
      "|    iterations         | 19         |\n",
      "|    time_elapsed       | 200        |\n",
      "|    total_timesteps    | 49963008   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01915889 |\n",
      "|    entropy_loss       | -2.25      |\n",
      "|    explained_variance | 0.968      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0871    |\n",
      "|    mean_step_reward   | 0.0345271  |\n",
      "|    n_updates          | 72/128     |\n",
      "|    policyGradLoss     | -0.015     |\n",
      "|    value_loss         | 0.137      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 211         |\n",
      "|    total_timesteps    | 49971200    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023693308 |\n",
      "|    entropy_loss       | -2.27       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.103      |\n",
      "|    mean_step_reward   | 0.018370662 |\n",
      "|    n_updates          | 76/128      |\n",
      "|    policyGradLoss     | -0.0214     |\n",
      "|    value_loss         | 0.0872      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 221         |\n",
      "|    total_timesteps    | 49979392    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020608127 |\n",
      "|    entropy_loss       | -2.3        |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.107      |\n",
      "|    mean_step_reward   | 0.021666009 |\n",
      "|    n_updates          | 80/128      |\n",
      "|    policyGradLoss     | -0.0172     |\n",
      "|    value_loss         | 0.0999      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 232         |\n",
      "|    total_timesteps    | 49987584    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017895348 |\n",
      "|    entropy_loss       | -2.28       |\n",
      "|    explained_variance | 0.944       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0889     |\n",
      "|    mean_step_reward   | 0.018173203 |\n",
      "|    n_updates          | 84/128      |\n",
      "|    policyGradLoss     | -0.0146     |\n",
      "|    value_loss         | 0.185       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 243         |\n",
      "|    total_timesteps    | 49995776    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017434096 |\n",
      "|    entropy_loss       | -2.17       |\n",
      "|    explained_variance | 0.872       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0304     |\n",
      "|    mean_step_reward   | 0.022937909 |\n",
      "|    n_updates          | 88/128      |\n",
      "|    policyGradLoss     | -0.0113     |\n",
      "|    value_loss         | 0.409       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 254         |\n",
      "|    total_timesteps    | 50003968    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018838875 |\n",
      "|    entropy_loss       | -2.15       |\n",
      "|    explained_variance | 0.932       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0361     |\n",
      "|    mean_step_reward   | 0.028731203 |\n",
      "|    n_updates          | 92/128      |\n",
      "|    policyGradLoss     | -0.0165     |\n",
      "|    value_loss         | 0.395       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 265         |\n",
      "|    total_timesteps    | 50012160    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026262749 |\n",
      "|    entropy_loss       | -2.18       |\n",
      "|    explained_variance | 0.857       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0244      |\n",
      "|    mean_step_reward   | 0.022653872 |\n",
      "|    n_updates          | 96/128      |\n",
      "|    policyGradLoss     | -0.016      |\n",
      "|    value_loss         | 0.347       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 275         |\n",
      "|    total_timesteps    | 50020352    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02053029  |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.945       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0837     |\n",
      "|    mean_step_reward   | 0.024215832 |\n",
      "|    n_updates          | 100/128     |\n",
      "|    policyGradLoss     | -0.0202     |\n",
      "|    value_loss         | 0.142       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 286         |\n",
      "|    total_timesteps    | 50028544    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021853387 |\n",
      "|    entropy_loss       | -2.17       |\n",
      "|    explained_variance | 0.932       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.017      |\n",
      "|    mean_step_reward   | 0.030637283 |\n",
      "|    n_updates          | 104/128     |\n",
      "|    policyGradLoss     | -0.0181     |\n",
      "|    value_loss         | 0.396       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 297         |\n",
      "|    total_timesteps    | 50036736    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023476183 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.897       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0711     |\n",
      "|    mean_step_reward   | 0.035822827 |\n",
      "|    n_updates          | 108/128     |\n",
      "|    policyGradLoss     | -0.014      |\n",
      "|    value_loss         | 0.264       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 307         |\n",
      "|    total_timesteps    | 50044928    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030238286 |\n",
      "|    entropy_loss       | -2.33       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.124      |\n",
      "|    mean_step_reward   | 0.017979415 |\n",
      "|    n_updates          | 112/128     |\n",
      "|    policyGradLoss     | -0.0245     |\n",
      "|    value_loss         | 0.0288      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 771          |\n",
      "|    iterations         | 30           |\n",
      "|    time_elapsed       | 318          |\n",
      "|    total_timesteps    | 50053120     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.01908496   |\n",
      "|    entropy_loss       | -2.31        |\n",
      "|    explained_variance | 0.862        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0942      |\n",
      "|    mean_step_reward   | 0.0118535105 |\n",
      "|    n_updates          | 116/128      |\n",
      "|    policyGradLoss     | -0.0161      |\n",
      "|    value_loss         | 0.137        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 329         |\n",
      "|    total_timesteps    | 50061312    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021676224 |\n",
      "|    entropy_loss       | -2.16       |\n",
      "|    explained_variance | 0.858       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0132     |\n",
      "|    mean_step_reward   | 0.02462147  |\n",
      "|    n_updates          | 120/128     |\n",
      "|    policyGradLoss     | -0.015      |\n",
      "|    value_loss         | 0.486       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 340         |\n",
      "|    total_timesteps    | 50069504    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029874831 |\n",
      "|    entropy_loss       | -2.14       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0984     |\n",
      "|    mean_step_reward   | 0.054855075 |\n",
      "|    n_updates          | 124/128     |\n",
      "|    policyGradLoss     | -0.0225     |\n",
      "|    value_loss         | 0.108       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/NoArti_190.zip\n",
      "[EVAL] Mean Return: 32.730, Best Return: 34.730\n",
      "Saved video to ./runs_smw/videos/NoArti/NoArti_190_32.73.mp4\n",
      "\n",
      "=== Round 192 | Learn 262144 steps (Total trained: 50069504) ===\n",
      "Logging to ./runs_smw/tb/NoArti_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1105     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 50077696 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 907         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 50085888    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026195016 |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.937       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.113      |\n",
      "|    mean_step_reward   | 0.013022039 |\n",
      "|    n_updates          | 4/128       |\n",
      "|    policyGradLoss     | -0.0216     |\n",
      "|    value_loss         | 0.126       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 863         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 50094080    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025145575 |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.945       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.105      |\n",
      "|    mean_step_reward   | 0.028763255 |\n",
      "|    n_updates          | 8/128       |\n",
      "|    policyGradLoss     | -0.0192     |\n",
      "|    value_loss         | 0.138       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 834         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 50102272    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028280169 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.107      |\n",
      "|    mean_step_reward   | 0.033998832 |\n",
      "|    n_updates          | 12/128      |\n",
      "|    policyGradLoss     | -0.0183     |\n",
      "|    value_loss         | 0.0643      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 821         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 49          |\n",
      "|    total_timesteps    | 50110464    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021060795 |\n",
      "|    entropy_loss       | -2.27       |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0586     |\n",
      "|    mean_step_reward   | 0.028127104 |\n",
      "|    n_updates          | 16/128      |\n",
      "|    policyGradLoss     | -0.0128     |\n",
      "|    value_loss         | 0.21        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 60          |\n",
      "|    total_timesteps    | 50118656    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01762734  |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.882       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0723     |\n",
      "|    mean_step_reward   | 0.010493088 |\n",
      "|    n_updates          | 20/128      |\n",
      "|    policyGradLoss     | -0.0157     |\n",
      "|    value_loss         | 0.217       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 803         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 71          |\n",
      "|    total_timesteps    | 50126848    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018817049 |\n",
      "|    entropy_loss       | -2.2        |\n",
      "|    explained_variance | 0.916       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0787     |\n",
      "|    mean_step_reward   | 0.037791282 |\n",
      "|    n_updates          | 24/128      |\n",
      "|    policyGradLoss     | -0.0152     |\n",
      "|    value_loss         | 0.237       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 794         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 82          |\n",
      "|    total_timesteps    | 50135040    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019751884 |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.908       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0633     |\n",
      "|    mean_step_reward   | 0.027816204 |\n",
      "|    n_updates          | 28/128      |\n",
      "|    policyGradLoss     | -0.0205     |\n",
      "|    value_loss         | 0.234       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 792         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 93          |\n",
      "|    total_timesteps    | 50143232    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025524482 |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.108      |\n",
      "|    mean_step_reward   | 0.025849713 |\n",
      "|    n_updates          | 32/128      |\n",
      "|    policyGradLoss     | -0.0235     |\n",
      "|    value_loss         | 0.0716      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 103         |\n",
      "|    total_timesteps    | 50151424    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024431333 |\n",
      "|    entropy_loss       | -2.33       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.116      |\n",
      "|    mean_step_reward   | 0.018611288 |\n",
      "|    n_updates          | 36/128      |\n",
      "|    policyGradLoss     | -0.0211     |\n",
      "|    value_loss         | 0.0472      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 114         |\n",
      "|    total_timesteps    | 50159616    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018223792 |\n",
      "|    entropy_loss       | -2.29       |\n",
      "|    explained_variance | 0.871       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0494     |\n",
      "|    mean_step_reward   | 0.010905778 |\n",
      "|    n_updates          | 40/128      |\n",
      "|    policyGradLoss     | -0.0154     |\n",
      "|    value_loss         | 0.194       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 125         |\n",
      "|    total_timesteps    | 50167808    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016192859 |\n",
      "|    entropy_loss       | -2.17       |\n",
      "|    explained_variance | 0.924       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0164     |\n",
      "|    mean_step_reward   | 0.030736392 |\n",
      "|    n_updates          | 44/128      |\n",
      "|    policyGradLoss     | -0.0142     |\n",
      "|    value_loss         | 0.406       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 136         |\n",
      "|    total_timesteps    | 50176000    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018823547 |\n",
      "|    entropy_loss       | -2.17       |\n",
      "|    explained_variance | 0.878       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0588     |\n",
      "|    mean_step_reward   | 0.017769221 |\n",
      "|    n_updates          | 48/128      |\n",
      "|    policyGradLoss     | -0.0149     |\n",
      "|    value_loss         | 0.37        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 146         |\n",
      "|    total_timesteps    | 50184192    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025827363 |\n",
      "|    entropy_loss       | -2.2        |\n",
      "|    explained_variance | 0.915       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.038      |\n",
      "|    mean_step_reward   | 0.028230054 |\n",
      "|    n_updates          | 52/128      |\n",
      "|    policyGradLoss     | -0.0199     |\n",
      "|    value_loss         | 0.247       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 157         |\n",
      "|    total_timesteps    | 50192384    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.032479517 |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.119      |\n",
      "|    mean_step_reward   | 0.022656929 |\n",
      "|    n_updates          | 56/128      |\n",
      "|    policyGradLoss     | -0.0239     |\n",
      "|    value_loss         | 0.0686      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 168         |\n",
      "|    total_timesteps    | 50200576    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025814516 |\n",
      "|    entropy_loss       | -2.19       |\n",
      "|    explained_variance | 0.897       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0809     |\n",
      "|    mean_step_reward   | 0.035943303 |\n",
      "|    n_updates          | 60/128      |\n",
      "|    policyGradLoss     | -0.0109     |\n",
      "|    value_loss         | 0.265       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 179         |\n",
      "|    total_timesteps    | 50208768    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029210012 |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0938     |\n",
      "|    mean_step_reward   | 0.03285516  |\n",
      "|    n_updates          | 64/128      |\n",
      "|    policyGradLoss     | -0.0186     |\n",
      "|    value_loss         | 0.0914      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 190         |\n",
      "|    total_timesteps    | 50216960    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020004433 |\n",
      "|    entropy_loss       | -2.29       |\n",
      "|    explained_variance | 0.707       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0616     |\n",
      "|    mean_step_reward   | 0.004743453 |\n",
      "|    n_updates          | 68/128      |\n",
      "|    policyGradLoss     | -0.0126     |\n",
      "|    value_loss         | 0.275       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 200         |\n",
      "|    total_timesteps    | 50225152    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018222336 |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.919       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0718     |\n",
      "|    mean_step_reward   | 0.026483845 |\n",
      "|    n_updates          | 72/128      |\n",
      "|    policyGradLoss     | -0.0146     |\n",
      "|    value_loss         | 0.307       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 211         |\n",
      "|    total_timesteps    | 50233344    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01887934  |\n",
      "|    entropy_loss       | -2.19       |\n",
      "|    explained_variance | 0.911       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.021      |\n",
      "|    mean_step_reward   | 0.030300293 |\n",
      "|    n_updates          | 76/128      |\n",
      "|    policyGradLoss     | -0.0134     |\n",
      "|    value_loss         | 0.323       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 222         |\n",
      "|    total_timesteps    | 50241536    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027191347 |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.909       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0974     |\n",
      "|    mean_step_reward   | 0.023771573 |\n",
      "|    n_updates          | 80/128      |\n",
      "|    policyGradLoss     | -0.0202     |\n",
      "|    value_loss         | 0.105       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 233         |\n",
      "|    total_timesteps    | 50249728    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017213222 |\n",
      "|    entropy_loss       | -2.2        |\n",
      "|    explained_variance | 0.936       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0696     |\n",
      "|    mean_step_reward   | 0.023069669 |\n",
      "|    n_updates          | 84/128      |\n",
      "|    policyGradLoss     | -0.0159     |\n",
      "|    value_loss         | 0.287       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 244         |\n",
      "|    total_timesteps    | 50257920    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024529792 |\n",
      "|    entropy_loss       | -2.18       |\n",
      "|    explained_variance | 0.923       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0713     |\n",
      "|    mean_step_reward   | 0.03273516  |\n",
      "|    n_updates          | 88/128      |\n",
      "|    policyGradLoss     | -0.0198     |\n",
      "|    value_loss         | 0.208       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 254         |\n",
      "|    total_timesteps    | 50266112    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020223763 |\n",
      "|    entropy_loss       | -2.28       |\n",
      "|    explained_variance | 0.924       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.101      |\n",
      "|    mean_step_reward   | 0.016861146 |\n",
      "|    n_updates          | 92/128      |\n",
      "|    policyGradLoss     | -0.016      |\n",
      "|    value_loss         | 0.123       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 265         |\n",
      "|    total_timesteps    | 50274304    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022638928 |\n",
      "|    entropy_loss       | -2.27       |\n",
      "|    explained_variance | 0.945       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0978     |\n",
      "|    mean_step_reward   | 0.027834166 |\n",
      "|    n_updates          | 96/128      |\n",
      "|    policyGradLoss     | -0.0177     |\n",
      "|    value_loss         | 0.116       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 276         |\n",
      "|    total_timesteps    | 50282496    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024175163 |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.108      |\n",
      "|    mean_step_reward   | 0.020345144 |\n",
      "|    n_updates          | 100/128     |\n",
      "|    policyGradLoss     | -0.0224     |\n",
      "|    value_loss         | 0.0549      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 287         |\n",
      "|    total_timesteps    | 50290688    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024289045 |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.935       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.076      |\n",
      "|    mean_step_reward   | 0.02401163  |\n",
      "|    n_updates          | 104/128     |\n",
      "|    policyGradLoss     | -0.0153     |\n",
      "|    value_loss         | 0.198       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 298         |\n",
      "|    total_timesteps    | 50298880    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023145556 |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.932       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0813     |\n",
      "|    mean_step_reward   | 0.031159934 |\n",
      "|    n_updates          | 108/128     |\n",
      "|    policyGradLoss     | -0.0151     |\n",
      "|    value_loss         | 0.181       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 308         |\n",
      "|    total_timesteps    | 50307072    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023381315 |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.951       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0997     |\n",
      "|    mean_step_reward   | 0.030310398 |\n",
      "|    n_updates          | 112/128     |\n",
      "|    policyGradLoss     | -0.0164     |\n",
      "|    value_loss         | 0.211       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 319         |\n",
      "|    total_timesteps    | 50315264    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021359444 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0943     |\n",
      "|    mean_step_reward   | 0.02590268  |\n",
      "|    n_updates          | 116/128     |\n",
      "|    policyGradLoss     | -0.017      |\n",
      "|    value_loss         | 0.102       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 330         |\n",
      "|    total_timesteps    | 50323456    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021643221 |\n",
      "|    entropy_loss       | -2.28       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.103      |\n",
      "|    mean_step_reward   | 0.01842885  |\n",
      "|    n_updates          | 120/128     |\n",
      "|    policyGradLoss     | -0.0197     |\n",
      "|    value_loss         | 0.0739      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 341         |\n",
      "|    total_timesteps    | 50331648    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021659525 |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.939       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0878     |\n",
      "|    mean_step_reward   | 0.02626196  |\n",
      "|    n_updates          | 124/128     |\n",
      "|    policyGradLoss     | -0.0166     |\n",
      "|    value_loss         | 0.146       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/NoArti_191.zip\n",
      "[EVAL] Mean Return: -57.527, Best Return: -55.515\n",
      "Saved video to ./runs_smw/videos/NoArti/NoArti_191_-57.53.mp4\n",
      "\n",
      "=== Round 193 | Learn 262144 steps (Total trained: 50331648) ===\n",
      "Logging to ./runs_smw/tb/NoArti_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1119     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 50339840 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 905         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 50348032    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029093191 |\n",
      "|    entropy_loss       | -2.14       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.087      |\n",
      "|    mean_step_reward   | 0.040694997 |\n",
      "|    n_updates          | 4/128       |\n",
      "|    policyGradLoss     | -0.0229     |\n",
      "|    value_loss         | 0.12        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 849         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 50356224    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.033687823 |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0465     |\n",
      "|    mean_step_reward   | 0.03783142  |\n",
      "|    n_updates          | 8/128       |\n",
      "|    policyGradLoss     | -0.0209     |\n",
      "|    value_loss         | 0.0945      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 821         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 50364416    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02488495  |\n",
      "|    entropy_loss       | -2.28       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0899     |\n",
      "|    mean_step_reward   | 0.021418493 |\n",
      "|    n_updates          | 12/128      |\n",
      "|    policyGradLoss     | -0.0151     |\n",
      "|    value_loss         | 0.107       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 50          |\n",
      "|    total_timesteps    | 50372608    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028436    |\n",
      "|    entropy_loss       | -2.27       |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.114      |\n",
      "|    mean_step_reward   | 0.013915764 |\n",
      "|    n_updates          | 16/128      |\n",
      "|    policyGradLoss     | -0.023      |\n",
      "|    value_loss         | 0.0511      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 800         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 61          |\n",
      "|    total_timesteps    | 50380800    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026435953 |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0892     |\n",
      "|    mean_step_reward   | 0.027994998 |\n",
      "|    n_updates          | 20/128      |\n",
      "|    policyGradLoss     | -0.0151     |\n",
      "|    value_loss         | 0.103       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 796         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 72          |\n",
      "|    total_timesteps    | 50388992    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023798391 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.089      |\n",
      "|    mean_step_reward   | 0.024160534 |\n",
      "|    n_updates          | 24/128      |\n",
      "|    policyGradLoss     | -0.0166     |\n",
      "|    value_loss         | 0.123       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 790         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 82          |\n",
      "|    total_timesteps    | 50397184    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025016906 |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.944       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0573     |\n",
      "|    mean_step_reward   | 0.024086267 |\n",
      "|    n_updates          | 28/128      |\n",
      "|    policyGradLoss     | -0.0163     |\n",
      "|    value_loss         | 0.207       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 93          |\n",
      "|    total_timesteps    | 50405376    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026497923 |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.936       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.106      |\n",
      "|    mean_step_reward   | 0.021466263 |\n",
      "|    n_updates          | 32/128      |\n",
      "|    policyGradLoss     | -0.0202     |\n",
      "|    value_loss         | 0.12        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 104         |\n",
      "|    total_timesteps    | 50413568    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021960538 |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.924       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0553     |\n",
      "|    mean_step_reward   | 0.010771314 |\n",
      "|    n_updates          | 36/128      |\n",
      "|    policyGradLoss     | -0.0178     |\n",
      "|    value_loss         | 0.231       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 114         |\n",
      "|    total_timesteps    | 50421760    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.03784639  |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.12       |\n",
      "|    mean_step_reward   | 0.027961567 |\n",
      "|    n_updates          | 40/128      |\n",
      "|    policyGradLoss     | -0.0261     |\n",
      "|    value_loss         | 0.0418      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 125         |\n",
      "|    total_timesteps    | 50429952    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019544685 |\n",
      "|    entropy_loss       | -2.29       |\n",
      "|    explained_variance | 0.93        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.102      |\n",
      "|    mean_step_reward   | 0.012555892 |\n",
      "|    n_updates          | 44/128      |\n",
      "|    policyGradLoss     | -0.0135     |\n",
      "|    value_loss         | 0.178       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 136         |\n",
      "|    total_timesteps    | 50438144    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02927722  |\n",
      "|    entropy_loss       | -2.28       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.101      |\n",
      "|    mean_step_reward   | 0.023012683 |\n",
      "|    n_updates          | 48/128      |\n",
      "|    policyGradLoss     | -0.0153     |\n",
      "|    value_loss         | 0.065       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 778          |\n",
      "|    iterations         | 14           |\n",
      "|    time_elapsed       | 147          |\n",
      "|    total_timesteps    | 50446336     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.014341201  |\n",
      "|    entropy_loss       | -2.32        |\n",
      "|    explained_variance | 0.899        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0884      |\n",
      "|    mean_step_reward   | 0.0061160317 |\n",
      "|    n_updates          | 52/128       |\n",
      "|    policyGradLoss     | -0.0119      |\n",
      "|    value_loss         | 0.155        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 158         |\n",
      "|    total_timesteps    | 50454528    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014366439 |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.934       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00255     |\n",
      "|    mean_step_reward   | 0.012710286 |\n",
      "|    n_updates          | 56/128      |\n",
      "|    policyGradLoss     | -0.0133     |\n",
      "|    value_loss         | 0.294       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 168         |\n",
      "|    total_timesteps    | 50462720    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.03545545  |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.108      |\n",
      "|    mean_step_reward   | 0.040339906 |\n",
      "|    n_updates          | 60/128      |\n",
      "|    policyGradLoss     | -0.0197     |\n",
      "|    value_loss         | 0.0817      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 179         |\n",
      "|    total_timesteps    | 50470912    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022811212 |\n",
      "|    entropy_loss       | -2.32       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.103      |\n",
      "|    mean_step_reward   | 0.012920058 |\n",
      "|    n_updates          | 64/128      |\n",
      "|    policyGradLoss     | -0.0145     |\n",
      "|    value_loss         | 0.0616      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 190         |\n",
      "|    total_timesteps    | 50479104    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019838208 |\n",
      "|    entropy_loss       | -2.27       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0784     |\n",
      "|    mean_step_reward   | 0.014659008 |\n",
      "|    n_updates          | 68/128      |\n",
      "|    policyGradLoss     | -0.0164     |\n",
      "|    value_loss         | 0.0889      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 201         |\n",
      "|    total_timesteps    | 50487296    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016765902 |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.849       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0784      |\n",
      "|    mean_step_reward   | 0.014043011 |\n",
      "|    n_updates          | 72/128      |\n",
      "|    policyGradLoss     | -0.0109     |\n",
      "|    value_loss         | 0.718       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 212         |\n",
      "|    total_timesteps    | 50495488    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.03051261  |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.104      |\n",
      "|    mean_step_reward   | 0.038198143 |\n",
      "|    n_updates          | 76/128      |\n",
      "|    policyGradLoss     | -0.0214     |\n",
      "|    value_loss         | 0.0575      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 770          |\n",
      "|    iterations         | 21           |\n",
      "|    time_elapsed       | 223          |\n",
      "|    total_timesteps    | 50503680     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.020377163  |\n",
      "|    entropy_loss       | -2.35        |\n",
      "|    explained_variance | 0.984        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.118       |\n",
      "|    mean_step_reward   | 0.0106002595 |\n",
      "|    n_updates          | 80/128       |\n",
      "|    policyGradLoss     | -0.014       |\n",
      "|    value_loss         | 0.0244       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 770           |\n",
      "|    iterations         | 22            |\n",
      "|    time_elapsed       | 233           |\n",
      "|    total_timesteps    | 50511872      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.015721854   |\n",
      "|    entropy_loss       | -2.38         |\n",
      "|    explained_variance | 0.924         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.1          |\n",
      "|    mean_step_reward   | -0.0027275933 |\n",
      "|    n_updates          | 84/128        |\n",
      "|    policyGradLoss     | -0.0111       |\n",
      "|    value_loss         | 0.0351        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 244         |\n",
      "|    total_timesteps    | 50520064    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020623256 |\n",
      "|    entropy_loss       | -2.27       |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0787     |\n",
      "|    mean_step_reward   | 0.020251788 |\n",
      "|    n_updates          | 88/128      |\n",
      "|    policyGradLoss     | -0.014      |\n",
      "|    value_loss         | 0.152       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 255         |\n",
      "|    total_timesteps    | 50528256    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02464008  |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.958       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.103      |\n",
      "|    mean_step_reward   | 0.034721076 |\n",
      "|    n_updates          | 92/128      |\n",
      "|    policyGradLoss     | -0.0153     |\n",
      "|    value_loss         | 0.0804      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 770          |\n",
      "|    iterations         | 25           |\n",
      "|    time_elapsed       | 265          |\n",
      "|    total_timesteps    | 50536448     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.020780392  |\n",
      "|    entropy_loss       | -2.26        |\n",
      "|    explained_variance | 0.935        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0866      |\n",
      "|    mean_step_reward   | 0.0121934265 |\n",
      "|    n_updates          | 96/128       |\n",
      "|    policyGradLoss     | -0.0146      |\n",
      "|    value_loss         | 0.185        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 276         |\n",
      "|    total_timesteps    | 50544640    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020583348 |\n",
      "|    entropy_loss       | -2.27       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.103      |\n",
      "|    mean_step_reward   | 0.014733636 |\n",
      "|    n_updates          | 100/128     |\n",
      "|    policyGradLoss     | -0.0174     |\n",
      "|    value_loss         | 0.0785      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 287         |\n",
      "|    total_timesteps    | 50552832    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02402278  |\n",
      "|    entropy_loss       | -2.17       |\n",
      "|    explained_variance | 0.898       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0499     |\n",
      "|    mean_step_reward   | 0.020135675 |\n",
      "|    n_updates          | 104/128     |\n",
      "|    policyGradLoss     | -0.0173     |\n",
      "|    value_loss         | 0.179       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 298         |\n",
      "|    total_timesteps    | 50561024    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017570011 |\n",
      "|    entropy_loss       | -2.1        |\n",
      "|    explained_variance | 0.933       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0396     |\n",
      "|    mean_step_reward   | 0.056699235 |\n",
      "|    n_updates          | 108/128     |\n",
      "|    policyGradLoss     | -0.0149     |\n",
      "|    value_loss         | 0.302       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 309         |\n",
      "|    total_timesteps    | 50569216    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027032979 |\n",
      "|    entropy_loss       | -2.17       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0776     |\n",
      "|    mean_step_reward   | 0.04321123  |\n",
      "|    n_updates          | 112/128     |\n",
      "|    policyGradLoss     | -0.0204     |\n",
      "|    value_loss         | 0.124       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 767          |\n",
      "|    iterations         | 30           |\n",
      "|    time_elapsed       | 320          |\n",
      "|    total_timesteps    | 50577408     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.015247882  |\n",
      "|    entropy_loss       | -2.22        |\n",
      "|    explained_variance | 0.912        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0635      |\n",
      "|    mean_step_reward   | 0.0153626315 |\n",
      "|    n_updates          | 116/128      |\n",
      "|    policyGradLoss     | -0.0149      |\n",
      "|    value_loss         | 0.243        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 330         |\n",
      "|    total_timesteps    | 50585600    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027919702 |\n",
      "|    entropy_loss       | -2.29       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.108      |\n",
      "|    mean_step_reward   | 0.020282991 |\n",
      "|    n_updates          | 120/128     |\n",
      "|    policyGradLoss     | -0.0211     |\n",
      "|    value_loss         | 0.075       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 341         |\n",
      "|    total_timesteps    | 50593792    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026829964 |\n",
      "|    entropy_loss       | -2.3        |\n",
      "|    explained_variance | 0.945       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.103      |\n",
      "|    mean_step_reward   | 0.018688597 |\n",
      "|    n_updates          | 124/128     |\n",
      "|    policyGradLoss     | -0.0193     |\n",
      "|    value_loss         | 0.0467      |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/NoArti_192.zip\n",
      "[EVAL] Mean Return: 69.661, Best Return: 71.661\n",
      "Saved video to ./runs_smw/videos/NoArti/NoArti_192_69.66.mp4\n",
      "\n",
      "=== Round 194 | Learn 262144 steps (Total trained: 50593792) ===\n",
      "Logging to ./runs_smw/tb/NoArti_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1152     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 50601984 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 925         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 50610176    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022211557 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.926       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0885     |\n",
      "|    mean_step_reward   | 0.018936537 |\n",
      "|    n_updates          | 4/128       |\n",
      "|    policyGradLoss     | -0.0139     |\n",
      "|    value_loss         | 0.187       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 855         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 50618368    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015116827 |\n",
      "|    entropy_loss       | -2.18       |\n",
      "|    explained_variance | 0.915       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0711     |\n",
      "|    mean_step_reward   | 0.015385833 |\n",
      "|    n_updates          | 8/128       |\n",
      "|    policyGradLoss     | -0.0184     |\n",
      "|    value_loss         | 0.188       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 834         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 50626560    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015783858 |\n",
      "|    entropy_loss       | -2.19       |\n",
      "|    explained_variance | 0.776       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0809     |\n",
      "|    mean_step_reward   | 0.034668516 |\n",
      "|    n_updates          | 12/128      |\n",
      "|    policyGradLoss     | -0.0132     |\n",
      "|    value_loss         | 0.284       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 818         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 50          |\n",
      "|    total_timesteps    | 50634752    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021698259 |\n",
      "|    entropy_loss       | -2.31       |\n",
      "|    explained_variance | 0.912       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00297    |\n",
      "|    mean_step_reward   | 0.01992279  |\n",
      "|    n_updates          | 16/128      |\n",
      "|    policyGradLoss     | -0.0127     |\n",
      "|    value_loss         | 0.248       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 809          |\n",
      "|    iterations         | 6            |\n",
      "|    time_elapsed       | 60           |\n",
      "|    total_timesteps    | 50642944     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.018244095  |\n",
      "|    entropy_loss       | -2.27        |\n",
      "|    explained_variance | 0.866        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.103       |\n",
      "|    mean_step_reward   | 0.0077551696 |\n",
      "|    n_updates          | 20/128       |\n",
      "|    policyGradLoss     | -0.0122      |\n",
      "|    value_loss         | 0.11         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 803         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 71          |\n",
      "|    total_timesteps    | 50651136    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020895045 |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.862       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.104      |\n",
      "|    mean_step_reward   | 0.018483307 |\n",
      "|    n_updates          | 24/128      |\n",
      "|    policyGradLoss     | -0.0174     |\n",
      "|    value_loss         | 0.144       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 797         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 82          |\n",
      "|    total_timesteps    | 50659328    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016754255 |\n",
      "|    entropy_loss       | -2.2        |\n",
      "|    explained_variance | 0.91        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0708     |\n",
      "|    mean_step_reward   | 0.023506207 |\n",
      "|    n_updates          | 28/128      |\n",
      "|    policyGradLoss     | -0.0152     |\n",
      "|    value_loss         | 0.326       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 791         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 93          |\n",
      "|    total_timesteps    | 50667520    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022385951 |\n",
      "|    entropy_loss       | -2.14       |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0443     |\n",
      "|    mean_step_reward   | 0.04922896  |\n",
      "|    n_updates          | 32/128      |\n",
      "|    policyGradLoss     | -0.0176     |\n",
      "|    value_loss         | 0.248       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 104         |\n",
      "|    total_timesteps    | 50675712    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023194708 |\n",
      "|    entropy_loss       | -2.11       |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.1        |\n",
      "|    mean_step_reward   | 0.03669078  |\n",
      "|    n_updates          | 36/128      |\n",
      "|    policyGradLoss     | -0.0194     |\n",
      "|    value_loss         | 0.134       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 114         |\n",
      "|    total_timesteps    | 50683904    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02081842  |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.1        |\n",
      "|    mean_step_reward   | 0.033665158 |\n",
      "|    n_updates          | 40/128      |\n",
      "|    policyGradLoss     | -0.0187     |\n",
      "|    value_loss         | 0.0819      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 125         |\n",
      "|    total_timesteps    | 50692096    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028037267 |\n",
      "|    entropy_loss       | -2.28       |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.11       |\n",
      "|    mean_step_reward   | 0.030212514 |\n",
      "|    n_updates          | 44/128      |\n",
      "|    policyGradLoss     | -0.0173     |\n",
      "|    value_loss         | 0.0859      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 136         |\n",
      "|    total_timesteps    | 50700288    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021537386 |\n",
      "|    entropy_loss       | -2.3        |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0808     |\n",
      "|    mean_step_reward   | 0.019785894 |\n",
      "|    n_updates          | 48/128      |\n",
      "|    policyGradLoss     | -0.0183     |\n",
      "|    value_loss         | 0.0715      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 147         |\n",
      "|    total_timesteps    | 50708480    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020469747 |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.91        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0901     |\n",
      "|    mean_step_reward   | 0.025649238 |\n",
      "|    n_updates          | 52/128      |\n",
      "|    policyGradLoss     | -0.0124     |\n",
      "|    value_loss         | 0.258       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 158         |\n",
      "|    total_timesteps    | 50716672    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02168398  |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0937     |\n",
      "|    mean_step_reward   | 0.030345514 |\n",
      "|    n_updates          | 56/128      |\n",
      "|    policyGradLoss     | -0.0183     |\n",
      "|    value_loss         | 0.129       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 168         |\n",
      "|    total_timesteps    | 50724864    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027608905 |\n",
      "|    entropy_loss       | -2.12       |\n",
      "|    explained_variance | 0.949       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0826     |\n",
      "|    mean_step_reward   | 0.037668634 |\n",
      "|    n_updates          | 60/128      |\n",
      "|    policyGradLoss     | -0.0186     |\n",
      "|    value_loss         | 0.21        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 179         |\n",
      "|    total_timesteps    | 50733056    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023743752 |\n",
      "|    entropy_loss       | -2.12       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.089      |\n",
      "|    mean_step_reward   | 0.047409456 |\n",
      "|    n_updates          | 64/128      |\n",
      "|    policyGradLoss     | -0.0181     |\n",
      "|    value_loss         | 0.186       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 190         |\n",
      "|    total_timesteps    | 50741248    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024061447 |\n",
      "|    entropy_loss       | -2.13       |\n",
      "|    explained_variance | 0.935       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0736     |\n",
      "|    mean_step_reward   | 0.046038806 |\n",
      "|    n_updates          | 68/128      |\n",
      "|    policyGradLoss     | -0.0172     |\n",
      "|    value_loss         | 0.299       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 200         |\n",
      "|    total_timesteps    | 50749440    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025281847 |\n",
      "|    entropy_loss       | -2.08       |\n",
      "|    explained_variance | 0.857       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00206    |\n",
      "|    mean_step_reward   | 0.037327714 |\n",
      "|    n_updates          | 72/128      |\n",
      "|    policyGradLoss     | -0.0119     |\n",
      "|    value_loss         | 0.537       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 211         |\n",
      "|    total_timesteps    | 50757632    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024609422 |\n",
      "|    entropy_loss       | -2.12       |\n",
      "|    explained_variance | 0.931       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0881     |\n",
      "|    mean_step_reward   | 0.044532962 |\n",
      "|    n_updates          | 76/128      |\n",
      "|    policyGradLoss     | -0.0181     |\n",
      "|    value_loss         | 0.227       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 222         |\n",
      "|    total_timesteps    | 50765824    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028729301 |\n",
      "|    entropy_loss       | -2.15       |\n",
      "|    explained_variance | 0.887       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0448     |\n",
      "|    mean_step_reward   | 0.030592423 |\n",
      "|    n_updates          | 80/128      |\n",
      "|    policyGradLoss     | -0.017      |\n",
      "|    value_loss         | 0.457       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 233         |\n",
      "|    total_timesteps    | 50774016    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02056323  |\n",
      "|    entropy_loss       | -2.18       |\n",
      "|    explained_variance | 0.888       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0469     |\n",
      "|    mean_step_reward   | 0.025394807 |\n",
      "|    n_updates          | 84/128      |\n",
      "|    policyGradLoss     | -0.0136     |\n",
      "|    value_loss         | 0.339       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 244         |\n",
      "|    total_timesteps    | 50782208    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01696055  |\n",
      "|    entropy_loss       | -2.3        |\n",
      "|    explained_variance | 0.717       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0968     |\n",
      "|    mean_step_reward   | 0.018742645 |\n",
      "|    n_updates          | 88/128      |\n",
      "|    policyGradLoss     | -0.0128     |\n",
      "|    value_loss         | 0.211       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 255         |\n",
      "|    total_timesteps    | 50790400    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01660401  |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.902       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0181     |\n",
      "|    mean_step_reward   | 0.020026628 |\n",
      "|    n_updates          | 92/128      |\n",
      "|    policyGradLoss     | -0.0161     |\n",
      "|    value_loss         | 0.288       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 266         |\n",
      "|    total_timesteps    | 50798592    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017659206 |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.882       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00941     |\n",
      "|    mean_step_reward   | 0.014440414 |\n",
      "|    n_updates          | 96/128      |\n",
      "|    policyGradLoss     | -0.0161     |\n",
      "|    value_loss         | 0.27        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 277         |\n",
      "|    total_timesteps    | 50806784    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019201096 |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.897       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0982     |\n",
      "|    mean_step_reward   | 0.015435698 |\n",
      "|    n_updates          | 100/128     |\n",
      "|    policyGradLoss     | -0.0201     |\n",
      "|    value_loss         | 0.223       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 287         |\n",
      "|    total_timesteps    | 50814976    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026211074 |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.954       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.115      |\n",
      "|    mean_step_reward   | 0.024222579 |\n",
      "|    n_updates          | 104/128     |\n",
      "|    policyGradLoss     | -0.0229     |\n",
      "|    value_loss         | 0.0926      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 298         |\n",
      "|    total_timesteps    | 50823168    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020241525 |\n",
      "|    entropy_loss       | -2.28       |\n",
      "|    explained_variance | 0.945       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.102      |\n",
      "|    mean_step_reward   | 0.018816981 |\n",
      "|    n_updates          | 108/128     |\n",
      "|    policyGradLoss     | -0.0167     |\n",
      "|    value_loss         | 0.12        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 309         |\n",
      "|    total_timesteps    | 50831360    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018510243 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.944       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0791     |\n",
      "|    mean_step_reward   | 0.022890909 |\n",
      "|    n_updates          | 112/128     |\n",
      "|    policyGradLoss     | -0.017      |\n",
      "|    value_loss         | 0.202       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 320         |\n",
      "|    total_timesteps    | 50839552    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019656278 |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.941       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.096      |\n",
      "|    mean_step_reward   | 0.015680907 |\n",
      "|    n_updates          | 116/128     |\n",
      "|    policyGradLoss     | -0.0197     |\n",
      "|    value_loss         | 0.18        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 330         |\n",
      "|    total_timesteps    | 50847744    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023955625 |\n",
      "|    entropy_loss       | -2.19       |\n",
      "|    explained_variance | 0.949       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.093      |\n",
      "|    mean_step_reward   | 0.039540246 |\n",
      "|    n_updates          | 120/128     |\n",
      "|    policyGradLoss     | -0.0213     |\n",
      "|    value_loss         | 0.179       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 341         |\n",
      "|    total_timesteps    | 50855936    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021621363 |\n",
      "|    entropy_loss       | -2.28       |\n",
      "|    explained_variance | 0.949       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0913     |\n",
      "|    mean_step_reward   | 0.037296712 |\n",
      "|    n_updates          | 124/128     |\n",
      "|    policyGradLoss     | -0.0172     |\n",
      "|    value_loss         | 0.129       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/NoArti_193.zip\n",
      "[EVAL] Mean Return: -66.971, Best Return: -64.963\n",
      "Saved video to ./runs_smw/videos/NoArti/NoArti_193_-66.97.mp4\n",
      "\n",
      "=== Round 195 | Learn 262144 steps (Total trained: 50855936) ===\n",
      "Logging to ./runs_smw/tb/NoArti_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1113     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 50864128 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 914         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 50872320    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02605456  |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.105      |\n",
      "|    mean_step_reward   | 0.036386747 |\n",
      "|    n_updates          | 4/128       |\n",
      "|    policyGradLoss     | -0.0213     |\n",
      "|    value_loss         | 0.151       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 859         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 50880512    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028807303 |\n",
      "|    entropy_loss       | -2.34       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.119      |\n",
      "|    mean_step_reward   | 0.01566086  |\n",
      "|    n_updates          | 8/128       |\n",
      "|    policyGradLoss     | -0.021      |\n",
      "|    value_loss         | 0.0293      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 839           |\n",
      "|    iterations         | 4             |\n",
      "|    time_elapsed       | 39            |\n",
      "|    total_timesteps    | 50888704      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.014077513   |\n",
      "|    entropy_loss       | -2.4          |\n",
      "|    explained_variance | 0.864         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0881       |\n",
      "|    mean_step_reward   | -0.0005952033 |\n",
      "|    n_updates          | 12/128        |\n",
      "|    policyGradLoss     | -0.0102       |\n",
      "|    value_loss         | 0.0918        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 823          |\n",
      "|    iterations         | 5            |\n",
      "|    time_elapsed       | 49           |\n",
      "|    total_timesteps    | 50896896     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.014778247  |\n",
      "|    entropy_loss       | -2.39        |\n",
      "|    explained_variance | 0.946        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.108       |\n",
      "|    mean_step_reward   | 0.0018480527 |\n",
      "|    n_updates          | 16/128       |\n",
      "|    policyGradLoss     | -0.0163      |\n",
      "|    value_loss         | 0.0483       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 814          |\n",
      "|    iterations         | 6            |\n",
      "|    time_elapsed       | 60           |\n",
      "|    total_timesteps    | 50905088     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.020027474  |\n",
      "|    entropy_loss       | -2.3         |\n",
      "|    explained_variance | 0.913        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0723      |\n",
      "|    mean_step_reward   | 0.0061595943 |\n",
      "|    n_updates          | 20/128       |\n",
      "|    policyGradLoss     | -0.0153      |\n",
      "|    value_loss         | 0.258        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 805         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 71          |\n",
      "|    total_timesteps    | 50913280    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.032913387 |\n",
      "|    entropy_loss       | -2.29       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.118      |\n",
      "|    mean_step_reward   | 0.027174987 |\n",
      "|    n_updates          | 24/128      |\n",
      "|    policyGradLoss     | -0.0228     |\n",
      "|    value_loss         | 0.0536      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 801          |\n",
      "|    iterations         | 8            |\n",
      "|    time_elapsed       | 81           |\n",
      "|    total_timesteps    | 50921472     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.013452509  |\n",
      "|    entropy_loss       | -2.39        |\n",
      "|    explained_variance | 0.983        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.103       |\n",
      "|    mean_step_reward   | 0.0060752085 |\n",
      "|    n_updates          | 28/128       |\n",
      "|    policyGradLoss     | -0.0123      |\n",
      "|    value_loss         | 0.0232       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 798           |\n",
      "|    iterations         | 9             |\n",
      "|    time_elapsed       | 92            |\n",
      "|    total_timesteps    | 50929664      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.011245191   |\n",
      "|    entropy_loss       | -2.29         |\n",
      "|    explained_variance | 0.961         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0904       |\n",
      "|    mean_step_reward   | -0.0017651559 |\n",
      "|    n_updates          | 32/128        |\n",
      "|    policyGradLoss     | -0.0177       |\n",
      "|    value_loss         | 0.118         |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 794         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 103         |\n",
      "|    total_timesteps    | 50937856    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02829589  |\n",
      "|    entropy_loss       | -2.2        |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.107      |\n",
      "|    mean_step_reward   | 0.046285287 |\n",
      "|    n_updates          | 36/128      |\n",
      "|    policyGradLoss     | -0.0193     |\n",
      "|    value_loss         | 0.0841      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 793         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 113         |\n",
      "|    total_timesteps    | 50946048    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02964199  |\n",
      "|    entropy_loss       | -2.36       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.12       |\n",
      "|    mean_step_reward   | 0.012937669 |\n",
      "|    n_updates          | 40/128      |\n",
      "|    policyGradLoss     | -0.0165     |\n",
      "|    value_loss         | 0.013       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 789          |\n",
      "|    iterations         | 12           |\n",
      "|    time_elapsed       | 124          |\n",
      "|    total_timesteps    | 50954240     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.016859973  |\n",
      "|    entropy_loss       | -2.3         |\n",
      "|    explained_variance | 0.95         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0926      |\n",
      "|    mean_step_reward   | 0.0047166077 |\n",
      "|    n_updates          | 44/128       |\n",
      "|    policyGradLoss     | -0.0141      |\n",
      "|    value_loss         | 0.101        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 789         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 134         |\n",
      "|    total_timesteps    | 50962432    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017376974 |\n",
      "|    entropy_loss       | -2.16       |\n",
      "|    explained_variance | 0.9         |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0378      |\n",
      "|    mean_step_reward   | 0.017339893 |\n",
      "|    n_updates          | 48/128      |\n",
      "|    policyGradLoss     | -0.0134     |\n",
      "|    value_loss         | 0.452       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 788         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 145         |\n",
      "|    total_timesteps    | 50970624    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025317755 |\n",
      "|    entropy_loss       | -2.18       |\n",
      "|    explained_variance | 0.948       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0574     |\n",
      "|    mean_step_reward   | 0.037410703 |\n",
      "|    n_updates          | 52/128      |\n",
      "|    policyGradLoss     | -0.0179     |\n",
      "|    value_loss         | 0.244       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 156         |\n",
      "|    total_timesteps    | 50978816    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023447555 |\n",
      "|    entropy_loss       | -2.31       |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.103      |\n",
      "|    mean_step_reward   | 0.021714045 |\n",
      "|    n_updates          | 56/128      |\n",
      "|    policyGradLoss     | -0.0141     |\n",
      "|    value_loss         | 0.0648      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 167         |\n",
      "|    total_timesteps    | 50987008    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010389353 |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.906       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.068      |\n",
      "|    mean_step_reward   | 0.007432551 |\n",
      "|    n_updates          | 60/128      |\n",
      "|    policyGradLoss     | -0.0114     |\n",
      "|    value_loss         | 0.218       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 178         |\n",
      "|    total_timesteps    | 50995200    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027724655 |\n",
      "|    entropy_loss       | -2.17       |\n",
      "|    explained_variance | 0.941       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0843     |\n",
      "|    mean_step_reward   | 0.029694881 |\n",
      "|    n_updates          | 64/128      |\n",
      "|    policyGradLoss     | -0.0191     |\n",
      "|    value_loss         | 0.167       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 188         |\n",
      "|    total_timesteps    | 51003392    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030166753 |\n",
      "|    entropy_loss       | -2.12       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0947     |\n",
      "|    mean_step_reward   | 0.049263395 |\n",
      "|    n_updates          | 68/128      |\n",
      "|    policyGradLoss     | -0.0223     |\n",
      "|    value_loss         | 0.145       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 199         |\n",
      "|    total_timesteps    | 51011584    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019709675 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0948     |\n",
      "|    mean_step_reward   | 0.028605238 |\n",
      "|    n_updates          | 72/128      |\n",
      "|    policyGradLoss     | -0.0195     |\n",
      "|    value_loss         | 0.129       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 210         |\n",
      "|    total_timesteps    | 51019776    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030533018 |\n",
      "|    entropy_loss       | -2.31       |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.102      |\n",
      "|    mean_step_reward   | 0.013337666 |\n",
      "|    n_updates          | 76/128      |\n",
      "|    policyGradLoss     | -0.018      |\n",
      "|    value_loss         | 0.0542      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 221         |\n",
      "|    total_timesteps    | 51027968    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013857398 |\n",
      "|    entropy_loss       | -2.34       |\n",
      "|    explained_variance | 0.912       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0698     |\n",
      "|    mean_step_reward   | 0.010131082 |\n",
      "|    n_updates          | 80/128      |\n",
      "|    policyGradLoss     | -0.0127     |\n",
      "|    value_loss         | 0.191       |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 776            |\n",
      "|    iterations         | 22             |\n",
      "|    time_elapsed       | 232            |\n",
      "|    total_timesteps    | 51036160       |\n",
      "| train/                |                |\n",
      "|    approx_kl          | 0.01875233     |\n",
      "|    entropy_loss       | -2.32          |\n",
      "|    explained_variance | 0.839          |\n",
      "|    learning_rate      | 0.0001         |\n",
      "|    loss               | -0.0882        |\n",
      "|    mean_step_reward   | -0.00035129226 |\n",
      "|    n_updates          | 84/128         |\n",
      "|    policyGradLoss     | -0.015         |\n",
      "|    value_loss         | 0.137          |\n",
      "------------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 775        |\n",
      "|    iterations         | 23         |\n",
      "|    time_elapsed       | 242        |\n",
      "|    total_timesteps    | 51044352   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01686483 |\n",
      "|    entropy_loss       | -2.29      |\n",
      "|    explained_variance | 0.908      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0892    |\n",
      "|    mean_step_reward   | 0.01861881 |\n",
      "|    n_updates          | 88/128     |\n",
      "|    policyGradLoss     | -0.0162    |\n",
      "|    value_loss         | 0.163      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 253         |\n",
      "|    total_timesteps    | 51052544    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013848856 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.913       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00853    |\n",
      "|    mean_step_reward   | 0.004075125 |\n",
      "|    n_updates          | 92/128      |\n",
      "|    policyGradLoss     | -0.0171     |\n",
      "|    value_loss         | 0.296       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 264         |\n",
      "|    total_timesteps    | 51060736    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023203002 |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.899       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0925     |\n",
      "|    mean_step_reward   | 0.027118716 |\n",
      "|    n_updates          | 96/128      |\n",
      "|    policyGradLoss     | -0.0165     |\n",
      "|    value_loss         | 0.224       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 274         |\n",
      "|    total_timesteps    | 51068928    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020631898 |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.923       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0875     |\n",
      "|    mean_step_reward   | 0.022522012 |\n",
      "|    n_updates          | 100/128     |\n",
      "|    policyGradLoss     | -0.0189     |\n",
      "|    value_loss         | 0.13        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 285         |\n",
      "|    total_timesteps    | 51077120    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026558304 |\n",
      "|    entropy_loss       | -2.27       |\n",
      "|    explained_variance | 0.943       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0987     |\n",
      "|    mean_step_reward   | 0.02452138  |\n",
      "|    n_updates          | 104/128     |\n",
      "|    policyGradLoss     | -0.0161     |\n",
      "|    value_loss         | 0.139       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 296         |\n",
      "|    total_timesteps    | 51085312    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011060602 |\n",
      "|    entropy_loss       | -2.35       |\n",
      "|    explained_variance | 0.833       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0967     |\n",
      "|    mean_step_reward   | 0.009554534 |\n",
      "|    n_updates          | 108/128     |\n",
      "|    policyGradLoss     | -0.0116     |\n",
      "|    value_loss         | 0.236       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 773          |\n",
      "|    iterations         | 29           |\n",
      "|    time_elapsed       | 307          |\n",
      "|    total_timesteps    | 51093504     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.016766451  |\n",
      "|    entropy_loss       | -2.31        |\n",
      "|    explained_variance | 0.911        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0614      |\n",
      "|    mean_step_reward   | 0.0011439915 |\n",
      "|    n_updates          | 112/128      |\n",
      "|    policyGradLoss     | -0.0151      |\n",
      "|    value_loss         | 0.163        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 318         |\n",
      "|    total_timesteps    | 51101696    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022062015 |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.93        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.1        |\n",
      "|    mean_step_reward   | 0.042788573 |\n",
      "|    n_updates          | 116/128     |\n",
      "|    policyGradLoss     | -0.0122     |\n",
      "|    value_loss         | 0.189       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 328         |\n",
      "|    total_timesteps    | 51109888    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025549741 |\n",
      "|    entropy_loss       | -2.29       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.108      |\n",
      "|    mean_step_reward   | 0.021598352 |\n",
      "|    n_updates          | 120/128     |\n",
      "|    policyGradLoss     | -0.0194     |\n",
      "|    value_loss         | 0.0514      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 339         |\n",
      "|    total_timesteps    | 51118080    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018087199 |\n",
      "|    entropy_loss       | -2.29       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.107      |\n",
      "|    mean_step_reward   | 0.02078287  |\n",
      "|    n_updates          | 124/128     |\n",
      "|    policyGradLoss     | -0.0169     |\n",
      "|    value_loss         | 0.0902      |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/NoArti_194.zip\n",
      "[EVAL] Mean Return: 132.369, Best Return: 134.969\n",
      "Saved video to ./runs_smw/videos/NoArti/NoArti_194_132.37.mp4\n",
      "\n",
      "=== Round 196 | Learn 262144 steps (Total trained: 51118080) ===\n",
      "Logging to ./runs_smw/tb/NoArti_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1149     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 51126272 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 907         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 51134464    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.03319686  |\n",
      "|    entropy_loss       | -2.17       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0851     |\n",
      "|    mean_step_reward   | 0.050812494 |\n",
      "|    n_updates          | 4/128       |\n",
      "|    policyGradLoss     | -0.0223     |\n",
      "|    value_loss         | 0.117       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 849         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 51142656    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023110041 |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.942       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.109      |\n",
      "|    mean_step_reward   | 0.015796922 |\n",
      "|    n_updates          | 8/128       |\n",
      "|    policyGradLoss     | -0.015      |\n",
      "|    value_loss         | 0.0912      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 827         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 51150848    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021747883 |\n",
      "|    entropy_loss       | -2.12       |\n",
      "|    explained_variance | 0.919       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0762     |\n",
      "|    mean_step_reward   | 0.026398527 |\n",
      "|    n_updates          | 12/128      |\n",
      "|    policyGradLoss     | -0.0149     |\n",
      "|    value_loss         | 0.376       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 814        |\n",
      "|    iterations         | 5          |\n",
      "|    time_elapsed       | 50         |\n",
      "|    total_timesteps    | 51159040   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02376106 |\n",
      "|    entropy_loss       | -2.17      |\n",
      "|    explained_variance | 0.969      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.095     |\n",
      "|    mean_step_reward   | 0.04392167 |\n",
      "|    n_updates          | 16/128     |\n",
      "|    policyGradLoss     | -0.0218    |\n",
      "|    value_loss         | 0.121      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 802         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 61          |\n",
      "|    total_timesteps    | 51167232    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027387643 |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0884     |\n",
      "|    mean_step_reward   | 0.038163815 |\n",
      "|    n_updates          | 20/128      |\n",
      "|    policyGradLoss     | -0.0221     |\n",
      "|    value_loss         | 0.127       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 796         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 72          |\n",
      "|    total_timesteps    | 51175424    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024456676 |\n",
      "|    entropy_loss       | -2.32       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.117      |\n",
      "|    mean_step_reward   | 0.013795628 |\n",
      "|    n_updates          | 24/128      |\n",
      "|    policyGradLoss     | -0.0229     |\n",
      "|    value_loss         | 0.0291      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 789         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 82          |\n",
      "|    total_timesteps    | 51183616    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01717005  |\n",
      "|    entropy_loss       | -2.28       |\n",
      "|    explained_variance | 0.925       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0311     |\n",
      "|    mean_step_reward   | 0.012227293 |\n",
      "|    n_updates          | 28/128      |\n",
      "|    policyGradLoss     | -0.0117     |\n",
      "|    value_loss         | 0.197       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 93          |\n",
      "|    total_timesteps    | 51191808    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021085465 |\n",
      "|    entropy_loss       | -2.27       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.1        |\n",
      "|    mean_step_reward   | 0.023903856 |\n",
      "|    n_updates          | 32/128      |\n",
      "|    policyGradLoss     | -0.0164     |\n",
      "|    value_loss         | 0.0876      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 105         |\n",
      "|    total_timesteps    | 51200000    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024313986 |\n",
      "|    entropy_loss       | -2.2        |\n",
      "|    explained_variance | 0.913       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0876     |\n",
      "|    mean_step_reward   | 0.024373945 |\n",
      "|    n_updates          | 36/128      |\n",
      "|    policyGradLoss     | -0.015      |\n",
      "|    value_loss         | 0.237       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 115         |\n",
      "|    total_timesteps    | 51208192    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018963385 |\n",
      "|    entropy_loss       | -2.07       |\n",
      "|    explained_variance | 0.924       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0679     |\n",
      "|    mean_step_reward   | 0.051442713 |\n",
      "|    n_updates          | 40/128      |\n",
      "|    policyGradLoss     | -0.0147     |\n",
      "|    value_loss         | 0.348       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 126         |\n",
      "|    total_timesteps    | 51216384    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023766413 |\n",
      "|    entropy_loss       | -2.16       |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0942     |\n",
      "|    mean_step_reward   | 0.044771083 |\n",
      "|    n_updates          | 44/128      |\n",
      "|    policyGradLoss     | -0.0194     |\n",
      "|    value_loss         | 0.138       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 137         |\n",
      "|    total_timesteps    | 51224576    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021131963 |\n",
      "|    entropy_loss       | -2.29       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.106      |\n",
      "|    mean_step_reward   | 0.022134498 |\n",
      "|    n_updates          | 48/128      |\n",
      "|    policyGradLoss     | -0.0191     |\n",
      "|    value_loss         | 0.0793      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 772          |\n",
      "|    iterations         | 14           |\n",
      "|    time_elapsed       | 148          |\n",
      "|    total_timesteps    | 51232768     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.02171514   |\n",
      "|    entropy_loss       | -2.29        |\n",
      "|    explained_variance | 0.705        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.101       |\n",
      "|    mean_step_reward   | 0.0087022465 |\n",
      "|    n_updates          | 52/128       |\n",
      "|    policyGradLoss     | -0.0171      |\n",
      "|    value_loss         | 0.147        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 771          |\n",
      "|    iterations         | 15           |\n",
      "|    time_elapsed       | 159          |\n",
      "|    total_timesteps    | 51240960     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.020750236  |\n",
      "|    entropy_loss       | -2.3         |\n",
      "|    explained_variance | 0.673        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0714      |\n",
      "|    mean_step_reward   | -0.001663411 |\n",
      "|    n_updates          | 56/128       |\n",
      "|    policyGradLoss     | -0.0171      |\n",
      "|    value_loss         | 0.194        |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 770        |\n",
      "|    iterations         | 16         |\n",
      "|    time_elapsed       | 170        |\n",
      "|    total_timesteps    | 51249152   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02301909 |\n",
      "|    entropy_loss       | -2.21      |\n",
      "|    explained_variance | 0.918      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0965    |\n",
      "|    mean_step_reward   | 0.02613971 |\n",
      "|    n_updates          | 60/128     |\n",
      "|    policyGradLoss     | -0.018     |\n",
      "|    value_loss         | 0.158      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 181         |\n",
      "|    total_timesteps    | 51257344    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026047435 |\n",
      "|    entropy_loss       | -2.16       |\n",
      "|    explained_variance | 0.93        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0604     |\n",
      "|    mean_step_reward   | 0.025845526 |\n",
      "|    n_updates          | 64/128      |\n",
      "|    policyGradLoss     | -0.0222     |\n",
      "|    value_loss         | 0.202       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 192         |\n",
      "|    total_timesteps    | 51265536    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015740339 |\n",
      "|    entropy_loss       | -2.19       |\n",
      "|    explained_variance | 0.918       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0587     |\n",
      "|    mean_step_reward   | 0.03338223  |\n",
      "|    n_updates          | 68/128      |\n",
      "|    policyGradLoss     | -0.0132     |\n",
      "|    value_loss         | 0.299       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 768        |\n",
      "|    iterations         | 19         |\n",
      "|    time_elapsed       | 202        |\n",
      "|    total_timesteps    | 51273728   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03228032 |\n",
      "|    entropy_loss       | -2.16      |\n",
      "|    explained_variance | 0.894      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0874    |\n",
      "|    mean_step_reward   | 0.03023679 |\n",
      "|    n_updates          | 72/128     |\n",
      "|    policyGradLoss     | -0.019     |\n",
      "|    value_loss         | 0.162      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 767        |\n",
      "|    iterations         | 20         |\n",
      "|    time_elapsed       | 213        |\n",
      "|    total_timesteps    | 51281920   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03051038 |\n",
      "|    entropy_loss       | -2.2       |\n",
      "|    explained_variance | 0.944      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.088     |\n",
      "|    mean_step_reward   | 0.03724713 |\n",
      "|    n_updates          | 76/128     |\n",
      "|    policyGradLoss     | -0.0215    |\n",
      "|    value_loss         | 0.198      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 224         |\n",
      "|    total_timesteps    | 51290112    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021540485 |\n",
      "|    entropy_loss       | -2.15       |\n",
      "|    explained_variance | 0.902       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0496     |\n",
      "|    mean_step_reward   | 0.02206825  |\n",
      "|    n_updates          | 80/128      |\n",
      "|    policyGradLoss     | -0.0158     |\n",
      "|    value_loss         | 0.355       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 235         |\n",
      "|    total_timesteps    | 51298304    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022773426 |\n",
      "|    entropy_loss       | -2.16       |\n",
      "|    explained_variance | 0.928       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0939     |\n",
      "|    mean_step_reward   | 0.03403744  |\n",
      "|    n_updates          | 84/128      |\n",
      "|    policyGradLoss     | -0.0183     |\n",
      "|    value_loss         | 0.153       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 765         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 246         |\n",
      "|    total_timesteps    | 51306496    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018663691 |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.889       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0393     |\n",
      "|    mean_step_reward   | 0.025532845 |\n",
      "|    n_updates          | 88/128      |\n",
      "|    policyGradLoss     | -0.0119     |\n",
      "|    value_loss         | 0.307       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 764          |\n",
      "|    iterations         | 24           |\n",
      "|    time_elapsed       | 257          |\n",
      "|    total_timesteps    | 51314688     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0147560965 |\n",
      "|    entropy_loss       | -2.23        |\n",
      "|    explained_variance | 0.789        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0686      |\n",
      "|    mean_step_reward   | 0.026008807  |\n",
      "|    n_updates          | 92/128       |\n",
      "|    policyGradLoss     | -0.0124      |\n",
      "|    value_loss         | 0.397        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 765         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 267         |\n",
      "|    total_timesteps    | 51322880    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02316941  |\n",
      "|    entropy_loss       | -2.17       |\n",
      "|    explained_variance | 0.947       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0807     |\n",
      "|    mean_step_reward   | 0.033984926 |\n",
      "|    n_updates          | 96/128      |\n",
      "|    policyGradLoss     | -0.0175     |\n",
      "|    value_loss         | 0.152       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 764         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 278         |\n",
      "|    total_timesteps    | 51331072    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020312872 |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.932       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0972     |\n",
      "|    mean_step_reward   | 0.025778688 |\n",
      "|    n_updates          | 100/128     |\n",
      "|    policyGradLoss     | -0.0127     |\n",
      "|    value_loss         | 0.127       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 764        |\n",
      "|    iterations         | 27         |\n",
      "|    time_elapsed       | 289        |\n",
      "|    total_timesteps    | 51339264   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01611712 |\n",
      "|    entropy_loss       | -2.29      |\n",
      "|    explained_variance | 0.884      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0823    |\n",
      "|    mean_step_reward   | 0.01640167 |\n",
      "|    n_updates          | 104/128    |\n",
      "|    policyGradLoss     | -0.0133    |\n",
      "|    value_loss         | 0.134      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 764         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 299         |\n",
      "|    total_timesteps    | 51347456    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022400782 |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.106      |\n",
      "|    mean_step_reward   | 0.023250056 |\n",
      "|    n_updates          | 108/128     |\n",
      "|    policyGradLoss     | -0.0234     |\n",
      "|    value_loss         | 0.0906      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 764         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 310         |\n",
      "|    total_timesteps    | 51355648    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01833259  |\n",
      "|    entropy_loss       | -2.15       |\n",
      "|    explained_variance | 0.943       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0526     |\n",
      "|    mean_step_reward   | 0.036654096 |\n",
      "|    n_updates          | 112/128     |\n",
      "|    policyGradLoss     | -0.0161     |\n",
      "|    value_loss         | 0.272       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 764         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 321         |\n",
      "|    total_timesteps    | 51363840    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023595901 |\n",
      "|    entropy_loss       | -2.2        |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0822     |\n",
      "|    mean_step_reward   | 0.030272093 |\n",
      "|    n_updates          | 116/128     |\n",
      "|    policyGradLoss     | -0.0224     |\n",
      "|    value_loss         | 0.113       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 763         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 332         |\n",
      "|    total_timesteps    | 51372032    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.0285515   |\n",
      "|    entropy_loss       | -2.19       |\n",
      "|    explained_variance | 0.927       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0989     |\n",
      "|    mean_step_reward   | 0.026856164 |\n",
      "|    n_updates          | 120/128     |\n",
      "|    policyGradLoss     | -0.0205     |\n",
      "|    value_loss         | 0.124       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 763        |\n",
      "|    iterations         | 32         |\n",
      "|    time_elapsed       | 343        |\n",
      "|    total_timesteps    | 51380224   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.0211933  |\n",
      "|    entropy_loss       | -2.12      |\n",
      "|    explained_variance | 0.962      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0641    |\n",
      "|    mean_step_reward   | 0.03986859 |\n",
      "|    n_updates          | 124/128    |\n",
      "|    policyGradLoss     | -0.0182    |\n",
      "|    value_loss         | 0.22       |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/NoArti_195.zip\n",
      "[EVAL] Mean Return: 133.263, Best Return: 135.863\n",
      "Saved video to ./runs_smw/videos/NoArti/NoArti_195_133.26.mp4\n",
      "\n",
      "=== Round 197 | Learn 262144 steps (Total trained: 51380224) ===\n",
      "Logging to ./runs_smw/tb/NoArti_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1091     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 51388416 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 910         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 51396608    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024465518 |\n",
      "|    entropy_loss       | -2.18       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.098      |\n",
      "|    mean_step_reward   | 0.04177536  |\n",
      "|    n_updates          | 4/128       |\n",
      "|    policyGradLoss     | -0.0206     |\n",
      "|    value_loss         | 0.116       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 859         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 51404800    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016758118 |\n",
      "|    entropy_loss       | -2.2        |\n",
      "|    explained_variance | 0.844       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0335     |\n",
      "|    mean_step_reward   | 0.021105878 |\n",
      "|    n_updates          | 8/128       |\n",
      "|    policyGradLoss     | -0.0139     |\n",
      "|    value_loss         | 0.403       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 836         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 51412992    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024695406 |\n",
      "|    entropy_loss       | -2.17       |\n",
      "|    explained_variance | 0.917       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00503    |\n",
      "|    mean_step_reward   | 0.030778974 |\n",
      "|    n_updates          | 12/128      |\n",
      "|    policyGradLoss     | -0.0181     |\n",
      "|    value_loss         | 0.294       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 816         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 50          |\n",
      "|    total_timesteps    | 51421184    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016547814 |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.895       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0494     |\n",
      "|    mean_step_reward   | 0.038735308 |\n",
      "|    n_updates          | 16/128      |\n",
      "|    policyGradLoss     | -0.0119     |\n",
      "|    value_loss         | 0.413       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 806          |\n",
      "|    iterations         | 6            |\n",
      "|    time_elapsed       | 60           |\n",
      "|    total_timesteps    | 51429376     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.028219672  |\n",
      "|    entropy_loss       | -2.34        |\n",
      "|    explained_variance | 0.97         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.124       |\n",
      "|    mean_step_reward   | 0.0153251365 |\n",
      "|    n_updates          | 20/128       |\n",
      "|    policyGradLoss     | -0.0226      |\n",
      "|    value_loss         | 0.0278       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 796           |\n",
      "|    iterations         | 7             |\n",
      "|    time_elapsed       | 71            |\n",
      "|    total_timesteps    | 51437568      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.014015324   |\n",
      "|    entropy_loss       | -2.3          |\n",
      "|    explained_variance | 0.894         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0327       |\n",
      "|    mean_step_reward   | 0.00015966408 |\n",
      "|    n_updates          | 24/128        |\n",
      "|    policyGradLoss     | -0.0134       |\n",
      "|    value_loss         | 0.22          |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 793         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 82          |\n",
      "|    total_timesteps    | 51445760    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018488118 |\n",
      "|    entropy_loss       | -2.18       |\n",
      "|    explained_variance | 0.873       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0509     |\n",
      "|    mean_step_reward   | 0.025931358 |\n",
      "|    n_updates          | 28/128      |\n",
      "|    policyGradLoss     | -0.0147     |\n",
      "|    value_loss         | 0.366       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 791         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 93          |\n",
      "|    total_timesteps    | 51453952    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023602813 |\n",
      "|    entropy_loss       | -2.19       |\n",
      "|    explained_variance | 0.933       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0894     |\n",
      "|    mean_step_reward   | 0.03800119  |\n",
      "|    n_updates          | 32/128      |\n",
      "|    policyGradLoss     | -0.0209     |\n",
      "|    value_loss         | 0.198       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 104         |\n",
      "|    total_timesteps    | 51462144    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017484011 |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.925       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0537     |\n",
      "|    mean_step_reward   | 0.022811476 |\n",
      "|    n_updates          | 36/128      |\n",
      "|    policyGradLoss     | -0.0193     |\n",
      "|    value_loss         | 0.294       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 114         |\n",
      "|    total_timesteps    | 51470336    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029574782 |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.929       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0547      |\n",
      "|    mean_step_reward   | 0.026434783 |\n",
      "|    n_updates          | 40/128      |\n",
      "|    policyGradLoss     | -0.0191     |\n",
      "|    value_loss         | 0.241       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 125         |\n",
      "|    total_timesteps    | 51478528    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027495569 |\n",
      "|    entropy_loss       | -2.2        |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0999     |\n",
      "|    mean_step_reward   | 0.03779218  |\n",
      "|    n_updates          | 44/128      |\n",
      "|    policyGradLoss     | -0.0191     |\n",
      "|    value_loss         | 0.101       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 136         |\n",
      "|    total_timesteps    | 51486720    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025784131 |\n",
      "|    entropy_loss       | -2.31       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.11       |\n",
      "|    mean_step_reward   | 0.02264662  |\n",
      "|    n_updates          | 48/128      |\n",
      "|    policyGradLoss     | -0.0164     |\n",
      "|    value_loss         | 0.0497      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 778          |\n",
      "|    iterations         | 14           |\n",
      "|    time_elapsed       | 147          |\n",
      "|    total_timesteps    | 51494912     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.024566218  |\n",
      "|    entropy_loss       | -2.33        |\n",
      "|    explained_variance | 0.928        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.111       |\n",
      "|    mean_step_reward   | 0.0012298296 |\n",
      "|    n_updates          | 52/128       |\n",
      "|    policyGradLoss     | -0.0189      |\n",
      "|    value_loss         | 0.103        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 158         |\n",
      "|    total_timesteps    | 51503104    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.0232412   |\n",
      "|    entropy_loss       | -2.3        |\n",
      "|    explained_variance | 0.947       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.107      |\n",
      "|    mean_step_reward   | 0.011743521 |\n",
      "|    n_updates          | 56/128      |\n",
      "|    policyGradLoss     | -0.0156     |\n",
      "|    value_loss         | 0.0992      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 169         |\n",
      "|    total_timesteps    | 51511296    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014721422 |\n",
      "|    entropy_loss       | -2.27       |\n",
      "|    explained_variance | 0.948       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0844     |\n",
      "|    mean_step_reward   | 0.00925325  |\n",
      "|    n_updates          | 60/128      |\n",
      "|    policyGradLoss     | -0.0145     |\n",
      "|    value_loss         | 0.184       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 179         |\n",
      "|    total_timesteps    | 51519488    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028283415 |\n",
      "|    entropy_loss       | -2.28       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.108      |\n",
      "|    mean_step_reward   | 0.034942813 |\n",
      "|    n_updates          | 64/128      |\n",
      "|    policyGradLoss     | -0.0188     |\n",
      "|    value_loss         | 0.0678      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 775          |\n",
      "|    iterations         | 18           |\n",
      "|    time_elapsed       | 190          |\n",
      "|    total_timesteps    | 51527680     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.018544832  |\n",
      "|    entropy_loss       | -2.29        |\n",
      "|    explained_variance | 0.959        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0702      |\n",
      "|    mean_step_reward   | 0.0069164257 |\n",
      "|    n_updates          | 68/128       |\n",
      "|    policyGradLoss     | -0.015       |\n",
      "|    value_loss         | 0.119        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 200         |\n",
      "|    total_timesteps    | 51535872    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024076935 |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.109      |\n",
      "|    mean_step_reward   | 0.029265888 |\n",
      "|    n_updates          | 72/128      |\n",
      "|    policyGradLoss     | -0.0184     |\n",
      "|    value_loss         | 0.0731      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 773          |\n",
      "|    iterations         | 20           |\n",
      "|    time_elapsed       | 211          |\n",
      "|    total_timesteps    | 51544064     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.020657219  |\n",
      "|    entropy_loss       | -2.34        |\n",
      "|    explained_variance | 0.874        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.103       |\n",
      "|    mean_step_reward   | 0.0059878477 |\n",
      "|    n_updates          | 76/128       |\n",
      "|    policyGradLoss     | -0.0123      |\n",
      "|    value_loss         | 0.0501       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 222         |\n",
      "|    total_timesteps    | 51552256    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015573873 |\n",
      "|    entropy_loss       | -2.31       |\n",
      "|    explained_variance | 0.9         |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0814     |\n",
      "|    mean_step_reward   | 0.013810453 |\n",
      "|    n_updates          | 80/128      |\n",
      "|    policyGradLoss     | -0.012      |\n",
      "|    value_loss         | 0.228       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 233         |\n",
      "|    total_timesteps    | 51560448    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02202642  |\n",
      "|    entropy_loss       | -2.27       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.107      |\n",
      "|    mean_step_reward   | 0.017753314 |\n",
      "|    n_updates          | 84/128      |\n",
      "|    policyGradLoss     | -0.0193     |\n",
      "|    value_loss         | 0.0988      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 243         |\n",
      "|    total_timesteps    | 51568640    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019858059 |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0916     |\n",
      "|    mean_step_reward   | 0.031519398 |\n",
      "|    n_updates          | 88/128      |\n",
      "|    policyGradLoss     | -0.0202     |\n",
      "|    value_loss         | 0.0845      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 254         |\n",
      "|    total_timesteps    | 51576832    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012800766 |\n",
      "|    entropy_loss       | -2.14       |\n",
      "|    explained_variance | 0.945       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0729     |\n",
      "|    mean_step_reward   | 0.035731837 |\n",
      "|    n_updates          | 92/128      |\n",
      "|    policyGradLoss     | -0.0143     |\n",
      "|    value_loss         | 0.257       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 265         |\n",
      "|    total_timesteps    | 51585024    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024486193 |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.95        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0861     |\n",
      "|    mean_step_reward   | 0.03430725  |\n",
      "|    n_updates          | 96/128      |\n",
      "|    policyGradLoss     | -0.0155     |\n",
      "|    value_loss         | 0.172       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 275         |\n",
      "|    total_timesteps    | 51593216    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018250968 |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.943       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0749     |\n",
      "|    mean_step_reward   | 0.012984821 |\n",
      "|    n_updates          | 100/128     |\n",
      "|    policyGradLoss     | -0.0163     |\n",
      "|    value_loss         | 0.193       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 286         |\n",
      "|    total_timesteps    | 51601408    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030430984 |\n",
      "|    entropy_loss       | -2.2        |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.111      |\n",
      "|    mean_step_reward   | 0.037888523 |\n",
      "|    n_updates          | 104/128     |\n",
      "|    policyGradLoss     | -0.0221     |\n",
      "|    value_loss         | 0.0699      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 296         |\n",
      "|    total_timesteps    | 51609600    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028292306 |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.088      |\n",
      "|    mean_step_reward   | 0.032359593 |\n",
      "|    n_updates          | 108/128     |\n",
      "|    policyGradLoss     | -0.0152     |\n",
      "|    value_loss         | 0.102       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 307         |\n",
      "|    total_timesteps    | 51617792    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024270149 |\n",
      "|    entropy_loss       | -2.19       |\n",
      "|    explained_variance | 0.943       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0899     |\n",
      "|    mean_step_reward   | 0.026113736 |\n",
      "|    n_updates          | 112/128     |\n",
      "|    policyGradLoss     | -0.0167     |\n",
      "|    value_loss         | 0.142       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 318         |\n",
      "|    total_timesteps    | 51625984    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022712596 |\n",
      "|    entropy_loss       | -2.2        |\n",
      "|    explained_variance | 0.954       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0837     |\n",
      "|    mean_step_reward   | 0.026946247 |\n",
      "|    n_updates          | 116/128     |\n",
      "|    policyGradLoss     | -0.0201     |\n",
      "|    value_loss         | 0.142       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 329         |\n",
      "|    total_timesteps    | 51634176    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013431119 |\n",
      "|    entropy_loss       | -2.2        |\n",
      "|    explained_variance | 0.912       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0865     |\n",
      "|    mean_step_reward   | 0.03895864  |\n",
      "|    n_updates          | 120/128     |\n",
      "|    policyGradLoss     | -0.0114     |\n",
      "|    value_loss         | 0.262       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 340         |\n",
      "|    total_timesteps    | 51642368    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021126831 |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.936       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0878     |\n",
      "|    mean_step_reward   | 0.022274967 |\n",
      "|    n_updates          | 124/128     |\n",
      "|    policyGradLoss     | -0.0158     |\n",
      "|    value_loss         | 0.135       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/NoArti_196.zip\n",
      "[EVAL] Mean Return: 65.766, Best Return: 67.766\n",
      "Saved video to ./runs_smw/videos/NoArti/NoArti_196_65.77.mp4\n",
      "\n",
      "=== Round 198 | Learn 262144 steps (Total trained: 51642368) ===\n",
      "Logging to ./runs_smw/tb/NoArti_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1090     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 51650560 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 902         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 51658752    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021012146 |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.915       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.08       |\n",
      "|    mean_step_reward   | 0.022982936 |\n",
      "|    n_updates          | 4/128       |\n",
      "|    policyGradLoss     | -0.015      |\n",
      "|    value_loss         | 0.157       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 842        |\n",
      "|    iterations         | 3          |\n",
      "|    time_elapsed       | 29         |\n",
      "|    total_timesteps    | 51666944   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01783273 |\n",
      "|    entropy_loss       | -2.25      |\n",
      "|    explained_variance | 0.931      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0793    |\n",
      "|    mean_step_reward   | 0.01751345 |\n",
      "|    n_updates          | 8/128      |\n",
      "|    policyGradLoss     | -0.0159    |\n",
      "|    value_loss         | 0.201      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 824        |\n",
      "|    iterations         | 4          |\n",
      "|    time_elapsed       | 39         |\n",
      "|    total_timesteps    | 51675136   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01698389 |\n",
      "|    entropy_loss       | -2.24      |\n",
      "|    explained_variance | 0.934      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0999    |\n",
      "|    mean_step_reward   | 0.03444724 |\n",
      "|    n_updates          | 12/128     |\n",
      "|    policyGradLoss     | -0.0128    |\n",
      "|    value_loss         | 0.189      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 813         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 50          |\n",
      "|    total_timesteps    | 51683328    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018934919 |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.925       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0733     |\n",
      "|    mean_step_reward   | 0.024921194 |\n",
      "|    n_updates          | 16/128      |\n",
      "|    policyGradLoss     | -0.0127     |\n",
      "|    value_loss         | 0.142       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 800         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 61          |\n",
      "|    total_timesteps    | 51691520    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020091526 |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.91        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0854     |\n",
      "|    mean_step_reward   | 0.015403584 |\n",
      "|    n_updates          | 20/128      |\n",
      "|    policyGradLoss     | -0.0173     |\n",
      "|    value_loss         | 0.233       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 791         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 72          |\n",
      "|    total_timesteps    | 51699712    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01862562  |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.863       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0896     |\n",
      "|    mean_step_reward   | 0.027235832 |\n",
      "|    n_updates          | 24/128      |\n",
      "|    policyGradLoss     | -0.0164     |\n",
      "|    value_loss         | 0.218       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 83          |\n",
      "|    total_timesteps    | 51707904    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019495558 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.95        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0945     |\n",
      "|    mean_step_reward   | 0.025516074 |\n",
      "|    n_updates          | 28/128      |\n",
      "|    policyGradLoss     | -0.0168     |\n",
      "|    value_loss         | 0.187       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 93          |\n",
      "|    total_timesteps    | 51716096    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022337697 |\n",
      "|    entropy_loss       | -2.2        |\n",
      "|    explained_variance | 0.911       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0758     |\n",
      "|    mean_step_reward   | 0.030589119 |\n",
      "|    n_updates          | 32/128      |\n",
      "|    policyGradLoss     | -0.017      |\n",
      "|    value_loss         | 0.213       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 104         |\n",
      "|    total_timesteps    | 51724288    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026401794 |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.113      |\n",
      "|    mean_step_reward   | 0.029634167 |\n",
      "|    n_updates          | 36/128      |\n",
      "|    policyGradLoss     | -0.0235     |\n",
      "|    value_loss         | 0.0839      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 115         |\n",
      "|    total_timesteps    | 51732480    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028100237 |\n",
      "|    entropy_loss       | -2.28       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.109      |\n",
      "|    mean_step_reward   | 0.023692222 |\n",
      "|    n_updates          | 40/128      |\n",
      "|    policyGradLoss     | -0.0218     |\n",
      "|    value_loss         | 0.0341      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 125         |\n",
      "|    total_timesteps    | 51740672    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023990003 |\n",
      "|    entropy_loss       | -2.28       |\n",
      "|    explained_variance | 0.91        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0983     |\n",
      "|    mean_step_reward   | 0.01071264  |\n",
      "|    n_updates          | 44/128      |\n",
      "|    policyGradLoss     | -0.016      |\n",
      "|    value_loss         | 0.178       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 136         |\n",
      "|    total_timesteps    | 51748864    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02034479  |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.901       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0828     |\n",
      "|    mean_step_reward   | 0.033912357 |\n",
      "|    n_updates          | 48/128      |\n",
      "|    policyGradLoss     | -0.0184     |\n",
      "|    value_loss         | 0.192       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 147         |\n",
      "|    total_timesteps    | 51757056    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013262616 |\n",
      "|    entropy_loss       | -2.3        |\n",
      "|    explained_variance | 0.882       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0967     |\n",
      "|    mean_step_reward   | 0.022421792 |\n",
      "|    n_updates          | 52/128      |\n",
      "|    policyGradLoss     | -0.0125     |\n",
      "|    value_loss         | 0.2         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 158         |\n",
      "|    total_timesteps    | 51765248    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023692986 |\n",
      "|    entropy_loss       | -2.32       |\n",
      "|    explained_variance | 0.933       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0921     |\n",
      "|    mean_step_reward   | 0.008571122 |\n",
      "|    n_updates          | 56/128      |\n",
      "|    policyGradLoss     | -0.0138     |\n",
      "|    value_loss         | 0.112       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 168         |\n",
      "|    total_timesteps    | 51773440    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021835413 |\n",
      "|    entropy_loss       | -2.29       |\n",
      "|    explained_variance | 0.915       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0757     |\n",
      "|    mean_step_reward   | 0.020382453 |\n",
      "|    n_updates          | 60/128      |\n",
      "|    policyGradLoss     | -0.0184     |\n",
      "|    value_loss         | 0.089       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 179         |\n",
      "|    total_timesteps    | 51781632    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023106456 |\n",
      "|    entropy_loss       | -2.28       |\n",
      "|    explained_variance | 0.932       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.041      |\n",
      "|    mean_step_reward   | 0.023784425 |\n",
      "|    n_updates          | 64/128      |\n",
      "|    policyGradLoss     | -0.0144     |\n",
      "|    value_loss         | 0.155       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 189         |\n",
      "|    total_timesteps    | 51789824    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020947978 |\n",
      "|    entropy_loss       | -2.33       |\n",
      "|    explained_variance | 0.941       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.105      |\n",
      "|    mean_step_reward   | 0.016768768 |\n",
      "|    n_updates          | 68/128      |\n",
      "|    policyGradLoss     | -0.0118     |\n",
      "|    value_loss         | 0.0856      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 200         |\n",
      "|    total_timesteps    | 51798016    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013029929 |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.889       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00446    |\n",
      "|    mean_step_reward   | 0.004505436 |\n",
      "|    n_updates          | 72/128      |\n",
      "|    policyGradLoss     | -0.014      |\n",
      "|    value_loss         | 0.444       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 211         |\n",
      "|    total_timesteps    | 51806208    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020594794 |\n",
      "|    entropy_loss       | -2.18       |\n",
      "|    explained_variance | 0.914       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0764     |\n",
      "|    mean_step_reward   | 0.030144876 |\n",
      "|    n_updates          | 76/128      |\n",
      "|    policyGradLoss     | -0.0181     |\n",
      "|    value_loss         | 0.234       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 221         |\n",
      "|    total_timesteps    | 51814400    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017970048 |\n",
      "|    entropy_loss       | -2.18       |\n",
      "|    explained_variance | 0.916       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0377      |\n",
      "|    mean_step_reward   | 0.029784318 |\n",
      "|    n_updates          | 80/128      |\n",
      "|    policyGradLoss     | -0.0155     |\n",
      "|    value_loss         | 0.402       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 232         |\n",
      "|    total_timesteps    | 51822592    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026826348 |\n",
      "|    entropy_loss       | -2.2        |\n",
      "|    explained_variance | 0.938       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.103      |\n",
      "|    mean_step_reward   | 0.037788585 |\n",
      "|    n_updates          | 84/128      |\n",
      "|    policyGradLoss     | -0.0215     |\n",
      "|    value_loss         | 0.16        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 243         |\n",
      "|    total_timesteps    | 51830784    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016058043 |\n",
      "|    entropy_loss       | -2.17       |\n",
      "|    explained_variance | 0.903       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.021      |\n",
      "|    mean_step_reward   | 0.036206603 |\n",
      "|    n_updates          | 88/128      |\n",
      "|    policyGradLoss     | -0.0116     |\n",
      "|    value_loss         | 0.379       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 254         |\n",
      "|    total_timesteps    | 51838976    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020680785 |\n",
      "|    entropy_loss       | -2.14       |\n",
      "|    explained_variance | 0.941       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0968     |\n",
      "|    mean_step_reward   | 0.038089007 |\n",
      "|    n_updates          | 92/128      |\n",
      "|    policyGradLoss     | -0.0175     |\n",
      "|    value_loss         | 0.199       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 265         |\n",
      "|    total_timesteps    | 51847168    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025312219 |\n",
      "|    entropy_loss       | -2.27       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.117      |\n",
      "|    mean_step_reward   | 0.024049278 |\n",
      "|    n_updates          | 96/128      |\n",
      "|    policyGradLoss     | -0.0204     |\n",
      "|    value_loss         | 0.072       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 275         |\n",
      "|    total_timesteps    | 51855360    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02440373  |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.935       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0968     |\n",
      "|    mean_step_reward   | 0.019961877 |\n",
      "|    n_updates          | 100/128     |\n",
      "|    policyGradLoss     | -0.0146     |\n",
      "|    value_loss         | 0.174       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 286         |\n",
      "|    total_timesteps    | 51863552    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028542358 |\n",
      "|    entropy_loss       | -2.31       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.112      |\n",
      "|    mean_step_reward   | 0.023467503 |\n",
      "|    n_updates          | 104/128     |\n",
      "|    policyGradLoss     | -0.0189     |\n",
      "|    value_loss         | 0.0309      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 297         |\n",
      "|    total_timesteps    | 51871744    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020321637 |\n",
      "|    entropy_loss       | -2.3        |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0966     |\n",
      "|    mean_step_reward   | 0.014536796 |\n",
      "|    n_updates          | 108/128     |\n",
      "|    policyGradLoss     | -0.0151     |\n",
      "|    value_loss         | 0.0793      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 308         |\n",
      "|    total_timesteps    | 51879936    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.033243176 |\n",
      "|    entropy_loss       | -2.27       |\n",
      "|    explained_variance | 0.994       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.118      |\n",
      "|    mean_step_reward   | 0.034458436 |\n",
      "|    n_updates          | 112/128     |\n",
      "|    policyGradLoss     | -0.0236     |\n",
      "|    value_loss         | 0.0281      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 770           |\n",
      "|    iterations         | 30            |\n",
      "|    time_elapsed       | 319           |\n",
      "|    total_timesteps    | 51888128      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.020042043   |\n",
      "|    entropy_loss       | -2.29         |\n",
      "|    explained_variance | 0.931         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0992       |\n",
      "|    mean_step_reward   | -0.0010896996 |\n",
      "|    n_updates          | 116/128       |\n",
      "|    policyGradLoss     | -0.0155       |\n",
      "|    value_loss         | 0.142         |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 329         |\n",
      "|    total_timesteps    | 51896320    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023014644 |\n",
      "|    entropy_loss       | -2.13       |\n",
      "|    explained_variance | 0.929       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0203     |\n",
      "|    mean_step_reward   | 0.034186497 |\n",
      "|    n_updates          | 120/128     |\n",
      "|    policyGradLoss     | -0.0121     |\n",
      "|    value_loss         | 0.384       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 769        |\n",
      "|    iterations         | 32         |\n",
      "|    time_elapsed       | 340        |\n",
      "|    total_timesteps    | 51904512   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02100294 |\n",
      "|    entropy_loss       | -2.14      |\n",
      "|    explained_variance | 0.966      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.0104     |\n",
      "|    mean_step_reward   | 0.04041419 |\n",
      "|    n_updates          | 124/128    |\n",
      "|    policyGradLoss     | -0.0192    |\n",
      "|    value_loss         | 0.196      |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/NoArti_197.zip\n",
      "[EVAL] Mean Return: 1.039, Best Return: 1.239\n",
      "Saved video to ./runs_smw/videos/NoArti/NoArti_197_1.04.mp4\n",
      "\n",
      "=== Round 199 | Learn 262144 steps (Total trained: 51904512) ===\n",
      "Logging to ./runs_smw/tb/NoArti_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1109     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 51912704 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 887         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 51920896    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021753587 |\n",
      "|    entropy_loss       | -2.33       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.108      |\n",
      "|    mean_step_reward   | 0.01489181  |\n",
      "|    n_updates          | 4/128       |\n",
      "|    policyGradLoss     | -0.0143     |\n",
      "|    value_loss         | 0.0337      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 846          |\n",
      "|    iterations         | 3            |\n",
      "|    time_elapsed       | 29           |\n",
      "|    total_timesteps    | 51929088     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.020095972  |\n",
      "|    entropy_loss       | -2.35        |\n",
      "|    explained_variance | 0.79         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0902      |\n",
      "|    mean_step_reward   | 0.0055347593 |\n",
      "|    n_updates          | 8/128        |\n",
      "|    policyGradLoss     | -0.0121      |\n",
      "|    value_loss         | 0.153        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 818         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 40          |\n",
      "|    total_timesteps    | 51937280    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024076555 |\n",
      "|    entropy_loss       | -2.32       |\n",
      "|    explained_variance | 0.993       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.109      |\n",
      "|    mean_step_reward   | 0.025453176 |\n",
      "|    n_updates          | 12/128      |\n",
      "|    policyGradLoss     | -0.0192     |\n",
      "|    value_loss         | 0.0274      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 809           |\n",
      "|    iterations         | 5             |\n",
      "|    time_elapsed       | 50            |\n",
      "|    total_timesteps    | 51945472      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.015563019   |\n",
      "|    entropy_loss       | -2.35         |\n",
      "|    explained_variance | 0.963         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.106        |\n",
      "|    mean_step_reward   | -0.0043196864 |\n",
      "|    n_updates          | 16/128        |\n",
      "|    policyGradLoss     | -0.0141       |\n",
      "|    value_loss         | 0.0396        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 799         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 61          |\n",
      "|    total_timesteps    | 51953664    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022004958 |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.958       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.107      |\n",
      "|    mean_step_reward   | 0.01890504  |\n",
      "|    n_updates          | 20/128      |\n",
      "|    policyGradLoss     | -0.0185     |\n",
      "|    value_loss         | 0.114       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 793         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 72          |\n",
      "|    total_timesteps    | 51961856    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019936735 |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0866     |\n",
      "|    mean_step_reward   | 0.018136064 |\n",
      "|    n_updates          | 24/128      |\n",
      "|    policyGradLoss     | -0.018      |\n",
      "|    value_loss         | 0.134       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 788        |\n",
      "|    iterations         | 8          |\n",
      "|    time_elapsed       | 83         |\n",
      "|    total_timesteps    | 51970048   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02018589 |\n",
      "|    entropy_loss       | -2.15      |\n",
      "|    explained_variance | 0.947      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0835    |\n",
      "|    mean_step_reward   | 0.03090546 |\n",
      "|    n_updates          | 28/128     |\n",
      "|    policyGradLoss     | -0.0146    |\n",
      "|    value_loss         | 0.2        |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 94          |\n",
      "|    total_timesteps    | 51978240    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023108268 |\n",
      "|    entropy_loss       | -2.14       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0941     |\n",
      "|    mean_step_reward   | 0.05241452  |\n",
      "|    n_updates          | 32/128      |\n",
      "|    policyGradLoss     | -0.018      |\n",
      "|    value_loss         | 0.127       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 104         |\n",
      "|    total_timesteps    | 51986432    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02175553  |\n",
      "|    entropy_loss       | -2.11       |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0874     |\n",
      "|    mean_step_reward   | 0.047301456 |\n",
      "|    n_updates          | 36/128      |\n",
      "|    policyGradLoss     | -0.0161     |\n",
      "|    value_loss         | 0.152       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 115         |\n",
      "|    total_timesteps    | 51994624    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019808901 |\n",
      "|    entropy_loss       | -2.1        |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0802     |\n",
      "|    mean_step_reward   | 0.041371033 |\n",
      "|    n_updates          | 40/128      |\n",
      "|    policyGradLoss     | -0.0159     |\n",
      "|    value_loss         | 0.214       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 126         |\n",
      "|    total_timesteps    | 52002816    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024838619 |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.118      |\n",
      "|    mean_step_reward   | 0.0375709   |\n",
      "|    n_updates          | 44/128      |\n",
      "|    policyGradLoss     | -0.023      |\n",
      "|    value_loss         | 0.0397      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 137         |\n",
      "|    total_timesteps    | 52011008    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018185757 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.951       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0311     |\n",
      "|    mean_step_reward   | 0.01604562  |\n",
      "|    n_updates          | 48/128      |\n",
      "|    policyGradLoss     | -0.0157     |\n",
      "|    value_loss         | 0.165       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 147         |\n",
      "|    total_timesteps    | 52019200    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027171277 |\n",
      "|    entropy_loss       | -2.19       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0947     |\n",
      "|    mean_step_reward   | 0.042515226 |\n",
      "|    n_updates          | 52/128      |\n",
      "|    policyGradLoss     | -0.0247     |\n",
      "|    value_loss         | 0.0878      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 158         |\n",
      "|    total_timesteps    | 52027392    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02260549  |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0509     |\n",
      "|    mean_step_reward   | 0.029253937 |\n",
      "|    n_updates          | 56/128      |\n",
      "|    policyGradLoss     | -0.0178     |\n",
      "|    value_loss         | 0.12        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 772          |\n",
      "|    iterations         | 16           |\n",
      "|    time_elapsed       | 169          |\n",
      "|    total_timesteps    | 52035584     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.014996015  |\n",
      "|    entropy_loss       | -2.25        |\n",
      "|    explained_variance | 0.962        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0348      |\n",
      "|    mean_step_reward   | 0.0071471045 |\n",
      "|    n_updates          | 60/128       |\n",
      "|    policyGradLoss     | -0.0153      |\n",
      "|    value_loss         | 0.141        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 180         |\n",
      "|    total_timesteps    | 52043776    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017624436 |\n",
      "|    entropy_loss       | -2.12       |\n",
      "|    explained_variance | 0.944       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0109      |\n",
      "|    mean_step_reward   | 0.038941853 |\n",
      "|    n_updates          | 64/128      |\n",
      "|    policyGradLoss     | -0.0149     |\n",
      "|    value_loss         | 0.369       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 191         |\n",
      "|    total_timesteps    | 52051968    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027437042 |\n",
      "|    entropy_loss       | -2.28       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.113      |\n",
      "|    mean_step_reward   | 0.02612098  |\n",
      "|    n_updates          | 68/128      |\n",
      "|    policyGradLoss     | -0.0163     |\n",
      "|    value_loss         | 0.0864      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 201         |\n",
      "|    total_timesteps    | 52060160    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022078505 |\n",
      "|    entropy_loss       | -2.32       |\n",
      "|    explained_variance | 0.935       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0983     |\n",
      "|    mean_step_reward   | 0.008685991 |\n",
      "|    n_updates          | 72/128      |\n",
      "|    policyGradLoss     | -0.0183     |\n",
      "|    value_loss         | 0.126       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 212         |\n",
      "|    total_timesteps    | 52068352    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02107058  |\n",
      "|    entropy_loss       | -2.31       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.111      |\n",
      "|    mean_step_reward   | 0.015721682 |\n",
      "|    n_updates          | 76/128      |\n",
      "|    policyGradLoss     | -0.0199     |\n",
      "|    value_loss         | 0.037       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 223         |\n",
      "|    total_timesteps    | 52076544    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017688584 |\n",
      "|    entropy_loss       | -2.3        |\n",
      "|    explained_variance | 0.948       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0677     |\n",
      "|    mean_step_reward   | 0.014209332 |\n",
      "|    n_updates          | 80/128      |\n",
      "|    policyGradLoss     | -0.0159     |\n",
      "|    value_loss         | 0.111       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 234         |\n",
      "|    total_timesteps    | 52084736    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026242618 |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.804       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.086      |\n",
      "|    mean_step_reward   | 0.009592854 |\n",
      "|    n_updates          | 84/128      |\n",
      "|    policyGradLoss     | -0.013      |\n",
      "|    value_loss         | 0.285       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 244         |\n",
      "|    total_timesteps    | 52092928    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024025984 |\n",
      "|    entropy_loss       | -2.2        |\n",
      "|    explained_variance | 0.883       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00587     |\n",
      "|    mean_step_reward   | 0.016951395 |\n",
      "|    n_updates          | 88/128      |\n",
      "|    policyGradLoss     | -0.0135     |\n",
      "|    value_loss         | 0.334       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 255         |\n",
      "|    total_timesteps    | 52101120    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02026593  |\n",
      "|    entropy_loss       | -2.17       |\n",
      "|    explained_variance | 0.879       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0827     |\n",
      "|    mean_step_reward   | 0.046924256 |\n",
      "|    n_updates          | 92/128      |\n",
      "|    policyGradLoss     | -0.0127     |\n",
      "|    value_loss         | 0.262       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 266         |\n",
      "|    total_timesteps    | 52109312    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016238825 |\n",
      "|    entropy_loss       | -2.29       |\n",
      "|    explained_variance | 0.922       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0651     |\n",
      "|    mean_step_reward   | 0.020657457 |\n",
      "|    n_updates          | 96/128      |\n",
      "|    policyGradLoss     | -0.013      |\n",
      "|    value_loss         | 0.197       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 277         |\n",
      "|    total_timesteps    | 52117504    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029381726 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.109      |\n",
      "|    mean_step_reward   | 0.02737879  |\n",
      "|    n_updates          | 100/128     |\n",
      "|    policyGradLoss     | -0.0217     |\n",
      "|    value_loss         | 0.085       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 288         |\n",
      "|    total_timesteps    | 52125696    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021147769 |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0758     |\n",
      "|    mean_step_reward   | 0.029779928 |\n",
      "|    n_updates          | 104/128     |\n",
      "|    policyGradLoss     | -0.0144     |\n",
      "|    value_loss         | 0.166       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 765         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 299         |\n",
      "|    total_timesteps    | 52133888    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024393236 |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.078      |\n",
      "|    mean_step_reward   | 0.027099214 |\n",
      "|    n_updates          | 108/128     |\n",
      "|    policyGradLoss     | -0.0168     |\n",
      "|    value_loss         | 0.123       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 765         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 310         |\n",
      "|    total_timesteps    | 52142080    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.032796614 |\n",
      "|    entropy_loss       | -2.29       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.119      |\n",
      "|    mean_step_reward   | 0.010762702 |\n",
      "|    n_updates          | 112/128     |\n",
      "|    policyGradLoss     | -0.0246     |\n",
      "|    value_loss         | 0.0448      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 765         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 321         |\n",
      "|    total_timesteps    | 52150272    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025820617 |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.949       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.099      |\n",
      "|    mean_step_reward   | 0.019443661 |\n",
      "|    n_updates          | 116/128     |\n",
      "|    policyGradLoss     | -0.0177     |\n",
      "|    value_loss         | 0.119       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 763         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 332         |\n",
      "|    total_timesteps    | 52158464    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024114221 |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.098      |\n",
      "|    mean_step_reward   | 0.033237707 |\n",
      "|    n_updates          | 120/128     |\n",
      "|    policyGradLoss     | -0.0201     |\n",
      "|    value_loss         | 0.113       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 763         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 343         |\n",
      "|    total_timesteps    | 52166656    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018505665 |\n",
      "|    entropy_loss       | -2.19       |\n",
      "|    explained_variance | 0.901       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0725     |\n",
      "|    mean_step_reward   | 0.016910788 |\n",
      "|    n_updates          | 124/128     |\n",
      "|    policyGradLoss     | -0.0157     |\n",
      "|    value_loss         | 0.214       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/NoArti_198.zip\n",
      "[EVAL] Mean Return: -67.101, Best Return: -65.097\n",
      "Saved video to ./runs_smw/videos/NoArti/NoArti_198_-67.10.mp4\n",
      "\n",
      "=== Round 200 | Learn 262144 steps (Total trained: 52166656) ===\n",
      "Logging to ./runs_smw/tb/NoArti_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1152     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 52174848 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 927         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 52183040    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022205576 |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.945       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0772     |\n",
      "|    mean_step_reward   | 0.028762618 |\n",
      "|    n_updates          | 4/128       |\n",
      "|    policyGradLoss     | -0.0155     |\n",
      "|    value_loss         | 0.251       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 874         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 52191232    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023742864 |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.921       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.097      |\n",
      "|    mean_step_reward   | 0.021027397 |\n",
      "|    n_updates          | 8/128       |\n",
      "|    policyGradLoss     | -0.0152     |\n",
      "|    value_loss         | 0.144       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 842        |\n",
      "|    iterations         | 4          |\n",
      "|    time_elapsed       | 38         |\n",
      "|    total_timesteps    | 52199424   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03069714 |\n",
      "|    entropy_loss       | -2.2       |\n",
      "|    explained_variance | 0.981      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.107     |\n",
      "|    mean_step_reward   | 0.0415626  |\n",
      "|    n_updates          | 12/128     |\n",
      "|    policyGradLoss     | -0.0246    |\n",
      "|    value_loss         | 0.0883     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 820         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 49          |\n",
      "|    total_timesteps    | 52207616    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021281045 |\n",
      "|    entropy_loss       | -2.28       |\n",
      "|    explained_variance | 0.958       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0908     |\n",
      "|    mean_step_reward   | 0.025764305 |\n",
      "|    n_updates          | 16/128      |\n",
      "|    policyGradLoss     | -0.0174     |\n",
      "|    value_loss         | 0.106       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 807         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 60          |\n",
      "|    total_timesteps    | 52215808    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.0194136   |\n",
      "|    entropy_loss       | -2.2        |\n",
      "|    explained_variance | 0.95        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0994     |\n",
      "|    mean_step_reward   | 0.017941345 |\n",
      "|    n_updates          | 20/128      |\n",
      "|    policyGradLoss     | -0.018      |\n",
      "|    value_loss         | 0.115       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 800        |\n",
      "|    iterations         | 7          |\n",
      "|    time_elapsed       | 71         |\n",
      "|    total_timesteps    | 52224000   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02916959 |\n",
      "|    entropy_loss       | -2.21      |\n",
      "|    explained_variance | 0.972      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0903    |\n",
      "|    mean_step_reward   | 0.03522017 |\n",
      "|    n_updates          | 24/128     |\n",
      "|    policyGradLoss     | -0.0213    |\n",
      "|    value_loss         | 0.13       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 795         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 82          |\n",
      "|    total_timesteps    | 52232192    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023421884 |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.952       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0962     |\n",
      "|    mean_step_reward   | 0.032560192 |\n",
      "|    n_updates          | 28/128      |\n",
      "|    policyGradLoss     | -0.0198     |\n",
      "|    value_loss         | 0.208       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 793         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 92          |\n",
      "|    total_timesteps    | 52240384    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020731246 |\n",
      "|    entropy_loss       | -2.19       |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0993     |\n",
      "|    mean_step_reward   | 0.028829519 |\n",
      "|    n_updates          | 32/128      |\n",
      "|    policyGradLoss     | -0.0203     |\n",
      "|    value_loss         | 0.138       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 790         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 103         |\n",
      "|    total_timesteps    | 52248576    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022177905 |\n",
      "|    entropy_loss       | -2.16       |\n",
      "|    explained_variance | 0.938       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0966     |\n",
      "|    mean_step_reward   | 0.041573096 |\n",
      "|    n_updates          | 36/128      |\n",
      "|    policyGradLoss     | -0.0177     |\n",
      "|    value_loss         | 0.213       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 787        |\n",
      "|    iterations         | 11         |\n",
      "|    time_elapsed       | 114        |\n",
      "|    total_timesteps    | 52256768   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02648122 |\n",
      "|    entropy_loss       | -2.17      |\n",
      "|    explained_variance | 0.973      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0971    |\n",
      "|    mean_step_reward   | 0.04786767 |\n",
      "|    n_updates          | 40/128     |\n",
      "|    policyGradLoss     | -0.0229    |\n",
      "|    value_loss         | 0.092      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 124         |\n",
      "|    total_timesteps    | 52264960    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026871385 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.107      |\n",
      "|    mean_step_reward   | 0.03687618  |\n",
      "|    n_updates          | 44/128      |\n",
      "|    policyGradLoss     | -0.0186     |\n",
      "|    value_loss         | 0.0793      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 786          |\n",
      "|    iterations         | 13           |\n",
      "|    time_elapsed       | 135          |\n",
      "|    total_timesteps    | 52273152     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.01661903   |\n",
      "|    entropy_loss       | -2.3         |\n",
      "|    explained_variance | 0.908        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0533       |\n",
      "|    mean_step_reward   | 0.0130521525 |\n",
      "|    n_updates          | 48/128       |\n",
      "|    policyGradLoss     | -0.0138      |\n",
      "|    value_loss         | 0.261        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 145         |\n",
      "|    total_timesteps    | 52281344    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014723977 |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0888     |\n",
      "|    mean_step_reward   | 0.022815906 |\n",
      "|    n_updates          | 52/128      |\n",
      "|    policyGradLoss     | -0.0134     |\n",
      "|    value_loss         | 0.15        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 156         |\n",
      "|    total_timesteps    | 52289536    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021075835 |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.861       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0776     |\n",
      "|    mean_step_reward   | 0.021467533 |\n",
      "|    n_updates          | 56/128      |\n",
      "|    policyGradLoss     | -0.0164     |\n",
      "|    value_loss         | 0.313       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 167         |\n",
      "|    total_timesteps    | 52297728    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022453351 |\n",
      "|    entropy_loss       | -2.13       |\n",
      "|    explained_variance | 0.944       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0586     |\n",
      "|    mean_step_reward   | 0.036735557 |\n",
      "|    n_updates          | 60/128      |\n",
      "|    policyGradLoss     | -0.0176     |\n",
      "|    value_loss         | 0.351       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 178         |\n",
      "|    total_timesteps    | 52305920    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.0136989   |\n",
      "|    entropy_loss       | -2.12       |\n",
      "|    explained_variance | 0.91        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0324     |\n",
      "|    mean_step_reward   | 0.050489247 |\n",
      "|    n_updates          | 64/128      |\n",
      "|    policyGradLoss     | -0.0118     |\n",
      "|    value_loss         | 0.462       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 188         |\n",
      "|    total_timesteps    | 52314112    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024156302 |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.944       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0927     |\n",
      "|    mean_step_reward   | 0.026670504 |\n",
      "|    n_updates          | 68/128      |\n",
      "|    policyGradLoss     | -0.0159     |\n",
      "|    value_loss         | 0.161       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 199         |\n",
      "|    total_timesteps    | 52322304    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02510153  |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.106      |\n",
      "|    mean_step_reward   | 0.022847967 |\n",
      "|    n_updates          | 72/128      |\n",
      "|    policyGradLoss     | -0.022      |\n",
      "|    value_loss         | 0.106       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 210         |\n",
      "|    total_timesteps    | 52330496    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029796027 |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0812     |\n",
      "|    mean_step_reward   | 0.034011535 |\n",
      "|    n_updates          | 76/128      |\n",
      "|    policyGradLoss     | -0.0183     |\n",
      "|    value_loss         | 0.129       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 221         |\n",
      "|    total_timesteps    | 52338688    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021699283 |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.9         |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.103      |\n",
      "|    mean_step_reward   | 0.025584567 |\n",
      "|    n_updates          | 80/128      |\n",
      "|    policyGradLoss     | -0.0148     |\n",
      "|    value_loss         | 0.188       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 232         |\n",
      "|    total_timesteps    | 52346880    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029073417 |\n",
      "|    entropy_loss       | -2.17       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.106      |\n",
      "|    mean_step_reward   | 0.027831795 |\n",
      "|    n_updates          | 84/128      |\n",
      "|    policyGradLoss     | -0.0198     |\n",
      "|    value_loss         | 0.0959      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 242         |\n",
      "|    total_timesteps    | 52355072    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014244568 |\n",
      "|    entropy_loss       | -2.13       |\n",
      "|    explained_variance | 0.934       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0037     |\n",
      "|    mean_step_reward   | 0.03673961  |\n",
      "|    n_updates          | 88/128      |\n",
      "|    policyGradLoss     | -0.0126     |\n",
      "|    value_loss         | 0.339       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 253         |\n",
      "|    total_timesteps    | 52363264    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017962951 |\n",
      "|    entropy_loss       | -2.18       |\n",
      "|    explained_variance | 0.914       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0564     |\n",
      "|    mean_step_reward   | 0.01878334  |\n",
      "|    n_updates          | 92/128      |\n",
      "|    policyGradLoss     | -0.0147     |\n",
      "|    value_loss         | 0.334       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 264         |\n",
      "|    total_timesteps    | 52371456    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017466318 |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.894       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0458     |\n",
      "|    mean_step_reward   | 0.040451318 |\n",
      "|    n_updates          | 96/128      |\n",
      "|    policyGradLoss     | -0.0115     |\n",
      "|    value_loss         | 0.399       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 274         |\n",
      "|    total_timesteps    | 52379648    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019862471 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.899       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0795     |\n",
      "|    mean_step_reward   | 0.0183883   |\n",
      "|    n_updates          | 100/128     |\n",
      "|    policyGradLoss     | -0.0156     |\n",
      "|    value_loss         | 0.191       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 285         |\n",
      "|    total_timesteps    | 52387840    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02401061  |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0913     |\n",
      "|    mean_step_reward   | 0.033888157 |\n",
      "|    n_updates          | 104/128     |\n",
      "|    policyGradLoss     | -0.0179     |\n",
      "|    value_loss         | 0.122       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 296         |\n",
      "|    total_timesteps    | 52396032    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02564368  |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.935       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.083      |\n",
      "|    mean_step_reward   | 0.011066735 |\n",
      "|    n_updates          | 108/128     |\n",
      "|    policyGradLoss     | -0.0172     |\n",
      "|    value_loss         | 0.179       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 307         |\n",
      "|    total_timesteps    | 52404224    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022436477 |\n",
      "|    entropy_loss       | -2.08       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0815     |\n",
      "|    mean_step_reward   | 0.03924044  |\n",
      "|    n_updates          | 112/128     |\n",
      "|    policyGradLoss     | -0.0169     |\n",
      "|    value_loss         | 0.156       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 773        |\n",
      "|    iterations         | 30         |\n",
      "|    time_elapsed       | 317        |\n",
      "|    total_timesteps    | 52412416   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03190378 |\n",
      "|    entropy_loss       | -2.1       |\n",
      "|    explained_variance | 0.969      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0866    |\n",
      "|    mean_step_reward   | 0.05182888 |\n",
      "|    n_updates          | 116/128    |\n",
      "|    policyGradLoss     | -0.0206    |\n",
      "|    value_loss         | 0.15       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 328         |\n",
      "|    total_timesteps    | 52420608    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030391145 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.109      |\n",
      "|    mean_step_reward   | 0.02855599  |\n",
      "|    n_updates          | 120/128     |\n",
      "|    policyGradLoss     | -0.022      |\n",
      "|    value_loss         | 0.0814      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 339         |\n",
      "|    total_timesteps    | 52428800    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026079014 |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.087      |\n",
      "|    mean_step_reward   | 0.03077982  |\n",
      "|    n_updates          | 124/128     |\n",
      "|    policyGradLoss     | -0.0201     |\n",
      "|    value_loss         | 0.117       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/NoArti_199.zip\n",
      "[EVAL] Mean Return: 69.009, Best Return: 71.009\n",
      "Saved video to ./runs_smw/videos/NoArti/NoArti_199_69.01.mp4\n",
      "\n",
      "=== Round 201 | Learn 262144 steps (Total trained: 52428800) ===\n",
      "Logging to ./runs_smw/tb/NoArti_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1058     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 52436992 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 891         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 52445184    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020315535 |\n",
      "|    entropy_loss       | -2.28       |\n",
      "|    explained_variance | 0.929       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0447     |\n",
      "|    mean_step_reward   | 0.013840143 |\n",
      "|    n_updates          | 4/128       |\n",
      "|    policyGradLoss     | -0.014      |\n",
      "|    value_loss         | 0.162       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 837         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 29          |\n",
      "|    total_timesteps    | 52453376    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023357227 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.94        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0837     |\n",
      "|    mean_step_reward   | 0.024249747 |\n",
      "|    n_updates          | 8/128       |\n",
      "|    policyGradLoss     | -0.0191     |\n",
      "|    value_loss         | 0.178       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 818         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 40          |\n",
      "|    total_timesteps    | 52461568    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018438477 |\n",
      "|    entropy_loss       | -2.11       |\n",
      "|    explained_variance | 0.816       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0555     |\n",
      "|    mean_step_reward   | 0.019471796 |\n",
      "|    n_updates          | 12/128      |\n",
      "|    policyGradLoss     | -0.0108     |\n",
      "|    value_loss         | 0.497       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 805         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 50          |\n",
      "|    total_timesteps    | 52469760    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.0229811   |\n",
      "|    entropy_loss       | -2.12       |\n",
      "|    explained_variance | 0.935       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0547     |\n",
      "|    mean_step_reward   | 0.051232837 |\n",
      "|    n_updates          | 16/128      |\n",
      "|    policyGradLoss     | -0.0129     |\n",
      "|    value_loss         | 0.271       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 798         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 61          |\n",
      "|    total_timesteps    | 52477952    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019632712 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.946       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0883     |\n",
      "|    mean_step_reward   | 0.02268291  |\n",
      "|    n_updates          | 20/128      |\n",
      "|    policyGradLoss     | -0.0199     |\n",
      "|    value_loss         | 0.158       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 793         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 72          |\n",
      "|    total_timesteps    | 52486144    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021431122 |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.911       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0956     |\n",
      "|    mean_step_reward   | 0.014170261 |\n",
      "|    n_updates          | 24/128      |\n",
      "|    policyGradLoss     | -0.0222     |\n",
      "|    value_loss         | 0.205       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 83          |\n",
      "|    total_timesteps    | 52494336    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023674887 |\n",
      "|    entropy_loss       | -2.32       |\n",
      "|    explained_variance | 0.95        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.116      |\n",
      "|    mean_step_reward   | 0.010415639 |\n",
      "|    n_updates          | 28/128      |\n",
      "|    policyGradLoss     | -0.02       |\n",
      "|    value_loss         | 0.061       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 93          |\n",
      "|    total_timesteps    | 52502528    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022816747 |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.94        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0548     |\n",
      "|    mean_step_reward   | 0.018555177 |\n",
      "|    n_updates          | 32/128      |\n",
      "|    policyGradLoss     | -0.0156     |\n",
      "|    value_loss         | 0.128       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 104         |\n",
      "|    total_timesteps    | 52510720    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021031562 |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.958       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.105      |\n",
      "|    mean_step_reward   | 0.023489624 |\n",
      "|    n_updates          | 36/128      |\n",
      "|    policyGradLoss     | -0.0154     |\n",
      "|    value_loss         | 0.0952      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 115         |\n",
      "|    total_timesteps    | 52518912    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018707117 |\n",
      "|    entropy_loss       | -2.18       |\n",
      "|    explained_variance | 0.893       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0341     |\n",
      "|    mean_step_reward   | 0.020543046 |\n",
      "|    n_updates          | 40/128      |\n",
      "|    policyGradLoss     | -0.0153     |\n",
      "|    value_loss         | 0.419       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 126         |\n",
      "|    total_timesteps    | 52527104    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026077569 |\n",
      "|    entropy_loss       | -2.09       |\n",
      "|    explained_variance | 0.95        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0815     |\n",
      "|    mean_step_reward   | 0.05373351  |\n",
      "|    n_updates          | 44/128      |\n",
      "|    policyGradLoss     | -0.0149     |\n",
      "|    value_loss         | 0.187       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 137         |\n",
      "|    total_timesteps    | 52535296    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028401006 |\n",
      "|    entropy_loss       | -2.17       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.102      |\n",
      "|    mean_step_reward   | 0.045611773 |\n",
      "|    n_updates          | 48/128      |\n",
      "|    policyGradLoss     | -0.0167     |\n",
      "|    value_loss         | 0.0896      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 147         |\n",
      "|    total_timesteps    | 52543488    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021798734 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0966     |\n",
      "|    mean_step_reward   | 0.034264967 |\n",
      "|    n_updates          | 52/128      |\n",
      "|    policyGradLoss     | -0.021      |\n",
      "|    value_loss         | 0.0803      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 158         |\n",
      "|    total_timesteps    | 52551680    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023892269 |\n",
      "|    entropy_loss       | -2.19       |\n",
      "|    explained_variance | 0.937       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0661     |\n",
      "|    mean_step_reward   | 0.02809912  |\n",
      "|    n_updates          | 56/128      |\n",
      "|    policyGradLoss     | -0.0166     |\n",
      "|    value_loss         | 0.189       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 168         |\n",
      "|    total_timesteps    | 52559872    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024644535 |\n",
      "|    entropy_loss       | -2.17       |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0883     |\n",
      "|    mean_step_reward   | 0.044548683 |\n",
      "|    n_updates          | 60/128      |\n",
      "|    policyGradLoss     | -0.018      |\n",
      "|    value_loss         | 0.209       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 180         |\n",
      "|    total_timesteps    | 52568064    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018913357 |\n",
      "|    entropy_loss       | -2.17       |\n",
      "|    explained_variance | 0.897       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0496     |\n",
      "|    mean_step_reward   | 0.040846594 |\n",
      "|    n_updates          | 64/128      |\n",
      "|    policyGradLoss     | -0.0143     |\n",
      "|    value_loss         | 0.425       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 191         |\n",
      "|    total_timesteps    | 52576256    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021295229 |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.897       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0876     |\n",
      "|    mean_step_reward   | 0.03107641  |\n",
      "|    n_updates          | 68/128      |\n",
      "|    policyGradLoss     | -0.0181     |\n",
      "|    value_loss         | 0.199       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 201         |\n",
      "|    total_timesteps    | 52584448    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021745387 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.923       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.077      |\n",
      "|    mean_step_reward   | 0.029620554 |\n",
      "|    n_updates          | 72/128      |\n",
      "|    policyGradLoss     | -0.0237     |\n",
      "|    value_loss         | 0.178       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 212         |\n",
      "|    total_timesteps    | 52592640    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022359822 |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.93        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0217     |\n",
      "|    mean_step_reward   | 0.018130982 |\n",
      "|    n_updates          | 76/128      |\n",
      "|    policyGradLoss     | -0.0187     |\n",
      "|    value_loss         | 0.161       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 223         |\n",
      "|    total_timesteps    | 52600832    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021350965 |\n",
      "|    entropy_loss       | -2.2        |\n",
      "|    explained_variance | 0.943       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0893     |\n",
      "|    mean_step_reward   | 0.033374313 |\n",
      "|    n_updates          | 80/128      |\n",
      "|    policyGradLoss     | -0.018      |\n",
      "|    value_loss         | 0.19        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 234         |\n",
      "|    total_timesteps    | 52609024    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023355376 |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.947       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0976     |\n",
      "|    mean_step_reward   | 0.02605531  |\n",
      "|    n_updates          | 84/128      |\n",
      "|    policyGradLoss     | -0.0187     |\n",
      "|    value_loss         | 0.108       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 245         |\n",
      "|    total_timesteps    | 52617216    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01923566  |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.933       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0238      |\n",
      "|    mean_step_reward   | 0.029275604 |\n",
      "|    n_updates          | 88/128      |\n",
      "|    policyGradLoss     | -0.0141     |\n",
      "|    value_loss         | 0.306       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 255         |\n",
      "|    total_timesteps    | 52625408    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019209985 |\n",
      "|    entropy_loss       | -2.18       |\n",
      "|    explained_variance | 0.914       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0675     |\n",
      "|    mean_step_reward   | 0.028339354 |\n",
      "|    n_updates          | 92/128      |\n",
      "|    policyGradLoss     | -0.0158     |\n",
      "|    value_loss         | 0.347       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 266         |\n",
      "|    total_timesteps    | 52633600    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027092975 |\n",
      "|    entropy_loss       | -2.18       |\n",
      "|    explained_variance | 0.916       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0908     |\n",
      "|    mean_step_reward   | 0.02705745  |\n",
      "|    n_updates          | 96/128      |\n",
      "|    policyGradLoss     | -0.0176     |\n",
      "|    value_loss         | 0.224       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 276         |\n",
      "|    total_timesteps    | 52641792    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020201935 |\n",
      "|    entropy_loss       | -2.14       |\n",
      "|    explained_variance | 0.933       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0586     |\n",
      "|    mean_step_reward   | 0.031906877 |\n",
      "|    n_updates          | 100/128     |\n",
      "|    policyGradLoss     | -0.0197     |\n",
      "|    value_loss         | 0.342       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 287         |\n",
      "|    total_timesteps    | 52649984    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022681065 |\n",
      "|    entropy_loss       | -2.17       |\n",
      "|    explained_variance | 0.936       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0674     |\n",
      "|    mean_step_reward   | 0.041748356 |\n",
      "|    n_updates          | 104/128     |\n",
      "|    policyGradLoss     | -0.0191     |\n",
      "|    value_loss         | 0.236       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 298         |\n",
      "|    total_timesteps    | 52658176    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026018856 |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.957       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0708     |\n",
      "|    mean_step_reward   | 0.036232192 |\n",
      "|    n_updates          | 108/128     |\n",
      "|    policyGradLoss     | -0.0184     |\n",
      "|    value_loss         | 0.0982      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 309         |\n",
      "|    total_timesteps    | 52666368    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017620554 |\n",
      "|    entropy_loss       | -2.28       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0814     |\n",
      "|    mean_step_reward   | 0.022592716 |\n",
      "|    n_updates          | 112/128     |\n",
      "|    policyGradLoss     | -0.0147     |\n",
      "|    value_loss         | 0.115       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 320         |\n",
      "|    total_timesteps    | 52674560    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016775815 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.745       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0567     |\n",
      "|    mean_step_reward   | 0.027395887 |\n",
      "|    n_updates          | 116/128     |\n",
      "|    policyGradLoss     | -0.00945    |\n",
      "|    value_loss         | 0.348       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 330         |\n",
      "|    total_timesteps    | 52682752    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026427431 |\n",
      "|    entropy_loss       | -2.2        |\n",
      "|    explained_variance | 0.927       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0127     |\n",
      "|    mean_step_reward   | 0.028896809 |\n",
      "|    n_updates          | 120/128     |\n",
      "|    policyGradLoss     | -0.0167     |\n",
      "|    value_loss         | 0.246       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 342         |\n",
      "|    total_timesteps    | 52690944    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016740605 |\n",
      "|    entropy_loss       | -2.17       |\n",
      "|    explained_variance | 0.899       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0381     |\n",
      "|    mean_step_reward   | 0.0324747   |\n",
      "|    n_updates          | 124/128     |\n",
      "|    policyGradLoss     | -0.0135     |\n",
      "|    value_loss         | 0.431       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/NoArti_200.zip\n",
      "[EVAL] Mean Return: 109.770, Best Return: 112.170\n",
      "Saved video to ./runs_smw/videos/NoArti/NoArti_200_109.77.mp4\n",
      "\n",
      "=== Round 202 | Learn 262144 steps (Total trained: 52690944) ===\n",
      "Logging to ./runs_smw/tb/NoArti_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1061     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 52699136 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 884         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 52707328    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030667774 |\n",
      "|    entropy_loss       | -2.18       |\n",
      "|    explained_variance | 0.949       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0942     |\n",
      "|    mean_step_reward   | 0.033308282 |\n",
      "|    n_updates          | 4/128       |\n",
      "|    policyGradLoss     | -0.022      |\n",
      "|    value_loss         | 0.131       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 847         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 29          |\n",
      "|    total_timesteps    | 52715520    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018640988 |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.904       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.044      |\n",
      "|    mean_step_reward   | 0.031774934 |\n",
      "|    n_updates          | 8/128       |\n",
      "|    policyGradLoss     | -0.0116     |\n",
      "|    value_loss         | 0.321       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 825         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 52723712    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.03402708  |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.934       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0961     |\n",
      "|    mean_step_reward   | 0.030979175 |\n",
      "|    n_updates          | 12/128      |\n",
      "|    policyGradLoss     | -0.0167     |\n",
      "|    value_loss         | 0.119       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 814         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 50          |\n",
      "|    total_timesteps    | 52731904    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013586765 |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.806       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0739     |\n",
      "|    mean_step_reward   | 0.015353935 |\n",
      "|    n_updates          | 16/128      |\n",
      "|    policyGradLoss     | -0.0101     |\n",
      "|    value_loss         | 0.373       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 802         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 61          |\n",
      "|    total_timesteps    | 52740096    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.0130987   |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.929       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0903     |\n",
      "|    mean_step_reward   | 0.030855581 |\n",
      "|    n_updates          | 20/128      |\n",
      "|    policyGradLoss     | -0.00991    |\n",
      "|    value_loss         | 0.216       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 791         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 72          |\n",
      "|    total_timesteps    | 52748288    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02092015  |\n",
      "|    entropy_loss       | -2.2        |\n",
      "|    explained_variance | 0.945       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0963     |\n",
      "|    mean_step_reward   | 0.023151826 |\n",
      "|    n_updates          | 24/128      |\n",
      "|    policyGradLoss     | -0.0175     |\n",
      "|    value_loss         | 0.165       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 83          |\n",
      "|    total_timesteps    | 52756480    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027355792 |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.958       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0935     |\n",
      "|    mean_step_reward   | 0.027799344 |\n",
      "|    n_updates          | 28/128      |\n",
      "|    policyGradLoss     | -0.0173     |\n",
      "|    value_loss         | 0.143       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 94          |\n",
      "|    total_timesteps    | 52764672    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024970774 |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.954       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0788     |\n",
      "|    mean_step_reward   | 0.017520035 |\n",
      "|    n_updates          | 32/128      |\n",
      "|    policyGradLoss     | -0.0208     |\n",
      "|    value_loss         | 0.155       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 104         |\n",
      "|    total_timesteps    | 52772864    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025234394 |\n",
      "|    entropy_loss       | -2.19       |\n",
      "|    explained_variance | 0.937       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0754     |\n",
      "|    mean_step_reward   | 0.023217898 |\n",
      "|    n_updates          | 36/128      |\n",
      "|    policyGradLoss     | -0.0182     |\n",
      "|    value_loss         | 0.17        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 115         |\n",
      "|    total_timesteps    | 52781056    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023595052 |\n",
      "|    entropy_loss       | -2.15       |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0759     |\n",
      "|    mean_step_reward   | 0.05015322  |\n",
      "|    n_updates          | 40/128      |\n",
      "|    policyGradLoss     | -0.0162     |\n",
      "|    value_loss         | 0.238       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 126         |\n",
      "|    total_timesteps    | 52789248    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029562134 |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.104      |\n",
      "|    mean_step_reward   | 0.03360053  |\n",
      "|    n_updates          | 44/128      |\n",
      "|    policyGradLoss     | -0.0219     |\n",
      "|    value_loss         | 0.0865      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 137         |\n",
      "|    total_timesteps    | 52797440    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021382261 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.893       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0677     |\n",
      "|    mean_step_reward   | 0.017319383 |\n",
      "|    n_updates          | 48/128      |\n",
      "|    policyGradLoss     | -0.0164     |\n",
      "|    value_loss         | 0.17        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 148         |\n",
      "|    total_timesteps    | 52805632    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021020522 |\n",
      "|    entropy_loss       | -2.3        |\n",
      "|    explained_variance | 0.87        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0341     |\n",
      "|    mean_step_reward   | 0.011284373 |\n",
      "|    n_updates          | 52/128      |\n",
      "|    policyGradLoss     | -0.0158     |\n",
      "|    value_loss         | 0.233       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 159         |\n",
      "|    total_timesteps    | 52813824    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014109371 |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.906       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0694     |\n",
      "|    mean_step_reward   | 0.03930953  |\n",
      "|    n_updates          | 56/128      |\n",
      "|    policyGradLoss     | -0.0125     |\n",
      "|    value_loss         | 0.288       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 171         |\n",
      "|    total_timesteps    | 52822016    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020145148 |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.95        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0929     |\n",
      "|    mean_step_reward   | 0.026544921 |\n",
      "|    n_updates          | 60/128      |\n",
      "|    policyGradLoss     | -0.0183     |\n",
      "|    value_loss         | 0.156       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 765         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 182         |\n",
      "|    total_timesteps    | 52830208    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017764252 |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.914       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0704     |\n",
      "|    mean_step_reward   | 0.026444513 |\n",
      "|    n_updates          | 64/128      |\n",
      "|    policyGradLoss     | -0.0142     |\n",
      "|    value_loss         | 0.258       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 765         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 192         |\n",
      "|    total_timesteps    | 52838400    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022198899 |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.932       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.086      |\n",
      "|    mean_step_reward   | 0.0388063   |\n",
      "|    n_updates          | 68/128      |\n",
      "|    policyGradLoss     | -0.0181     |\n",
      "|    value_loss         | 0.141       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 763         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 203         |\n",
      "|    total_timesteps    | 52846592    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022666756 |\n",
      "|    entropy_loss       | -2.17       |\n",
      "|    explained_variance | 0.949       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0785     |\n",
      "|    mean_step_reward   | 0.040345907 |\n",
      "|    n_updates          | 72/128      |\n",
      "|    policyGradLoss     | -0.0181     |\n",
      "|    value_loss         | 0.253       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 763         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 214         |\n",
      "|    total_timesteps    | 52854784    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023505144 |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.955       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0902     |\n",
      "|    mean_step_reward   | 0.02619672  |\n",
      "|    n_updates          | 76/128      |\n",
      "|    policyGradLoss     | -0.0161     |\n",
      "|    value_loss         | 0.138       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 763         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 225         |\n",
      "|    total_timesteps    | 52862976    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019645805 |\n",
      "|    entropy_loss       | -2.27       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.111      |\n",
      "|    mean_step_reward   | 0.01674243  |\n",
      "|    n_updates          | 80/128      |\n",
      "|    policyGradLoss     | -0.0202     |\n",
      "|    value_loss         | 0.061       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 762         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 236         |\n",
      "|    total_timesteps    | 52871168    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021884562 |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0939     |\n",
      "|    mean_step_reward   | 0.022681404 |\n",
      "|    n_updates          | 84/128      |\n",
      "|    policyGradLoss     | -0.0163     |\n",
      "|    value_loss         | 0.0908      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 762         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 247         |\n",
      "|    total_timesteps    | 52879360    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.032926425 |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.105      |\n",
      "|    mean_step_reward   | 0.025550392 |\n",
      "|    n_updates          | 88/128      |\n",
      "|    policyGradLoss     | -0.0233     |\n",
      "|    value_loss         | 0.0714      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 762         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 257         |\n",
      "|    total_timesteps    | 52887552    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030083325 |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.119      |\n",
      "|    mean_step_reward   | 0.021448333 |\n",
      "|    n_updates          | 92/128      |\n",
      "|    policyGradLoss     | -0.0265     |\n",
      "|    value_loss         | 0.0413      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 762        |\n",
      "|    iterations         | 25         |\n",
      "|    time_elapsed       | 268        |\n",
      "|    total_timesteps    | 52895744   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01975806 |\n",
      "|    entropy_loss       | -2.1       |\n",
      "|    explained_variance | 0.938      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.00852    |\n",
      "|    mean_step_reward   | 0.0373673  |\n",
      "|    n_updates          | 96/128     |\n",
      "|    policyGradLoss     | -0.0165    |\n",
      "|    value_loss         | 0.295      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 761         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 279         |\n",
      "|    total_timesteps    | 52903936    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029865291 |\n",
      "|    entropy_loss       | -2.09       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.103      |\n",
      "|    mean_step_reward   | 0.061523665 |\n",
      "|    n_updates          | 100/128     |\n",
      "|    policyGradLoss     | -0.0204     |\n",
      "|    value_loss         | 0.108       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 762         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 290         |\n",
      "|    total_timesteps    | 52912128    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029775016 |\n",
      "|    entropy_loss       | -2.2        |\n",
      "|    explained_variance | 0.847       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.09       |\n",
      "|    mean_step_reward   | 0.017517833 |\n",
      "|    n_updates          | 104/128     |\n",
      "|    policyGradLoss     | -0.015      |\n",
      "|    value_loss         | 0.161       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 761         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 301         |\n",
      "|    total_timesteps    | 52920320    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025046956 |\n",
      "|    entropy_loss       | -2.19       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0919     |\n",
      "|    mean_step_reward   | 0.047449697 |\n",
      "|    n_updates          | 108/128     |\n",
      "|    policyGradLoss     | -0.0177     |\n",
      "|    value_loss         | 0.136       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 760         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 312         |\n",
      "|    total_timesteps    | 52928512    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029227162 |\n",
      "|    entropy_loss       | -2.31       |\n",
      "|    explained_variance | 0.945       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.112      |\n",
      "|    mean_step_reward   | 0.009866732 |\n",
      "|    n_updates          | 112/128     |\n",
      "|    policyGradLoss     | -0.0176     |\n",
      "|    value_loss         | 0.0715      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 759         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 323         |\n",
      "|    total_timesteps    | 52936704    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027118327 |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.951       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0976     |\n",
      "|    mean_step_reward   | 0.02613404  |\n",
      "|    n_updates          | 116/128     |\n",
      "|    policyGradLoss     | -0.0185     |\n",
      "|    value_loss         | 0.114       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 759         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 334         |\n",
      "|    total_timesteps    | 52944896    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02350247  |\n",
      "|    entropy_loss       | -2.17       |\n",
      "|    explained_variance | 0.95        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0209     |\n",
      "|    mean_step_reward   | 0.019732695 |\n",
      "|    n_updates          | 120/128     |\n",
      "|    policyGradLoss     | -0.0173     |\n",
      "|    value_loss         | 0.311       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 758         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 345         |\n",
      "|    total_timesteps    | 52953088    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024847986 |\n",
      "|    entropy_loss       | -2.18       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0977     |\n",
      "|    mean_step_reward   | 0.036381427 |\n",
      "|    n_updates          | 124/128     |\n",
      "|    policyGradLoss     | -0.0184     |\n",
      "|    value_loss         | 0.134       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/NoArti_201.zip\n",
      "[EVAL] Mean Return: -5.639, Best Return: -5.439\n",
      "Saved video to ./runs_smw/videos/NoArti/NoArti_201_-5.64.mp4\n",
      "\n",
      "=== Round 203 | Learn 262144 steps (Total trained: 52953088) ===\n",
      "Logging to ./runs_smw/tb/NoArti_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1104     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 52961280 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 877         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 52969472    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019783279 |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.897       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0854     |\n",
      "|    mean_step_reward   | 0.014905371 |\n",
      "|    n_updates          | 4/128       |\n",
      "|    policyGradLoss     | -0.0145     |\n",
      "|    value_loss         | 0.165       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 829         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 29          |\n",
      "|    total_timesteps    | 52977664    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021738017 |\n",
      "|    entropy_loss       | -2.31       |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.11       |\n",
      "|    mean_step_reward   | 0.026227131 |\n",
      "|    n_updates          | 8/128       |\n",
      "|    policyGradLoss     | -0.0203     |\n",
      "|    value_loss         | 0.046       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 807         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 40          |\n",
      "|    total_timesteps    | 52985856    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026120815 |\n",
      "|    entropy_loss       | -2.32       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.11       |\n",
      "|    mean_step_reward   | 0.01048957  |\n",
      "|    n_updates          | 12/128      |\n",
      "|    policyGradLoss     | -0.02       |\n",
      "|    value_loss         | 0.0491      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 797         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 51          |\n",
      "|    total_timesteps    | 52994048    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015646514 |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.939       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0735     |\n",
      "|    mean_step_reward   | 0.015875774 |\n",
      "|    n_updates          | 16/128      |\n",
      "|    policyGradLoss     | -0.015      |\n",
      "|    value_loss         | 0.191       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 789         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 62          |\n",
      "|    total_timesteps    | 53002240    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023933671 |\n",
      "|    entropy_loss       | -2          |\n",
      "|    explained_variance | 0.951       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0321      |\n",
      "|    mean_step_reward   | 0.066226214 |\n",
      "|    n_updates          | 20/128      |\n",
      "|    policyGradLoss     | -0.0148     |\n",
      "|    value_loss         | 0.296       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 72          |\n",
      "|    total_timesteps    | 53010432    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02207921  |\n",
      "|    entropy_loss       | -2.13       |\n",
      "|    explained_variance | 0.909       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0711     |\n",
      "|    mean_step_reward   | 0.050094094 |\n",
      "|    n_updates          | 24/128      |\n",
      "|    policyGradLoss     | -0.0137     |\n",
      "|    value_loss         | 0.357       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 83          |\n",
      "|    total_timesteps    | 53018624    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017624358 |\n",
      "|    entropy_loss       | -2.12       |\n",
      "|    explained_variance | 0.942       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0543     |\n",
      "|    mean_step_reward   | 0.0504061   |\n",
      "|    n_updates          | 28/128      |\n",
      "|    policyGradLoss     | -0.0168     |\n",
      "|    value_loss         | 0.303       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 779        |\n",
      "|    iterations         | 9          |\n",
      "|    time_elapsed       | 94         |\n",
      "|    total_timesteps    | 53026816   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03111973 |\n",
      "|    entropy_loss       | -2.15      |\n",
      "|    explained_variance | 0.977      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.11      |\n",
      "|    mean_step_reward   | 0.04560418 |\n",
      "|    n_updates          | 32/128     |\n",
      "|    policyGradLoss     | -0.0232    |\n",
      "|    value_loss         | 0.0876     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 105         |\n",
      "|    total_timesteps    | 53035008    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020082831 |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.887       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.083      |\n",
      "|    mean_step_reward   | 0.029324053 |\n",
      "|    n_updates          | 36/128      |\n",
      "|    policyGradLoss     | -0.0168     |\n",
      "|    value_loss         | 0.361       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 775        |\n",
      "|    iterations         | 11         |\n",
      "|    time_elapsed       | 116        |\n",
      "|    total_timesteps    | 53043200   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01912576 |\n",
      "|    entropy_loss       | -2.2       |\n",
      "|    explained_variance | 0.85       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0888    |\n",
      "|    mean_step_reward   | 0.02869076 |\n",
      "|    n_updates          | 40/128     |\n",
      "|    policyGradLoss     | -0.0176    |\n",
      "|    value_loss         | 0.256      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 127         |\n",
      "|    total_timesteps    | 53051392    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022113342 |\n",
      "|    entropy_loss       | -2.29       |\n",
      "|    explained_variance | 0.879       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0973     |\n",
      "|    mean_step_reward   | 0.020909254 |\n",
      "|    n_updates          | 44/128      |\n",
      "|    policyGradLoss     | -0.00979    |\n",
      "|    value_loss         | 0.167       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 137         |\n",
      "|    total_timesteps    | 53059584    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026483193 |\n",
      "|    entropy_loss       | -2.28       |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.12       |\n",
      "|    mean_step_reward   | 0.02083815  |\n",
      "|    n_updates          | 48/128      |\n",
      "|    policyGradLoss     | -0.0205     |\n",
      "|    value_loss         | 0.0508      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 148         |\n",
      "|    total_timesteps    | 53067776    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026881725 |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.119      |\n",
      "|    mean_step_reward   | 0.015494183 |\n",
      "|    n_updates          | 52/128      |\n",
      "|    policyGradLoss     | -0.0258     |\n",
      "|    value_loss         | 0.0394      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 158         |\n",
      "|    total_timesteps    | 53075968    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026707837 |\n",
      "|    entropy_loss       | -2.15       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0658     |\n",
      "|    mean_step_reward   | 0.02603005  |\n",
      "|    n_updates          | 56/128      |\n",
      "|    policyGradLoss     | -0.0213     |\n",
      "|    value_loss         | 0.151       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 169         |\n",
      "|    total_timesteps    | 53084160    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021632228 |\n",
      "|    entropy_loss       | -2.19       |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0651     |\n",
      "|    mean_step_reward   | 0.03568249  |\n",
      "|    n_updates          | 60/128      |\n",
      "|    policyGradLoss     | -0.016      |\n",
      "|    value_loss         | 0.209       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 181         |\n",
      "|    total_timesteps    | 53092352    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017838664 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.922       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0899     |\n",
      "|    mean_step_reward   | 0.015071316 |\n",
      "|    n_updates          | 64/128      |\n",
      "|    policyGradLoss     | -0.0159     |\n",
      "|    value_loss         | 0.132       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 192         |\n",
      "|    total_timesteps    | 53100544    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020028472 |\n",
      "|    entropy_loss       | -2.3        |\n",
      "|    explained_variance | 0.933       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.105      |\n",
      "|    mean_step_reward   | 0.016753776 |\n",
      "|    n_updates          | 68/128      |\n",
      "|    policyGradLoss     | -0.0156     |\n",
      "|    value_loss         | 0.102       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 766          |\n",
      "|    iterations         | 19           |\n",
      "|    time_elapsed       | 203          |\n",
      "|    total_timesteps    | 53108736     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.015971936  |\n",
      "|    entropy_loss       | -2.31        |\n",
      "|    explained_variance | 0.843        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0815      |\n",
      "|    mean_step_reward   | -0.004220921 |\n",
      "|    n_updates          | 72/128       |\n",
      "|    policyGradLoss     | -0.0162      |\n",
      "|    value_loss         | 0.214        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 765         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 214         |\n",
      "|    total_timesteps    | 53116928    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021678083 |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.919       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0994     |\n",
      "|    mean_step_reward   | 0.020640638 |\n",
      "|    n_updates          | 76/128      |\n",
      "|    policyGradLoss     | -0.0182     |\n",
      "|    value_loss         | 0.153       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 765        |\n",
      "|    iterations         | 21         |\n",
      "|    time_elapsed       | 224        |\n",
      "|    total_timesteps    | 53125120   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01965741 |\n",
      "|    entropy_loss       | -2.17      |\n",
      "|    explained_variance | 0.971      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0794    |\n",
      "|    mean_step_reward   | 0.01861199 |\n",
      "|    n_updates          | 80/128     |\n",
      "|    policyGradLoss     | -0.0207    |\n",
      "|    value_loss         | 0.145      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 765        |\n",
      "|    iterations         | 22         |\n",
      "|    time_elapsed       | 235        |\n",
      "|    total_timesteps    | 53133312   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03295047 |\n",
      "|    entropy_loss       | -2.13      |\n",
      "|    explained_variance | 0.944      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0796    |\n",
      "|    mean_step_reward   | 0.04682724 |\n",
      "|    n_updates          | 84/128     |\n",
      "|    policyGradLoss     | -0.0217    |\n",
      "|    value_loss         | 0.331      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 764         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 246         |\n",
      "|    total_timesteps    | 53141504    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019843765 |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.914       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0689     |\n",
      "|    mean_step_reward   | 0.013113749 |\n",
      "|    n_updates          | 88/128      |\n",
      "|    policyGradLoss     | -0.014      |\n",
      "|    value_loss         | 0.2         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 764         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 257         |\n",
      "|    total_timesteps    | 53149696    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016501695 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.922       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.091      |\n",
      "|    mean_step_reward   | 0.030332772 |\n",
      "|    n_updates          | 92/128      |\n",
      "|    policyGradLoss     | -0.0142     |\n",
      "|    value_loss         | 0.143       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 764         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 267         |\n",
      "|    total_timesteps    | 53157888    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020614883 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.914       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0577     |\n",
      "|    mean_step_reward   | 0.025927845 |\n",
      "|    n_updates          | 96/128      |\n",
      "|    policyGradLoss     | -0.0109     |\n",
      "|    value_loss         | 0.215       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 764         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 278         |\n",
      "|    total_timesteps    | 53166080    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024413357 |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.952       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0874     |\n",
      "|    mean_step_reward   | 0.022713097 |\n",
      "|    n_updates          | 100/128     |\n",
      "|    policyGradLoss     | -0.0172     |\n",
      "|    value_loss         | 0.203       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 763         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 289         |\n",
      "|    total_timesteps    | 53174272    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.0163273   |\n",
      "|    entropy_loss       | -2.19       |\n",
      "|    explained_variance | 0.943       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0779     |\n",
      "|    mean_step_reward   | 0.024861274 |\n",
      "|    n_updates          | 104/128     |\n",
      "|    policyGradLoss     | -0.0125     |\n",
      "|    value_loss         | 0.242       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 762         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 300         |\n",
      "|    total_timesteps    | 53182464    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026680272 |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.95        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0952     |\n",
      "|    mean_step_reward   | 0.02152012  |\n",
      "|    n_updates          | 108/128     |\n",
      "|    policyGradLoss     | -0.0223     |\n",
      "|    value_loss         | 0.113       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 763         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 311         |\n",
      "|    total_timesteps    | 53190656    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02226618  |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.95        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0938     |\n",
      "|    mean_step_reward   | 0.019755585 |\n",
      "|    n_updates          | 112/128     |\n",
      "|    policyGradLoss     | -0.0148     |\n",
      "|    value_loss         | 0.122       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 762         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 322         |\n",
      "|    total_timesteps    | 53198848    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01997235  |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.112      |\n",
      "|    mean_step_reward   | 0.026901547 |\n",
      "|    n_updates          | 116/128     |\n",
      "|    policyGradLoss     | -0.0191     |\n",
      "|    value_loss         | 0.0588      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 762         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 333         |\n",
      "|    total_timesteps    | 53207040    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022377148 |\n",
      "|    entropy_loss       | -2.27       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.107      |\n",
      "|    mean_step_reward   | 0.026656859 |\n",
      "|    n_updates          | 120/128     |\n",
      "|    policyGradLoss     | -0.0171     |\n",
      "|    value_loss         | 0.0634      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 762         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 343         |\n",
      "|    total_timesteps    | 53215232    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020104859 |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0907     |\n",
      "|    mean_step_reward   | 0.016634556 |\n",
      "|    n_updates          | 124/128     |\n",
      "|    policyGradLoss     | -0.0172     |\n",
      "|    value_loss         | 0.133       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/NoArti_202.zip\n",
      "[EVAL] Mean Return: 43.383, Best Return: 45.183\n",
      "Saved video to ./runs_smw/videos/NoArti/NoArti_202_43.38.mp4\n",
      "\n",
      "=== Round 204 | Learn 262144 steps (Total trained: 53215232) ===\n",
      "Logging to ./runs_smw/tb/NoArti_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1085     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 53223424 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 884         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 53231616    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026201654 |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0984     |\n",
      "|    mean_step_reward   | 0.034206916 |\n",
      "|    n_updates          | 4/128       |\n",
      "|    policyGradLoss     | -0.0221     |\n",
      "|    value_loss         | 0.105       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 845         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 29          |\n",
      "|    total_timesteps    | 53239808    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023618478 |\n",
      "|    entropy_loss       | -2.29       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.11       |\n",
      "|    mean_step_reward   | 0.019940358 |\n",
      "|    n_updates          | 8/128       |\n",
      "|    policyGradLoss     | -0.0194     |\n",
      "|    value_loss         | 0.0598      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 816          |\n",
      "|    iterations         | 4            |\n",
      "|    time_elapsed       | 40           |\n",
      "|    total_timesteps    | 53248000     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.028440919  |\n",
      "|    entropy_loss       | -2.34        |\n",
      "|    explained_variance | 0.987        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.123       |\n",
      "|    mean_step_reward   | 0.0062911003 |\n",
      "|    n_updates          | 12/128       |\n",
      "|    policyGradLoss     | -0.0222      |\n",
      "|    value_loss         | 0.027        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 799          |\n",
      "|    iterations         | 5            |\n",
      "|    time_elapsed       | 51           |\n",
      "|    total_timesteps    | 53256192     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.023556154  |\n",
      "|    entropy_loss       | -2.29        |\n",
      "|    explained_variance | 0.843        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0896      |\n",
      "|    mean_step_reward   | 0.0058250753 |\n",
      "|    n_updates          | 16/128       |\n",
      "|    policyGradLoss     | -0.0158      |\n",
      "|    value_loss         | 0.18         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 792         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 62          |\n",
      "|    total_timesteps    | 53264384    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027643183 |\n",
      "|    entropy_loss       | -2.27       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.111      |\n",
      "|    mean_step_reward   | 0.013489474 |\n",
      "|    n_updates          | 20/128      |\n",
      "|    policyGradLoss     | -0.0192     |\n",
      "|    value_loss         | 0.0961      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 788         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 72          |\n",
      "|    total_timesteps    | 53272576    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02285552  |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.109      |\n",
      "|    mean_step_reward   | 0.016347192 |\n",
      "|    n_updates          | 24/128      |\n",
      "|    policyGradLoss     | -0.0205     |\n",
      "|    value_loss         | 0.072       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 83          |\n",
      "|    total_timesteps    | 53280768    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026291117 |\n",
      "|    entropy_loss       | -2.2        |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.109      |\n",
      "|    mean_step_reward   | 0.02728495  |\n",
      "|    n_updates          | 28/128      |\n",
      "|    policyGradLoss     | -0.0196     |\n",
      "|    value_loss         | 0.124       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 778          |\n",
      "|    iterations         | 9            |\n",
      "|    time_elapsed       | 94           |\n",
      "|    total_timesteps    | 53288960     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.024460103  |\n",
      "|    entropy_loss       | -2.32        |\n",
      "|    explained_variance | 0.906        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.105       |\n",
      "|    mean_step_reward   | 0.0075785737 |\n",
      "|    n_updates          | 32/128       |\n",
      "|    policyGradLoss     | -0.0163      |\n",
      "|    value_loss         | 0.0791       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 776          |\n",
      "|    iterations         | 10           |\n",
      "|    time_elapsed       | 105          |\n",
      "|    total_timesteps    | 53297152     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.020325348  |\n",
      "|    entropy_loss       | -2.33        |\n",
      "|    explained_variance | 0.899        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.046       |\n",
      "|    mean_step_reward   | 0.0027813155 |\n",
      "|    n_updates          | 36/128       |\n",
      "|    policyGradLoss     | -0.0147      |\n",
      "|    value_loss         | 0.134        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 116         |\n",
      "|    total_timesteps    | 53305344    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015276723 |\n",
      "|    entropy_loss       | -2.32       |\n",
      "|    explained_variance | 0.926       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.102      |\n",
      "|    mean_step_reward   | 0.018385142 |\n",
      "|    n_updates          | 40/128      |\n",
      "|    policyGradLoss     | -0.012      |\n",
      "|    value_loss         | 0.116       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 127         |\n",
      "|    total_timesteps    | 53313536    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024854006 |\n",
      "|    entropy_loss       | -2.32       |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.114      |\n",
      "|    mean_step_reward   | 0.008613944 |\n",
      "|    n_updates          | 44/128      |\n",
      "|    policyGradLoss     | -0.0207     |\n",
      "|    value_loss         | 0.046       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 138         |\n",
      "|    total_timesteps    | 53321728    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016023923 |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0872     |\n",
      "|    mean_step_reward   | 0.024836848 |\n",
      "|    n_updates          | 48/128      |\n",
      "|    policyGradLoss     | -0.0151     |\n",
      "|    value_loss         | 0.148       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 149         |\n",
      "|    total_timesteps    | 53329920    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021162184 |\n",
      "|    entropy_loss       | -2.14       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0866     |\n",
      "|    mean_step_reward   | 0.036368057 |\n",
      "|    n_updates          | 52/128      |\n",
      "|    policyGradLoss     | -0.019      |\n",
      "|    value_loss         | 0.16        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 160         |\n",
      "|    total_timesteps    | 53338112    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02388173  |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.107      |\n",
      "|    mean_step_reward   | 0.030870976 |\n",
      "|    n_updates          | 56/128      |\n",
      "|    policyGradLoss     | -0.0208     |\n",
      "|    value_loss         | 0.0888      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 766          |\n",
      "|    iterations         | 16           |\n",
      "|    time_elapsed       | 170          |\n",
      "|    total_timesteps    | 53346304     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.017472541  |\n",
      "|    entropy_loss       | -2.27        |\n",
      "|    explained_variance | 0.914        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0241      |\n",
      "|    mean_step_reward   | 0.0070871776 |\n",
      "|    n_updates          | 60/128       |\n",
      "|    policyGradLoss     | -0.0149      |\n",
      "|    value_loss         | 0.248        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 765         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 181         |\n",
      "|    total_timesteps    | 53354496    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028625047 |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0751     |\n",
      "|    mean_step_reward   | 0.034699477 |\n",
      "|    n_updates          | 64/128      |\n",
      "|    policyGradLoss     | -0.0207     |\n",
      "|    value_loss         | 0.129       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 765         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 192         |\n",
      "|    total_timesteps    | 53362688    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026286852 |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.945       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0882     |\n",
      "|    mean_step_reward   | 0.018554544 |\n",
      "|    n_updates          | 68/128      |\n",
      "|    policyGradLoss     | -0.0184     |\n",
      "|    value_loss         | 0.188       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 764         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 203         |\n",
      "|    total_timesteps    | 53370880    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028499153 |\n",
      "|    entropy_loss       | -2.29       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.106      |\n",
      "|    mean_step_reward   | 0.024906525 |\n",
      "|    n_updates          | 72/128      |\n",
      "|    policyGradLoss     | -0.0214     |\n",
      "|    value_loss         | 0.0592      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 764         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 214         |\n",
      "|    total_timesteps    | 53379072    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020644046 |\n",
      "|    entropy_loss       | -2.28       |\n",
      "|    explained_variance | 0.952       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0742     |\n",
      "|    mean_step_reward   | 0.009605445 |\n",
      "|    n_updates          | 76/128      |\n",
      "|    policyGradLoss     | -0.0187     |\n",
      "|    value_loss         | 0.127       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 763         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 225         |\n",
      "|    total_timesteps    | 53387264    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020352818 |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.885       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0688     |\n",
      "|    mean_step_reward   | 0.023808513 |\n",
      "|    n_updates          | 80/128      |\n",
      "|    policyGradLoss     | -0.0147     |\n",
      "|    value_loss         | 0.252       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 762         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 236         |\n",
      "|    total_timesteps    | 53395456    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022895463 |\n",
      "|    entropy_loss       | -2.3        |\n",
      "|    explained_variance | 0.952       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0802     |\n",
      "|    mean_step_reward   | 0.008539233 |\n",
      "|    n_updates          | 84/128      |\n",
      "|    policyGradLoss     | -0.0149     |\n",
      "|    value_loss         | 0.128       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 763         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 246         |\n",
      "|    total_timesteps    | 53403648    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022506673 |\n",
      "|    entropy_loss       | -2.18       |\n",
      "|    explained_variance | 0.936       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0789     |\n",
      "|    mean_step_reward   | 0.027410727 |\n",
      "|    n_updates          | 88/128      |\n",
      "|    policyGradLoss     | -0.0125     |\n",
      "|    value_loss         | 0.209       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 762        |\n",
      "|    iterations         | 24         |\n",
      "|    time_elapsed       | 257        |\n",
      "|    total_timesteps    | 53411840   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02262763 |\n",
      "|    entropy_loss       | -2.13      |\n",
      "|    explained_variance | 0.961      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0674    |\n",
      "|    mean_step_reward   | 0.04457969 |\n",
      "|    n_updates          | 92/128     |\n",
      "|    policyGradLoss     | -0.0143    |\n",
      "|    value_loss         | 0.19       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 762         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 268         |\n",
      "|    total_timesteps    | 53420032    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014299274 |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0841     |\n",
      "|    mean_step_reward   | 0.027926963 |\n",
      "|    n_updates          | 96/128      |\n",
      "|    policyGradLoss     | -0.015      |\n",
      "|    value_loss         | 0.141       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 762         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 279         |\n",
      "|    total_timesteps    | 53428224    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019837897 |\n",
      "|    entropy_loss       | -2.19       |\n",
      "|    explained_variance | 0.933       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00411     |\n",
      "|    mean_step_reward   | 0.022452012 |\n",
      "|    n_updates          | 100/128     |\n",
      "|    policyGradLoss     | -0.0127     |\n",
      "|    value_loss         | 0.308       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 762         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 290         |\n",
      "|    total_timesteps    | 53436416    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022220142 |\n",
      "|    entropy_loss       | -2.16       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.081      |\n",
      "|    mean_step_reward   | 0.0413778   |\n",
      "|    n_updates          | 104/128     |\n",
      "|    policyGradLoss     | -0.014      |\n",
      "|    value_loss         | 0.186       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 762         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 300         |\n",
      "|    total_timesteps    | 53444608    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01908101  |\n",
      "|    entropy_loss       | -2.27       |\n",
      "|    explained_variance | 0.929       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.104      |\n",
      "|    mean_step_reward   | 0.016305925 |\n",
      "|    n_updates          | 108/128     |\n",
      "|    policyGradLoss     | -0.0145     |\n",
      "|    value_loss         | 0.111       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 762         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 311         |\n",
      "|    total_timesteps    | 53452800    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024266206 |\n",
      "|    entropy_loss       | -2.18       |\n",
      "|    explained_variance | 0.952       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.103      |\n",
      "|    mean_step_reward   | 0.022814587 |\n",
      "|    n_updates          | 112/128     |\n",
      "|    policyGradLoss     | -0.0172     |\n",
      "|    value_loss         | 0.104       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 762         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 322         |\n",
      "|    total_timesteps    | 53460992    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020178396 |\n",
      "|    entropy_loss       | -2.27       |\n",
      "|    explained_variance | 0.917       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.093      |\n",
      "|    mean_step_reward   | 0.019227173 |\n",
      "|    n_updates          | 116/128     |\n",
      "|    policyGradLoss     | -0.0153     |\n",
      "|    value_loss         | 0.124       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 761         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 333         |\n",
      "|    total_timesteps    | 53469184    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02551434  |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0934     |\n",
      "|    mean_step_reward   | 0.025033144 |\n",
      "|    n_updates          | 120/128     |\n",
      "|    policyGradLoss     | -0.0196     |\n",
      "|    value_loss         | 0.099       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 760         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 344         |\n",
      "|    total_timesteps    | 53477376    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02518598  |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0611     |\n",
      "|    mean_step_reward   | 0.019728456 |\n",
      "|    n_updates          | 124/128     |\n",
      "|    policyGradLoss     | -0.0144     |\n",
      "|    value_loss         | 0.144       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/NoArti_203.zip\n",
      "[EVAL] Mean Return: 132.188, Best Return: 134.788\n",
      "Saved video to ./runs_smw/videos/NoArti/NoArti_203_132.19.mp4\n",
      "\n",
      "=== Round 205 | Learn 262144 steps (Total trained: 53477376) ===\n",
      "Logging to ./runs_smw/tb/NoArti_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1096     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 53485568 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 891         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 53493760    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021659661 |\n",
      "|    entropy_loss       | -2.29       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.094      |\n",
      "|    mean_step_reward   | 0.023177816 |\n",
      "|    n_updates          | 4/128       |\n",
      "|    policyGradLoss     | -0.0163     |\n",
      "|    value_loss         | 0.148       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 833          |\n",
      "|    iterations         | 3            |\n",
      "|    time_elapsed       | 29           |\n",
      "|    total_timesteps    | 53501952     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.020022232  |\n",
      "|    entropy_loss       | -2.19        |\n",
      "|    explained_variance | 0.943        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0712      |\n",
      "|    mean_step_reward   | 0.0121506145 |\n",
      "|    n_updates          | 8/128        |\n",
      "|    policyGradLoss     | -0.015       |\n",
      "|    value_loss         | 0.216        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 809         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 40          |\n",
      "|    total_timesteps    | 53510144    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023268875 |\n",
      "|    entropy_loss       | -2.13       |\n",
      "|    explained_variance | 0.923       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0408      |\n",
      "|    mean_step_reward   | 0.02957774  |\n",
      "|    n_updates          | 12/128      |\n",
      "|    policyGradLoss     | -0.0165     |\n",
      "|    value_loss         | 0.252       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 795         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 51          |\n",
      "|    total_timesteps    | 53518336    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017867962 |\n",
      "|    entropy_loss       | -2.3        |\n",
      "|    explained_variance | 0.88        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0549     |\n",
      "|    mean_step_reward   | 0.015961155 |\n",
      "|    n_updates          | 16/128      |\n",
      "|    policyGradLoss     | -0.0093     |\n",
      "|    value_loss         | 0.131       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 789         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 62          |\n",
      "|    total_timesteps    | 53526528    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.0201075   |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.887       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0875     |\n",
      "|    mean_step_reward   | 0.015446315 |\n",
      "|    n_updates          | 20/128      |\n",
      "|    policyGradLoss     | -0.0158     |\n",
      "|    value_loss         | 0.119       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 72          |\n",
      "|    total_timesteps    | 53534720    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01964923  |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.945       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0993     |\n",
      "|    mean_step_reward   | 0.037687127 |\n",
      "|    n_updates          | 24/128      |\n",
      "|    policyGradLoss     | -0.0161     |\n",
      "|    value_loss         | 0.121       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 780          |\n",
      "|    iterations         | 8            |\n",
      "|    time_elapsed       | 83           |\n",
      "|    total_timesteps    | 53542912     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.020780899  |\n",
      "|    entropy_loss       | -2.27        |\n",
      "|    explained_variance | 0.975        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.101       |\n",
      "|    mean_step_reward   | 0.0153085925 |\n",
      "|    n_updates          | 28/128       |\n",
      "|    policyGradLoss     | -0.0195      |\n",
      "|    value_loss         | 0.0611       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 94          |\n",
      "|    total_timesteps    | 53551104    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017552886 |\n",
      "|    entropy_loss       | -2.19       |\n",
      "|    explained_variance | 0.786       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.045       |\n",
      "|    mean_step_reward   | 0.019113239 |\n",
      "|    n_updates          | 32/128      |\n",
      "|    policyGradLoss     | -0.0119     |\n",
      "|    value_loss         | 0.676       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 105         |\n",
      "|    total_timesteps    | 53559296    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01981144  |\n",
      "|    entropy_loss       | -2.08       |\n",
      "|    explained_variance | 0.899       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00351    |\n",
      "|    mean_step_reward   | 0.053689126 |\n",
      "|    n_updates          | 36/128      |\n",
      "|    policyGradLoss     | -0.00842    |\n",
      "|    value_loss         | 0.408       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 116         |\n",
      "|    total_timesteps    | 53567488    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022086382 |\n",
      "|    entropy_loss       | -2.18       |\n",
      "|    explained_variance | 0.936       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0894     |\n",
      "|    mean_step_reward   | 0.04166167  |\n",
      "|    n_updates          | 40/128      |\n",
      "|    policyGradLoss     | -0.0202     |\n",
      "|    value_loss         | 0.173       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 127         |\n",
      "|    total_timesteps    | 53575680    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015682396 |\n",
      "|    entropy_loss       | -2.27       |\n",
      "|    explained_variance | 0.75        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.089      |\n",
      "|    mean_step_reward   | 0.012453004 |\n",
      "|    n_updates          | 44/128      |\n",
      "|    policyGradLoss     | -0.0119     |\n",
      "|    value_loss         | 0.192       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 138         |\n",
      "|    total_timesteps    | 53583872    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018025048 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.899       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.099      |\n",
      "|    mean_step_reward   | 0.032000117 |\n",
      "|    n_updates          | 48/128      |\n",
      "|    policyGradLoss     | -0.0162     |\n",
      "|    value_loss         | 0.158       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 148         |\n",
      "|    total_timesteps    | 53592064    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018580303 |\n",
      "|    entropy_loss       | -2.29       |\n",
      "|    explained_variance | 0.898       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.088      |\n",
      "|    mean_step_reward   | 0.019796954 |\n",
      "|    n_updates          | 52/128      |\n",
      "|    policyGradLoss     | -0.0158     |\n",
      "|    value_loss         | 0.181       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 159         |\n",
      "|    total_timesteps    | 53600256    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01692904  |\n",
      "|    entropy_loss       | -2.33       |\n",
      "|    explained_variance | 0.955       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.102      |\n",
      "|    mean_step_reward   | 0.010054404 |\n",
      "|    n_updates          | 56/128      |\n",
      "|    policyGradLoss     | -0.0194     |\n",
      "|    value_loss         | 0.0942      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 170         |\n",
      "|    total_timesteps    | 53608448    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018408649 |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.95        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.102      |\n",
      "|    mean_step_reward   | 0.018359926 |\n",
      "|    n_updates          | 60/128      |\n",
      "|    policyGradLoss     | -0.0186     |\n",
      "|    value_loss         | 0.0844      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 181         |\n",
      "|    total_timesteps    | 53616640    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01580283  |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.934       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00488    |\n",
      "|    mean_step_reward   | 0.033877425 |\n",
      "|    n_updates          | 64/128      |\n",
      "|    policyGradLoss     | -0.0151     |\n",
      "|    value_loss         | 0.219       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 192         |\n",
      "|    total_timesteps    | 53624832    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023520973 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.101      |\n",
      "|    mean_step_reward   | 0.021482654 |\n",
      "|    n_updates          | 68/128      |\n",
      "|    policyGradLoss     | -0.0223     |\n",
      "|    value_loss         | 0.093       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 202         |\n",
      "|    total_timesteps    | 53633024    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011788163 |\n",
      "|    entropy_loss       | -2.2        |\n",
      "|    explained_variance | 0.832       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0427     |\n",
      "|    mean_step_reward   | 0.031441297 |\n",
      "|    n_updates          | 72/128      |\n",
      "|    policyGradLoss     | -0.00968    |\n",
      "|    value_loss         | 0.462       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 213         |\n",
      "|    total_timesteps    | 53641216    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021390613 |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0813     |\n",
      "|    mean_step_reward   | 0.030638976 |\n",
      "|    n_updates          | 76/128      |\n",
      "|    policyGradLoss     | -0.0185     |\n",
      "|    value_loss         | 0.201       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 224         |\n",
      "|    total_timesteps    | 53649408    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018551597 |\n",
      "|    entropy_loss       | -2.29       |\n",
      "|    explained_variance | 0.762       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0792     |\n",
      "|    mean_step_reward   | 0.017539253 |\n",
      "|    n_updates          | 80/128      |\n",
      "|    policyGradLoss     | -0.012      |\n",
      "|    value_loss         | 0.275       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 235         |\n",
      "|    total_timesteps    | 53657600    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024391282 |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.101      |\n",
      "|    mean_step_reward   | 0.019352896 |\n",
      "|    n_updates          | 84/128      |\n",
      "|    policyGradLoss     | -0.0197     |\n",
      "|    value_loss         | 0.14        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 245         |\n",
      "|    total_timesteps    | 53665792    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013247184 |\n",
      "|    entropy_loss       | -2.32       |\n",
      "|    explained_variance | 0.631       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0824     |\n",
      "|    mean_step_reward   | 0.016052723 |\n",
      "|    n_updates          | 88/128      |\n",
      "|    policyGradLoss     | -0.00677    |\n",
      "|    value_loss         | 0.282       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 256         |\n",
      "|    total_timesteps    | 53673984    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016527142 |\n",
      "|    entropy_loss       | -2.28       |\n",
      "|    explained_variance | 0.947       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0578     |\n",
      "|    mean_step_reward   | 0.008228241 |\n",
      "|    n_updates          | 92/128      |\n",
      "|    policyGradLoss     | -0.0161     |\n",
      "|    value_loss         | 0.183       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 267         |\n",
      "|    total_timesteps    | 53682176    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022638949 |\n",
      "|    entropy_loss       | -2.2        |\n",
      "|    explained_variance | 0.944       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0448     |\n",
      "|    mean_step_reward   | 0.03927137  |\n",
      "|    n_updates          | 96/128      |\n",
      "|    policyGradLoss     | -0.0139     |\n",
      "|    value_loss         | 0.272       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 765         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 278         |\n",
      "|    total_timesteps    | 53690368    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018895764 |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.9         |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0765     |\n",
      "|    mean_step_reward   | 0.022929665 |\n",
      "|    n_updates          | 100/128     |\n",
      "|    policyGradLoss     | -0.0127     |\n",
      "|    value_loss         | 0.323       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 288         |\n",
      "|    total_timesteps    | 53698560    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016051821 |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.879       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0623     |\n",
      "|    mean_step_reward   | 0.019181434 |\n",
      "|    n_updates          | 104/128     |\n",
      "|    policyGradLoss     | -0.0125     |\n",
      "|    value_loss         | 0.272       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 765         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 299         |\n",
      "|    total_timesteps    | 53706752    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019033143 |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.941       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.103      |\n",
      "|    mean_step_reward   | 0.018568711 |\n",
      "|    n_updates          | 108/128     |\n",
      "|    policyGradLoss     | -0.0168     |\n",
      "|    value_loss         | 0.122       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 765         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 310         |\n",
      "|    total_timesteps    | 53714944    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019458419 |\n",
      "|    entropy_loss       | -2.3        |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.108      |\n",
      "|    mean_step_reward   | 0.025081936 |\n",
      "|    n_updates          | 112/128     |\n",
      "|    policyGradLoss     | -0.015      |\n",
      "|    value_loss         | 0.0752      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 765          |\n",
      "|    iterations         | 30           |\n",
      "|    time_elapsed       | 321          |\n",
      "|    total_timesteps    | 53723136     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.016851936  |\n",
      "|    entropy_loss       | -2.29        |\n",
      "|    explained_variance | 0.906        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0981      |\n",
      "|    mean_step_reward   | 0.0065341974 |\n",
      "|    n_updates          | 116/128      |\n",
      "|    policyGradLoss     | -0.0118      |\n",
      "|    value_loss         | 0.149        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 764         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 332         |\n",
      "|    total_timesteps    | 53731328    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026935142 |\n",
      "|    entropy_loss       | -2.27       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.109      |\n",
      "|    mean_step_reward   | 0.023852274 |\n",
      "|    n_updates          | 120/128     |\n",
      "|    policyGradLoss     | -0.0207     |\n",
      "|    value_loss         | 0.0765      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 764         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 343         |\n",
      "|    total_timesteps    | 53739520    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017836966 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.093      |\n",
      "|    mean_step_reward   | 0.020920627 |\n",
      "|    n_updates          | 124/128     |\n",
      "|    policyGradLoss     | -0.0192     |\n",
      "|    value_loss         | 0.153       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/NoArti_204.zip\n",
      "[EVAL] Mean Return: -69.305, Best Return: -67.473\n",
      "Saved video to ./runs_smw/videos/NoArti/NoArti_204_-69.31.mp4\n",
      "\n",
      "=== Round 206 | Learn 262144 steps (Total trained: 53739520) ===\n",
      "Logging to ./runs_smw/tb/NoArti_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1108     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 53747712 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 905         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 53755904    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018980835 |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.927       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0794     |\n",
      "|    mean_step_reward   | 0.032020114 |\n",
      "|    n_updates          | 4/128       |\n",
      "|    policyGradLoss     | -0.017      |\n",
      "|    value_loss         | 0.326       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 845         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 29          |\n",
      "|    total_timesteps    | 53764096    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029499192 |\n",
      "|    entropy_loss       | -2.29       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.124      |\n",
      "|    mean_step_reward   | 0.016575411 |\n",
      "|    n_updates          | 8/128       |\n",
      "|    policyGradLoss     | -0.0234     |\n",
      "|    value_loss         | 0.0407      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 814         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 40          |\n",
      "|    total_timesteps    | 53772288    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020251475 |\n",
      "|    entropy_loss       | -2.39       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.114      |\n",
      "|    mean_step_reward   | 0.004843214 |\n",
      "|    n_updates          | 12/128      |\n",
      "|    policyGradLoss     | -0.0124     |\n",
      "|    value_loss         | 0.0546      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 806          |\n",
      "|    iterations         | 5            |\n",
      "|    time_elapsed       | 50           |\n",
      "|    total_timesteps    | 53780480     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.023764584  |\n",
      "|    entropy_loss       | -2.32        |\n",
      "|    explained_variance | 0.944        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.114       |\n",
      "|    mean_step_reward   | 0.0077611925 |\n",
      "|    n_updates          | 16/128       |\n",
      "|    policyGradLoss     | -0.0188      |\n",
      "|    value_loss         | 0.0416       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 795         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 61          |\n",
      "|    total_timesteps    | 53788672    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021647083 |\n",
      "|    entropy_loss       | -2.29       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.107      |\n",
      "|    mean_step_reward   | 0.02343737  |\n",
      "|    n_updates          | 20/128      |\n",
      "|    policyGradLoss     | -0.0171     |\n",
      "|    value_loss         | 0.118       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 789         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 72          |\n",
      "|    total_timesteps    | 53796864    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018873608 |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0548     |\n",
      "|    mean_step_reward   | 0.014761364 |\n",
      "|    n_updates          | 24/128      |\n",
      "|    policyGradLoss     | -0.0215     |\n",
      "|    value_loss         | 0.125       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 83          |\n",
      "|    total_timesteps    | 53805056    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015970666 |\n",
      "|    entropy_loss       | -2.13       |\n",
      "|    explained_variance | 0.938       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0514     |\n",
      "|    mean_step_reward   | 0.04186703  |\n",
      "|    n_updates          | 28/128      |\n",
      "|    policyGradLoss     | -0.0136     |\n",
      "|    value_loss         | 0.358       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 94          |\n",
      "|    total_timesteps    | 53813248    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023891972 |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.932       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.112      |\n",
      "|    mean_step_reward   | 0.033886336 |\n",
      "|    n_updates          | 32/128      |\n",
      "|    policyGradLoss     | -0.0194     |\n",
      "|    value_loss         | 0.111       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 105         |\n",
      "|    total_timesteps    | 53821440    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02524187  |\n",
      "|    entropy_loss       | -2.29       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.113      |\n",
      "|    mean_step_reward   | 0.029485798 |\n",
      "|    n_updates          | 36/128      |\n",
      "|    policyGradLoss     | -0.0214     |\n",
      "|    value_loss         | 0.0778      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 115         |\n",
      "|    total_timesteps    | 53829632    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020640908 |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.884       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0981     |\n",
      "|    mean_step_reward   | 0.010957645 |\n",
      "|    n_updates          | 40/128      |\n",
      "|    policyGradLoss     | -0.0163     |\n",
      "|    value_loss         | 0.157       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 126         |\n",
      "|    total_timesteps    | 53837824    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020286739 |\n",
      "|    entropy_loss       | -2.34       |\n",
      "|    explained_variance | 0.951       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.108      |\n",
      "|    mean_step_reward   | 0.02012296  |\n",
      "|    n_updates          | 44/128      |\n",
      "|    policyGradLoss     | -0.0159     |\n",
      "|    value_loss         | 0.108       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 774          |\n",
      "|    iterations         | 13           |\n",
      "|    time_elapsed       | 137          |\n",
      "|    total_timesteps    | 53846016     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.01927568   |\n",
      "|    entropy_loss       | -2.3         |\n",
      "|    explained_variance | 0.933        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0735      |\n",
      "|    mean_step_reward   | 0.0045747077 |\n",
      "|    n_updates          | 48/128       |\n",
      "|    policyGradLoss     | -0.0163      |\n",
      "|    value_loss         | 0.162        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 148         |\n",
      "|    total_timesteps    | 53854208    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018837849 |\n",
      "|    entropy_loss       | -2.16       |\n",
      "|    explained_variance | 0.912       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0639     |\n",
      "|    mean_step_reward   | 0.018476667 |\n",
      "|    n_updates          | 52/128      |\n",
      "|    policyGradLoss     | -0.0168     |\n",
      "|    value_loss         | 0.361       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 159         |\n",
      "|    total_timesteps    | 53862400    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023211934 |\n",
      "|    entropy_loss       | -2.15       |\n",
      "|    explained_variance | 0.913       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0712     |\n",
      "|    mean_step_reward   | 0.042954367 |\n",
      "|    n_updates          | 56/128      |\n",
      "|    policyGradLoss     | -0.0163     |\n",
      "|    value_loss         | 0.372       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 170         |\n",
      "|    total_timesteps    | 53870592    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018001435 |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.752       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0792     |\n",
      "|    mean_step_reward   | 0.031032586 |\n",
      "|    n_updates          | 60/128      |\n",
      "|    policyGradLoss     | -0.00949    |\n",
      "|    value_loss         | 0.434       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 181         |\n",
      "|    total_timesteps    | 53878784    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013887895 |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.926       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.088      |\n",
      "|    mean_step_reward   | 0.028860336 |\n",
      "|    n_updates          | 64/128      |\n",
      "|    policyGradLoss     | -0.0154     |\n",
      "|    value_loss         | 0.21        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 192         |\n",
      "|    total_timesteps    | 53886976    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017974652 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.89        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0755     |\n",
      "|    mean_step_reward   | 0.03568565  |\n",
      "|    n_updates          | 68/128      |\n",
      "|    policyGradLoss     | -0.0126     |\n",
      "|    value_loss         | 0.297       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 203         |\n",
      "|    total_timesteps    | 53895168    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018879466 |\n",
      "|    entropy_loss       | -2.3        |\n",
      "|    explained_variance | 0.835       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0864     |\n",
      "|    mean_step_reward   | 0.020234272 |\n",
      "|    n_updates          | 72/128      |\n",
      "|    policyGradLoss     | -0.0116     |\n",
      "|    value_loss         | 0.168       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 213         |\n",
      "|    total_timesteps    | 53903360    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011265275 |\n",
      "|    entropy_loss       | -2.33       |\n",
      "|    explained_variance | 0.887       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.103      |\n",
      "|    mean_step_reward   | 0.009258825 |\n",
      "|    n_updates          | 76/128      |\n",
      "|    policyGradLoss     | -0.014      |\n",
      "|    value_loss         | 0.159       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 765         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 224         |\n",
      "|    total_timesteps    | 53911552    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018101368 |\n",
      "|    entropy_loss       | -2.33       |\n",
      "|    explained_variance | 0.925       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.107      |\n",
      "|    mean_step_reward   | 0.012758478 |\n",
      "|    n_updates          | 80/128      |\n",
      "|    policyGradLoss     | -0.0172     |\n",
      "|    value_loss         | 0.0656      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 764          |\n",
      "|    iterations         | 22           |\n",
      "|    time_elapsed       | 235          |\n",
      "|    total_timesteps    | 53919744     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.013836145  |\n",
      "|    entropy_loss       | -2.28        |\n",
      "|    explained_variance | 0.861        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0858      |\n",
      "|    mean_step_reward   | 0.0070644068 |\n",
      "|    n_updates          | 84/128       |\n",
      "|    policyGradLoss     | -0.0145      |\n",
      "|    value_loss         | 0.206        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 764         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 246         |\n",
      "|    total_timesteps    | 53927936    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01222262  |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.85        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0924     |\n",
      "|    mean_step_reward   | 0.024090638 |\n",
      "|    n_updates          | 88/128      |\n",
      "|    policyGradLoss     | -0.0109     |\n",
      "|    value_loss         | 0.353       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 763         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 257         |\n",
      "|    total_timesteps    | 53936128    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016722845 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.916       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0747     |\n",
      "|    mean_step_reward   | 0.014759813 |\n",
      "|    n_updates          | 92/128      |\n",
      "|    policyGradLoss     | -0.0175     |\n",
      "|    value_loss         | 0.208       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 763         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 268         |\n",
      "|    total_timesteps    | 53944320    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024163004 |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.897       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0722     |\n",
      "|    mean_step_reward   | 0.029634608 |\n",
      "|    n_updates          | 96/128      |\n",
      "|    policyGradLoss     | -0.0195     |\n",
      "|    value_loss         | 0.162       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 763         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 278         |\n",
      "|    total_timesteps    | 53952512    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015465118 |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.912       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.116      |\n",
      "|    mean_step_reward   | 0.018846843 |\n",
      "|    n_updates          | 100/128     |\n",
      "|    policyGradLoss     | -0.0204     |\n",
      "|    value_loss         | 0.137       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 762         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 290         |\n",
      "|    total_timesteps    | 53960704    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02009498  |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.837       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0873     |\n",
      "|    mean_step_reward   | 0.026810423 |\n",
      "|    n_updates          | 104/128     |\n",
      "|    policyGradLoss     | -0.0148     |\n",
      "|    value_loss         | 0.159       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 762         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 300         |\n",
      "|    total_timesteps    | 53968896    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015229901 |\n",
      "|    entropy_loss       | -2.28       |\n",
      "|    explained_variance | 0.881       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0651     |\n",
      "|    mean_step_reward   | 0.021909978 |\n",
      "|    n_updates          | 108/128     |\n",
      "|    policyGradLoss     | -0.0133     |\n",
      "|    value_loss         | 0.322       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 762         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 311         |\n",
      "|    total_timesteps    | 53977088    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022730276 |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.946       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0984     |\n",
      "|    mean_step_reward   | 0.015552508 |\n",
      "|    n_updates          | 112/128     |\n",
      "|    policyGradLoss     | -0.0201     |\n",
      "|    value_loss         | 0.0975      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 762         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 322         |\n",
      "|    total_timesteps    | 53985280    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016370488 |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.927       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0808     |\n",
      "|    mean_step_reward   | 0.02791281  |\n",
      "|    n_updates          | 116/128     |\n",
      "|    policyGradLoss     | -0.0152     |\n",
      "|    value_loss         | 0.225       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 763         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 332         |\n",
      "|    total_timesteps    | 53993472    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021743644 |\n",
      "|    entropy_loss       | -2.27       |\n",
      "|    explained_variance | 0.954       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.025      |\n",
      "|    mean_step_reward   | 0.02607213  |\n",
      "|    n_updates          | 120/128     |\n",
      "|    policyGradLoss     | -0.0174     |\n",
      "|    value_loss         | 0.173       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 762         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 343         |\n",
      "|    total_timesteps    | 54001664    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026688533 |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.937       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0313     |\n",
      "|    mean_step_reward   | 0.020794993 |\n",
      "|    n_updates          | 124/128     |\n",
      "|    policyGradLoss     | -0.0159     |\n",
      "|    value_loss         | 0.199       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/NoArti_205.zip\n",
      "[EVAL] Mean Return: 39.074, Best Return: 41.074\n",
      "Saved video to ./runs_smw/videos/NoArti/NoArti_205_39.07.mp4\n",
      "\n",
      "=== Round 207 | Learn 262144 steps (Total trained: 54001664) ===\n",
      "Logging to ./runs_smw/tb/NoArti_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1098     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 54009856 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 896         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 54018048    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019905657 |\n",
      "|    entropy_loss       | -2.31       |\n",
      "|    explained_variance | 0.906       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0928     |\n",
      "|    mean_step_reward   | 0.015169296 |\n",
      "|    n_updates          | 4/128       |\n",
      "|    policyGradLoss     | -0.0193     |\n",
      "|    value_loss         | 0.0981      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 849         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 54026240    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017639093 |\n",
      "|    entropy_loss       | -2.33       |\n",
      "|    explained_variance | 0.805       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0655     |\n",
      "|    mean_step_reward   | 0.015283237 |\n",
      "|    n_updates          | 8/128       |\n",
      "|    policyGradLoss     | -0.0125     |\n",
      "|    value_loss         | 0.217       |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 827           |\n",
      "|    iterations         | 4             |\n",
      "|    time_elapsed       | 39            |\n",
      "|    total_timesteps    | 54034432      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.014827345   |\n",
      "|    entropy_loss       | -2.31         |\n",
      "|    explained_variance | 0.95          |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.108        |\n",
      "|    mean_step_reward   | 0.00043999916 |\n",
      "|    n_updates          | 12/128        |\n",
      "|    policyGradLoss     | -0.0173       |\n",
      "|    value_loss         | 0.0822        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 50          |\n",
      "|    total_timesteps    | 54042624    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026677255 |\n",
      "|    entropy_loss       | -2.29       |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.104      |\n",
      "|    mean_step_reward   | 0.027731888 |\n",
      "|    n_updates          | 16/128      |\n",
      "|    policyGradLoss     | -0.0163     |\n",
      "|    value_loss         | 0.0563      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 802         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 61          |\n",
      "|    total_timesteps    | 54050816    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018390214 |\n",
      "|    entropy_loss       | -2.3        |\n",
      "|    explained_variance | 0.95        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.098      |\n",
      "|    mean_step_reward   | 0.007815374 |\n",
      "|    n_updates          | 20/128      |\n",
      "|    policyGradLoss     | -0.015      |\n",
      "|    value_loss         | 0.164       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 797         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 71          |\n",
      "|    total_timesteps    | 54059008    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013298074 |\n",
      "|    entropy_loss       | -2.27       |\n",
      "|    explained_variance | 0.876       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0751     |\n",
      "|    mean_step_reward   | 0.01232741  |\n",
      "|    n_updates          | 24/128      |\n",
      "|    policyGradLoss     | -0.0135     |\n",
      "|    value_loss         | 0.201       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 791         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 82          |\n",
      "|    total_timesteps    | 54067200    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023879044 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.11       |\n",
      "|    mean_step_reward   | 0.032080792 |\n",
      "|    n_updates          | 28/128      |\n",
      "|    policyGradLoss     | -0.0226     |\n",
      "|    value_loss         | 0.117       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 788         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 93          |\n",
      "|    total_timesteps    | 54075392    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019822378 |\n",
      "|    entropy_loss       | -2.31       |\n",
      "|    explained_variance | 0.939       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0943     |\n",
      "|    mean_step_reward   | 0.009809788 |\n",
      "|    n_updates          | 32/128      |\n",
      "|    policyGradLoss     | -0.0164     |\n",
      "|    value_loss         | 0.12        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 104         |\n",
      "|    total_timesteps    | 54083584    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018649934 |\n",
      "|    entropy_loss       | -2.18       |\n",
      "|    explained_variance | 0.949       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0454     |\n",
      "|    mean_step_reward   | 0.025841324 |\n",
      "|    n_updates          | 36/128      |\n",
      "|    policyGradLoss     | -0.0161     |\n",
      "|    value_loss         | 0.192       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 114         |\n",
      "|    total_timesteps    | 54091776    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021433596 |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.105      |\n",
      "|    mean_step_reward   | 0.029096287 |\n",
      "|    n_updates          | 40/128      |\n",
      "|    policyGradLoss     | -0.0204     |\n",
      "|    value_loss         | 0.12        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 125         |\n",
      "|    total_timesteps    | 54099968    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016423611 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0837     |\n",
      "|    mean_step_reward   | 0.025050864 |\n",
      "|    n_updates          | 44/128      |\n",
      "|    policyGradLoss     | -0.0169     |\n",
      "|    value_loss         | 0.109       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 136         |\n",
      "|    total_timesteps    | 54108160    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01934505  |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.952       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0757     |\n",
      "|    mean_step_reward   | 0.022621535 |\n",
      "|    n_updates          | 48/128      |\n",
      "|    policyGradLoss     | -0.0173     |\n",
      "|    value_loss         | 0.152       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 147         |\n",
      "|    total_timesteps    | 54116352    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023036554 |\n",
      "|    entropy_loss       | -2.18       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.1        |\n",
      "|    mean_step_reward   | 0.044371203 |\n",
      "|    n_updates          | 52/128      |\n",
      "|    policyGradLoss     | -0.0156     |\n",
      "|    value_loss         | 0.143       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 158         |\n",
      "|    total_timesteps    | 54124544    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02122738  |\n",
      "|    entropy_loss       | -2.28       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0866     |\n",
      "|    mean_step_reward   | 0.016846197 |\n",
      "|    n_updates          | 56/128      |\n",
      "|    policyGradLoss     | -0.0172     |\n",
      "|    value_loss         | 0.133       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 169         |\n",
      "|    total_timesteps    | 54132736    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023496523 |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.114      |\n",
      "|    mean_step_reward   | 0.019848961 |\n",
      "|    n_updates          | 60/128      |\n",
      "|    policyGradLoss     | -0.021      |\n",
      "|    value_loss         | 0.09        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 179         |\n",
      "|    total_timesteps    | 54140928    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022970587 |\n",
      "|    entropy_loss       | -2.19       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0813     |\n",
      "|    mean_step_reward   | 0.035292163 |\n",
      "|    n_updates          | 64/128      |\n",
      "|    policyGradLoss     | -0.0178     |\n",
      "|    value_loss         | 0.137       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 190         |\n",
      "|    total_timesteps    | 54149120    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030879289 |\n",
      "|    entropy_loss       | -2.16       |\n",
      "|    explained_variance | 0.921       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0711     |\n",
      "|    mean_step_reward   | 0.02089823  |\n",
      "|    n_updates          | 68/128      |\n",
      "|    policyGradLoss     | -0.0185     |\n",
      "|    value_loss         | 0.374       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 201         |\n",
      "|    total_timesteps    | 54157312    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028564272 |\n",
      "|    entropy_loss       | -2.14       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0994     |\n",
      "|    mean_step_reward   | 0.052483935 |\n",
      "|    n_updates          | 72/128      |\n",
      "|    policyGradLoss     | -0.0164     |\n",
      "|    value_loss         | 0.144       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 212         |\n",
      "|    total_timesteps    | 54165504    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024318647 |\n",
      "|    entropy_loss       | -2.29       |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.113      |\n",
      "|    mean_step_reward   | 0.008482173 |\n",
      "|    n_updates          | 76/128      |\n",
      "|    policyGradLoss     | -0.0222     |\n",
      "|    value_loss         | 0.0656      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 222         |\n",
      "|    total_timesteps    | 54173696    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021371575 |\n",
      "|    entropy_loss       | -2.28       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0801     |\n",
      "|    mean_step_reward   | 0.027045783 |\n",
      "|    n_updates          | 80/128      |\n",
      "|    policyGradLoss     | -0.0184     |\n",
      "|    value_loss         | 0.0561      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 233         |\n",
      "|    total_timesteps    | 54181888    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023003899 |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0932     |\n",
      "|    mean_step_reward   | 0.019537041 |\n",
      "|    n_updates          | 84/128      |\n",
      "|    policyGradLoss     | -0.0186     |\n",
      "|    value_loss         | 0.0744      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 769        |\n",
      "|    iterations         | 23         |\n",
      "|    time_elapsed       | 244        |\n",
      "|    total_timesteps    | 54190080   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02024443 |\n",
      "|    entropy_loss       | -2.21      |\n",
      "|    explained_variance | 0.943      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0693    |\n",
      "|    mean_step_reward   | 0.03138131 |\n",
      "|    n_updates          | 88/128     |\n",
      "|    policyGradLoss     | -0.0141    |\n",
      "|    value_loss         | 0.284      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 255         |\n",
      "|    total_timesteps    | 54198272    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022573907 |\n",
      "|    entropy_loss       | -2.17       |\n",
      "|    explained_variance | 0.945       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0903     |\n",
      "|    mean_step_reward   | 0.032388836 |\n",
      "|    n_updates          | 92/128      |\n",
      "|    policyGradLoss     | -0.0139     |\n",
      "|    value_loss         | 0.14        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 266         |\n",
      "|    total_timesteps    | 54206464    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021767233 |\n",
      "|    entropy_loss       | -2.14       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0945     |\n",
      "|    mean_step_reward   | 0.041362576 |\n",
      "|    n_updates          | 96/128      |\n",
      "|    policyGradLoss     | -0.0196     |\n",
      "|    value_loss         | 0.19        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 277         |\n",
      "|    total_timesteps    | 54214656    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02639159  |\n",
      "|    entropy_loss       | -2.19       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.11       |\n",
      "|    mean_step_reward   | 0.036625337 |\n",
      "|    n_updates          | 100/128     |\n",
      "|    policyGradLoss     | -0.0181     |\n",
      "|    value_loss         | 0.0936      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 288         |\n",
      "|    total_timesteps    | 54222848    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029450633 |\n",
      "|    entropy_loss       | -2.18       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.102      |\n",
      "|    mean_step_reward   | 0.034145206 |\n",
      "|    n_updates          | 104/128     |\n",
      "|    policyGradLoss     | -0.0209     |\n",
      "|    value_loss         | 0.0721      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 299         |\n",
      "|    total_timesteps    | 54231040    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023746729 |\n",
      "|    entropy_loss       | -2.19       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.105      |\n",
      "|    mean_step_reward   | 0.03756187  |\n",
      "|    n_updates          | 108/128     |\n",
      "|    policyGradLoss     | -0.023      |\n",
      "|    value_loss         | 0.0497      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 309         |\n",
      "|    total_timesteps    | 54239232    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027345542 |\n",
      "|    entropy_loss       | -2.28       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.114      |\n",
      "|    mean_step_reward   | 0.027327823 |\n",
      "|    n_updates          | 112/128     |\n",
      "|    policyGradLoss     | -0.0214     |\n",
      "|    value_loss         | 0.0503      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 320         |\n",
      "|    total_timesteps    | 54247424    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022795372 |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.102      |\n",
      "|    mean_step_reward   | 0.019104466 |\n",
      "|    n_updates          | 116/128     |\n",
      "|    policyGradLoss     | -0.021      |\n",
      "|    value_loss         | 0.0599      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 331         |\n",
      "|    total_timesteps    | 54255616    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028137034 |\n",
      "|    entropy_loss       | -2.17       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.105      |\n",
      "|    mean_step_reward   | 0.040985793 |\n",
      "|    n_updates          | 120/128     |\n",
      "|    policyGradLoss     | -0.0186     |\n",
      "|    value_loss         | 0.0877      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 341         |\n",
      "|    total_timesteps    | 54263808    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024809074 |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0979     |\n",
      "|    mean_step_reward   | 0.016432878 |\n",
      "|    n_updates          | 124/128     |\n",
      "|    policyGradLoss     | -0.0228     |\n",
      "|    value_loss         | 0.0675      |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/NoArti_206.zip\n",
      "[EVAL] Mean Return: 126.793, Best Return: 129.393\n",
      "Saved video to ./runs_smw/videos/NoArti/NoArti_206_126.79.mp4\n",
      "\n",
      "=== Round 208 | Learn 262144 steps (Total trained: 54263808) ===\n",
      "Logging to ./runs_smw/tb/NoArti_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1105     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 54272000 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 886         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 54280192    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025749221 |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0997     |\n",
      "|    mean_step_reward   | 0.026944734 |\n",
      "|    n_updates          | 4/128       |\n",
      "|    policyGradLoss     | -0.0186     |\n",
      "|    value_loss         | 0.0969      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 838         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 29          |\n",
      "|    total_timesteps    | 54288384    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025711277 |\n",
      "|    entropy_loss       | -2.19       |\n",
      "|    explained_variance | 0.919       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0927     |\n",
      "|    mean_step_reward   | 0.028239492 |\n",
      "|    n_updates          | 8/128       |\n",
      "|    policyGradLoss     | -0.0168     |\n",
      "|    value_loss         | 0.252       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 815         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 40          |\n",
      "|    total_timesteps    | 54296576    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.03080773  |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.113      |\n",
      "|    mean_step_reward   | 0.030445892 |\n",
      "|    n_updates          | 12/128      |\n",
      "|    policyGradLoss     | -0.0267     |\n",
      "|    value_loss         | 0.0606      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 805         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 50          |\n",
      "|    total_timesteps    | 54304768    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018383153 |\n",
      "|    entropy_loss       | -2.2        |\n",
      "|    explained_variance | 0.913       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0528     |\n",
      "|    mean_step_reward   | 0.030982958 |\n",
      "|    n_updates          | 16/128      |\n",
      "|    policyGradLoss     | -0.0142     |\n",
      "|    value_loss         | 0.339       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 793         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 61          |\n",
      "|    total_timesteps    | 54312960    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020504493 |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.917       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0872     |\n",
      "|    mean_step_reward   | 0.032128386 |\n",
      "|    n_updates          | 20/128      |\n",
      "|    policyGradLoss     | -0.0153     |\n",
      "|    value_loss         | 0.198       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 73          |\n",
      "|    total_timesteps    | 54321152    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029139508 |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.1        |\n",
      "|    mean_step_reward   | 0.024136437 |\n",
      "|    n_updates          | 24/128      |\n",
      "|    policyGradLoss     | -0.022      |\n",
      "|    value_loss         | 0.0741      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 84          |\n",
      "|    total_timesteps    | 54329344    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02365902  |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0859     |\n",
      "|    mean_step_reward   | 0.024119414 |\n",
      "|    n_updates          | 28/128      |\n",
      "|    policyGradLoss     | -0.0173     |\n",
      "|    value_loss         | 0.166       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 94          |\n",
      "|    total_timesteps    | 54337536    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02165366  |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.876       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0431      |\n",
      "|    mean_step_reward   | 0.009818966 |\n",
      "|    n_updates          | 32/128      |\n",
      "|    policyGradLoss     | -0.0173     |\n",
      "|    value_loss         | 0.308       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 105         |\n",
      "|    total_timesteps    | 54345728    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02586586  |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0773     |\n",
      "|    mean_step_reward   | 0.032069974 |\n",
      "|    n_updates          | 36/128      |\n",
      "|    policyGradLoss     | -0.0201     |\n",
      "|    value_loss         | 0.163       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 116         |\n",
      "|    total_timesteps    | 54353920    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018259753 |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.938       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0918     |\n",
      "|    mean_step_reward   | 0.02740869  |\n",
      "|    n_updates          | 40/128      |\n",
      "|    policyGradLoss     | -0.0169     |\n",
      "|    value_loss         | 0.229       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 127         |\n",
      "|    total_timesteps    | 54362112    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024142884 |\n",
      "|    entropy_loss       | -2.15       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.1        |\n",
      "|    mean_step_reward   | 0.03515391  |\n",
      "|    n_updates          | 44/128      |\n",
      "|    policyGradLoss     | -0.0214     |\n",
      "|    value_loss         | 0.159       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 138         |\n",
      "|    total_timesteps    | 54370304    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013918586 |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.804       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0824     |\n",
      "|    mean_step_reward   | 0.024572574 |\n",
      "|    n_updates          | 48/128      |\n",
      "|    policyGradLoss     | -0.011      |\n",
      "|    value_loss         | 0.34        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 148         |\n",
      "|    total_timesteps    | 54378496    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017146725 |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.852       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0511     |\n",
      "|    mean_step_reward   | 0.022723982 |\n",
      "|    n_updates          | 52/128      |\n",
      "|    policyGradLoss     | -0.0166     |\n",
      "|    value_loss         | 0.28        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 159         |\n",
      "|    total_timesteps    | 54386688    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02597421  |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.862       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0755     |\n",
      "|    mean_step_reward   | 0.022324659 |\n",
      "|    n_updates          | 56/128      |\n",
      "|    policyGradLoss     | -0.02       |\n",
      "|    value_loss         | 0.262       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 170         |\n",
      "|    total_timesteps    | 54394880    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01717521  |\n",
      "|    entropy_loss       | -2.29       |\n",
      "|    explained_variance | 0.74        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0551     |\n",
      "|    mean_step_reward   | 0.007972579 |\n",
      "|    n_updates          | 60/128      |\n",
      "|    policyGradLoss     | -0.015      |\n",
      "|    value_loss         | 0.372       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 180         |\n",
      "|    total_timesteps    | 54403072    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022875173 |\n",
      "|    entropy_loss       | -2.2        |\n",
      "|    explained_variance | 0.917       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0318     |\n",
      "|    mean_step_reward   | 0.024455313 |\n",
      "|    n_updates          | 64/128      |\n",
      "|    policyGradLoss     | -0.0184     |\n",
      "|    value_loss         | 0.314       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 768        |\n",
      "|    iterations         | 18         |\n",
      "|    time_elapsed       | 191        |\n",
      "|    total_timesteps    | 54411264   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02170139 |\n",
      "|    entropy_loss       | -2.19      |\n",
      "|    explained_variance | 0.93       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0867    |\n",
      "|    mean_step_reward   | 0.03523974 |\n",
      "|    n_updates          | 68/128     |\n",
      "|    policyGradLoss     | -0.0154    |\n",
      "|    value_loss         | 0.214      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 202         |\n",
      "|    total_timesteps    | 54419456    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024766851 |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.945       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0749     |\n",
      "|    mean_step_reward   | 0.04193383  |\n",
      "|    n_updates          | 72/128      |\n",
      "|    policyGradLoss     | -0.0174     |\n",
      "|    value_loss         | 0.151       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 213         |\n",
      "|    total_timesteps    | 54427648    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01472335  |\n",
      "|    entropy_loss       | -2.2        |\n",
      "|    explained_variance | 0.748       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.047      |\n",
      "|    mean_step_reward   | 0.015034035 |\n",
      "|    n_updates          | 76/128      |\n",
      "|    policyGradLoss     | -0.00761    |\n",
      "|    value_loss         | 0.457       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 224         |\n",
      "|    total_timesteps    | 54435840    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019091846 |\n",
      "|    entropy_loss       | -2.14       |\n",
      "|    explained_variance | 0.904       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0429     |\n",
      "|    mean_step_reward   | 0.037925493 |\n",
      "|    n_updates          | 80/128      |\n",
      "|    policyGradLoss     | -0.0145     |\n",
      "|    value_loss         | 0.386       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 235         |\n",
      "|    total_timesteps    | 54444032    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020985939 |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.922       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.083      |\n",
      "|    mean_step_reward   | 0.032876827 |\n",
      "|    n_updates          | 84/128      |\n",
      "|    policyGradLoss     | -0.0143     |\n",
      "|    value_loss         | 0.19        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 765        |\n",
      "|    iterations         | 23         |\n",
      "|    time_elapsed       | 246        |\n",
      "|    total_timesteps    | 54452224   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02003606 |\n",
      "|    entropy_loss       | -2.27      |\n",
      "|    explained_variance | 0.957      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.115     |\n",
      "|    mean_step_reward   | 0.02310232 |\n",
      "|    n_updates          | 88/128     |\n",
      "|    policyGradLoss     | -0.0207    |\n",
      "|    value_loss         | 0.0669     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 764         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 257         |\n",
      "|    total_timesteps    | 54460416    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018533258 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.909       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0716     |\n",
      "|    mean_step_reward   | 0.02681181  |\n",
      "|    n_updates          | 92/128      |\n",
      "|    policyGradLoss     | -0.0145     |\n",
      "|    value_loss         | 0.302       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 764         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 267         |\n",
      "|    total_timesteps    | 54468608    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016420148 |\n",
      "|    entropy_loss       | -2.31       |\n",
      "|    explained_variance | 0.872       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0903     |\n",
      "|    mean_step_reward   | 0.018146815 |\n",
      "|    n_updates          | 96/128      |\n",
      "|    policyGradLoss     | -0.0112     |\n",
      "|    value_loss         | 0.161       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 763         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 278         |\n",
      "|    total_timesteps    | 54476800    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016559286 |\n",
      "|    entropy_loss       | -2.29       |\n",
      "|    explained_variance | 0.933       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.094      |\n",
      "|    mean_step_reward   | 0.008746373 |\n",
      "|    n_updates          | 100/128     |\n",
      "|    policyGradLoss     | -0.0151     |\n",
      "|    value_loss         | 0.142       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 763         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 289         |\n",
      "|    total_timesteps    | 54484992    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02001137  |\n",
      "|    entropy_loss       | -2.16       |\n",
      "|    explained_variance | 0.9         |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0145     |\n",
      "|    mean_step_reward   | 0.025985148 |\n",
      "|    n_updates          | 104/128     |\n",
      "|    policyGradLoss     | -0.0157     |\n",
      "|    value_loss         | 0.353       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 763         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 300         |\n",
      "|    total_timesteps    | 54493184    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024454297 |\n",
      "|    entropy_loss       | -2.2        |\n",
      "|    explained_variance | 0.952       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.104      |\n",
      "|    mean_step_reward   | 0.041109987 |\n",
      "|    n_updates          | 108/128     |\n",
      "|    policyGradLoss     | -0.0206     |\n",
      "|    value_loss         | 0.117       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 762          |\n",
      "|    iterations         | 29           |\n",
      "|    time_elapsed       | 311          |\n",
      "|    total_timesteps    | 54501376     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0105358455 |\n",
      "|    entropy_loss       | -2.31        |\n",
      "|    explained_variance | 0.755        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0918      |\n",
      "|    mean_step_reward   | 0.017387401  |\n",
      "|    n_updates          | 112/128      |\n",
      "|    policyGradLoss     | -0.00735     |\n",
      "|    value_loss         | 0.221        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 762          |\n",
      "|    iterations         | 30           |\n",
      "|    time_elapsed       | 322          |\n",
      "|    total_timesteps    | 54509568     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.012316913  |\n",
      "|    entropy_loss       | -2.3         |\n",
      "|    explained_variance | 0.772        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0926      |\n",
      "|    mean_step_reward   | 0.0148006845 |\n",
      "|    n_updates          | 116/128      |\n",
      "|    policyGradLoss     | -0.0116      |\n",
      "|    value_loss         | 0.291        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 762         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 333         |\n",
      "|    total_timesteps    | 54517760    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017032148 |\n",
      "|    entropy_loss       | -2.32       |\n",
      "|    explained_variance | 0.95        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.112      |\n",
      "|    mean_step_reward   | 0.027784921 |\n",
      "|    n_updates          | 120/128     |\n",
      "|    policyGradLoss     | -0.0207     |\n",
      "|    value_loss         | 0.0745      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 762          |\n",
      "|    iterations         | 32           |\n",
      "|    time_elapsed       | 343          |\n",
      "|    total_timesteps    | 54525952     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.018812232  |\n",
      "|    entropy_loss       | -2.32        |\n",
      "|    explained_variance | 0.931        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0829      |\n",
      "|    mean_step_reward   | 0.0019769056 |\n",
      "|    n_updates          | 124/128      |\n",
      "|    policyGradLoss     | -0.019       |\n",
      "|    value_loss         | 0.239        |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/NoArti_207.zip\n",
      "[EVAL] Mean Return: 127.901, Best Return: 130.301\n",
      "Saved video to ./runs_smw/videos/NoArti/NoArti_207_127.90.mp4\n",
      "\n",
      "=== Round 209 | Learn 262144 steps (Total trained: 54525952) ===\n",
      "Logging to ./runs_smw/tb/NoArti_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1131     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 54534144 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 896         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 54542336    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024885118 |\n",
      "|    entropy_loss       | -2.16       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0994     |\n",
      "|    mean_step_reward   | 0.046030596 |\n",
      "|    n_updates          | 4/128       |\n",
      "|    policyGradLoss     | -0.0213     |\n",
      "|    value_loss         | 0.14        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 851         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 54550528    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019364888 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.901       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0679     |\n",
      "|    mean_step_reward   | 0.030426959 |\n",
      "|    n_updates          | 8/128       |\n",
      "|    policyGradLoss     | -0.0179     |\n",
      "|    value_loss         | 0.309       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 830         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 54558720    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018578727 |\n",
      "|    entropy_loss       | -2.19       |\n",
      "|    explained_variance | 0.921       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0562     |\n",
      "|    mean_step_reward   | 0.031811617 |\n",
      "|    n_updates          | 12/128      |\n",
      "|    policyGradLoss     | -0.019      |\n",
      "|    value_loss         | 0.318       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 811         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 50          |\n",
      "|    total_timesteps    | 54566912    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019411579 |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.91        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.091      |\n",
      "|    mean_step_reward   | 0.033996277 |\n",
      "|    n_updates          | 16/128      |\n",
      "|    policyGradLoss     | -0.0145     |\n",
      "|    value_loss         | 0.162       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 800         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 61          |\n",
      "|    total_timesteps    | 54575104    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019390225 |\n",
      "|    entropy_loss       | -2.31       |\n",
      "|    explained_variance | 0.935       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0867     |\n",
      "|    mean_step_reward   | 0.012290001 |\n",
      "|    n_updates          | 20/128      |\n",
      "|    policyGradLoss     | -0.0142     |\n",
      "|    value_loss         | 0.151       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 793         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 72          |\n",
      "|    total_timesteps    | 54583296    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015201369 |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.928       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00953     |\n",
      "|    mean_step_reward   | 0.02345686  |\n",
      "|    n_updates          | 24/128      |\n",
      "|    policyGradLoss     | -0.014      |\n",
      "|    value_loss         | 0.347       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 790         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 82          |\n",
      "|    total_timesteps    | 54591488    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01985922  |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.928       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0964     |\n",
      "|    mean_step_reward   | 0.026732456 |\n",
      "|    n_updates          | 28/128      |\n",
      "|    policyGradLoss     | -0.0215     |\n",
      "|    value_loss         | 0.126       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 93          |\n",
      "|    total_timesteps    | 54599680    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02190663  |\n",
      "|    entropy_loss       | -2.29       |\n",
      "|    explained_variance | 0.949       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0967     |\n",
      "|    mean_step_reward   | 0.011454195 |\n",
      "|    n_updates          | 32/128      |\n",
      "|    policyGradLoss     | -0.0172     |\n",
      "|    value_loss         | 0.162       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 104         |\n",
      "|    total_timesteps    | 54607872    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027917657 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.111      |\n",
      "|    mean_step_reward   | 0.019229472 |\n",
      "|    n_updates          | 36/128      |\n",
      "|    policyGradLoss     | -0.027      |\n",
      "|    value_loss         | 0.0771      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 115         |\n",
      "|    total_timesteps    | 54616064    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017155934 |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.928       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0981     |\n",
      "|    mean_step_reward   | 0.024550315 |\n",
      "|    n_updates          | 40/128      |\n",
      "|    policyGradLoss     | -0.0174     |\n",
      "|    value_loss         | 0.169       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 126         |\n",
      "|    total_timesteps    | 54624256    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019827709 |\n",
      "|    entropy_loss       | -2.33       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.121      |\n",
      "|    mean_step_reward   | 0.014238284 |\n",
      "|    n_updates          | 44/128      |\n",
      "|    policyGradLoss     | -0.0196     |\n",
      "|    value_loss         | 0.0485      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 778        |\n",
      "|    iterations         | 13         |\n",
      "|    time_elapsed       | 136        |\n",
      "|    total_timesteps    | 54632448   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02276956 |\n",
      "|    entropy_loss       | -2.26      |\n",
      "|    explained_variance | 0.955      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.101     |\n",
      "|    mean_step_reward   | 0.01639133 |\n",
      "|    n_updates          | 48/128     |\n",
      "|    policyGradLoss     | -0.0187    |\n",
      "|    value_loss         | 0.0688     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 776        |\n",
      "|    iterations         | 14         |\n",
      "|    time_elapsed       | 147        |\n",
      "|    total_timesteps    | 54640640   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02613839 |\n",
      "|    entropy_loss       | -2.26      |\n",
      "|    explained_variance | 0.963      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.103     |\n",
      "|    mean_step_reward   | 0.03345352 |\n",
      "|    n_updates          | 52/128     |\n",
      "|    policyGradLoss     | -0.017     |\n",
      "|    value_loss         | 0.178      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 158         |\n",
      "|    total_timesteps    | 54648832    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022981968 |\n",
      "|    entropy_loss       | -2.3        |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.115      |\n",
      "|    mean_step_reward   | 0.019653564 |\n",
      "|    n_updates          | 56/128      |\n",
      "|    policyGradLoss     | -0.0194     |\n",
      "|    value_loss         | 0.0488      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 169         |\n",
      "|    total_timesteps    | 54657024    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020263966 |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.952       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0884     |\n",
      "|    mean_step_reward   | 0.013354952 |\n",
      "|    n_updates          | 60/128      |\n",
      "|    policyGradLoss     | -0.0197     |\n",
      "|    value_loss         | 0.116       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 179         |\n",
      "|    total_timesteps    | 54665216    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022568412 |\n",
      "|    entropy_loss       | -2.19       |\n",
      "|    explained_variance | 0.932       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0782     |\n",
      "|    mean_step_reward   | 0.030039892 |\n",
      "|    n_updates          | 64/128      |\n",
      "|    policyGradLoss     | -0.0172     |\n",
      "|    value_loss         | 0.29        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 773        |\n",
      "|    iterations         | 18         |\n",
      "|    time_elapsed       | 190        |\n",
      "|    total_timesteps    | 54673408   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02828624 |\n",
      "|    entropy_loss       | -2.18      |\n",
      "|    explained_variance | 0.968      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.11      |\n",
      "|    mean_step_reward   | 0.04047819 |\n",
      "|    n_updates          | 68/128     |\n",
      "|    policyGradLoss     | -0.025     |\n",
      "|    value_loss         | 0.131      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 201         |\n",
      "|    total_timesteps    | 54681600    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024143983 |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.103      |\n",
      "|    mean_step_reward   | 0.023997908 |\n",
      "|    n_updates          | 72/128      |\n",
      "|    policyGradLoss     | -0.0226     |\n",
      "|    value_loss         | 0.0685      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 212         |\n",
      "|    total_timesteps    | 54689792    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018918142 |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.915       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0949     |\n",
      "|    mean_step_reward   | 0.02725697  |\n",
      "|    n_updates          | 76/128      |\n",
      "|    policyGradLoss     | -0.0176     |\n",
      "|    value_loss         | 0.157       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 223         |\n",
      "|    total_timesteps    | 54697984    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023350667 |\n",
      "|    entropy_loss       | -2.27       |\n",
      "|    explained_variance | 0.883       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.089      |\n",
      "|    mean_step_reward   | 0.0214325   |\n",
      "|    n_updates          | 80/128      |\n",
      "|    policyGradLoss     | -0.0179     |\n",
      "|    value_loss         | 0.311       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 233         |\n",
      "|    total_timesteps    | 54706176    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026760103 |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.106      |\n",
      "|    mean_step_reward   | 0.026863355 |\n",
      "|    n_updates          | 84/128      |\n",
      "|    policyGradLoss     | -0.0202     |\n",
      "|    value_loss         | 0.073       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 244         |\n",
      "|    total_timesteps    | 54714368    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028672127 |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.12       |\n",
      "|    mean_step_reward   | 0.024855558 |\n",
      "|    n_updates          | 88/128      |\n",
      "|    policyGradLoss     | -0.026      |\n",
      "|    value_loss         | 0.0503      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 255         |\n",
      "|    total_timesteps    | 54722560    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.032434054 |\n",
      "|    entropy_loss       | -2.27       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.117      |\n",
      "|    mean_step_reward   | 0.016289072 |\n",
      "|    n_updates          | 92/128      |\n",
      "|    policyGradLoss     | -0.0274     |\n",
      "|    value_loss         | 0.0441      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 266         |\n",
      "|    total_timesteps    | 54730752    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018894074 |\n",
      "|    entropy_loss       | -2.28       |\n",
      "|    explained_variance | 0.932       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0521     |\n",
      "|    mean_step_reward   | 0.02392931  |\n",
      "|    n_updates          | 96/128      |\n",
      "|    policyGradLoss     | -0.0162     |\n",
      "|    value_loss         | 0.154       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 277         |\n",
      "|    total_timesteps    | 54738944    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015909996 |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.879       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0659     |\n",
      "|    mean_step_reward   | 0.00852626  |\n",
      "|    n_updates          | 100/128     |\n",
      "|    policyGradLoss     | -0.0161     |\n",
      "|    value_loss         | 0.282       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 288         |\n",
      "|    total_timesteps    | 54747136    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017805466 |\n",
      "|    entropy_loss       | -2.09       |\n",
      "|    explained_variance | 0.937       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0804      |\n",
      "|    mean_step_reward   | 0.03821152  |\n",
      "|    n_updates          | 104/128     |\n",
      "|    policyGradLoss     | -0.0128     |\n",
      "|    value_loss         | 0.384       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 766        |\n",
      "|    iterations         | 28         |\n",
      "|    time_elapsed       | 299        |\n",
      "|    total_timesteps    | 54755328   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03354418 |\n",
      "|    entropy_loss       | -2.15      |\n",
      "|    explained_variance | 0.982      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.107     |\n",
      "|    mean_step_reward   | 0.04577718 |\n",
      "|    n_updates          | 108/128    |\n",
      "|    policyGradLoss     | -0.0238    |\n",
      "|    value_loss         | 0.085      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 765         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 310         |\n",
      "|    total_timesteps    | 54763520    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027873999 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.114      |\n",
      "|    mean_step_reward   | 0.025318686 |\n",
      "|    n_updates          | 112/128     |\n",
      "|    policyGradLoss     | -0.0197     |\n",
      "|    value_loss         | 0.0622      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 765         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 320         |\n",
      "|    total_timesteps    | 54771712    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.037701942 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.115      |\n",
      "|    mean_step_reward   | 0.028203364 |\n",
      "|    n_updates          | 116/128     |\n",
      "|    policyGradLoss     | -0.0217     |\n",
      "|    value_loss         | 0.0448      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 331         |\n",
      "|    total_timesteps    | 54779904    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026065478 |\n",
      "|    entropy_loss       | -2.3        |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.1        |\n",
      "|    mean_step_reward   | 0.020417355 |\n",
      "|    n_updates          | 120/128     |\n",
      "|    policyGradLoss     | -0.0175     |\n",
      "|    value_loss         | 0.0778      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 765         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 342         |\n",
      "|    total_timesteps    | 54788096    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026552243 |\n",
      "|    entropy_loss       | -2.37       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.111      |\n",
      "|    mean_step_reward   | 0.001273975 |\n",
      "|    n_updates          | 124/128     |\n",
      "|    policyGradLoss     | -0.0179     |\n",
      "|    value_loss         | 0.0258      |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/NoArti_208.zip\n",
      "[EVAL] Mean Return: 63.782, Best Return: 65.582\n",
      "Saved video to ./runs_smw/videos/NoArti/NoArti_208_63.78.mp4\n",
      "\n",
      "=== Round 210 | Learn 262144 steps (Total trained: 54788096) ===\n",
      "Logging to ./runs_smw/tb/NoArti_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1108     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 54796288 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 893         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 54804480    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.032167938 |\n",
      "|    entropy_loss       | -2.07       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0515     |\n",
      "|    mean_step_reward   | 0.056700185 |\n",
      "|    n_updates          | 4/128       |\n",
      "|    policyGradLoss     | -0.0206     |\n",
      "|    value_loss         | 0.188       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 846         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 29          |\n",
      "|    total_timesteps    | 54812672    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029381592 |\n",
      "|    entropy_loss       | -2.15       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0765     |\n",
      "|    mean_step_reward   | 0.035340633 |\n",
      "|    n_updates          | 8/128       |\n",
      "|    policyGradLoss     | -0.0178     |\n",
      "|    value_loss         | 0.132       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 816         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 40          |\n",
      "|    total_timesteps    | 54820864    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019705951 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.926       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0937     |\n",
      "|    mean_step_reward   | 0.018777667 |\n",
      "|    n_updates          | 12/128      |\n",
      "|    policyGradLoss     | -0.0121     |\n",
      "|    value_loss         | 0.16        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 799         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 51          |\n",
      "|    total_timesteps    | 54829056    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02308765  |\n",
      "|    entropy_loss       | -2.2        |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0877     |\n",
      "|    mean_step_reward   | 0.036461867 |\n",
      "|    n_updates          | 16/128      |\n",
      "|    policyGradLoss     | -0.0168     |\n",
      "|    value_loss         | 0.146       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 791         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 62          |\n",
      "|    total_timesteps    | 54837248    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015660003 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.863       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0666     |\n",
      "|    mean_step_reward   | 0.024597315 |\n",
      "|    n_updates          | 20/128      |\n",
      "|    policyGradLoss     | -0.011      |\n",
      "|    value_loss         | 0.266       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 72          |\n",
      "|    total_timesteps    | 54845440    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02211554  |\n",
      "|    entropy_loss       | -2.18       |\n",
      "|    explained_variance | 0.957       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0873     |\n",
      "|    mean_step_reward   | 0.016084526 |\n",
      "|    n_updates          | 24/128      |\n",
      "|    policyGradLoss     | -0.0168     |\n",
      "|    value_loss         | 0.164       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 83          |\n",
      "|    total_timesteps    | 54853632    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024304502 |\n",
      "|    entropy_loss       | -2.12       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0639     |\n",
      "|    mean_step_reward   | 0.036274876 |\n",
      "|    n_updates          | 28/128      |\n",
      "|    policyGradLoss     | -0.0199     |\n",
      "|    value_loss         | 0.162       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 94          |\n",
      "|    total_timesteps    | 54861824    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029682701 |\n",
      "|    entropy_loss       | -2.17       |\n",
      "|    explained_variance | 0.955       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.105      |\n",
      "|    mean_step_reward   | 0.03758164  |\n",
      "|    n_updates          | 32/128      |\n",
      "|    policyGradLoss     | -0.0183     |\n",
      "|    value_loss         | 0.127       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 105         |\n",
      "|    total_timesteps    | 54870016    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030301219 |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.919       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0994     |\n",
      "|    mean_step_reward   | 0.023917943 |\n",
      "|    n_updates          | 36/128      |\n",
      "|    policyGradLoss     | -0.0174     |\n",
      "|    value_loss         | 0.118       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 116         |\n",
      "|    total_timesteps    | 54878208    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022275496 |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.11       |\n",
      "|    mean_step_reward   | 0.02171883  |\n",
      "|    n_updates          | 40/128      |\n",
      "|    policyGradLoss     | -0.018      |\n",
      "|    value_loss         | 0.0836      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 127         |\n",
      "|    total_timesteps    | 54886400    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026167234 |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0922     |\n",
      "|    mean_step_reward   | 0.026937958 |\n",
      "|    n_updates          | 44/128      |\n",
      "|    policyGradLoss     | -0.0158     |\n",
      "|    value_loss         | 0.0975      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 138         |\n",
      "|    total_timesteps    | 54894592    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019299265 |\n",
      "|    entropy_loss       | -2.18       |\n",
      "|    explained_variance | 0.94        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0759     |\n",
      "|    mean_step_reward   | 0.02993673  |\n",
      "|    n_updates          | 48/128      |\n",
      "|    policyGradLoss     | -0.0162     |\n",
      "|    value_loss         | 0.237       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 149         |\n",
      "|    total_timesteps    | 54902784    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025263652 |\n",
      "|    entropy_loss       | -2.16       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0972     |\n",
      "|    mean_step_reward   | 0.030543309 |\n",
      "|    n_updates          | 52/128      |\n",
      "|    policyGradLoss     | -0.0178     |\n",
      "|    value_loss         | 0.118       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 160         |\n",
      "|    total_timesteps    | 54910976    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028693624 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0957     |\n",
      "|    mean_step_reward   | 0.03401131  |\n",
      "|    n_updates          | 56/128      |\n",
      "|    policyGradLoss     | -0.022      |\n",
      "|    value_loss         | 0.0407      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 765         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 171         |\n",
      "|    total_timesteps    | 54919168    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020930659 |\n",
      "|    entropy_loss       | -2.29       |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0845     |\n",
      "|    mean_step_reward   | 0.013114715 |\n",
      "|    n_updates          | 60/128      |\n",
      "|    policyGradLoss     | -0.0147     |\n",
      "|    value_loss         | 0.136       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 181         |\n",
      "|    total_timesteps    | 54927360    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01997572  |\n",
      "|    entropy_loss       | -2.33       |\n",
      "|    explained_variance | 0.957       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.111      |\n",
      "|    mean_step_reward   | 0.014560148 |\n",
      "|    n_updates          | 64/128      |\n",
      "|    policyGradLoss     | -0.0156     |\n",
      "|    value_loss         | 0.0457      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 765         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 192         |\n",
      "|    total_timesteps    | 54935552    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020653298 |\n",
      "|    entropy_loss       | -2.28       |\n",
      "|    explained_variance | 0.945       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0982     |\n",
      "|    mean_step_reward   | 0.010940518 |\n",
      "|    n_updates          | 68/128      |\n",
      "|    policyGradLoss     | -0.0146     |\n",
      "|    value_loss         | 0.0859      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 765         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 203         |\n",
      "|    total_timesteps    | 54943744    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014183326 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.926       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0649     |\n",
      "|    mean_step_reward   | 0.023867872 |\n",
      "|    n_updates          | 72/128      |\n",
      "|    policyGradLoss     | -0.0126     |\n",
      "|    value_loss         | 0.24        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 765         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 214         |\n",
      "|    total_timesteps    | 54951936    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021567196 |\n",
      "|    entropy_loss       | -2.08       |\n",
      "|    explained_variance | 0.931       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0556     |\n",
      "|    mean_step_reward   | 0.037365768 |\n",
      "|    n_updates          | 76/128      |\n",
      "|    policyGradLoss     | -0.0124     |\n",
      "|    value_loss         | 0.352       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 764         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 224         |\n",
      "|    total_timesteps    | 54960128    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025631057 |\n",
      "|    entropy_loss       | -2.11       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0811     |\n",
      "|    mean_step_reward   | 0.063868806 |\n",
      "|    n_updates          | 80/128      |\n",
      "|    policyGradLoss     | -0.0178     |\n",
      "|    value_loss         | 0.138       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 764         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 235         |\n",
      "|    total_timesteps    | 54968320    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025645211 |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0716     |\n",
      "|    mean_step_reward   | 0.029413287 |\n",
      "|    n_updates          | 84/128      |\n",
      "|    policyGradLoss     | -0.0165     |\n",
      "|    value_loss         | 0.136       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 764         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 246         |\n",
      "|    total_timesteps    | 54976512    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019391505 |\n",
      "|    entropy_loss       | -2.2        |\n",
      "|    explained_variance | 0.932       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0754     |\n",
      "|    mean_step_reward   | 0.035438225 |\n",
      "|    n_updates          | 88/128      |\n",
      "|    policyGradLoss     | -0.0138     |\n",
      "|    value_loss         | 0.259       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 765         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 256         |\n",
      "|    total_timesteps    | 54984704    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019031003 |\n",
      "|    entropy_loss       | -2.18       |\n",
      "|    explained_variance | 0.934       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0918     |\n",
      "|    mean_step_reward   | 0.032101057 |\n",
      "|    n_updates          | 92/128      |\n",
      "|    policyGradLoss     | -0.0172     |\n",
      "|    value_loss         | 0.205       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 764         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 267         |\n",
      "|    total_timesteps    | 54992896    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029468607 |\n",
      "|    entropy_loss       | -2.16       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.116      |\n",
      "|    mean_step_reward   | 0.04497066  |\n",
      "|    n_updates          | 96/128      |\n",
      "|    policyGradLoss     | -0.0265     |\n",
      "|    value_loss         | 0.0565      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 763         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 278         |\n",
      "|    total_timesteps    | 55001088    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01775871  |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.911       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0574      |\n",
      "|    mean_step_reward   | 0.020873994 |\n",
      "|    n_updates          | 100/128     |\n",
      "|    policyGradLoss     | -0.0157     |\n",
      "|    value_loss         | 0.288       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 763         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 289         |\n",
      "|    total_timesteps    | 55009280    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021359079 |\n",
      "|    entropy_loss       | -2.2        |\n",
      "|    explained_variance | 0.922       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0795     |\n",
      "|    mean_step_reward   | 0.028635118 |\n",
      "|    n_updates          | 104/128     |\n",
      "|    policyGradLoss     | -0.0182     |\n",
      "|    value_loss         | 0.262       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 762         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 300         |\n",
      "|    total_timesteps    | 55017472    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.03156795  |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.121      |\n",
      "|    mean_step_reward   | 0.025085118 |\n",
      "|    n_updates          | 108/128     |\n",
      "|    policyGradLoss     | -0.0242     |\n",
      "|    value_loss         | 0.0579      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 761         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 311         |\n",
      "|    total_timesteps    | 55025664    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025486102 |\n",
      "|    entropy_loss       | -2.34       |\n",
      "|    explained_variance | 0.883       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.103      |\n",
      "|    mean_step_reward   | 0.009791945 |\n",
      "|    n_updates          | 112/128     |\n",
      "|    policyGradLoss     | -0.0151     |\n",
      "|    value_loss         | 0.15        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 762         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 322         |\n",
      "|    total_timesteps    | 55033856    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019104045 |\n",
      "|    entropy_loss       | -2.33       |\n",
      "|    explained_variance | 0.957       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0851     |\n",
      "|    mean_step_reward   | 0.007926859 |\n",
      "|    n_updates          | 116/128     |\n",
      "|    policyGradLoss     | -0.0166     |\n",
      "|    value_loss         | 0.08        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 761         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 333         |\n",
      "|    total_timesteps    | 55042048    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.03209049  |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0441      |\n",
      "|    mean_step_reward   | 0.023004469 |\n",
      "|    n_updates          | 120/128     |\n",
      "|    policyGradLoss     | -0.0212     |\n",
      "|    value_loss         | 0.134       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 760         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 344         |\n",
      "|    total_timesteps    | 55050240    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023318987 |\n",
      "|    entropy_loss       | -2.2        |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0993     |\n",
      "|    mean_step_reward   | 0.015329401 |\n",
      "|    n_updates          | 124/128     |\n",
      "|    policyGradLoss     | -0.0217     |\n",
      "|    value_loss         | 0.0914      |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/NoArti_209.zip\n",
      "[EVAL] Mean Return: 1.704, Best Return: 1.904\n",
      "Saved video to ./runs_smw/videos/NoArti/NoArti_209_1.70.mp4\n",
      "\n",
      "=== Round 211 | Learn 262144 steps (Total trained: 55050240) ===\n",
      "Logging to ./runs_smw/tb/NoArti_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1102     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 55058432 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 901         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 55066624    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.034680873 |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0975     |\n",
      "|    mean_step_reward   | 0.031927217 |\n",
      "|    n_updates          | 4/128       |\n",
      "|    policyGradLoss     | -0.0185     |\n",
      "|    value_loss         | 0.118       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 858         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 55074816    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019992875 |\n",
      "|    entropy_loss       | -2.28       |\n",
      "|    explained_variance | 0.905       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0551     |\n",
      "|    mean_step_reward   | 0.010583774 |\n",
      "|    n_updates          | 8/128       |\n",
      "|    policyGradLoss     | -0.0186     |\n",
      "|    value_loss         | 0.201       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 835         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 55083008    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024562033 |\n",
      "|    entropy_loss       | -2.17       |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0939     |\n",
      "|    mean_step_reward   | 0.034642495 |\n",
      "|    n_updates          | 12/128      |\n",
      "|    policyGradLoss     | -0.0201     |\n",
      "|    value_loss         | 0.133       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 816         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 50          |\n",
      "|    total_timesteps    | 55091200    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021776307 |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.91        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0773     |\n",
      "|    mean_step_reward   | 0.018383654 |\n",
      "|    n_updates          | 16/128      |\n",
      "|    policyGradLoss     | -0.0152     |\n",
      "|    value_loss         | 0.234       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 808         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 60          |\n",
      "|    total_timesteps    | 55099392    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022743788 |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0948     |\n",
      "|    mean_step_reward   | 0.025146674 |\n",
      "|    n_updates          | 20/128      |\n",
      "|    policyGradLoss     | -0.0212     |\n",
      "|    value_loss         | 0.0925      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 803         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 71          |\n",
      "|    total_timesteps    | 55107584    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026090011 |\n",
      "|    entropy_loss       | -2.19       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0815     |\n",
      "|    mean_step_reward   | 0.03771917  |\n",
      "|    n_updates          | 24/128      |\n",
      "|    policyGradLoss     | -0.0202     |\n",
      "|    value_loss         | 0.119       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 797         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 82          |\n",
      "|    total_timesteps    | 55115776    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.032042615 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0991     |\n",
      "|    mean_step_reward   | 0.025035333 |\n",
      "|    n_updates          | 28/128      |\n",
      "|    policyGradLoss     | -0.0255     |\n",
      "|    value_loss         | 0.0509      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 794         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 92          |\n",
      "|    total_timesteps    | 55123968    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021079049 |\n",
      "|    entropy_loss       | -2.2        |\n",
      "|    explained_variance | 0.946       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0752     |\n",
      "|    mean_step_reward   | 0.028609583 |\n",
      "|    n_updates          | 32/128      |\n",
      "|    policyGradLoss     | -0.0154     |\n",
      "|    value_loss         | 0.226       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 791         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 103         |\n",
      "|    total_timesteps    | 55132160    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022175595 |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00241     |\n",
      "|    mean_step_reward   | 0.031079099 |\n",
      "|    n_updates          | 36/128      |\n",
      "|    policyGradLoss     | -0.0164     |\n",
      "|    value_loss         | 0.236       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 114         |\n",
      "|    total_timesteps    | 55140352    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026131175 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.111      |\n",
      "|    mean_step_reward   | 0.024541866 |\n",
      "|    n_updates          | 40/128      |\n",
      "|    policyGradLoss     | -0.0221     |\n",
      "|    value_loss         | 0.0815      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 125         |\n",
      "|    total_timesteps    | 55148544    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018923588 |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.919       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0573     |\n",
      "|    mean_step_reward   | 0.012968935 |\n",
      "|    n_updates          | 44/128      |\n",
      "|    policyGradLoss     | -0.0167     |\n",
      "|    value_loss         | 0.208       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 136         |\n",
      "|    total_timesteps    | 55156736    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016682748 |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.928       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0871     |\n",
      "|    mean_step_reward   | 0.034583144 |\n",
      "|    n_updates          | 48/128      |\n",
      "|    policyGradLoss     | -0.0164     |\n",
      "|    value_loss         | 0.254       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 147         |\n",
      "|    total_timesteps    | 55164928    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027018696 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.939       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0899     |\n",
      "|    mean_step_reward   | 0.019623844 |\n",
      "|    n_updates          | 52/128      |\n",
      "|    policyGradLoss     | -0.019      |\n",
      "|    value_loss         | 0.198       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 158         |\n",
      "|    total_timesteps    | 55173120    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024646437 |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.931       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.108      |\n",
      "|    mean_step_reward   | 0.023614101 |\n",
      "|    n_updates          | 56/128      |\n",
      "|    policyGradLoss     | -0.0184     |\n",
      "|    value_loss         | 0.172       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 169         |\n",
      "|    total_timesteps    | 55181312    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024146717 |\n",
      "|    entropy_loss       | -2.16       |\n",
      "|    explained_variance | 0.946       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0589     |\n",
      "|    mean_step_reward   | 0.034486197 |\n",
      "|    n_updates          | 60/128      |\n",
      "|    policyGradLoss     | -0.0186     |\n",
      "|    value_loss         | 0.293       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 180         |\n",
      "|    total_timesteps    | 55189504    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030619739 |\n",
      "|    entropy_loss       | -2.15       |\n",
      "|    explained_variance | 0.934       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.067      |\n",
      "|    mean_step_reward   | 0.037904564 |\n",
      "|    n_updates          | 64/128      |\n",
      "|    policyGradLoss     | -0.0197     |\n",
      "|    value_loss         | 0.278       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 191         |\n",
      "|    total_timesteps    | 55197696    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023944242 |\n",
      "|    entropy_loss       | -2.2        |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0898     |\n",
      "|    mean_step_reward   | 0.022951514 |\n",
      "|    n_updates          | 68/128      |\n",
      "|    policyGradLoss     | -0.0231     |\n",
      "|    value_loss         | 0.144       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 202         |\n",
      "|    total_timesteps    | 55205888    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026439112 |\n",
      "|    entropy_loss       | -2.2        |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0874     |\n",
      "|    mean_step_reward   | 0.038427837 |\n",
      "|    n_updates          | 72/128      |\n",
      "|    policyGradLoss     | -0.0188     |\n",
      "|    value_loss         | 0.146       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 212         |\n",
      "|    total_timesteps    | 55214080    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023477672 |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0936     |\n",
      "|    mean_step_reward   | 0.03202404  |\n",
      "|    n_updates          | 76/128      |\n",
      "|    policyGradLoss     | -0.0216     |\n",
      "|    value_loss         | 0.12        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 223         |\n",
      "|    total_timesteps    | 55222272    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022639409 |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.931       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0474     |\n",
      "|    mean_step_reward   | 0.018519564 |\n",
      "|    n_updates          | 80/128      |\n",
      "|    policyGradLoss     | -0.0186     |\n",
      "|    value_loss         | 0.266       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 234         |\n",
      "|    total_timesteps    | 55230464    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02859818  |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0778     |\n",
      "|    mean_step_reward   | 0.026096314 |\n",
      "|    n_updates          | 84/128      |\n",
      "|    policyGradLoss     | -0.0199     |\n",
      "|    value_loss         | 0.103       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 245         |\n",
      "|    total_timesteps    | 55238656    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019764997 |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.957       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.05       |\n",
      "|    mean_step_reward   | 0.027287975 |\n",
      "|    n_updates          | 88/128      |\n",
      "|    policyGradLoss     | -0.0147     |\n",
      "|    value_loss         | 0.198       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 256         |\n",
      "|    total_timesteps    | 55246848    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016941214 |\n",
      "|    entropy_loss       | -2.15       |\n",
      "|    explained_variance | 0.919       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0365     |\n",
      "|    mean_step_reward   | 0.016485892 |\n",
      "|    n_updates          | 92/128      |\n",
      "|    policyGradLoss     | -0.0143     |\n",
      "|    value_loss         | 0.411       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 267         |\n",
      "|    total_timesteps    | 55255040    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022633344 |\n",
      "|    entropy_loss       | -2.14       |\n",
      "|    explained_variance | 0.94        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0717     |\n",
      "|    mean_step_reward   | 0.033101358 |\n",
      "|    n_updates          | 96/128      |\n",
      "|    policyGradLoss     | -0.0175     |\n",
      "|    value_loss         | 0.301       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 765         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 278         |\n",
      "|    total_timesteps    | 55263232    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024265755 |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.916       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0889     |\n",
      "|    mean_step_reward   | 0.027352039 |\n",
      "|    n_updates          | 100/128     |\n",
      "|    policyGradLoss     | -0.0179     |\n",
      "|    value_loss         | 0.243       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 765         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 288         |\n",
      "|    total_timesteps    | 55271424    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026493035 |\n",
      "|    entropy_loss       | -2.28       |\n",
      "|    explained_variance | 0.935       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.102      |\n",
      "|    mean_step_reward   | 0.013611306 |\n",
      "|    n_updates          | 104/128     |\n",
      "|    policyGradLoss     | -0.0187     |\n",
      "|    value_loss         | 0.114       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 765         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 299         |\n",
      "|    total_timesteps    | 55279616    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028402831 |\n",
      "|    entropy_loss       | -2.3        |\n",
      "|    explained_variance | 0.864       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0255     |\n",
      "|    mean_step_reward   | 0.003666658 |\n",
      "|    n_updates          | 108/128     |\n",
      "|    policyGradLoss     | -0.0171     |\n",
      "|    value_loss         | 0.163       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 765         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 310         |\n",
      "|    total_timesteps    | 55287808    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027403545 |\n",
      "|    entropy_loss       | -2.27       |\n",
      "|    explained_variance | 0.942       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.109      |\n",
      "|    mean_step_reward   | 0.015370583 |\n",
      "|    n_updates          | 112/128     |\n",
      "|    policyGradLoss     | -0.0192     |\n",
      "|    value_loss         | 0.107       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 764        |\n",
      "|    iterations         | 30         |\n",
      "|    time_elapsed       | 321        |\n",
      "|    total_timesteps    | 55296000   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03635908 |\n",
      "|    entropy_loss       | -2.23      |\n",
      "|    explained_variance | 0.965      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.106     |\n",
      "|    mean_step_reward   | 0.02682066 |\n",
      "|    n_updates          | 116/128    |\n",
      "|    policyGradLoss     | -0.0242    |\n",
      "|    value_loss         | 0.0926     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 764         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 332         |\n",
      "|    total_timesteps    | 55304192    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02371405  |\n",
      "|    entropy_loss       | -2.28       |\n",
      "|    explained_variance | 0.958       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.113      |\n",
      "|    mean_step_reward   | 0.020755168 |\n",
      "|    n_updates          | 120/128     |\n",
      "|    policyGradLoss     | -0.0207     |\n",
      "|    value_loss         | 0.0756      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 764         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 342         |\n",
      "|    total_timesteps    | 55312384    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017116167 |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.864       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0674     |\n",
      "|    mean_step_reward   | 0.012163112 |\n",
      "|    n_updates          | 124/128     |\n",
      "|    policyGradLoss     | -0.0113     |\n",
      "|    value_loss         | 0.395       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/NoArti_210.zip\n",
      "[EVAL] Mean Return: 87.029, Best Return: 89.029\n",
      "Saved video to ./runs_smw/videos/NoArti/NoArti_210_87.03.mp4\n",
      "\n",
      "=== Round 212 | Learn 262144 steps (Total trained: 55312384) ===\n",
      "Logging to ./runs_smw/tb/NoArti_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1133     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 55320576 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 901         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 55328768    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.03165003  |\n",
      "|    entropy_loss       | -2.13       |\n",
      "|    explained_variance | 0.943       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0852     |\n",
      "|    mean_step_reward   | 0.036776803 |\n",
      "|    n_updates          | 4/128       |\n",
      "|    policyGradLoss     | -0.0163     |\n",
      "|    value_loss         | 0.268       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 851         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 55336960    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017066598 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.893       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0965     |\n",
      "|    mean_step_reward   | 0.013140186 |\n",
      "|    n_updates          | 8/128       |\n",
      "|    policyGradLoss     | -0.017      |\n",
      "|    value_loss         | 0.209       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 818         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 40          |\n",
      "|    total_timesteps    | 55345152    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027437681 |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0931     |\n",
      "|    mean_step_reward   | 0.030415602 |\n",
      "|    n_updates          | 12/128      |\n",
      "|    policyGradLoss     | -0.0171     |\n",
      "|    value_loss         | 0.135       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 800         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 51          |\n",
      "|    total_timesteps    | 55353344    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025229104 |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.879       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.102      |\n",
      "|    mean_step_reward   | 0.011166908 |\n",
      "|    n_updates          | 16/128      |\n",
      "|    policyGradLoss     | -0.0207     |\n",
      "|    value_loss         | 0.181       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 794         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 61          |\n",
      "|    total_timesteps    | 55361536    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017853405 |\n",
      "|    entropy_loss       | -2.13       |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0697     |\n",
      "|    mean_step_reward   | 0.03200179  |\n",
      "|    n_updates          | 20/128      |\n",
      "|    policyGradLoss     | -0.0168     |\n",
      "|    value_loss         | 0.232       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 789         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 72          |\n",
      "|    total_timesteps    | 55369728    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022905149 |\n",
      "|    entropy_loss       | -2.19       |\n",
      "|    explained_variance | 0.934       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0773     |\n",
      "|    mean_step_reward   | 0.028804198 |\n",
      "|    n_updates          | 24/128      |\n",
      "|    policyGradLoss     | -0.0182     |\n",
      "|    value_loss         | 0.251       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 83          |\n",
      "|    total_timesteps    | 55377920    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019908614 |\n",
      "|    entropy_loss       | -2.12       |\n",
      "|    explained_variance | 0.914       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0835     |\n",
      "|    mean_step_reward   | 0.037817158 |\n",
      "|    n_updates          | 28/128      |\n",
      "|    policyGradLoss     | -0.0165     |\n",
      "|    value_loss         | 0.38        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 94          |\n",
      "|    total_timesteps    | 55386112    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021823097 |\n",
      "|    entropy_loss       | -2.17       |\n",
      "|    explained_variance | 0.92        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.062      |\n",
      "|    mean_step_reward   | 0.029246943 |\n",
      "|    n_updates          | 32/128      |\n",
      "|    policyGradLoss     | -0.0215     |\n",
      "|    value_loss         | 0.196       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 105         |\n",
      "|    total_timesteps    | 55394304    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018231058 |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.708       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0821     |\n",
      "|    mean_step_reward   | 0.019670876 |\n",
      "|    n_updates          | 36/128      |\n",
      "|    policyGradLoss     | -0.016      |\n",
      "|    value_loss         | 0.355       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 116         |\n",
      "|    total_timesteps    | 55402496    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022911053 |\n",
      "|    entropy_loss       | -2.14       |\n",
      "|    explained_variance | 0.916       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0428     |\n",
      "|    mean_step_reward   | 0.024471242 |\n",
      "|    n_updates          | 40/128      |\n",
      "|    policyGradLoss     | -0.0182     |\n",
      "|    value_loss         | 0.325       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 127         |\n",
      "|    total_timesteps    | 55410688    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022912363 |\n",
      "|    entropy_loss       | -2.13       |\n",
      "|    explained_variance | 0.899       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0755     |\n",
      "|    mean_step_reward   | 0.048401374 |\n",
      "|    n_updates          | 44/128      |\n",
      "|    policyGradLoss     | -0.0181     |\n",
      "|    value_loss         | 0.288       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 138         |\n",
      "|    total_timesteps    | 55418880    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028252821 |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.789       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.101      |\n",
      "|    mean_step_reward   | 0.015194615 |\n",
      "|    n_updates          | 48/128      |\n",
      "|    policyGradLoss     | -0.013      |\n",
      "|    value_loss         | 0.196       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 148         |\n",
      "|    total_timesteps    | 55427072    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016475309 |\n",
      "|    entropy_loss       | -2.18       |\n",
      "|    explained_variance | 0.877       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0684     |\n",
      "|    mean_step_reward   | 0.008351222 |\n",
      "|    n_updates          | 52/128      |\n",
      "|    policyGradLoss     | -0.015      |\n",
      "|    value_loss         | 0.307       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 159         |\n",
      "|    total_timesteps    | 55435264    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018453639 |\n",
      "|    entropy_loss       | -2.2        |\n",
      "|    explained_variance | 0.862       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0808     |\n",
      "|    mean_step_reward   | 0.029663354 |\n",
      "|    n_updates          | 56/128      |\n",
      "|    policyGradLoss     | -0.0118     |\n",
      "|    value_loss         | 0.29        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 170         |\n",
      "|    total_timesteps    | 55443456    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023653891 |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.92        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0786     |\n",
      "|    mean_step_reward   | 0.019680118 |\n",
      "|    n_updates          | 60/128      |\n",
      "|    policyGradLoss     | -0.0174     |\n",
      "|    value_loss         | 0.256       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 181         |\n",
      "|    total_timesteps    | 55451648    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030260954 |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.941       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0818     |\n",
      "|    mean_step_reward   | 0.033225946 |\n",
      "|    n_updates          | 64/128      |\n",
      "|    policyGradLoss     | -0.0206     |\n",
      "|    value_loss         | 0.132       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 192         |\n",
      "|    total_timesteps    | 55459840    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021781178 |\n",
      "|    entropy_loss       | -2.19       |\n",
      "|    explained_variance | 0.925       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0773     |\n",
      "|    mean_step_reward   | 0.023351198 |\n",
      "|    n_updates          | 68/128      |\n",
      "|    policyGradLoss     | -0.0202     |\n",
      "|    value_loss         | 0.325       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 202         |\n",
      "|    total_timesteps    | 55468032    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02416525  |\n",
      "|    entropy_loss       | -2.13       |\n",
      "|    explained_variance | 0.906       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0572     |\n",
      "|    mean_step_reward   | 0.034775846 |\n",
      "|    n_updates          | 72/128      |\n",
      "|    policyGradLoss     | -0.0162     |\n",
      "|    value_loss         | 0.361       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 213         |\n",
      "|    total_timesteps    | 55476224    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025546025 |\n",
      "|    entropy_loss       | -2.1        |\n",
      "|    explained_variance | 0.952       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0901     |\n",
      "|    mean_step_reward   | 0.03957154  |\n",
      "|    n_updates          | 76/128      |\n",
      "|    policyGradLoss     | -0.02       |\n",
      "|    value_loss         | 0.196       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 224         |\n",
      "|    total_timesteps    | 55484416    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025472097 |\n",
      "|    entropy_loss       | -2.2        |\n",
      "|    explained_variance | 0.895       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0939     |\n",
      "|    mean_step_reward   | 0.032052733 |\n",
      "|    n_updates          | 80/128      |\n",
      "|    policyGradLoss     | -0.0184     |\n",
      "|    value_loss         | 0.156       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 767        |\n",
      "|    iterations         | 22         |\n",
      "|    time_elapsed       | 234        |\n",
      "|    total_timesteps    | 55492608   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02690266 |\n",
      "|    entropy_loss       | -2.21      |\n",
      "|    explained_variance | 0.932      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0925    |\n",
      "|    mean_step_reward   | 0.02763228 |\n",
      "|    n_updates          | 84/128     |\n",
      "|    policyGradLoss     | -0.0201    |\n",
      "|    value_loss         | 0.188      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 245         |\n",
      "|    total_timesteps    | 55500800    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023079675 |\n",
      "|    entropy_loss       | -2.2        |\n",
      "|    explained_variance | 0.791       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0697     |\n",
      "|    mean_step_reward   | 0.028313601 |\n",
      "|    n_updates          | 88/128      |\n",
      "|    policyGradLoss     | -0.0125     |\n",
      "|    value_loss         | 0.321       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 256         |\n",
      "|    total_timesteps    | 55508992    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023024937 |\n",
      "|    entropy_loss       | -2.18       |\n",
      "|    explained_variance | 0.852       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0813     |\n",
      "|    mean_step_reward   | 0.021601902 |\n",
      "|    n_updates          | 92/128      |\n",
      "|    policyGradLoss     | -0.0185     |\n",
      "|    value_loss         | 0.34        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 266         |\n",
      "|    total_timesteps    | 55517184    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024192017 |\n",
      "|    entropy_loss       | -2.09       |\n",
      "|    explained_variance | 0.921       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0881     |\n",
      "|    mean_step_reward   | 0.0472223   |\n",
      "|    n_updates          | 96/128      |\n",
      "|    policyGradLoss     | -0.0194     |\n",
      "|    value_loss         | 0.223       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 277         |\n",
      "|    total_timesteps    | 55525376    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022657678 |\n",
      "|    entropy_loss       | -2.14       |\n",
      "|    explained_variance | 0.913       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0639     |\n",
      "|    mean_step_reward   | 0.0353813   |\n",
      "|    n_updates          | 100/128     |\n",
      "|    policyGradLoss     | -0.019      |\n",
      "|    value_loss         | 0.32        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 288         |\n",
      "|    total_timesteps    | 55533568    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020739926 |\n",
      "|    entropy_loss       | -2.16       |\n",
      "|    explained_variance | 0.915       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0787     |\n",
      "|    mean_step_reward   | 0.037553214 |\n",
      "|    n_updates          | 104/128     |\n",
      "|    policyGradLoss     | -0.0216     |\n",
      "|    value_loss         | 0.287       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 298         |\n",
      "|    total_timesteps    | 55541760    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028447483 |\n",
      "|    entropy_loss       | -2.16       |\n",
      "|    explained_variance | 0.903       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0303     |\n",
      "|    mean_step_reward   | 0.031818777 |\n",
      "|    n_updates          | 108/128     |\n",
      "|    policyGradLoss     | -0.0236     |\n",
      "|    value_loss         | 0.194       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 309         |\n",
      "|    total_timesteps    | 55549952    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020076815 |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.92        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0124      |\n",
      "|    mean_step_reward   | 0.030233568 |\n",
      "|    n_updates          | 112/128     |\n",
      "|    policyGradLoss     | -0.0198     |\n",
      "|    value_loss         | 0.307       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 320         |\n",
      "|    total_timesteps    | 55558144    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025896814 |\n",
      "|    entropy_loss       | -2.17       |\n",
      "|    explained_variance | 0.875       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0195      |\n",
      "|    mean_step_reward   | 0.03210772  |\n",
      "|    n_updates          | 116/128     |\n",
      "|    policyGradLoss     | -0.0144     |\n",
      "|    value_loss         | 0.306       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 331         |\n",
      "|    total_timesteps    | 55566336    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023026647 |\n",
      "|    entropy_loss       | -2.18       |\n",
      "|    explained_variance | 0.958       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0532     |\n",
      "|    mean_step_reward   | 0.04535155  |\n",
      "|    n_updates          | 120/128     |\n",
      "|    policyGradLoss     | -0.0214     |\n",
      "|    value_loss         | 0.205       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 341         |\n",
      "|    total_timesteps    | 55574528    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02098509  |\n",
      "|    entropy_loss       | -2.15       |\n",
      "|    explained_variance | 0.919       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.016      |\n",
      "|    mean_step_reward   | 0.029790865 |\n",
      "|    n_updates          | 124/128     |\n",
      "|    policyGradLoss     | -0.0174     |\n",
      "|    value_loss         | 0.358       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/NoArti_211.zip\n",
      "[EVAL] Mean Return: 85.119, Best Return: 87.319\n",
      "Saved video to ./runs_smw/videos/NoArti/NoArti_211_85.12.mp4\n",
      "\n",
      "=== Round 213 | Learn 262144 steps (Total trained: 55574528) ===\n",
      "Logging to ./runs_smw/tb/NoArti_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1067     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 55582720 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 891         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 55590912    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021776054 |\n",
      "|    entropy_loss       | -2.16       |\n",
      "|    explained_variance | 0.904       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0768     |\n",
      "|    mean_step_reward   | 0.026865112 |\n",
      "|    n_updates          | 4/128       |\n",
      "|    policyGradLoss     | -0.0126     |\n",
      "|    value_loss         | 0.315       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 836         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 29          |\n",
      "|    total_timesteps    | 55599104    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028294085 |\n",
      "|    entropy_loss       | -2.15       |\n",
      "|    explained_variance | 0.903       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0792     |\n",
      "|    mean_step_reward   | 0.029764244 |\n",
      "|    n_updates          | 8/128       |\n",
      "|    policyGradLoss     | -0.0211     |\n",
      "|    value_loss         | 0.264       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 814        |\n",
      "|    iterations         | 4          |\n",
      "|    time_elapsed       | 40         |\n",
      "|    total_timesteps    | 55607296   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02130521 |\n",
      "|    entropy_loss       | -2.18      |\n",
      "|    explained_variance | 0.907      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0847    |\n",
      "|    mean_step_reward   | 0.03668645 |\n",
      "|    n_updates          | 12/128     |\n",
      "|    policyGradLoss     | -0.0145    |\n",
      "|    value_loss         | 0.255      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 805         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 50          |\n",
      "|    total_timesteps    | 55615488    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.033064578 |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.919       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0933     |\n",
      "|    mean_step_reward   | 0.017955922 |\n",
      "|    n_updates          | 16/128      |\n",
      "|    policyGradLoss     | -0.0229     |\n",
      "|    value_loss         | 0.172       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 798         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 61          |\n",
      "|    total_timesteps    | 55623680    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019081533 |\n",
      "|    entropy_loss       | -2.16       |\n",
      "|    explained_variance | 0.945       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0366     |\n",
      "|    mean_step_reward   | 0.038411573 |\n",
      "|    n_updates          | 20/128      |\n",
      "|    policyGradLoss     | -0.0147     |\n",
      "|    value_loss         | 0.276       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 794         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 72          |\n",
      "|    total_timesteps    | 55631872    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021607976 |\n",
      "|    entropy_loss       | -2.17       |\n",
      "|    explained_variance | 0.911       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00841    |\n",
      "|    mean_step_reward   | 0.03737002  |\n",
      "|    n_updates          | 24/128      |\n",
      "|    policyGradLoss     | -0.0166     |\n",
      "|    value_loss         | 0.398       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 789         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 82          |\n",
      "|    total_timesteps    | 55640064    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025864432 |\n",
      "|    entropy_loss       | -2.17       |\n",
      "|    explained_variance | 0.916       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0961     |\n",
      "|    mean_step_reward   | 0.043069016 |\n",
      "|    n_updates          | 28/128      |\n",
      "|    policyGradLoss     | -0.0183     |\n",
      "|    value_loss         | 0.181       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 93          |\n",
      "|    total_timesteps    | 55648256    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023712581 |\n",
      "|    entropy_loss       | -2.09       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0834     |\n",
      "|    mean_step_reward   | 0.044616856 |\n",
      "|    n_updates          | 32/128      |\n",
      "|    policyGradLoss     | -0.0188     |\n",
      "|    value_loss         | 0.198       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 104         |\n",
      "|    total_timesteps    | 55656448    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026800252 |\n",
      "|    entropy_loss       | -2.15       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0865     |\n",
      "|    mean_step_reward   | 0.054147918 |\n",
      "|    n_updates          | 36/128      |\n",
      "|    policyGradLoss     | -0.024      |\n",
      "|    value_loss         | 0.16        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 115         |\n",
      "|    total_timesteps    | 55664640    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.031645842 |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.955       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.108      |\n",
      "|    mean_step_reward   | 0.030930988 |\n",
      "|    n_updates          | 40/128      |\n",
      "|    policyGradLoss     | -0.0209     |\n",
      "|    value_loss         | 0.0992      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 126         |\n",
      "|    total_timesteps    | 55672832    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02057043  |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.802       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0662     |\n",
      "|    mean_step_reward   | 0.017535243 |\n",
      "|    n_updates          | 44/128      |\n",
      "|    policyGradLoss     | -0.0147     |\n",
      "|    value_loss         | 0.329       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 137         |\n",
      "|    total_timesteps    | 55681024    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027258806 |\n",
      "|    entropy_loss       | -2.2        |\n",
      "|    explained_variance | 0.897       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0905     |\n",
      "|    mean_step_reward   | 0.026891205 |\n",
      "|    n_updates          | 48/128      |\n",
      "|    policyGradLoss     | -0.0144     |\n",
      "|    value_loss         | 0.241       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 148         |\n",
      "|    total_timesteps    | 55689216    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023824304 |\n",
      "|    entropy_loss       | -2.19       |\n",
      "|    explained_variance | 0.865       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0943     |\n",
      "|    mean_step_reward   | 0.02571641  |\n",
      "|    n_updates          | 52/128      |\n",
      "|    policyGradLoss     | -0.0148     |\n",
      "|    value_loss         | 0.185       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 771        |\n",
      "|    iterations         | 15         |\n",
      "|    time_elapsed       | 159        |\n",
      "|    total_timesteps    | 55697408   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02232501 |\n",
      "|    entropy_loss       | -2.2       |\n",
      "|    explained_variance | 0.956      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0783    |\n",
      "|    mean_step_reward   | 0.02548716 |\n",
      "|    n_updates          | 56/128     |\n",
      "|    policyGradLoss     | -0.0195    |\n",
      "|    value_loss         | 0.204      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 169         |\n",
      "|    total_timesteps    | 55705600    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024135193 |\n",
      "|    entropy_loss       | -2.16       |\n",
      "|    explained_variance | 0.85        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0496     |\n",
      "|    mean_step_reward   | 0.03152402  |\n",
      "|    n_updates          | 60/128      |\n",
      "|    policyGradLoss     | -0.0174     |\n",
      "|    value_loss         | 0.253       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 181         |\n",
      "|    total_timesteps    | 55713792    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030449267 |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.108      |\n",
      "|    mean_step_reward   | 0.044075627 |\n",
      "|    n_updates          | 64/128      |\n",
      "|    policyGradLoss     | -0.0225     |\n",
      "|    value_loss         | 0.0743      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 191         |\n",
      "|    total_timesteps    | 55721984    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022464614 |\n",
      "|    entropy_loss       | -2.3        |\n",
      "|    explained_variance | 0.923       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.117      |\n",
      "|    mean_step_reward   | 0.003844076 |\n",
      "|    n_updates          | 68/128      |\n",
      "|    policyGradLoss     | -0.019      |\n",
      "|    value_loss         | 0.0743      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 202         |\n",
      "|    total_timesteps    | 55730176    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016282082 |\n",
      "|    entropy_loss       | -2.27       |\n",
      "|    explained_variance | 0.755       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0837     |\n",
      "|    mean_step_reward   | 0.008206444 |\n",
      "|    n_updates          | 72/128      |\n",
      "|    policyGradLoss     | -0.0121     |\n",
      "|    value_loss         | 0.337       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 213         |\n",
      "|    total_timesteps    | 55738368    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022854485 |\n",
      "|    entropy_loss       | -2.29       |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0979     |\n",
      "|    mean_step_reward   | 0.019692242 |\n",
      "|    n_updates          | 76/128      |\n",
      "|    policyGradLoss     | -0.0171     |\n",
      "|    value_loss         | 0.0669      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 224         |\n",
      "|    total_timesteps    | 55746560    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018913109 |\n",
      "|    entropy_loss       | -2.29       |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.092      |\n",
      "|    mean_step_reward   | 0.0225922   |\n",
      "|    n_updates          | 80/128      |\n",
      "|    policyGradLoss     | -0.016      |\n",
      "|    value_loss         | 0.081       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 765         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 235         |\n",
      "|    total_timesteps    | 55754752    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030034201 |\n",
      "|    entropy_loss       | -2.18       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0998     |\n",
      "|    mean_step_reward   | 0.012283233 |\n",
      "|    n_updates          | 84/128      |\n",
      "|    policyGradLoss     | -0.0231     |\n",
      "|    value_loss         | 0.143       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 764         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 246         |\n",
      "|    total_timesteps    | 55762944    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019240018 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.943       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0872     |\n",
      "|    mean_step_reward   | 0.036412474 |\n",
      "|    n_updates          | 88/128      |\n",
      "|    policyGradLoss     | -0.0165     |\n",
      "|    value_loss         | 0.15        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 764         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 257         |\n",
      "|    total_timesteps    | 55771136    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021847982 |\n",
      "|    entropy_loss       | -2.27       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.11       |\n",
      "|    mean_step_reward   | 0.009402504 |\n",
      "|    n_updates          | 92/128      |\n",
      "|    policyGradLoss     | -0.0214     |\n",
      "|    value_loss         | 0.0483      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 764         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 267         |\n",
      "|    total_timesteps    | 55779328    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026277153 |\n",
      "|    entropy_loss       | -2.15       |\n",
      "|    explained_variance | 0.942       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0662     |\n",
      "|    mean_step_reward   | 0.037754767 |\n",
      "|    n_updates          | 96/128      |\n",
      "|    policyGradLoss     | -0.0157     |\n",
      "|    value_loss         | 0.293       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 764         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 278         |\n",
      "|    total_timesteps    | 55787520    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.035361726 |\n",
      "|    entropy_loss       | -2.18       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.107      |\n",
      "|    mean_step_reward   | 0.041947283 |\n",
      "|    n_updates          | 100/128     |\n",
      "|    policyGradLoss     | -0.0251     |\n",
      "|    value_loss         | 0.0691      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 764         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 289         |\n",
      "|    total_timesteps    | 55795712    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02507165  |\n",
      "|    entropy_loss       | -2.28       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0969     |\n",
      "|    mean_step_reward   | 0.019251363 |\n",
      "|    n_updates          | 104/128     |\n",
      "|    policyGradLoss     | -0.0172     |\n",
      "|    value_loss         | 0.0647      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 764          |\n",
      "|    iterations         | 28           |\n",
      "|    time_elapsed       | 300          |\n",
      "|    total_timesteps    | 55803904     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.025298184  |\n",
      "|    entropy_loss       | -2.3         |\n",
      "|    explained_variance | 0.98         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.117       |\n",
      "|    mean_step_reward   | 0.0069954256 |\n",
      "|    n_updates          | 108/128      |\n",
      "|    policyGradLoss     | -0.0252      |\n",
      "|    value_loss         | 0.0388       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 763         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 311         |\n",
      "|    total_timesteps    | 55812096    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028607164 |\n",
      "|    entropy_loss       | -2.31       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.113      |\n",
      "|    mean_step_reward   | 0.022647705 |\n",
      "|    n_updates          | 112/128     |\n",
      "|    policyGradLoss     | -0.0218     |\n",
      "|    value_loss         | 0.0363      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 763         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 321         |\n",
      "|    total_timesteps    | 55820288    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027237855 |\n",
      "|    entropy_loss       | -2.3        |\n",
      "|    explained_variance | 0.928       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.106      |\n",
      "|    mean_step_reward   | 0.010014807 |\n",
      "|    n_updates          | 116/128     |\n",
      "|    policyGradLoss     | -0.0161     |\n",
      "|    value_loss         | 0.097       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 764         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 332         |\n",
      "|    total_timesteps    | 55828480    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01842979  |\n",
      "|    entropy_loss       | -2.16       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.102      |\n",
      "|    mean_step_reward   | 0.024813592 |\n",
      "|    n_updates          | 120/128     |\n",
      "|    policyGradLoss     | -0.0193     |\n",
      "|    value_loss         | 0.0905      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 764         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 343         |\n",
      "|    total_timesteps    | 55836672    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018681277 |\n",
      "|    entropy_loss       | -2.15       |\n",
      "|    explained_variance | 0.867       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.044      |\n",
      "|    mean_step_reward   | 0.046923287 |\n",
      "|    n_updates          | 124/128     |\n",
      "|    policyGradLoss     | -0.0116     |\n",
      "|    value_loss         | 0.567       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/NoArti_212.zip\n",
      "[EVAL] Mean Return: 124.869, Best Return: 127.469\n",
      "Saved video to ./runs_smw/videos/NoArti/NoArti_212_124.87.mp4\n",
      "\n",
      "=== Round 214 | Learn 262144 steps (Total trained: 55836672) ===\n",
      "Logging to ./runs_smw/tb/NoArti_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1112     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 55844864 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 889         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 55853056    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.031205764 |\n",
      "|    entropy_loss       | -2.27       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.11       |\n",
      "|    mean_step_reward   | 0.020363534 |\n",
      "|    n_updates          | 4/128       |\n",
      "|    policyGradLoss     | -0.0201     |\n",
      "|    value_loss         | 0.0536      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 835         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 29          |\n",
      "|    total_timesteps    | 55861248    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02069364  |\n",
      "|    entropy_loss       | -2.31       |\n",
      "|    explained_variance | 0.926       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0595     |\n",
      "|    mean_step_reward   | 0.020262234 |\n",
      "|    n_updates          | 8/128       |\n",
      "|    policyGradLoss     | -0.0117     |\n",
      "|    value_loss         | 0.183       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 816         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 40          |\n",
      "|    total_timesteps    | 55869440    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023319267 |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.951       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.093      |\n",
      "|    mean_step_reward   | 0.015793    |\n",
      "|    n_updates          | 12/128      |\n",
      "|    policyGradLoss     | -0.0164     |\n",
      "|    value_loss         | 0.136       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 804         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 50          |\n",
      "|    total_timesteps    | 55877632    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016746785 |\n",
      "|    entropy_loss       | -2.14       |\n",
      "|    explained_variance | 0.945       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0396     |\n",
      "|    mean_step_reward   | 0.035312057 |\n",
      "|    n_updates          | 16/128      |\n",
      "|    policyGradLoss     | -0.0164     |\n",
      "|    value_loss         | 0.396       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 794         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 61          |\n",
      "|    total_timesteps    | 55885824    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027272724 |\n",
      "|    entropy_loss       | -2.09       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0751     |\n",
      "|    mean_step_reward   | 0.04652535  |\n",
      "|    n_updates          | 20/128      |\n",
      "|    policyGradLoss     | -0.0248     |\n",
      "|    value_loss         | 0.151       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 792         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 72          |\n",
      "|    total_timesteps    | 55894016    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026434831 |\n",
      "|    entropy_loss       | -2.11       |\n",
      "|    explained_variance | 0.921       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.054      |\n",
      "|    mean_step_reward   | 0.031896733 |\n",
      "|    n_updates          | 24/128      |\n",
      "|    policyGradLoss     | -0.0184     |\n",
      "|    value_loss         | 0.343       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 788         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 83          |\n",
      "|    total_timesteps    | 55902208    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026432626 |\n",
      "|    entropy_loss       | -2.16       |\n",
      "|    explained_variance | 0.949       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0924     |\n",
      "|    mean_step_reward   | 0.05028002  |\n",
      "|    n_updates          | 28/128      |\n",
      "|    policyGradLoss     | -0.0214     |\n",
      "|    value_loss         | 0.192       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 94          |\n",
      "|    total_timesteps    | 55910400    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018619213 |\n",
      "|    entropy_loss       | -2.16       |\n",
      "|    explained_variance | 0.757       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0562     |\n",
      "|    mean_step_reward   | 0.03039059  |\n",
      "|    n_updates          | 32/128      |\n",
      "|    policyGradLoss     | -0.00909    |\n",
      "|    value_loss         | 0.551       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 104         |\n",
      "|    total_timesteps    | 55918592    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019682476 |\n",
      "|    entropy_loss       | -2.17       |\n",
      "|    explained_variance | 0.957       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0866     |\n",
      "|    mean_step_reward   | 0.047363695 |\n",
      "|    n_updates          | 36/128      |\n",
      "|    policyGradLoss     | -0.0186     |\n",
      "|    value_loss         | 0.152       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 115         |\n",
      "|    total_timesteps    | 55926784    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.031030584 |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.101      |\n",
      "|    mean_step_reward   | 0.026508544 |\n",
      "|    n_updates          | 40/128      |\n",
      "|    policyGradLoss     | -0.0204     |\n",
      "|    value_loss         | 0.0903      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 126         |\n",
      "|    total_timesteps    | 55934976    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021447873 |\n",
      "|    entropy_loss       | -2.31       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0767     |\n",
      "|    mean_step_reward   | 0.012931243 |\n",
      "|    n_updates          | 44/128      |\n",
      "|    policyGradLoss     | -0.0225     |\n",
      "|    value_loss         | 0.0466      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 137         |\n",
      "|    total_timesteps    | 55943168    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022740275 |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0746     |\n",
      "|    mean_step_reward   | 0.018869046 |\n",
      "|    n_updates          | 48/128      |\n",
      "|    policyGradLoss     | -0.0175     |\n",
      "|    value_loss         | 0.167       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 148         |\n",
      "|    total_timesteps    | 55951360    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023473192 |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.114      |\n",
      "|    mean_step_reward   | 0.030689932 |\n",
      "|    n_updates          | 52/128      |\n",
      "|    policyGradLoss     | -0.02       |\n",
      "|    value_loss         | 0.0602      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 159         |\n",
      "|    total_timesteps    | 55959552    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029113999 |\n",
      "|    entropy_loss       | -2.2        |\n",
      "|    explained_variance | 0.932       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0841     |\n",
      "|    mean_step_reward   | 0.018459337 |\n",
      "|    n_updates          | 56/128      |\n",
      "|    policyGradLoss     | -0.0149     |\n",
      "|    value_loss         | 0.231       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 170         |\n",
      "|    total_timesteps    | 55967744    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027658239 |\n",
      "|    entropy_loss       | -2.15       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0959     |\n",
      "|    mean_step_reward   | 0.044201594 |\n",
      "|    n_updates          | 60/128      |\n",
      "|    policyGradLoss     | -0.0163     |\n",
      "|    value_loss         | 0.251       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 180         |\n",
      "|    total_timesteps    | 55975936    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030226462 |\n",
      "|    entropy_loss       | -2.2        |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0916     |\n",
      "|    mean_step_reward   | 0.038548704 |\n",
      "|    n_updates          | 64/128      |\n",
      "|    policyGradLoss     | -0.0207     |\n",
      "|    value_loss         | 0.113       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 191         |\n",
      "|    total_timesteps    | 55984128    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.03143218  |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.957       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.106      |\n",
      "|    mean_step_reward   | 0.025462544 |\n",
      "|    n_updates          | 68/128      |\n",
      "|    policyGradLoss     | -0.0188     |\n",
      "|    value_loss         | 0.118       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 768          |\n",
      "|    iterations         | 19           |\n",
      "|    time_elapsed       | 202          |\n",
      "|    total_timesteps    | 55992320     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.016716206  |\n",
      "|    entropy_loss       | -2.29        |\n",
      "|    explained_variance | 0.894        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0949      |\n",
      "|    mean_step_reward   | 0.0074432017 |\n",
      "|    n_updates          | 72/128       |\n",
      "|    policyGradLoss     | -0.0117      |\n",
      "|    value_loss         | 0.231        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 213         |\n",
      "|    total_timesteps    | 56000512    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030322125 |\n",
      "|    entropy_loss       | -2.18       |\n",
      "|    explained_variance | 0.935       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0326     |\n",
      "|    mean_step_reward   | 0.027190346 |\n",
      "|    n_updates          | 76/128      |\n",
      "|    policyGradLoss     | -0.0152     |\n",
      "|    value_loss         | 0.233       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 767        |\n",
      "|    iterations         | 21         |\n",
      "|    time_elapsed       | 224        |\n",
      "|    total_timesteps    | 56008704   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03253881 |\n",
      "|    entropy_loss       | -2.17      |\n",
      "|    explained_variance | 0.974      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.104     |\n",
      "|    mean_step_reward   | 0.03945706 |\n",
      "|    n_updates          | 80/128     |\n",
      "|    policyGradLoss     | -0.0232    |\n",
      "|    value_loss         | 0.107      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 234         |\n",
      "|    total_timesteps    | 56016896    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023556504 |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.941       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.1        |\n",
      "|    mean_step_reward   | 0.023919081 |\n",
      "|    n_updates          | 84/128      |\n",
      "|    policyGradLoss     | -0.0184     |\n",
      "|    value_loss         | 0.137       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 245         |\n",
      "|    total_timesteps    | 56025088    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022390183 |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.089      |\n",
      "|    mean_step_reward   | 0.025078312 |\n",
      "|    n_updates          | 88/128      |\n",
      "|    policyGradLoss     | -0.0156     |\n",
      "|    value_loss         | 0.175       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 256         |\n",
      "|    total_timesteps    | 56033280    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016780863 |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.865       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0371     |\n",
      "|    mean_step_reward   | 0.02626291  |\n",
      "|    n_updates          | 92/128      |\n",
      "|    policyGradLoss     | -0.015      |\n",
      "|    value_loss         | 0.274       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 267         |\n",
      "|    total_timesteps    | 56041472    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01433756  |\n",
      "|    entropy_loss       | -2.3        |\n",
      "|    explained_variance | 0.927       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0933     |\n",
      "|    mean_step_reward   | 0.020418879 |\n",
      "|    n_updates          | 96/128      |\n",
      "|    policyGradLoss     | -0.0149     |\n",
      "|    value_loss         | 0.176       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 765          |\n",
      "|    iterations         | 26           |\n",
      "|    time_elapsed       | 278          |\n",
      "|    total_timesteps    | 56049664     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0231834    |\n",
      "|    entropy_loss       | -2.24        |\n",
      "|    explained_variance | 0.948        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0937      |\n",
      "|    mean_step_reward   | 0.0038623274 |\n",
      "|    n_updates          | 100/128      |\n",
      "|    policyGradLoss     | -0.0179      |\n",
      "|    value_loss         | 0.141        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 764         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 289         |\n",
      "|    total_timesteps    | 56057856    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016694184 |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.896       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0626     |\n",
      "|    mean_step_reward   | 0.051014148 |\n",
      "|    n_updates          | 104/128     |\n",
      "|    policyGradLoss     | -0.0111     |\n",
      "|    value_loss         | 0.332       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 764         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 300         |\n",
      "|    total_timesteps    | 56066048    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017272044 |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.856       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0742     |\n",
      "|    mean_step_reward   | 0.0170275   |\n",
      "|    n_updates          | 108/128     |\n",
      "|    policyGradLoss     | -0.0122     |\n",
      "|    value_loss         | 0.314       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 763         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 311         |\n",
      "|    total_timesteps    | 56074240    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01848672  |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.932       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00186     |\n",
      "|    mean_step_reward   | 0.016792618 |\n",
      "|    n_updates          | 112/128     |\n",
      "|    policyGradLoss     | -0.0173     |\n",
      "|    value_loss         | 0.247       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 763         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 321         |\n",
      "|    total_timesteps    | 56082432    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020814193 |\n",
      "|    entropy_loss       | -2.2        |\n",
      "|    explained_variance | 0.881       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0756     |\n",
      "|    mean_step_reward   | 0.020418081 |\n",
      "|    n_updates          | 116/128     |\n",
      "|    policyGradLoss     | -0.0186     |\n",
      "|    value_loss         | 0.214       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 763         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 332         |\n",
      "|    total_timesteps    | 56090624    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019655852 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.916       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0786     |\n",
      "|    mean_step_reward   | 0.03514018  |\n",
      "|    n_updates          | 120/128     |\n",
      "|    policyGradLoss     | -0.0177     |\n",
      "|    value_loss         | 0.262       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 763         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 343         |\n",
      "|    total_timesteps    | 56098816    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017417708 |\n",
      "|    entropy_loss       | -2.29       |\n",
      "|    explained_variance | 0.902       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0651     |\n",
      "|    mean_step_reward   | 0.015952103 |\n",
      "|    n_updates          | 124/128     |\n",
      "|    policyGradLoss     | -0.0136     |\n",
      "|    value_loss         | 0.228       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/NoArti_213.zip\n",
      "[EVAL] Mean Return: -6.346, Best Return: -6.146\n",
      "Saved video to ./runs_smw/videos/NoArti/NoArti_213_-6.35.mp4\n",
      "\n",
      "=== Round 215 | Learn 262144 steps (Total trained: 56098816) ===\n",
      "Logging to ./runs_smw/tb/NoArti_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1122     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 56107008 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 906         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 56115200    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019846871 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.935       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0371     |\n",
      "|    mean_step_reward   | 0.009816977 |\n",
      "|    n_updates          | 4/128       |\n",
      "|    policyGradLoss     | -0.0179     |\n",
      "|    value_loss         | 0.292       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 854         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 56123392    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02179135  |\n",
      "|    entropy_loss       | -2.17       |\n",
      "|    explained_variance | 0.915       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0738     |\n",
      "|    mean_step_reward   | 0.022091579 |\n",
      "|    n_updates          | 8/128       |\n",
      "|    policyGradLoss     | -0.0181     |\n",
      "|    value_loss         | 0.224       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 835         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 56131584    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027818674 |\n",
      "|    entropy_loss       | -2.15       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.109      |\n",
      "|    mean_step_reward   | 0.061349023 |\n",
      "|    n_updates          | 12/128      |\n",
      "|    policyGradLoss     | -0.0215     |\n",
      "|    value_loss         | 0.111       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 810         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 50          |\n",
      "|    total_timesteps    | 56139776    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02649274  |\n",
      "|    entropy_loss       | -2.3        |\n",
      "|    explained_variance | 0.87        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.067      |\n",
      "|    mean_step_reward   | 0.010842734 |\n",
      "|    n_updates          | 16/128      |\n",
      "|    policyGradLoss     | -0.0123     |\n",
      "|    value_loss         | 0.223       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 798         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 61          |\n",
      "|    total_timesteps    | 56147968    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023555944 |\n",
      "|    entropy_loss       | -2.31       |\n",
      "|    explained_variance | 0.917       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0988     |\n",
      "|    mean_step_reward   | 0.01525062  |\n",
      "|    n_updates          | 20/128      |\n",
      "|    policyGradLoss     | -0.0177     |\n",
      "|    value_loss         | 0.128       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 795          |\n",
      "|    iterations         | 7            |\n",
      "|    time_elapsed       | 72           |\n",
      "|    total_timesteps    | 56156160     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.017244749  |\n",
      "|    entropy_loss       | -2.28        |\n",
      "|    explained_variance | 0.938        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.00479     |\n",
      "|    mean_step_reward   | 0.0014463919 |\n",
      "|    n_updates          | 24/128       |\n",
      "|    policyGradLoss     | -0.0154      |\n",
      "|    value_loss         | 0.271        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 791         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 82          |\n",
      "|    total_timesteps    | 56164352    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024250958 |\n",
      "|    entropy_loss       | -2.15       |\n",
      "|    explained_variance | 0.891       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0727     |\n",
      "|    mean_step_reward   | 0.036281653 |\n",
      "|    n_updates          | 28/128      |\n",
      "|    policyGradLoss     | -0.0127     |\n",
      "|    value_loss         | 0.392       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 93          |\n",
      "|    total_timesteps    | 56172544    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020224458 |\n",
      "|    entropy_loss       | -2.15       |\n",
      "|    explained_variance | 0.952       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.092      |\n",
      "|    mean_step_reward   | 0.048499275 |\n",
      "|    n_updates          | 32/128      |\n",
      "|    policyGradLoss     | -0.0199     |\n",
      "|    value_loss         | 0.274       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 104         |\n",
      "|    total_timesteps    | 56180736    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025424898 |\n",
      "|    entropy_loss       | -2.18       |\n",
      "|    explained_variance | 0.955       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0909     |\n",
      "|    mean_step_reward   | 0.042764485 |\n",
      "|    n_updates          | 36/128      |\n",
      "|    policyGradLoss     | -0.0203     |\n",
      "|    value_loss         | 0.204       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 115         |\n",
      "|    total_timesteps    | 56188928    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.03332843  |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.113      |\n",
      "|    mean_step_reward   | 0.038303416 |\n",
      "|    n_updates          | 40/128      |\n",
      "|    policyGradLoss     | -0.0223     |\n",
      "|    value_loss         | 0.0698      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 125         |\n",
      "|    total_timesteps    | 56197120    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029542113 |\n",
      "|    entropy_loss       | -2.36       |\n",
      "|    explained_variance | 0.9         |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.109      |\n",
      "|    mean_step_reward   | 0.006513286 |\n",
      "|    n_updates          | 44/128      |\n",
      "|    policyGradLoss     | -0.017      |\n",
      "|    value_loss         | 0.0739      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 779           |\n",
      "|    iterations         | 13            |\n",
      "|    time_elapsed       | 136           |\n",
      "|    total_timesteps    | 56205312      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.021461785   |\n",
      "|    entropy_loss       | -2.36         |\n",
      "|    explained_variance | 0.895         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.107        |\n",
      "|    mean_step_reward   | -0.0016059084 |\n",
      "|    n_updates          | 48/128        |\n",
      "|    policyGradLoss     | -0.0135       |\n",
      "|    value_loss         | 0.087         |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 147         |\n",
      "|    total_timesteps    | 56213504    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023603607 |\n",
      "|    entropy_loss       | -2.28       |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0541     |\n",
      "|    mean_step_reward   | 0.009408098 |\n",
      "|    n_updates          | 52/128      |\n",
      "|    policyGradLoss     | -0.0177     |\n",
      "|    value_loss         | 0.148       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 158         |\n",
      "|    total_timesteps    | 56221696    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027022121 |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.112      |\n",
      "|    mean_step_reward   | 0.017379435 |\n",
      "|    n_updates          | 56/128      |\n",
      "|    policyGradLoss     | -0.0249     |\n",
      "|    value_loss         | 0.123       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 168         |\n",
      "|    total_timesteps    | 56229888    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021254115 |\n",
      "|    entropy_loss       | -2.2        |\n",
      "|    explained_variance | 0.943       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0366     |\n",
      "|    mean_step_reward   | 0.028316848 |\n",
      "|    n_updates          | 60/128      |\n",
      "|    policyGradLoss     | -0.0172     |\n",
      "|    value_loss         | 0.342       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 179         |\n",
      "|    total_timesteps    | 56238080    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019554902 |\n",
      "|    entropy_loss       | -2.2        |\n",
      "|    explained_variance | 0.834       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0908     |\n",
      "|    mean_step_reward   | 0.023146303 |\n",
      "|    n_updates          | 64/128      |\n",
      "|    policyGradLoss     | -0.017      |\n",
      "|    value_loss         | 0.246       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 190         |\n",
      "|    total_timesteps    | 56246272    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.034107137 |\n",
      "|    entropy_loss       | -2.27       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.101      |\n",
      "|    mean_step_reward   | 0.034512527 |\n",
      "|    n_updates          | 68/128      |\n",
      "|    policyGradLoss     | -0.018      |\n",
      "|    value_loss         | 0.0557      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 201         |\n",
      "|    total_timesteps    | 56254464    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023856446 |\n",
      "|    entropy_loss       | -2.28       |\n",
      "|    explained_variance | 0.943       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0815     |\n",
      "|    mean_step_reward   | 0.01666073  |\n",
      "|    n_updates          | 72/128      |\n",
      "|    policyGradLoss     | -0.0175     |\n",
      "|    value_loss         | 0.109       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 211         |\n",
      "|    total_timesteps    | 56262656    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024449239 |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0828     |\n",
      "|    mean_step_reward   | 0.02421258  |\n",
      "|    n_updates          | 76/128      |\n",
      "|    policyGradLoss     | -0.0157     |\n",
      "|    value_loss         | 0.193       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 222         |\n",
      "|    total_timesteps    | 56270848    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026572444 |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.113      |\n",
      "|    mean_step_reward   | 0.023264803 |\n",
      "|    n_updates          | 80/128      |\n",
      "|    policyGradLoss     | -0.0238     |\n",
      "|    value_loss         | 0.0549      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 233         |\n",
      "|    total_timesteps    | 56279040    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023273982 |\n",
      "|    entropy_loss       | -2.29       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.102      |\n",
      "|    mean_step_reward   | 0.016585236 |\n",
      "|    n_updates          | 84/128      |\n",
      "|    policyGradLoss     | -0.0181     |\n",
      "|    value_loss         | 0.0448      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 244         |\n",
      "|    total_timesteps    | 56287232    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02750705  |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0889     |\n",
      "|    mean_step_reward   | 0.017597163 |\n",
      "|    n_updates          | 88/128      |\n",
      "|    policyGradLoss     | -0.0134     |\n",
      "|    value_loss         | 0.123       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 255         |\n",
      "|    total_timesteps    | 56295424    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02341015  |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0939     |\n",
      "|    mean_step_reward   | 0.023443863 |\n",
      "|    n_updates          | 92/128      |\n",
      "|    policyGradLoss     | -0.0173     |\n",
      "|    value_loss         | 0.0965      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 265         |\n",
      "|    total_timesteps    | 56303616    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028829642 |\n",
      "|    entropy_loss       | -2.32       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.112      |\n",
      "|    mean_step_reward   | 0.004158065 |\n",
      "|    n_updates          | 96/128      |\n",
      "|    policyGradLoss     | -0.0202     |\n",
      "|    value_loss         | 0.0316      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 277         |\n",
      "|    total_timesteps    | 56311808    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.031472478 |\n",
      "|    entropy_loss       | -2.3        |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.117      |\n",
      "|    mean_step_reward   | 0.017113    |\n",
      "|    n_updates          | 100/128     |\n",
      "|    policyGradLoss     | -0.0233     |\n",
      "|    value_loss         | 0.0323      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 288         |\n",
      "|    total_timesteps    | 56320000    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029093962 |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0847     |\n",
      "|    mean_step_reward   | 0.016784597 |\n",
      "|    n_updates          | 104/128     |\n",
      "|    policyGradLoss     | -0.0211     |\n",
      "|    value_loss         | 0.0811      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 299         |\n",
      "|    total_timesteps    | 56328192    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.03274879  |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.114      |\n",
      "|    mean_step_reward   | 0.025148952 |\n",
      "|    n_updates          | 108/128     |\n",
      "|    policyGradLoss     | -0.0223     |\n",
      "|    value_loss         | 0.0755      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 309         |\n",
      "|    total_timesteps    | 56336384    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016826198 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.957       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0887     |\n",
      "|    mean_step_reward   | 0.02182934  |\n",
      "|    n_updates          | 112/128     |\n",
      "|    policyGradLoss     | -0.0167     |\n",
      "|    value_loss         | 0.141       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 320         |\n",
      "|    total_timesteps    | 56344576    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029579561 |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.102      |\n",
      "|    mean_step_reward   | 0.025218237 |\n",
      "|    n_updates          | 116/128     |\n",
      "|    policyGradLoss     | -0.022      |\n",
      "|    value_loss         | 0.0737      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 331         |\n",
      "|    total_timesteps    | 56352768    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02914681  |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.117      |\n",
      "|    mean_step_reward   | 0.035689786 |\n",
      "|    n_updates          | 120/128     |\n",
      "|    policyGradLoss     | -0.0243     |\n",
      "|    value_loss         | 0.0483      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 765         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 342         |\n",
      "|    total_timesteps    | 56360960    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030936636 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0993     |\n",
      "|    mean_step_reward   | 0.022738565 |\n",
      "|    n_updates          | 124/128     |\n",
      "|    policyGradLoss     | -0.0213     |\n",
      "|    value_loss         | 0.106       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/NoArti_214.zip\n",
      "[EVAL] Mean Return: 90.364, Best Return: 92.364\n",
      "Saved video to ./runs_smw/videos/NoArti/NoArti_214_90.36.mp4\n",
      "\n",
      "=== Round 216 | Learn 262144 steps (Total trained: 56360960) ===\n",
      "Logging to ./runs_smw/tb/NoArti_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1091     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 56369152 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 875         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 56377344    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020892035 |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.104      |\n",
      "|    mean_step_reward   | 0.022954151 |\n",
      "|    n_updates          | 4/128       |\n",
      "|    policyGradLoss     | -0.0178     |\n",
      "|    value_loss         | 0.112       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 829         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 29          |\n",
      "|    total_timesteps    | 56385536    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025622673 |\n",
      "|    entropy_loss       | -2.27       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.107      |\n",
      "|    mean_step_reward   | 0.011915196 |\n",
      "|    n_updates          | 8/128       |\n",
      "|    policyGradLoss     | -0.023      |\n",
      "|    value_loss         | 0.0469      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 817         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 40          |\n",
      "|    total_timesteps    | 56393728    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020144748 |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.936       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0463     |\n",
      "|    mean_step_reward   | 0.019570377 |\n",
      "|    n_updates          | 12/128      |\n",
      "|    policyGradLoss     | -0.0128     |\n",
      "|    value_loss         | 0.236       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 807         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 50          |\n",
      "|    total_timesteps    | 56401920    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021455433 |\n",
      "|    entropy_loss       | -2.15       |\n",
      "|    explained_variance | 0.947       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0881     |\n",
      "|    mean_step_reward   | 0.040905558 |\n",
      "|    n_updates          | 16/128      |\n",
      "|    policyGradLoss     | -0.0122     |\n",
      "|    value_loss         | 0.18        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 800         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 61          |\n",
      "|    total_timesteps    | 56410112    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027969953 |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0927     |\n",
      "|    mean_step_reward   | 0.027942643 |\n",
      "|    n_updates          | 20/128      |\n",
      "|    policyGradLoss     | -0.0192     |\n",
      "|    value_loss         | 0.116       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 791         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 72          |\n",
      "|    total_timesteps    | 56418304    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027933948 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.923       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.106      |\n",
      "|    mean_step_reward   | 0.018334009 |\n",
      "|    n_updates          | 24/128      |\n",
      "|    policyGradLoss     | -0.0153     |\n",
      "|    value_loss         | 0.168       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 788         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 83          |\n",
      "|    total_timesteps    | 56426496    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026260618 |\n",
      "|    entropy_loss       | -2.31       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.106      |\n",
      "|    mean_step_reward   | 0.020418536 |\n",
      "|    n_updates          | 28/128      |\n",
      "|    policyGradLoss     | -0.0162     |\n",
      "|    value_loss         | 0.0633      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 94          |\n",
      "|    total_timesteps    | 56434688    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02136714  |\n",
      "|    entropy_loss       | -2.31       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.107      |\n",
      "|    mean_step_reward   | 0.010901968 |\n",
      "|    n_updates          | 32/128      |\n",
      "|    policyGradLoss     | -0.0183     |\n",
      "|    value_loss         | 0.0566      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 105         |\n",
      "|    total_timesteps    | 56442880    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026714526 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.107      |\n",
      "|    mean_step_reward   | 0.023822017 |\n",
      "|    n_updates          | 36/128      |\n",
      "|    policyGradLoss     | -0.024      |\n",
      "|    value_loss         | 0.0563      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 116         |\n",
      "|    total_timesteps    | 56451072    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015035029 |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.929       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0825     |\n",
      "|    mean_step_reward   | 0.023917705 |\n",
      "|    n_updates          | 40/128      |\n",
      "|    policyGradLoss     | -0.0136     |\n",
      "|    value_loss         | 0.208       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 126         |\n",
      "|    total_timesteps    | 56459264    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027143579 |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0829     |\n",
      "|    mean_step_reward   | 0.032315377 |\n",
      "|    n_updates          | 44/128      |\n",
      "|    policyGradLoss     | -0.0222     |\n",
      "|    value_loss         | 0.0987      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 137         |\n",
      "|    total_timesteps    | 56467456    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021149611 |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0484     |\n",
      "|    mean_step_reward   | 0.026247064 |\n",
      "|    n_updates          | 48/128      |\n",
      "|    policyGradLoss     | -0.0157     |\n",
      "|    value_loss         | 0.197       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 148         |\n",
      "|    total_timesteps    | 56475648    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.0239393   |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.101      |\n",
      "|    mean_step_reward   | 0.030945837 |\n",
      "|    n_updates          | 52/128      |\n",
      "|    policyGradLoss     | -0.0149     |\n",
      "|    value_loss         | 0.145       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 159         |\n",
      "|    total_timesteps    | 56483840    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026547102 |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.119      |\n",
      "|    mean_step_reward   | 0.018224163 |\n",
      "|    n_updates          | 56/128      |\n",
      "|    policyGradLoss     | -0.0235     |\n",
      "|    value_loss         | 0.0423      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 169         |\n",
      "|    total_timesteps    | 56492032    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025154289 |\n",
      "|    entropy_loss       | -2.32       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.105      |\n",
      "|    mean_step_reward   | 0.014516491 |\n",
      "|    n_updates          | 60/128      |\n",
      "|    policyGradLoss     | -0.0202     |\n",
      "|    value_loss         | 0.0748      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 180         |\n",
      "|    total_timesteps    | 56500224    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018868143 |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0212     |\n",
      "|    mean_step_reward   | 0.013045417 |\n",
      "|    n_updates          | 64/128      |\n",
      "|    policyGradLoss     | -0.0178     |\n",
      "|    value_loss         | 0.212       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 772        |\n",
      "|    iterations         | 18         |\n",
      "|    time_elapsed       | 190        |\n",
      "|    total_timesteps    | 56508416   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02681171 |\n",
      "|    entropy_loss       | -2.22      |\n",
      "|    explained_variance | 0.981      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.118     |\n",
      "|    mean_step_reward   | 0.03891199 |\n",
      "|    n_updates          | 68/128     |\n",
      "|    policyGradLoss     | -0.0229    |\n",
      "|    value_loss         | 0.0565     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 201         |\n",
      "|    total_timesteps    | 56516608    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022389218 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0898     |\n",
      "|    mean_step_reward   | 0.013699273 |\n",
      "|    n_updates          | 72/128      |\n",
      "|    policyGradLoss     | -0.0201     |\n",
      "|    value_loss         | 0.137       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 212         |\n",
      "|    total_timesteps    | 56524800    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026191708 |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.95        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0876     |\n",
      "|    mean_step_reward   | 0.014505643 |\n",
      "|    n_updates          | 76/128      |\n",
      "|    policyGradLoss     | -0.0184     |\n",
      "|    value_loss         | 0.17        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 223         |\n",
      "|    total_timesteps    | 56532992    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02445984  |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.94        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0697     |\n",
      "|    mean_step_reward   | 0.015735386 |\n",
      "|    n_updates          | 80/128      |\n",
      "|    policyGradLoss     | -0.0208     |\n",
      "|    value_loss         | 0.171       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 770        |\n",
      "|    iterations         | 22         |\n",
      "|    time_elapsed       | 233        |\n",
      "|    total_timesteps    | 56541184   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03205028 |\n",
      "|    entropy_loss       | -2.24      |\n",
      "|    explained_variance | 0.973      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.126     |\n",
      "|    mean_step_reward   | 0.02882275 |\n",
      "|    n_updates          | 84/128     |\n",
      "|    policyGradLoss     | -0.0268    |\n",
      "|    value_loss         | 0.0552     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 244         |\n",
      "|    total_timesteps    | 56549376    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01624496  |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.918       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.11       |\n",
      "|    mean_step_reward   | 0.023734445 |\n",
      "|    n_updates          | 88/128      |\n",
      "|    policyGradLoss     | -0.0219     |\n",
      "|    value_loss         | 0.21        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 770          |\n",
      "|    iterations         | 24           |\n",
      "|    time_elapsed       | 255          |\n",
      "|    total_timesteps    | 56557568     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.019854715  |\n",
      "|    entropy_loss       | -2.26        |\n",
      "|    explained_variance | 0.885        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0994      |\n",
      "|    mean_step_reward   | 0.0140694175 |\n",
      "|    n_updates          | 92/128       |\n",
      "|    policyGradLoss     | -0.0197      |\n",
      "|    value_loss         | 0.221        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 770           |\n",
      "|    iterations         | 25            |\n",
      "|    time_elapsed       | 265           |\n",
      "|    total_timesteps    | 56565760      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.021521032   |\n",
      "|    entropy_loss       | -2.27         |\n",
      "|    explained_variance | 0.812         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0978       |\n",
      "|    mean_step_reward   | 0.00031564315 |\n",
      "|    n_updates          | 96/128        |\n",
      "|    policyGradLoss     | -0.0152       |\n",
      "|    value_loss         | 0.264         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 770          |\n",
      "|    iterations         | 26           |\n",
      "|    time_elapsed       | 276          |\n",
      "|    total_timesteps    | 56573952     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.02190566   |\n",
      "|    entropy_loss       | -2.26        |\n",
      "|    explained_variance | 0.853        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.1         |\n",
      "|    mean_step_reward   | 0.0065403236 |\n",
      "|    n_updates          | 100/128      |\n",
      "|    policyGradLoss     | -0.0218      |\n",
      "|    value_loss         | 0.212        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 287         |\n",
      "|    total_timesteps    | 56582144    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020750768 |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.761       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0701     |\n",
      "|    mean_step_reward   | 0.031230986 |\n",
      "|    n_updates          | 104/128     |\n",
      "|    policyGradLoss     | -0.0147     |\n",
      "|    value_loss         | 0.297       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 297         |\n",
      "|    total_timesteps    | 56590336    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016505059 |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.819       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0728     |\n",
      "|    mean_step_reward   | 0.015173657 |\n",
      "|    n_updates          | 108/128     |\n",
      "|    policyGradLoss     | -0.0123     |\n",
      "|    value_loss         | 0.38        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 308         |\n",
      "|    total_timesteps    | 56598528    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014938923 |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.88        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0444     |\n",
      "|    mean_step_reward   | 0.021327164 |\n",
      "|    n_updates          | 112/128     |\n",
      "|    policyGradLoss     | -0.0137     |\n",
      "|    value_loss         | 0.25        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 319         |\n",
      "|    total_timesteps    | 56606720    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02696528  |\n",
      "|    entropy_loss       | -2.28       |\n",
      "|    explained_variance | 0.945       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.114      |\n",
      "|    mean_step_reward   | 0.019355668 |\n",
      "|    n_updates          | 116/128     |\n",
      "|    policyGradLoss     | -0.0224     |\n",
      "|    value_loss         | 0.035       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 768          |\n",
      "|    iterations         | 31           |\n",
      "|    time_elapsed       | 330          |\n",
      "|    total_timesteps    | 56614912     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.013550663  |\n",
      "|    entropy_loss       | -2.31        |\n",
      "|    explained_variance | 0.841        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0849      |\n",
      "|    mean_step_reward   | 0.0072256015 |\n",
      "|    n_updates          | 120/128      |\n",
      "|    policyGradLoss     | -0.0111      |\n",
      "|    value_loss         | 0.274        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 341         |\n",
      "|    total_timesteps    | 56623104    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021104489 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.859       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0255      |\n",
      "|    mean_step_reward   | 0.0155659   |\n",
      "|    n_updates          | 124/128     |\n",
      "|    policyGradLoss     | -0.0123     |\n",
      "|    value_loss         | 0.484       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/NoArti_215.zip\n",
      "[EVAL] Mean Return: 88.132, Best Return: 90.332\n",
      "Saved video to ./runs_smw/videos/NoArti/NoArti_215_88.13.mp4\n",
      "\n",
      "=== Round 217 | Learn 262144 steps (Total trained: 56623104) ===\n",
      "Logging to ./runs_smw/tb/NoArti_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1144     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 56631296 |\n",
      "---------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 899        |\n",
      "|    iterations         | 2          |\n",
      "|    time_elapsed       | 18         |\n",
      "|    total_timesteps    | 56639488   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01941209 |\n",
      "|    entropy_loss       | -2.23      |\n",
      "|    explained_variance | 0.95       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0704    |\n",
      "|    mean_step_reward   | 0.02896659 |\n",
      "|    n_updates          | 4/128      |\n",
      "|    policyGradLoss     | -0.0202    |\n",
      "|    value_loss         | 0.206      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 836         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 29          |\n",
      "|    total_timesteps    | 56647680    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022730697 |\n",
      "|    entropy_loss       | -2.19       |\n",
      "|    explained_variance | 0.915       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0929     |\n",
      "|    mean_step_reward   | 0.02842684  |\n",
      "|    n_updates          | 8/128       |\n",
      "|    policyGradLoss     | -0.0185     |\n",
      "|    value_loss         | 0.245       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 807         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 40          |\n",
      "|    total_timesteps    | 56655872    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026512437 |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.894       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0822     |\n",
      "|    mean_step_reward   | 0.016325533 |\n",
      "|    n_updates          | 12/128      |\n",
      "|    policyGradLoss     | -0.017      |\n",
      "|    value_loss         | 0.172       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 800         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 51          |\n",
      "|    total_timesteps    | 56664064    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017959015 |\n",
      "|    entropy_loss       | -2.34       |\n",
      "|    explained_variance | 0.931       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.113      |\n",
      "|    mean_step_reward   | 0.007816847 |\n",
      "|    n_updates          | 16/128      |\n",
      "|    policyGradLoss     | -0.0187     |\n",
      "|    value_loss         | 0.0853      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 790         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 62          |\n",
      "|    total_timesteps    | 56672256    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024011252 |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.811       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0847     |\n",
      "|    mean_step_reward   | 0.005064971 |\n",
      "|    n_updates          | 20/128      |\n",
      "|    policyGradLoss     | -0.0151     |\n",
      "|    value_loss         | 0.308       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 73          |\n",
      "|    total_timesteps    | 56680448    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023220321 |\n",
      "|    entropy_loss       | -2.15       |\n",
      "|    explained_variance | 0.948       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0683     |\n",
      "|    mean_step_reward   | 0.03455963  |\n",
      "|    n_updates          | 24/128      |\n",
      "|    policyGradLoss     | -0.0171     |\n",
      "|    value_loss         | 0.244       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 84          |\n",
      "|    total_timesteps    | 56688640    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029538793 |\n",
      "|    entropy_loss       | -2.17       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.109      |\n",
      "|    mean_step_reward   | 0.040094227 |\n",
      "|    n_updates          | 28/128      |\n",
      "|    policyGradLoss     | -0.0253     |\n",
      "|    value_loss         | 0.0664      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 95          |\n",
      "|    total_timesteps    | 56696832    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023982622 |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.916       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0868     |\n",
      "|    mean_step_reward   | 0.011107851 |\n",
      "|    n_updates          | 32/128      |\n",
      "|    policyGradLoss     | -0.0109     |\n",
      "|    value_loss         | 0.155       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 772          |\n",
      "|    iterations         | 10           |\n",
      "|    time_elapsed       | 105          |\n",
      "|    total_timesteps    | 56705024     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.016526327  |\n",
      "|    entropy_loss       | -2.26        |\n",
      "|    explained_variance | 0.86         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.052       |\n",
      "|    mean_step_reward   | 0.0096328985 |\n",
      "|    n_updates          | 36/128       |\n",
      "|    policyGradLoss     | -0.0156      |\n",
      "|    value_loss         | 0.222        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 116         |\n",
      "|    total_timesteps    | 56713216    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019081566 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.937       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0874     |\n",
      "|    mean_step_reward   | 0.028967887 |\n",
      "|    n_updates          | 40/128      |\n",
      "|    policyGradLoss     | -0.0154     |\n",
      "|    value_loss         | 0.217       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 127         |\n",
      "|    total_timesteps    | 56721408    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024855847 |\n",
      "|    entropy_loss       | -2.16       |\n",
      "|    explained_variance | 0.935       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.07       |\n",
      "|    mean_step_reward   | 0.015281221 |\n",
      "|    n_updates          | 44/128      |\n",
      "|    policyGradLoss     | -0.0193     |\n",
      "|    value_loss         | 0.202       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 138         |\n",
      "|    total_timesteps    | 56729600    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024944454 |\n",
      "|    entropy_loss       | -2.12       |\n",
      "|    explained_variance | 0.934       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0715     |\n",
      "|    mean_step_reward   | 0.052596867 |\n",
      "|    n_updates          | 48/128      |\n",
      "|    policyGradLoss     | -0.0166     |\n",
      "|    value_loss         | 0.277       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 764         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 149         |\n",
      "|    total_timesteps    | 56737792    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019070975 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.907       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0901     |\n",
      "|    mean_step_reward   | 0.025976479 |\n",
      "|    n_updates          | 52/128      |\n",
      "|    policyGradLoss     | -0.0109     |\n",
      "|    value_loss         | 0.209       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 762         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 161         |\n",
      "|    total_timesteps    | 56745984    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017999696 |\n",
      "|    entropy_loss       | -2.28       |\n",
      "|    explained_variance | 0.861       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0815     |\n",
      "|    mean_step_reward   | 0.018248739 |\n",
      "|    n_updates          | 56/128      |\n",
      "|    policyGradLoss     | -0.00786    |\n",
      "|    value_loss         | 0.188       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 762         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 171         |\n",
      "|    total_timesteps    | 56754176    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023484934 |\n",
      "|    entropy_loss       | -2.29       |\n",
      "|    explained_variance | 0.895       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.101      |\n",
      "|    mean_step_reward   | 0.014378076 |\n",
      "|    n_updates          | 60/128      |\n",
      "|    policyGradLoss     | -0.0154     |\n",
      "|    value_loss         | 0.162       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 762         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 182         |\n",
      "|    total_timesteps    | 56762368    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021817278 |\n",
      "|    entropy_loss       | -2.31       |\n",
      "|    explained_variance | 0.958       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.1        |\n",
      "|    mean_step_reward   | 0.015758362 |\n",
      "|    n_updates          | 64/128      |\n",
      "|    policyGradLoss     | -0.024      |\n",
      "|    value_loss         | 0.106       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 761         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 193         |\n",
      "|    total_timesteps    | 56770560    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023430644 |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.117      |\n",
      "|    mean_step_reward   | 0.015303325 |\n",
      "|    n_updates          | 68/128      |\n",
      "|    policyGradLoss     | -0.0235     |\n",
      "|    value_loss         | 0.062       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 760         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 204         |\n",
      "|    total_timesteps    | 56778752    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021998867 |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.915       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.102      |\n",
      "|    mean_step_reward   | 0.01177929  |\n",
      "|    n_updates          | 72/128      |\n",
      "|    policyGradLoss     | -0.0234     |\n",
      "|    value_loss         | 0.151       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 758         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 215         |\n",
      "|    total_timesteps    | 56786944    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020314116 |\n",
      "|    entropy_loss       | -2.19       |\n",
      "|    explained_variance | 0.913       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0928     |\n",
      "|    mean_step_reward   | 0.029771648 |\n",
      "|    n_updates          | 76/128      |\n",
      "|    policyGradLoss     | -0.017      |\n",
      "|    value_loss         | 0.292       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 757          |\n",
      "|    iterations         | 21           |\n",
      "|    time_elapsed       | 226          |\n",
      "|    total_timesteps    | 56795136     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.026886739  |\n",
      "|    entropy_loss       | -2.25        |\n",
      "|    explained_variance | 0.85         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.091       |\n",
      "|    mean_step_reward   | 0.0122217275 |\n",
      "|    n_updates          | 80/128       |\n",
      "|    policyGradLoss     | -0.0235      |\n",
      "|    value_loss         | 0.169        |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 757        |\n",
      "|    iterations         | 22         |\n",
      "|    time_elapsed       | 237        |\n",
      "|    total_timesteps    | 56803328   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02201412 |\n",
      "|    entropy_loss       | -2.2       |\n",
      "|    explained_variance | 0.916      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0144    |\n",
      "|    mean_step_reward   | 0.03266786 |\n",
      "|    n_updates          | 84/128     |\n",
      "|    policyGradLoss     | -0.0147    |\n",
      "|    value_loss         | 0.337      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 757         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 248         |\n",
      "|    total_timesteps    | 56811520    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.032610588 |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.923       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.111      |\n",
      "|    mean_step_reward   | 0.020874785 |\n",
      "|    n_updates          | 88/128      |\n",
      "|    policyGradLoss     | -0.0183     |\n",
      "|    value_loss         | 0.141       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 757         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 259         |\n",
      "|    total_timesteps    | 56819712    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.0274053   |\n",
      "|    entropy_loss       | -2.27       |\n",
      "|    explained_variance | 0.948       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.108      |\n",
      "|    mean_step_reward   | 0.017892323 |\n",
      "|    n_updates          | 92/128      |\n",
      "|    policyGradLoss     | -0.0178     |\n",
      "|    value_loss         | 0.0753      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 758         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 270         |\n",
      "|    total_timesteps    | 56827904    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018943748 |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.085      |\n",
      "|    mean_step_reward   | 0.016624713 |\n",
      "|    n_updates          | 96/128      |\n",
      "|    policyGradLoss     | -0.0176     |\n",
      "|    value_loss         | 0.162       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 758         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 280         |\n",
      "|    total_timesteps    | 56836096    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027442181 |\n",
      "|    entropy_loss       | -2.28       |\n",
      "|    explained_variance | 0.941       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.106      |\n",
      "|    mean_step_reward   | 0.01824795  |\n",
      "|    n_updates          | 100/128     |\n",
      "|    policyGradLoss     | -0.0202     |\n",
      "|    value_loss         | 0.0474      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 757         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 292         |\n",
      "|    total_timesteps    | 56844288    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021698527 |\n",
      "|    entropy_loss       | -2.3        |\n",
      "|    explained_variance | 0.937       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.108      |\n",
      "|    mean_step_reward   | 0.012704899 |\n",
      "|    n_updates          | 104/128     |\n",
      "|    policyGradLoss     | -0.0161     |\n",
      "|    value_loss         | 0.213       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 756         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 303         |\n",
      "|    total_timesteps    | 56852480    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019209964 |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.82        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0661     |\n",
      "|    mean_step_reward   | 0.008535041 |\n",
      "|    n_updates          | 108/128     |\n",
      "|    policyGradLoss     | -0.0135     |\n",
      "|    value_loss         | 0.228       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 756         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 314         |\n",
      "|    total_timesteps    | 56860672    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01688576  |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.817       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0835     |\n",
      "|    mean_step_reward   | 0.018601457 |\n",
      "|    n_updates          | 112/128     |\n",
      "|    policyGradLoss     | -0.0133     |\n",
      "|    value_loss         | 0.247       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 756         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 324         |\n",
      "|    total_timesteps    | 56868864    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022741541 |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.913       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0845     |\n",
      "|    mean_step_reward   | 0.01256291  |\n",
      "|    n_updates          | 116/128     |\n",
      "|    policyGradLoss     | -0.0166     |\n",
      "|    value_loss         | 0.197       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 756         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 335         |\n",
      "|    total_timesteps    | 56877056    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030606536 |\n",
      "|    entropy_loss       | -2.18       |\n",
      "|    explained_variance | 0.943       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0951     |\n",
      "|    mean_step_reward   | 0.03474377  |\n",
      "|    n_updates          | 120/128     |\n",
      "|    policyGradLoss     | -0.0262     |\n",
      "|    value_loss         | 0.175       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 755         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 346         |\n",
      "|    total_timesteps    | 56885248    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029234327 |\n",
      "|    entropy_loss       | -2.27       |\n",
      "|    explained_variance | 0.888       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0947     |\n",
      "|    mean_step_reward   | 0.012189899 |\n",
      "|    n_updates          | 124/128     |\n",
      "|    policyGradLoss     | -0.0151     |\n",
      "|    value_loss         | 0.178       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/NoArti_216.zip\n",
      "[EVAL] Mean Return: 58.141, Best Return: 60.341\n",
      "Saved video to ./runs_smw/videos/NoArti/NoArti_216_58.14.mp4\n",
      "\n",
      "=== Round 218 | Learn 262144 steps (Total trained: 56885248) ===\n",
      "Logging to ./runs_smw/tb/NoArti_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1083     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 56893440 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 890         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 56901632    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.031993434 |\n",
      "|    entropy_loss       | -2.17       |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0735     |\n",
      "|    mean_step_reward   | 0.023581924 |\n",
      "|    n_updates          | 4/128       |\n",
      "|    policyGradLoss     | -0.0204     |\n",
      "|    value_loss         | 0.189       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 843         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 29          |\n",
      "|    total_timesteps    | 56909824    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.03498809  |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.904       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.106      |\n",
      "|    mean_step_reward   | 0.019312005 |\n",
      "|    n_updates          | 8/128       |\n",
      "|    policyGradLoss     | -0.0232     |\n",
      "|    value_loss         | 0.0713      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 818         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 40          |\n",
      "|    total_timesteps    | 56918016    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026515905 |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.945       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0873     |\n",
      "|    mean_step_reward   | 0.009132523 |\n",
      "|    n_updates          | 12/128      |\n",
      "|    policyGradLoss     | -0.0214     |\n",
      "|    value_loss         | 0.141       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 796         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 51          |\n",
      "|    total_timesteps    | 56926208    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027444754 |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.87        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.097      |\n",
      "|    mean_step_reward   | 0.0236945   |\n",
      "|    n_updates          | 16/128      |\n",
      "|    policyGradLoss     | -0.0181     |\n",
      "|    value_loss         | 0.218       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 62          |\n",
      "|    total_timesteps    | 56934400    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022299778 |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.951       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0982     |\n",
      "|    mean_step_reward   | 0.03465716  |\n",
      "|    n_updates          | 20/128      |\n",
      "|    policyGradLoss     | -0.0165     |\n",
      "|    value_loss         | 0.221       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 73          |\n",
      "|    total_timesteps    | 56942592    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028874326 |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.112      |\n",
      "|    mean_step_reward   | 0.011303466 |\n",
      "|    n_updates          | 24/128      |\n",
      "|    policyGradLoss     | -0.0233     |\n",
      "|    value_loss         | 0.0937      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 84          |\n",
      "|    total_timesteps    | 56950784    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027917013 |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.932       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0912     |\n",
      "|    mean_step_reward   | 0.029769566 |\n",
      "|    n_updates          | 28/128      |\n",
      "|    policyGradLoss     | -0.0202     |\n",
      "|    value_loss         | 0.149       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 94          |\n",
      "|    total_timesteps    | 56958976    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029251525 |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.949       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0932     |\n",
      "|    mean_step_reward   | 0.021916488 |\n",
      "|    n_updates          | 32/128      |\n",
      "|    policyGradLoss     | -0.0235     |\n",
      "|    value_loss         | 0.142       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 105         |\n",
      "|    total_timesteps    | 56967168    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019385537 |\n",
      "|    entropy_loss       | -2.27       |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0977     |\n",
      "|    mean_step_reward   | 0.026736291 |\n",
      "|    n_updates          | 36/128      |\n",
      "|    policyGradLoss     | -0.0181     |\n",
      "|    value_loss         | 0.0917      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 116         |\n",
      "|    total_timesteps    | 56975360    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01567586  |\n",
      "|    entropy_loss       | -2.3        |\n",
      "|    explained_variance | 0.865       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.025      |\n",
      "|    mean_step_reward   | 0.003045192 |\n",
      "|    n_updates          | 40/128      |\n",
      "|    policyGradLoss     | -0.0127     |\n",
      "|    value_loss         | 0.371       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 127         |\n",
      "|    total_timesteps    | 56983552    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026762953 |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.937       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.086      |\n",
      "|    mean_step_reward   | 0.025286682 |\n",
      "|    n_updates          | 44/128      |\n",
      "|    policyGradLoss     | -0.0192     |\n",
      "|    value_loss         | 0.133       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 138         |\n",
      "|    total_timesteps    | 56991744    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023363484 |\n",
      "|    entropy_loss       | -2.19       |\n",
      "|    explained_variance | 0.916       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0291     |\n",
      "|    mean_step_reward   | 0.024639515 |\n",
      "|    n_updates          | 48/128      |\n",
      "|    policyGradLoss     | -0.0131     |\n",
      "|    value_loss         | 0.392       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 149         |\n",
      "|    total_timesteps    | 56999936    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029776536 |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.907       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.108      |\n",
      "|    mean_step_reward   | 0.014406633 |\n",
      "|    n_updates          | 52/128      |\n",
      "|    policyGradLoss     | -0.0225     |\n",
      "|    value_loss         | 0.169       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 160         |\n",
      "|    total_timesteps    | 57008128    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024325745 |\n",
      "|    entropy_loss       | -2.18       |\n",
      "|    explained_variance | 0.907       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0627     |\n",
      "|    mean_step_reward   | 0.030765891 |\n",
      "|    n_updates          | 56/128      |\n",
      "|    policyGradLoss     | -0.0164     |\n",
      "|    value_loss         | 0.294       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 171         |\n",
      "|    total_timesteps    | 57016320    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.031526517 |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.935       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0834     |\n",
      "|    mean_step_reward   | 0.024993725 |\n",
      "|    n_updates          | 60/128      |\n",
      "|    policyGradLoss     | -0.0175     |\n",
      "|    value_loss         | 0.144       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 181         |\n",
      "|    total_timesteps    | 57024512    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01742737  |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.951       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0918     |\n",
      "|    mean_step_reward   | 0.025603106 |\n",
      "|    n_updates          | 64/128      |\n",
      "|    policyGradLoss     | -0.0157     |\n",
      "|    value_loss         | 0.152       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 765         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 192         |\n",
      "|    total_timesteps    | 57032704    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019007582 |\n",
      "|    entropy_loss       | -2.29       |\n",
      "|    explained_variance | 0.902       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0944     |\n",
      "|    mean_step_reward   | 0.015160001 |\n",
      "|    n_updates          | 68/128      |\n",
      "|    policyGradLoss     | -0.0121     |\n",
      "|    value_loss         | 0.137       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 764          |\n",
      "|    iterations         | 19           |\n",
      "|    time_elapsed       | 203          |\n",
      "|    total_timesteps    | 57040896     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.017155273  |\n",
      "|    entropy_loss       | -2.29        |\n",
      "|    explained_variance | 0.903        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0909      |\n",
      "|    mean_step_reward   | 0.0074488125 |\n",
      "|    n_updates          | 72/128       |\n",
      "|    policyGradLoss     | -0.015       |\n",
      "|    value_loss         | 0.207        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 764         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 214         |\n",
      "|    total_timesteps    | 57049088    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028933458 |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.115      |\n",
      "|    mean_step_reward   | 0.019335806 |\n",
      "|    n_updates          | 76/128      |\n",
      "|    policyGradLoss     | -0.0246     |\n",
      "|    value_loss         | 0.0742      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 762         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 225         |\n",
      "|    total_timesteps    | 57057280    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02295291  |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.94        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0994     |\n",
      "|    mean_step_reward   | 0.017438255 |\n",
      "|    n_updates          | 80/128      |\n",
      "|    policyGradLoss     | -0.0194     |\n",
      "|    value_loss         | 0.155       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 762         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 236         |\n",
      "|    total_timesteps    | 57065472    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016183795 |\n",
      "|    entropy_loss       | -2.19       |\n",
      "|    explained_variance | 0.896       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0231      |\n",
      "|    mean_step_reward   | 0.024451377 |\n",
      "|    n_updates          | 84/128      |\n",
      "|    policyGradLoss     | -0.0137     |\n",
      "|    value_loss         | 0.415       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 762         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 246         |\n",
      "|    total_timesteps    | 57073664    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027173463 |\n",
      "|    entropy_loss       | -2.18       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.104      |\n",
      "|    mean_step_reward   | 0.04649846  |\n",
      "|    n_updates          | 88/128      |\n",
      "|    policyGradLoss     | -0.0227     |\n",
      "|    value_loss         | 0.104       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 762         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 257         |\n",
      "|    total_timesteps    | 57081856    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021294344 |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.877       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0999     |\n",
      "|    mean_step_reward   | 0.015461181 |\n",
      "|    n_updates          | 92/128      |\n",
      "|    policyGradLoss     | -0.0125     |\n",
      "|    value_loss         | 0.177       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 763         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 268         |\n",
      "|    total_timesteps    | 57090048    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022190712 |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.919       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.102      |\n",
      "|    mean_step_reward   | 0.030584628 |\n",
      "|    n_updates          | 96/128      |\n",
      "|    policyGradLoss     | -0.0135     |\n",
      "|    value_loss         | 0.197       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 762         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 279         |\n",
      "|    total_timesteps    | 57098240    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020429507 |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.951       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.103      |\n",
      "|    mean_step_reward   | 0.028328449 |\n",
      "|    n_updates          | 100/128     |\n",
      "|    policyGradLoss     | -0.0181     |\n",
      "|    value_loss         | 0.136       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 761         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 290         |\n",
      "|    total_timesteps    | 57106432    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021592703 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.958       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.1        |\n",
      "|    mean_step_reward   | 0.020467637 |\n",
      "|    n_updates          | 104/128     |\n",
      "|    policyGradLoss     | -0.0199     |\n",
      "|    value_loss         | 0.119       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 760         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 301         |\n",
      "|    total_timesteps    | 57114624    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02114078  |\n",
      "|    entropy_loss       | -2.18       |\n",
      "|    explained_variance | 0.95        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0839     |\n",
      "|    mean_step_reward   | 0.026039816 |\n",
      "|    n_updates          | 108/128     |\n",
      "|    policyGradLoss     | -0.0174     |\n",
      "|    value_loss         | 0.198       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 760         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 312         |\n",
      "|    total_timesteps    | 57122816    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027865553 |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0919     |\n",
      "|    mean_step_reward   | 0.028128792 |\n",
      "|    n_updates          | 112/128     |\n",
      "|    policyGradLoss     | -0.0181     |\n",
      "|    value_loss         | 0.122       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 760         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 323         |\n",
      "|    total_timesteps    | 57131008    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030564731 |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.114      |\n",
      "|    mean_step_reward   | 0.022341516 |\n",
      "|    n_updates          | 116/128     |\n",
      "|    policyGradLoss     | -0.0222     |\n",
      "|    value_loss         | 0.0781      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 759        |\n",
      "|    iterations         | 31         |\n",
      "|    time_elapsed       | 334        |\n",
      "|    total_timesteps    | 57139200   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03442887 |\n",
      "|    entropy_loss       | -2.24      |\n",
      "|    explained_variance | 0.982      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.101     |\n",
      "|    mean_step_reward   | 0.03180281 |\n",
      "|    n_updates          | 120/128    |\n",
      "|    policyGradLoss     | -0.0194    |\n",
      "|    value_loss         | 0.0664     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 759         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 345         |\n",
      "|    total_timesteps    | 57147392    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024837192 |\n",
      "|    entropy_loss       | -2.29       |\n",
      "|    explained_variance | 0.93        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0979     |\n",
      "|    mean_step_reward   | 0.015349933 |\n",
      "|    n_updates          | 124/128     |\n",
      "|    policyGradLoss     | -0.0158     |\n",
      "|    value_loss         | 0.079       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/NoArti_217.zip\n",
      "[EVAL] Mean Return: 75.105, Best Return: 77.305\n",
      "Saved video to ./runs_smw/videos/NoArti/NoArti_217_75.11.mp4\n",
      "\n",
      "=== Round 219 | Learn 262144 steps (Total trained: 57147392) ===\n",
      "Logging to ./runs_smw/tb/NoArti_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1085     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 57155584 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 902         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 57163776    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018036636 |\n",
      "|    entropy_loss       | -2.27       |\n",
      "|    explained_variance | 0.957       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.102      |\n",
      "|    mean_step_reward   | 0.012261839 |\n",
      "|    n_updates          | 4/128       |\n",
      "|    policyGradLoss     | -0.0198     |\n",
      "|    value_loss         | 0.127       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 850         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 57171968    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016052647 |\n",
      "|    entropy_loss       | -2.15       |\n",
      "|    explained_variance | 0.941       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0444     |\n",
      "|    mean_step_reward   | 0.031998083 |\n",
      "|    n_updates          | 8/128       |\n",
      "|    policyGradLoss     | -0.0142     |\n",
      "|    value_loss         | 0.315       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 825         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 57180160    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.033545285 |\n",
      "|    entropy_loss       | -2.1        |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0691     |\n",
      "|    mean_step_reward   | 0.05224225  |\n",
      "|    n_updates          | 12/128      |\n",
      "|    policyGradLoss     | -0.0241     |\n",
      "|    value_loss         | 0.157       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 805         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 50          |\n",
      "|    total_timesteps    | 57188352    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02218777  |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0981     |\n",
      "|    mean_step_reward   | 0.026172927 |\n",
      "|    n_updates          | 16/128      |\n",
      "|    policyGradLoss     | -0.0131     |\n",
      "|    value_loss         | 0.142       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 790         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 62          |\n",
      "|    total_timesteps    | 57196544    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027224524 |\n",
      "|    entropy_loss       | -2.31       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.124      |\n",
      "|    mean_step_reward   | 0.017074374 |\n",
      "|    n_updates          | 20/128      |\n",
      "|    policyGradLoss     | -0.0238     |\n",
      "|    value_loss         | 0.0244      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 73          |\n",
      "|    total_timesteps    | 57204736    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028805638 |\n",
      "|    entropy_loss       | -2.32       |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.104      |\n",
      "|    mean_step_reward   | 0.014290489 |\n",
      "|    n_updates          | 24/128      |\n",
      "|    policyGradLoss     | -0.0154     |\n",
      "|    value_loss         | 0.0392      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 780          |\n",
      "|    iterations         | 8            |\n",
      "|    time_elapsed       | 84           |\n",
      "|    total_timesteps    | 57212928     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.019533606  |\n",
      "|    entropy_loss       | -2.32        |\n",
      "|    explained_variance | 0.926        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.101       |\n",
      "|    mean_step_reward   | 0.0022663153 |\n",
      "|    n_updates          | 28/128       |\n",
      "|    policyGradLoss     | -0.0162      |\n",
      "|    value_loss         | 0.0818       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 775          |\n",
      "|    iterations         | 9            |\n",
      "|    time_elapsed       | 95           |\n",
      "|    total_timesteps    | 57221120     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.01959718   |\n",
      "|    entropy_loss       | -2.33        |\n",
      "|    explained_variance | 0.959        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.104       |\n",
      "|    mean_step_reward   | 0.0017787789 |\n",
      "|    n_updates          | 32/128       |\n",
      "|    policyGradLoss     | -0.0183      |\n",
      "|    value_loss         | 0.0684       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 105         |\n",
      "|    total_timesteps    | 57229312    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021386083 |\n",
      "|    entropy_loss       | -2.13       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0587     |\n",
      "|    mean_step_reward   | 0.023294792 |\n",
      "|    n_updates          | 36/128      |\n",
      "|    policyGradLoss     | -0.013      |\n",
      "|    value_loss         | 0.227       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 116         |\n",
      "|    total_timesteps    | 57237504    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023176381 |\n",
      "|    entropy_loss       | -2.14       |\n",
      "|    explained_variance | 0.934       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0835     |\n",
      "|    mean_step_reward   | 0.058292232 |\n",
      "|    n_updates          | 40/128      |\n",
      "|    policyGradLoss     | -0.0115     |\n",
      "|    value_loss         | 0.235       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 127         |\n",
      "|    total_timesteps    | 57245696    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025016472 |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.111      |\n",
      "|    mean_step_reward   | 0.016828043 |\n",
      "|    n_updates          | 44/128      |\n",
      "|    policyGradLoss     | -0.0113     |\n",
      "|    value_loss         | 0.0914      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 138         |\n",
      "|    total_timesteps    | 57253888    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030957362 |\n",
      "|    entropy_loss       | -2.3        |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.119      |\n",
      "|    mean_step_reward   | 0.018068278 |\n",
      "|    n_updates          | 48/128      |\n",
      "|    policyGradLoss     | -0.0195     |\n",
      "|    value_loss         | 0.0256      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 768          |\n",
      "|    iterations         | 14           |\n",
      "|    time_elapsed       | 149          |\n",
      "|    total_timesteps    | 57262080     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.01770111   |\n",
      "|    entropy_loss       | -2.32        |\n",
      "|    explained_variance | 0.936        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.102       |\n",
      "|    mean_step_reward   | 0.0059993435 |\n",
      "|    n_updates          | 52/128       |\n",
      "|    policyGradLoss     | -0.0149      |\n",
      "|    value_loss         | 0.1          |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 160         |\n",
      "|    total_timesteps    | 57270272    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.03481164  |\n",
      "|    entropy_loss       | -2.28       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.108      |\n",
      "|    mean_step_reward   | 0.023607682 |\n",
      "|    n_updates          | 56/128      |\n",
      "|    policyGradLoss     | -0.0214     |\n",
      "|    value_loss         | 0.0295      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 171         |\n",
      "|    total_timesteps    | 57278464    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023198014 |\n",
      "|    entropy_loss       | -2.2        |\n",
      "|    explained_variance | 0.951       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0474     |\n",
      "|    mean_step_reward   | 0.009736968 |\n",
      "|    n_updates          | 60/128      |\n",
      "|    policyGradLoss     | -0.0155     |\n",
      "|    value_loss         | 0.226       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 181         |\n",
      "|    total_timesteps    | 57286656    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029721566 |\n",
      "|    entropy_loss       | -2.19       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.086      |\n",
      "|    mean_step_reward   | 0.034205616 |\n",
      "|    n_updates          | 64/128      |\n",
      "|    policyGradLoss     | -0.0224     |\n",
      "|    value_loss         | 0.109       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 764         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 192         |\n",
      "|    total_timesteps    | 57294848    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023887757 |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0186     |\n",
      "|    mean_step_reward   | 0.015854083 |\n",
      "|    n_updates          | 68/128      |\n",
      "|    policyGradLoss     | -0.018      |\n",
      "|    value_loss         | 0.135       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 762         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 204         |\n",
      "|    total_timesteps    | 57303040    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023346514 |\n",
      "|    entropy_loss       | -2.2        |\n",
      "|    explained_variance | 0.913       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0813     |\n",
      "|    mean_step_reward   | 0.014214601 |\n",
      "|    n_updates          | 72/128      |\n",
      "|    policyGradLoss     | -0.0161     |\n",
      "|    value_loss         | 0.184       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 761         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 215         |\n",
      "|    total_timesteps    | 57311232    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.035335492 |\n",
      "|    entropy_loss       | -2.17       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0907     |\n",
      "|    mean_step_reward   | 0.040286608 |\n",
      "|    n_updates          | 76/128      |\n",
      "|    policyGradLoss     | -0.0186     |\n",
      "|    value_loss         | 0.112       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 760         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 226         |\n",
      "|    total_timesteps    | 57319424    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.03257983  |\n",
      "|    entropy_loss       | -2.3        |\n",
      "|    explained_variance | 0.993       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.122      |\n",
      "|    mean_step_reward   | 0.015843384 |\n",
      "|    n_updates          | 80/128      |\n",
      "|    policyGradLoss     | -0.0241     |\n",
      "|    value_loss         | 0.0178      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 760         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 236         |\n",
      "|    total_timesteps    | 57327616    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.0207158   |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.946       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0387      |\n",
      "|    mean_step_reward   | 0.007635099 |\n",
      "|    n_updates          | 84/128      |\n",
      "|    policyGradLoss     | -0.0159     |\n",
      "|    value_loss         | 0.199       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 760         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 247         |\n",
      "|    total_timesteps    | 57335808    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.034192618 |\n",
      "|    entropy_loss       | -2.2        |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.117      |\n",
      "|    mean_step_reward   | 0.029645046 |\n",
      "|    n_updates          | 88/128      |\n",
      "|    policyGradLoss     | -0.0236     |\n",
      "|    value_loss         | 0.0452      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 760         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 258         |\n",
      "|    total_timesteps    | 57344000    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02395229  |\n",
      "|    entropy_loss       | -2.19       |\n",
      "|    explained_variance | 0.945       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0875     |\n",
      "|    mean_step_reward   | 0.029110445 |\n",
      "|    n_updates          | 92/128      |\n",
      "|    policyGradLoss     | -0.0132     |\n",
      "|    value_loss         | 0.224       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 759         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 269         |\n",
      "|    total_timesteps    | 57352192    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020619769 |\n",
      "|    entropy_loss       | -2.19       |\n",
      "|    explained_variance | 0.954       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.077      |\n",
      "|    mean_step_reward   | 0.010393804 |\n",
      "|    n_updates          | 96/128      |\n",
      "|    policyGradLoss     | -0.0176     |\n",
      "|    value_loss         | 0.183       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 758         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 280         |\n",
      "|    total_timesteps    | 57360384    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029093426 |\n",
      "|    entropy_loss       | -2.17       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.107      |\n",
      "|    mean_step_reward   | 0.03616328  |\n",
      "|    n_updates          | 100/128     |\n",
      "|    policyGradLoss     | -0.0225     |\n",
      "|    value_loss         | 0.0925      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 759         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 291         |\n",
      "|    total_timesteps    | 57368576    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020988397 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.906       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0577     |\n",
      "|    mean_step_reward   | 0.03037998  |\n",
      "|    n_updates          | 104/128     |\n",
      "|    policyGradLoss     | -0.015      |\n",
      "|    value_loss         | 0.311       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 759         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 301         |\n",
      "|    total_timesteps    | 57376768    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.031891435 |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.121      |\n",
      "|    mean_step_reward   | 0.019943954 |\n",
      "|    n_updates          | 108/128     |\n",
      "|    policyGradLoss     | -0.0275     |\n",
      "|    value_loss         | 0.0479      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 759        |\n",
      "|    iterations         | 29         |\n",
      "|    time_elapsed       | 312        |\n",
      "|    total_timesteps    | 57384960   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02583591 |\n",
      "|    entropy_loss       | -2.16      |\n",
      "|    explained_variance | 0.959      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0344    |\n",
      "|    mean_step_reward   | 0.04134135 |\n",
      "|    n_updates          | 112/128    |\n",
      "|    policyGradLoss     | -0.0169    |\n",
      "|    value_loss         | 0.219      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 760         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 323         |\n",
      "|    total_timesteps    | 57393152    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02478825  |\n",
      "|    entropy_loss       | -2.13       |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0803     |\n",
      "|    mean_step_reward   | 0.029960433 |\n",
      "|    n_updates          | 116/128     |\n",
      "|    policyGradLoss     | -0.0166     |\n",
      "|    value_loss         | 0.181       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 759        |\n",
      "|    iterations         | 31         |\n",
      "|    time_elapsed       | 334        |\n",
      "|    total_timesteps    | 57401344   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02706514 |\n",
      "|    entropy_loss       | -2.11      |\n",
      "|    explained_variance | 0.973      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0932    |\n",
      "|    mean_step_reward   | 0.04341752 |\n",
      "|    n_updates          | 120/128    |\n",
      "|    policyGradLoss     | -0.0193    |\n",
      "|    value_loss         | 0.12       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 758         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 345         |\n",
      "|    total_timesteps    | 57409536    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02539511  |\n",
      "|    entropy_loss       | -2.14       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0794     |\n",
      "|    mean_step_reward   | 0.039490573 |\n",
      "|    n_updates          | 124/128     |\n",
      "|    policyGradLoss     | -0.0188     |\n",
      "|    value_loss         | 0.157       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/NoArti_218.zip\n",
      "[EVAL] Mean Return: -66.515, Best Return: -64.511\n",
      "Saved video to ./runs_smw/videos/NoArti/NoArti_218_-66.51.mp4\n",
      "\n",
      "=== Round 220 | Learn 262144 steps (Total trained: 57409536) ===\n",
      "Logging to ./runs_smw/tb/NoArti_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1099     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 57417728 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 898         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 57425920    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018112961 |\n",
      "|    entropy_loss       | -2.35       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.101      |\n",
      "|    mean_step_reward   | 0.01331755  |\n",
      "|    n_updates          | 4/128       |\n",
      "|    policyGradLoss     | -0.0105     |\n",
      "|    value_loss         | 0.0934      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 857         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 57434112    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021089427 |\n",
      "|    entropy_loss       | -2.27       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0506     |\n",
      "|    mean_step_reward   | 0.012704155 |\n",
      "|    n_updates          | 8/128       |\n",
      "|    policyGradLoss     | -0.0176     |\n",
      "|    value_loss         | 0.103       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 828         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 57442304    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026433647 |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.109      |\n",
      "|    mean_step_reward   | 0.019215094 |\n",
      "|    n_updates          | 12/128      |\n",
      "|    policyGradLoss     | -0.0198     |\n",
      "|    value_loss         | 0.0781      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 811         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 50          |\n",
      "|    total_timesteps    | 57450496    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022736046 |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.106      |\n",
      "|    mean_step_reward   | 0.018013828 |\n",
      "|    n_updates          | 16/128      |\n",
      "|    policyGradLoss     | -0.0204     |\n",
      "|    value_loss         | 0.0619      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 798         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 61          |\n",
      "|    total_timesteps    | 57458688    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020528695 |\n",
      "|    entropy_loss       | -2.19       |\n",
      "|    explained_variance | 0.951       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.1        |\n",
      "|    mean_step_reward   | 0.027808527 |\n",
      "|    n_updates          | 20/128      |\n",
      "|    policyGradLoss     | -0.0165     |\n",
      "|    value_loss         | 0.178       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 790        |\n",
      "|    iterations         | 7          |\n",
      "|    time_elapsed       | 72         |\n",
      "|    total_timesteps    | 57466880   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03266781 |\n",
      "|    entropy_loss       | -2.23      |\n",
      "|    explained_variance | 0.986      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.113     |\n",
      "|    mean_step_reward   | 0.03231223 |\n",
      "|    n_updates          | 24/128     |\n",
      "|    policyGradLoss     | -0.0245    |\n",
      "|    value_loss         | 0.0521     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 790          |\n",
      "|    iterations         | 8            |\n",
      "|    time_elapsed       | 82           |\n",
      "|    total_timesteps    | 57475072     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.019480627  |\n",
      "|    entropy_loss       | -2.37        |\n",
      "|    explained_variance | 0.964        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0828      |\n",
      "|    mean_step_reward   | 0.0021136494 |\n",
      "|    n_updates          | 28/128       |\n",
      "|    policyGradLoss     | -0.0119      |\n",
      "|    value_loss         | 0.0581       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 788          |\n",
      "|    iterations         | 9            |\n",
      "|    time_elapsed       | 93           |\n",
      "|    total_timesteps    | 57483264     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.018044816  |\n",
      "|    entropy_loss       | -2.32        |\n",
      "|    explained_variance | 0.951        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.102       |\n",
      "|    mean_step_reward   | 0.0050298125 |\n",
      "|    n_updates          | 32/128       |\n",
      "|    policyGradLoss     | -0.0173      |\n",
      "|    value_loss         | 0.112        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 104         |\n",
      "|    total_timesteps    | 57491456    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022523113 |\n",
      "|    entropy_loss       | -2.18       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0755     |\n",
      "|    mean_step_reward   | 0.024603143 |\n",
      "|    n_updates          | 36/128      |\n",
      "|    policyGradLoss     | -0.0169     |\n",
      "|    value_loss         | 0.134       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 115         |\n",
      "|    total_timesteps    | 57499648    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025332887 |\n",
      "|    entropy_loss       | -2.18       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0913     |\n",
      "|    mean_step_reward   | 0.033407442 |\n",
      "|    n_updates          | 40/128      |\n",
      "|    policyGradLoss     | -0.0178     |\n",
      "|    value_loss         | 0.117       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 125         |\n",
      "|    total_timesteps    | 57507840    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021743998 |\n",
      "|    entropy_loss       | -2.07       |\n",
      "|    explained_variance | 0.949       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0623     |\n",
      "|    mean_step_reward   | 0.0292143   |\n",
      "|    n_updates          | 44/128      |\n",
      "|    policyGradLoss     | -0.0165     |\n",
      "|    value_loss         | 0.283       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 136         |\n",
      "|    total_timesteps    | 57516032    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028927578 |\n",
      "|    entropy_loss       | -2.08       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0895     |\n",
      "|    mean_step_reward   | 0.05605787  |\n",
      "|    n_updates          | 48/128      |\n",
      "|    policyGradLoss     | -0.0174     |\n",
      "|    value_loss         | 0.2         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 147         |\n",
      "|    total_timesteps    | 57524224    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.035118006 |\n",
      "|    entropy_loss       | -2.3        |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.121      |\n",
      "|    mean_step_reward   | 0.022190362 |\n",
      "|    n_updates          | 52/128      |\n",
      "|    policyGradLoss     | -0.0214     |\n",
      "|    value_loss         | 0.0298      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 777          |\n",
      "|    iterations         | 15           |\n",
      "|    time_elapsed       | 158          |\n",
      "|    total_timesteps    | 57532416     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.025783872  |\n",
      "|    entropy_loss       | -2.34        |\n",
      "|    explained_variance | 0.988        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.115       |\n",
      "|    mean_step_reward   | 0.0063010673 |\n",
      "|    n_updates          | 56/128       |\n",
      "|    policyGradLoss     | -0.0229      |\n",
      "|    value_loss         | 0.0133       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 168         |\n",
      "|    total_timesteps    | 57540608    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.0217841   |\n",
      "|    entropy_loss       | -2.32       |\n",
      "|    explained_variance | 0.958       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.087      |\n",
      "|    mean_step_reward   | 0.016889635 |\n",
      "|    n_updates          | 60/128      |\n",
      "|    policyGradLoss     | -0.011      |\n",
      "|    value_loss         | 0.086       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 179         |\n",
      "|    total_timesteps    | 57548800    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.032228924 |\n",
      "|    entropy_loss       | -2.27       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.113      |\n",
      "|    mean_step_reward   | 0.029609557 |\n",
      "|    n_updates          | 64/128      |\n",
      "|    policyGradLoss     | -0.0203     |\n",
      "|    value_loss         | 0.0449      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 190         |\n",
      "|    total_timesteps    | 57556992    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01809382  |\n",
      "|    entropy_loss       | -2.18       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0561     |\n",
      "|    mean_step_reward   | 0.016659074 |\n",
      "|    n_updates          | 68/128      |\n",
      "|    policyGradLoss     | -0.0176     |\n",
      "|    value_loss         | 0.253       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 201         |\n",
      "|    total_timesteps    | 57565184    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025492918 |\n",
      "|    entropy_loss       | -2.19       |\n",
      "|    explained_variance | 0.948       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0546     |\n",
      "|    mean_step_reward   | 0.021744879 |\n",
      "|    n_updates          | 72/128      |\n",
      "|    policyGradLoss     | -0.0191     |\n",
      "|    value_loss         | 0.215       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 212         |\n",
      "|    total_timesteps    | 57573376    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02906066  |\n",
      "|    entropy_loss       | -2.29       |\n",
      "|    explained_variance | 0.948       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.114      |\n",
      "|    mean_step_reward   | 0.017969709 |\n",
      "|    n_updates          | 76/128      |\n",
      "|    policyGradLoss     | -0.0174     |\n",
      "|    value_loss         | 0.0566      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 222         |\n",
      "|    total_timesteps    | 57581568    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022005646 |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.95        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.104      |\n",
      "|    mean_step_reward   | 0.017457385 |\n",
      "|    n_updates          | 80/128      |\n",
      "|    policyGradLoss     | -0.0154     |\n",
      "|    value_loss         | 0.126       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 233         |\n",
      "|    total_timesteps    | 57589760    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02052612  |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.901       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0903     |\n",
      "|    mean_step_reward   | 0.031579975 |\n",
      "|    n_updates          | 84/128      |\n",
      "|    policyGradLoss     | -0.0133     |\n",
      "|    value_loss         | 0.254       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 244         |\n",
      "|    total_timesteps    | 57597952    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020273913 |\n",
      "|    entropy_loss       | -2.31       |\n",
      "|    explained_variance | 0.945       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.104      |\n",
      "|    mean_step_reward   | 0.01376134  |\n",
      "|    n_updates          | 88/128      |\n",
      "|    policyGradLoss     | -0.0171     |\n",
      "|    value_loss         | 0.0902      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 255         |\n",
      "|    total_timesteps    | 57606144    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021646049 |\n",
      "|    entropy_loss       | -2.27       |\n",
      "|    explained_variance | 0.89        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0706     |\n",
      "|    mean_step_reward   | 0.006551963 |\n",
      "|    n_updates          | 92/128      |\n",
      "|    policyGradLoss     | -0.0125     |\n",
      "|    value_loss         | 0.154       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 769          |\n",
      "|    iterations         | 25           |\n",
      "|    time_elapsed       | 266          |\n",
      "|    total_timesteps    | 57614336     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.023833938  |\n",
      "|    entropy_loss       | -2.26        |\n",
      "|    explained_variance | 0.929        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0383      |\n",
      "|    mean_step_reward   | 0.0097065065 |\n",
      "|    n_updates          | 96/128       |\n",
      "|    policyGradLoss     | -0.0202      |\n",
      "|    value_loss         | 0.167        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 276         |\n",
      "|    total_timesteps    | 57622528    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02177507  |\n",
      "|    entropy_loss       | -2.2        |\n",
      "|    explained_variance | 0.871       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0678     |\n",
      "|    mean_step_reward   | 0.022069968 |\n",
      "|    n_updates          | 100/128     |\n",
      "|    policyGradLoss     | -0.0195     |\n",
      "|    value_loss         | 0.3         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 287         |\n",
      "|    total_timesteps    | 57630720    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02825582  |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.95        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.107      |\n",
      "|    mean_step_reward   | 0.027622003 |\n",
      "|    n_updates          | 104/128     |\n",
      "|    policyGradLoss     | -0.0209     |\n",
      "|    value_loss         | 0.112       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 298         |\n",
      "|    total_timesteps    | 57638912    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022217115 |\n",
      "|    entropy_loss       | -2.3        |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0959     |\n",
      "|    mean_step_reward   | 0.012418892 |\n",
      "|    n_updates          | 108/128     |\n",
      "|    policyGradLoss     | -0.0201     |\n",
      "|    value_loss         | 0.0961      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 767          |\n",
      "|    iterations         | 29           |\n",
      "|    time_elapsed       | 309          |\n",
      "|    total_timesteps    | 57647104     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.020379234  |\n",
      "|    entropy_loss       | -2.28        |\n",
      "|    explained_variance | 0.854        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0869      |\n",
      "|    mean_step_reward   | 0.0009888314 |\n",
      "|    n_updates          | 112/128      |\n",
      "|    policyGradLoss     | -0.018       |\n",
      "|    value_loss         | 0.261        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 320         |\n",
      "|    total_timesteps    | 57655296    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023018327 |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.788       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.103      |\n",
      "|    mean_step_reward   | 0.018212244 |\n",
      "|    n_updates          | 116/128     |\n",
      "|    policyGradLoss     | -0.0189     |\n",
      "|    value_loss         | 0.133       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 331         |\n",
      "|    total_timesteps    | 57663488    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02790964  |\n",
      "|    entropy_loss       | -2.27       |\n",
      "|    explained_variance | 0.939       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.11       |\n",
      "|    mean_step_reward   | 0.022129012 |\n",
      "|    n_updates          | 120/128     |\n",
      "|    policyGradLoss     | -0.021      |\n",
      "|    value_loss         | 0.119       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 341         |\n",
      "|    total_timesteps    | 57671680    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019090733 |\n",
      "|    entropy_loss       | -2.18       |\n",
      "|    explained_variance | 0.941       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0734     |\n",
      "|    mean_step_reward   | 0.02857177  |\n",
      "|    n_updates          | 124/128     |\n",
      "|    policyGradLoss     | -0.0179     |\n",
      "|    value_loss         | 0.181       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/NoArti_219.zip\n",
      "\n",
      "Training interrupted manually.\n",
      "Training finished. Environment closed.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\ntensorboard --logdir=./runs_smw/tb\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    while trained < TOTAL_STEPS:\n",
    "        round_idx += 1\n",
    "        chunk = min(TRAIN_CHUNK, TOTAL_STEPS - trained)\n",
    "        # chunk = 2000\n",
    "        label = \"NoArti\"\n",
    "        tagged_label = f\"{label}_{int(trained/TRAIN_CHUNK)}\"\n",
    "\n",
    "        print(f\"\\n=== Round {round_idx} | Learn {chunk} steps (Total trained: {trained}) ===\")\n",
    "        \n",
    "        # --- Train ---\n",
    "        model.learn(total_timesteps=chunk, reset_num_timesteps=False, tb_log_name=label)\n",
    "        trained += chunk\n",
    "\n",
    "        # --- Save Checkpoint ---\n",
    "        ckpt_path = os.path.join(CKPT_DIR, f\"{tagged_label}.zip\")\n",
    "        model.save(ckpt_path)\n",
    "        print(f\"Saved checkpoint: {ckpt_path}\")\n",
    "\n",
    "        # --- Evaluate ---\n",
    "        mean_ret, best_ret = evaluate_policy(\n",
    "            model,\n",
    "            GAME,\n",
    "            STATE,\n",
    "            n_episodes=EVAL_EPISODES,\n",
    "            max_steps=EVAL_MAX_STEPS,\n",
    "        )\n",
    "        print(f\"[EVAL] Mean Return: {mean_ret:.3f}, Best Return: {best_ret:.3f}\")\n",
    "\n",
    "        # --- Record Video ---\n",
    "        out_path = os.path.join(VIDEO_DIR, label)\n",
    "        os.makedirs(out_path,  exist_ok=True)\n",
    "        record_video(\n",
    "            model,\n",
    "            GAME,\n",
    "            STATE,\n",
    "            VIDEO_DIR,\n",
    "            video_len=RECORD_STEPS,\n",
    "            prefix=f\"{label}/{tagged_label}_{mean_ret:.2f}\",\n",
    "        )\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nTraining interrupted manually.\")\n",
    "\n",
    "finally:\n",
    "    train_env.close()\n",
    "    print(\"Training finished. Environment closed.\")\n",
    "    \n",
    "\"\"\"\n",
    "tensorboard --logdir=./runs_smw/tb\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f088b0b3-2418-4866-b332-0312c9f6467f",
   "metadata": {},
   "source": [
    "## Display Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73191bb-e875-4939-b04c-a4670abd9612",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Video\n",
    "video = \"./runs_smw/videos/test_126.mp4\"\n",
    "display(Video(video, embed=True, width=768))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1865a364",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "[070] coins: 12 | score: 3540\n",
    "[071] coins: 10 | score: 2260\n",
    "[072] coins: 11 | score: 2760\n",
    "[073] coins:  2 | score:  690\n",
    "[074] coins: 12 | score: 3450\n",
    "[075] coins: 12 | score: 3515\n",
    "[076] coins: 12 | score: 3545\n",
    "[077] coins: 12 | score: 3545\n",
    "[078] coins: 10 | score: 2460\n",
    "[079] coins: 12 | score: 3515\n",
    "[080] coins: 12 | score: 3580\n",
    "[081] coins: 11 | score: 2750\n",
    "[082] coins: 12 | score: 3545\n",
    "[083] coins: 12 | score: 3565\n",
    "[084] coins: 11 | score: 3475\n",
    "[085] coins:  0 | score:    0\n",
    "[086] coins: 12 | score: 3535\n",
    "[087] coins: 12 | score: 3560\n",
    "[088] coins:  9 | score: 1420\n",
    "[089] coins: 11 | score: 3640\n",
    "[090] coins:  1 | score:  380\n",
    "[091] coins: 10 | score: 2440\n",
    "[092] coins: 12 | score: 3570\n",
    "[093] coins: 12 | score: 3490\n",
    "[094] coins: 11 | score: 2745\n",
    "[095] coins: 12 | score: 3565\n",
    "[096] coins:  0 | score:    0\n",
    "[097] coins: 12 | score: 3490\n",
    "[098] coins: 12 | score: 3570\n",
    "[099] coins:  2 | score:  560\n",
    "[100] coins:  2 | score:  660\n",
    "[101] coins: 12 | score: 3580\n",
    "[102] coins:  9 | score: 1420\n",
    "[103] coins: 12 | score: 3575\n",
    "[104] coins: 12 | score: 3585\n",
    "[105] coins: 12 | score: 3580\n",
    "[106] coins: 12 | score: 3525\n",
    "[107] coins:  2 | score:  540\n",
    "[108] coins:  2 | score:  660\n",
    "[109] coins: 10 | score: 2420\n",
    "[110] coins:  1 | score:  140\n",
    "[111] coins: 11 | score: 2680\n",
    "[112] coins:  2 | score:  580\n",
    "[113] coins:  2 | score:  580\n",
    "[114] coins:  2 | score:  560\n",
    "[115] coins: 11 | score: 2765\n",
    "[116] coins:  2 | score:  560\n",
    "[117] coins:  0 | score:    0\n",
    "[118] coins: 12 | score: 3570\n",
    "[119] coins:  1 | score:  340\n",
    "[120] coins: 11 | score: 2735\n",
    "[121] coins: 12 | score: 3570\n",
    "[122] coins: 12 | score: 3515\n",
    "[123] coins: 12 | score: 3580\n",
    "[124] coins: 12 | score: 3585\n",
    "[125] coins: 12 | score: 3560\n",
    "[126] coins: 12 | score: 3595\n",
    "[127] coins: 12 | score: 3515\n",
    "\n",
    "所有測試結束。\n",
    "在 reward 紀錄上，紀錄前10幀的 action 是甚麼，然後檢查\n",
    "\n",
    "--Run--\n",
    "[57] coins: 12 | score: 3630\n",
    "[58] coins: 12 | score: 3490\n",
    "[59] coins: 11 | score: 2855\n",
    "[60] coins: 12 | score: 3620\n",
    "[61] coins: 12 | score: 3690\n",
    "[62] coins: 12 | score: 3685\n",
    "[63] coins: 11 | score: 2860\n",
    "[64] coins: 10 | score: 2245\n",
    "[65] coins: 12 | score: 3685\n",
    "[66] coins: 12 | score: 3670\n",
    "[67] coins: 12 | score: 3565\n",
    "[68] coins: 12 | score: 3575\n",
    "[69] coins: 11 | score: 2880\n",
    "[70] coins: 12 | score: 3685\n",
    "\n",
    "[72] coins: 9 | score: 1315\n",
    "[73] coins: 12 | score: 3535\n",
    "[74] coins: 12 | score: 3570\n",
    "[75] coins: 12 | score: 3645\n",
    "[76] coins: 12 | score: 3690\n",
    "[77] coins: 8 | score: 1020\n",
    "[78] coins: 12 | score: 3695\n",
    "[79] coins: 11 | score: 2780\n",
    "[80] coins: 12 | score: 3695\n",
    "[81] coins: 12 | score: 3695\n",
    "[82] coins: 12 | score: 3655\n",
    "[83] coins: 12 | score: 3690\n",
    "[84] coins: 12 | score: 3635\n",
    "[85] coins: 11 | score: 2840\n",
    "[86] coins: 12 | score: 3680\n",
    "[87] coins: 12 | score: 3645\n",
    "[88] coins: 12 | score: 3625\n",
    "[89] coins: 0 | score: 0\n",
    "[90] coins: 12 | score: 3650\n",
    "[91] coins: 12 | score: 3695\n",
    "[92] coins: 12 | score: 3695\n",
    "[93] coins: 12 | score: 3700\n",
    "[94] coins: 12 | score: 3700\n",
    "[95] coins: 12 | score: 3625\n",
    "[96] coins: 12 | score: 3700\n",
    "[97] coins: 12 | score: 3705\n",
    "[98] coins: 12 | score: 3695\n",
    "[99] coins: 2 | score: 640\n",
    "[100] coins: 12 | score: 3705\n",
    "[101] coins: 9 | score: 1400\n",
    "[102] coins: 9 | score: 1420\n",
    "[103] coins: 12 | score: 3705\n",
    "[104] coins: 2 | score: 770\n",
    "[105] coins: 12 | score: 3705\n",
    "[106] coins: 12 | score: 3705\n",
    "[107] coins: 1 | score: 380\n",
    "[108] coins: 12 | score: 3745 *\n",
    "[109] coins: 12 | score: 3660\n",
    "[110] coins: 11 | score: 2915\n",
    "[111] coins: 5 | score: 2810\n",
    "[112] coins: 12 | score: 3680\n",
    "[113] coins: 12 | score: 3540\n",
    "[114] coins: 11 | score: 2860\n",
    "[115] coins: 12 | score: 3740\n",
    "[116] coins: 12 | score: 3730\n",
    "[117] coins: 12 | score: 3725\n",
    "[118] coins: 12 | score: 3680\n",
    "[119] coins: 6 | score: 3650\n",
    "[120] coins: 12 | score: 3745\n",
    "[121] coins: 12 | score: 3770 *\n",
    "[122] coins: 11 | score: 2885\n",
    "[123] coins: 12 | score: 3720\n",
    "[124] coins: 12 | score: 3710\n",
    "[125] coins: 11 | score: 2685\n",
    "[126] coins: 12 | score: 3510\n",
    "[127] coins: 12 | score: 3750 *\n",
    "[128] coins: 12 | score: 3730\n",
    "[129] coins: 12 | score: 3635\n",
    "[130] coins: 12 | score: 3730\n",
    "[131] coins: 11 | score: 2745\n",
    "[132] coins: 12 | score: 3720\n",
    "[133] coins: 12 | score: 3760 *\n",
    "[134] coins: 12 | score: 3730\n",
    "[135] coins: 12 | score: 3735\n",
    "[136] coins: 12 | score: 3715\n",
    "[137] coins: 12 | score: 3730\n",
    "[138] coins: 12 | score: 3670\n",
    "[139] coins: 12 | score: 3730\n",
    "[140] coins: 11 | score: 3685\n",
    "[141] coins: 13 | score: 3690\n",
    "[142] coins: 13 | score: 3740\n",
    "[143] coins: 13 | score: 3740\n",
    "[144] coins: 13 | score: 3735\n",
    "[145] coins: 13 | score: 3675\n",
    "\n",
    "--Nature\n",
    "[148] coins: 6 | score: 3745\n",
    "[149] coins: 6 | score: 3800\n",
    "[150] coins: 6 | score: 3790\n",
    "[151] coins: 6 | score: 3740\n",
    "[152] coins: 5 | score: 3725\n",
    "[153] coins: 6 | score: 3745\n",
    "[154] coins: 6 | score: 3635\n",
    "[155] coins: 2 | score: 820\n",
    "[156] coins: 6 | score: 3870 *\n",
    "[157] coins: 6 | score: 3750\n",
    "[158] coins: 6 | score: 3850\n",
    "[159] coins: 6 | score: 3855 *\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Lab8 (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
