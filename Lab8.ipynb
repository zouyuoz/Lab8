{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dceedafe-2782-41a1-8119-50ee3d6c21fd",
   "metadata": {},
   "source": [
    "# 2025 DL Lab8: RL Assignment_Super Mario World"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fa555a-e61c-4fb3-b5d0-289b66570139",
   "metadata": {},
   "source": [
    "**Your Answer:**    \n",
    "Hi I'm XXX, XXXXXXXXXX."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5b0974-9605-488a-9fd5-00816e7832cc",
   "metadata": {},
   "source": [
    "## Overview\n",
    "This project implements a **Deep Reinforcement Learning** pipeline to train an autonomous agent for Super Mario World. Leveraging the **Proximal Policy Optimization (PPO)** algorithm, the system interacts with the **stable-retro** environment to master the YoshiIsland1 level. Key components include a custom Vision Backbone for extracting features from raw pixel data and a suite of Environment Wrappers that handle frame preprocessing, action discretization, and reward shaping to facilitate efficient learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02696447",
   "metadata": {},
   "source": [
    "Reward function implement  \n",
    "should do something in the beginning (monster attack)  \n",
    "Custom PPO implement  \n",
    "pre train weight 差不多，主要是 reward function  \n",
    "model weight capacity 1GB  \n",
    "class name 不要動 (可以新增，但是原本有的不要動)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8a0ab9-f86d-4038-833d-761ec81fc4f2",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00b10def-362c-4910-9ed0-f3d0904343ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/m314834001/Lab8/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import retro\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, SubprocVecEnv\n",
    "from stable_baselines3.common.vec_env import VecNormalize\n",
    "\n",
    "from eval import evaluate_policy, record_video\n",
    "from custom_policy import VisionBackbonePolicy, CustomPPO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10361fd-f291-4d93-b50d-cc749a3af588",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b4f6a25-738c-49dd-8e66-ae164b74a45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Game Settings\n",
    "GAME = \"SuperMarioWorld-Snes\"\n",
    "STATE = \"YoshiIsland1\"\n",
    "\n",
    "# Training Settings\n",
    "TOTAL_STEPS = 6_553_600\n",
    "TRAIN_CHUNK =   655_360\n",
    "N_ENVS = 16\n",
    "LEARNING_RATE = 2.5e-4\n",
    "\n",
    "# Evaluation & Recording Settings\n",
    "EVAL_EPISODES = 3\n",
    "EVAL_MAX_STEPS = 18000\n",
    "RECORD_STEPS = 900\n",
    "\n",
    "# Directories\n",
    "LOG_DIR = \"./runs_smw\"\n",
    "VIDEO_DIR       = os.path.join(LOG_DIR, \"videos\")\n",
    "CKPT_DIR        = os.path.join(LOG_DIR, \"checkpoints\")\n",
    "TENSORBOARD_LOG = os.path.join(LOG_DIR, \"tb\")\n",
    "\n",
    "os.makedirs(LOG_DIR,   exist_ok=True)\n",
    "os.makedirs(CKPT_DIR,  exist_ok=True)\n",
    "os.makedirs(VIDEO_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a34b783-0273-4835-ad2e-f9186064f76f",
   "metadata": {},
   "source": [
    "## Environment Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c34213d-2c7c-42b8-922d-bafa285d1ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wrappers import make_base_env\n",
    "def _make_env_thunk(game: str, state: str):\n",
    "    \"\"\"Return a function that creates an environment (for multiprocessing).\"\"\"\n",
    "    def _thunk():\n",
    "        return make_base_env(game, state)\n",
    "    return _thunk\n",
    "\n",
    "def make_vec_env(game: str, state: str, n_envs: int, use_subproc: bool = True):\n",
    "    \"\"\"Create a vectorized environment (multiple envs running in parallel).\"\"\"\n",
    "    env_fns = [_make_env_thunk(game, state) for _ in range(n_envs)]\n",
    "    \n",
    "    if use_subproc and n_envs > 1:\n",
    "        vec_env = SubprocVecEnv(env_fns)\n",
    "    else:\n",
    "        vec_env = DummyVecEnv(env_fns)\n",
    "\n",
    "    return vec_env\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71dff476-ea2e-4262-8780-afb32ef1b233",
   "metadata": {},
   "source": [
    "## Initialize Env & Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8c7c5fe-6421-4dbc-9bd8-822d61769c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment created: SuperMarioWorld-Snes - YoshiIsland1 with 16 parallel envs.\n",
      "Loading model from runs_smw/checkpoints/SF84_step_1600000.zip...\n"
     ]
    }
   ],
   "source": [
    "# 1. Create Training Environment\n",
    "train_env = make_vec_env(GAME, STATE, n_envs=N_ENVS)\n",
    "# train_env = VecNormalize(train_env, norm_obs=True, norm_reward=True, clip_obs=10., clip_reward=10.)\n",
    "print(f\"Environment created: {GAME} - {STATE} with {N_ENVS} parallel envs.\")\n",
    "\n",
    "checkpoint_path = \"None\"\n",
    "checkpoint_path = \"runs_smw/checkpoints/SF84_step_1600000.zip\"\n",
    "\n",
    "# 2. Initialize Model\n",
    "if os.path.exists(checkpoint_path):\n",
    "    print(f\"Loading model from {checkpoint_path}...\")\n",
    "    # 讀取現有模型\n",
    "    model = CustomPPO.load(\n",
    "        checkpoint_path, \n",
    "        env=train_env,\n",
    "        device=\"cuda:0\" # 確保使用 GPU\n",
    "    )\n",
    "else:\n",
    "    model = CustomPPO(\n",
    "        VisionBackbonePolicy,\n",
    "        train_env,\n",
    "        policy_kwargs   = dict(normalize_images=False),\n",
    "        n_epochs        = 10,\n",
    "        n_steps         = 512,\n",
    "        batch_size      = 512,\n",
    "        learning_rate   = LEARNING_RATE,\n",
    "        verbose         = 1,\n",
    "        gamma           = 0.99,\n",
    "        kl_coef         = 1,\n",
    "        clip_range      = 0.5,\n",
    "        tensorboard_log = TENSORBOARD_LOG,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f594e443-843f-42c1-9fc6-3fbc82962021",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3af4932-c531-4113-a33a-defc6fb5858e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Round 1 | Learn 655360 steps (Total trained: 1600000) ===\n",
      "Logging to ./runs_smw/tb/SF84_lRWD_PT_0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/m314834001/Lab8/.venv/lib/python3.12/site-packages/rich/live.py:256: UserWarning: install \"ipywidgets\" for \n",
       "Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/m314834001/Lab8/.venv/lib/python3.12/site-packages/rich/live.py:256: UserWarning: install \"ipywidgets\" for \n",
       "Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 533     |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 15      |\n",
      "|    total_timesteps | 1613824 |\n",
      "--------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 358         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 45          |\n",
      "|    total_timesteps    | 1622016     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.093333654 |\n",
      "|    entropy_loss       | -2.41       |\n",
      "|    explained_variance | 0.745       |\n",
      "|    learning_rate      | 0.00025     |\n",
      "|    loss               | 36.7        |\n",
      "|    mean_step_reward   | 0.019992674 |\n",
      "|    n_updates          | 1970        |\n",
      "|    policyGradLoss     | -0.0119     |\n",
      "|    value_loss         | 370         |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 309           |\n",
      "|    iterations         | 3             |\n",
      "|    time_elapsed       | 79            |\n",
      "|    total_timesteps    | 1630208       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.063352436   |\n",
      "|    entropy_loss       | -2.45         |\n",
      "|    explained_variance | 0.762         |\n",
      "|    learning_rate      | 0.00025       |\n",
      "|    loss               | 23.2          |\n",
      "|    mean_step_reward   | -0.0008300785 |\n",
      "|    n_updates          | 1980          |\n",
      "|    policyGradLoss     | -0.0102       |\n",
      "|    value_loss         | 123           |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 296         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 110         |\n",
      "|    total_timesteps    | 1638400     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.042648096 |\n",
      "|    entropy_loss       | -2.41       |\n",
      "|    explained_variance | 0.757       |\n",
      "|    learning_rate      | 0.00025     |\n",
      "|    loss               | 5.34        |\n",
      "|    mean_step_reward   | -0.01081543 |\n",
      "|    n_updates          | 1990        |\n",
      "|    policyGradLoss     | -0.0152     |\n",
      "|    value_loss         | 41.3        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 288          |\n",
      "|    iterations         | 5            |\n",
      "|    time_elapsed       | 142          |\n",
      "|    total_timesteps    | 1646592      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.03631723   |\n",
      "|    entropy_loss       | -2.42        |\n",
      "|    explained_variance | 0.329        |\n",
      "|    learning_rate      | 0.00025      |\n",
      "|    loss               | 2.29         |\n",
      "|    mean_step_reward   | -0.010588379 |\n",
      "|    n_updates          | 2000         |\n",
      "|    policyGradLoss     | -0.00862     |\n",
      "|    value_loss         | 17.2         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 283          |\n",
      "|    iterations         | 6            |\n",
      "|    time_elapsed       | 173          |\n",
      "|    total_timesteps    | 1654784      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.025925398  |\n",
      "|    entropy_loss       | -2.45        |\n",
      "|    explained_variance | 0.699        |\n",
      "|    learning_rate      | 0.00025      |\n",
      "|    loss               | 2.93         |\n",
      "|    mean_step_reward   | -0.009367676 |\n",
      "|    n_updates          | 2010         |\n",
      "|    policyGradLoss     | -0.00391     |\n",
      "|    value_loss         | 16.3         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 279           |\n",
      "|    iterations         | 7             |\n",
      "|    time_elapsed       | 204           |\n",
      "|    total_timesteps    | 1662976       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.024487955   |\n",
      "|    entropy_loss       | -2.45         |\n",
      "|    explained_variance | 0.239         |\n",
      "|    learning_rate      | 0.00025       |\n",
      "|    loss               | 1.22          |\n",
      "|    mean_step_reward   | -0.0099450685 |\n",
      "|    n_updates          | 2020          |\n",
      "|    policyGradLoss     | -0.00164      |\n",
      "|    value_loss         | 9.25          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 277          |\n",
      "|    iterations         | 8            |\n",
      "|    time_elapsed       | 236          |\n",
      "|    total_timesteps    | 1671168      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.034956053  |\n",
      "|    entropy_loss       | -2.45        |\n",
      "|    explained_variance | 0.846        |\n",
      "|    learning_rate      | 0.00025      |\n",
      "|    loss               | 0.917        |\n",
      "|    mean_step_reward   | -0.009078369 |\n",
      "|    n_updates          | 2030         |\n",
      "|    policyGradLoss     | -0.0118      |\n",
      "|    value_loss         | 8.26         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 275          |\n",
      "|    iterations         | 9            |\n",
      "|    time_elapsed       | 268          |\n",
      "|    total_timesteps    | 1679360      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.03846669   |\n",
      "|    entropy_loss       | -2.46        |\n",
      "|    explained_variance | 0.3          |\n",
      "|    learning_rate      | 0.00025      |\n",
      "|    loss               | 2.36         |\n",
      "|    mean_step_reward   | -0.012951659 |\n",
      "|    n_updates          | 2040         |\n",
      "|    policyGradLoss     | -0.00343     |\n",
      "|    value_loss         | 16           |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 273          |\n",
      "|    iterations         | 10           |\n",
      "|    time_elapsed       | 299          |\n",
      "|    total_timesteps    | 1687552      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.025652373  |\n",
      "|    entropy_loss       | -2.46        |\n",
      "|    explained_variance | 0.706        |\n",
      "|    learning_rate      | 0.00025      |\n",
      "|    loss               | 1.17         |\n",
      "|    mean_step_reward   | -0.010372315 |\n",
      "|    n_updates          | 2050         |\n",
      "|    policyGradLoss     | -0.0068      |\n",
      "|    value_loss         | 9.17         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 272          |\n",
      "|    iterations         | 11           |\n",
      "|    time_elapsed       | 330          |\n",
      "|    total_timesteps    | 1695744      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.03761988   |\n",
      "|    entropy_loss       | -2.45        |\n",
      "|    explained_variance | 0.613        |\n",
      "|    learning_rate      | 0.00025      |\n",
      "|    loss               | 0.255        |\n",
      "|    mean_step_reward   | -0.010832519 |\n",
      "|    n_updates          | 2060         |\n",
      "|    policyGradLoss     | -0.00728     |\n",
      "|    value_loss         | 3.45         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 271          |\n",
      "|    iterations         | 12           |\n",
      "|    time_elapsed       | 361          |\n",
      "|    total_timesteps    | 1703936      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0489477    |\n",
      "|    entropy_loss       | -2.42        |\n",
      "|    explained_variance | 0.826        |\n",
      "|    learning_rate      | 0.00025      |\n",
      "|    loss               | 0.0197       |\n",
      "|    mean_step_reward   | -0.009682617 |\n",
      "|    n_updates          | 2070         |\n",
      "|    policyGradLoss     | -0.0142      |\n",
      "|    value_loss         | 1.86         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 270          |\n",
      "|    iterations         | 13           |\n",
      "|    time_elapsed       | 393          |\n",
      "|    total_timesteps    | 1712128      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0458436    |\n",
      "|    entropy_loss       | -2.44        |\n",
      "|    explained_variance | 0.235        |\n",
      "|    learning_rate      | 0.00025      |\n",
      "|    loss               | -0.079       |\n",
      "|    mean_step_reward   | -0.010583496 |\n",
      "|    n_updates          | 2080         |\n",
      "|    policyGradLoss     | -0.00422     |\n",
      "|    value_loss         | 1.19         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 270          |\n",
      "|    iterations         | 14           |\n",
      "|    time_elapsed       | 424          |\n",
      "|    total_timesteps    | 1720320      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.05475366   |\n",
      "|    entropy_loss       | -2.45        |\n",
      "|    explained_variance | 0.874        |\n",
      "|    learning_rate      | 0.00025      |\n",
      "|    loss               | -0.0264      |\n",
      "|    mean_step_reward   | -0.010078125 |\n",
      "|    n_updates          | 2090         |\n",
      "|    policyGradLoss     | -0.00574     |\n",
      "|    value_loss         | 1.03         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 272          |\n",
      "|    iterations         | 15           |\n",
      "|    time_elapsed       | 451          |\n",
      "|    total_timesteps    | 1728512      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.010506514  |\n",
      "|    entropy_loss       | -2.46        |\n",
      "|    explained_variance | 0.937        |\n",
      "|    learning_rate      | 0.00025      |\n",
      "|    loss               | -0.0414      |\n",
      "|    mean_step_reward   | -0.010455322 |\n",
      "|    n_updates          | 2100         |\n",
      "|    policyGradLoss     | -0.00101     |\n",
      "|    value_loss         | 0.964        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 270          |\n",
      "|    iterations         | 16           |\n",
      "|    time_elapsed       | 484          |\n",
      "|    total_timesteps    | 1736704      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.029254217  |\n",
      "|    entropy_loss       | -2.46        |\n",
      "|    explained_variance | 0.865        |\n",
      "|    learning_rate      | 0.00025      |\n",
      "|    loss               | -0.0475      |\n",
      "|    mean_step_reward   | -0.012562256 |\n",
      "|    n_updates          | 2110         |\n",
      "|    policyGradLoss     | -0.00623     |\n",
      "|    value_loss         | 0.89         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 269          |\n",
      "|    iterations         | 17           |\n",
      "|    time_elapsed       | 517          |\n",
      "|    total_timesteps    | 1744896      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.020901684  |\n",
      "|    entropy_loss       | -2.44        |\n",
      "|    explained_variance | 0.917        |\n",
      "|    learning_rate      | 0.00025      |\n",
      "|    loss               | -0.164       |\n",
      "|    mean_step_reward   | -0.009467773 |\n",
      "|    n_updates          | 2120         |\n",
      "|    policyGradLoss     | -0.00614     |\n",
      "|    value_loss         | 0.397        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 268          |\n",
      "|    iterations         | 18           |\n",
      "|    time_elapsed       | 549          |\n",
      "|    total_timesteps    | 1753088      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.06384251   |\n",
      "|    entropy_loss       | -2.4         |\n",
      "|    explained_variance | 0.91         |\n",
      "|    learning_rate      | 0.00025      |\n",
      "|    loss               | -0.203       |\n",
      "|    mean_step_reward   | -0.009827881 |\n",
      "|    n_updates          | 2130         |\n",
      "|    policyGradLoss     | -0.0147      |\n",
      "|    value_loss         | 0.296        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 268         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 580         |\n",
      "|    total_timesteps    | 1761280     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.03569133  |\n",
      "|    entropy_loss       | -2.39       |\n",
      "|    explained_variance | 0.346       |\n",
      "|    learning_rate      | 0.00025     |\n",
      "|    loss               | -0.196      |\n",
      "|    mean_step_reward   | -0.00927002 |\n",
      "|    n_updates          | 2140        |\n",
      "|    policyGradLoss     | -0.00416    |\n",
      "|    value_loss         | 0.208       |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 267           |\n",
      "|    iterations         | 20            |\n",
      "|    time_elapsed       | 612           |\n",
      "|    total_timesteps    | 1769472       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.04983487    |\n",
      "|    entropy_loss       | -2.41         |\n",
      "|    explained_variance | 0.79          |\n",
      "|    learning_rate      | 0.00025       |\n",
      "|    loss               | -0.225        |\n",
      "|    mean_step_reward   | -0.0103808595 |\n",
      "|    n_updates          | 2150          |\n",
      "|    policyGradLoss     | -0.0142       |\n",
      "|    value_loss         | 0.17          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 267          |\n",
      "|    iterations         | 21           |\n",
      "|    time_elapsed       | 643          |\n",
      "|    total_timesteps    | 1777664      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.036387734  |\n",
      "|    entropy_loss       | -2.45        |\n",
      "|    explained_variance | 0.672        |\n",
      "|    learning_rate      | 0.00025      |\n",
      "|    loss               | -0.243       |\n",
      "|    mean_step_reward   | -0.008054199 |\n",
      "|    n_updates          | 2160         |\n",
      "|    policyGradLoss     | -0.0146      |\n",
      "|    value_loss         | 0.236        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 266           |\n",
      "|    iterations         | 22            |\n",
      "|    time_elapsed       | 675           |\n",
      "|    total_timesteps    | 1785856       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.044462226   |\n",
      "|    entropy_loss       | -2.42         |\n",
      "|    explained_variance | 0.825         |\n",
      "|    learning_rate      | 0.00025       |\n",
      "|    loss               | -0.154        |\n",
      "|    mean_step_reward   | -0.0067468267 |\n",
      "|    n_updates          | 2170          |\n",
      "|    policyGradLoss     | -0.0214       |\n",
      "|    value_loss         | 0.4           |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 266         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 706         |\n",
      "|    total_timesteps    | 1794048     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.08040351  |\n",
      "|    entropy_loss       | -2.37       |\n",
      "|    explained_variance | 0.734       |\n",
      "|    learning_rate      | 0.00025     |\n",
      "|    loss               | -0.306      |\n",
      "|    mean_step_reward   | -0.00982544 |\n",
      "|    n_updates          | 2180        |\n",
      "|    policyGradLoss     | -0.0398     |\n",
      "|    value_loss         | 0.0575      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 266          |\n",
      "|    iterations         | 24           |\n",
      "|    time_elapsed       | 737          |\n",
      "|    total_timesteps    | 1802240      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.049975343  |\n",
      "|    entropy_loss       | -2.39        |\n",
      "|    explained_variance | 0.551        |\n",
      "|    learning_rate      | 0.00025      |\n",
      "|    loss               | -0.292       |\n",
      "|    mean_step_reward   | -0.009616699 |\n",
      "|    n_updates          | 2190         |\n",
      "|    policyGradLoss     | -0.0149      |\n",
      "|    value_loss         | 0.241        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 266          |\n",
      "|    iterations         | 25           |\n",
      "|    time_elapsed       | 769          |\n",
      "|    total_timesteps    | 1810432      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0608323    |\n",
      "|    entropy_loss       | -2.37        |\n",
      "|    explained_variance | 0.254        |\n",
      "|    learning_rate      | 0.00025      |\n",
      "|    loss               | -0.246       |\n",
      "|    mean_step_reward   | -0.010504151 |\n",
      "|    n_updates          | 2200         |\n",
      "|    policyGradLoss     | -0.0225      |\n",
      "|    value_loss         | 0.054        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 265          |\n",
      "|    iterations         | 26           |\n",
      "|    time_elapsed       | 800          |\n",
      "|    total_timesteps    | 1818624      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.058819804  |\n",
      "|    entropy_loss       | -2.38        |\n",
      "|    explained_variance | 0.519        |\n",
      "|    learning_rate      | 0.00025      |\n",
      "|    loss               | -0.259       |\n",
      "|    mean_step_reward   | -0.010115966 |\n",
      "|    n_updates          | 2210         |\n",
      "|    policyGradLoss     | -0.032       |\n",
      "|    value_loss         | 0.0557       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 265          |\n",
      "|    iterations         | 27           |\n",
      "|    time_elapsed       | 832          |\n",
      "|    total_timesteps    | 1826816      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.12444189   |\n",
      "|    entropy_loss       | -2.31        |\n",
      "|    explained_variance | 0.643        |\n",
      "|    learning_rate      | 0.00025      |\n",
      "|    loss               | -0.326       |\n",
      "|    mean_step_reward   | -0.010150147 |\n",
      "|    n_updates          | 2220         |\n",
      "|    policyGradLoss     | -0.0606      |\n",
      "|    value_loss         | 0.0226       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 266          |\n",
      "|    iterations         | 28           |\n",
      "|    time_elapsed       | 860          |\n",
      "|    total_timesteps    | 1835008      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.06765291   |\n",
      "|    entropy_loss       | -2.34        |\n",
      "|    explained_variance | 0.521        |\n",
      "|    learning_rate      | 0.00025      |\n",
      "|    loss               | -0.235       |\n",
      "|    mean_step_reward   | -0.009605713 |\n",
      "|    n_updates          | 2230         |\n",
      "|    policyGradLoss     | -0.0178      |\n",
      "|    value_loss         | 0.0811       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 265          |\n",
      "|    iterations         | 29           |\n",
      "|    time_elapsed       | 893          |\n",
      "|    total_timesteps    | 1843200      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.100867264  |\n",
      "|    entropy_loss       | -2.35        |\n",
      "|    explained_variance | 0.765        |\n",
      "|    learning_rate      | 0.00025      |\n",
      "|    loss               | -0.304       |\n",
      "|    mean_step_reward   | -0.010072022 |\n",
      "|    n_updates          | 2240         |\n",
      "|    policyGradLoss     | -0.0454      |\n",
      "|    value_loss         | 0.0522       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 264           |\n",
      "|    iterations         | 30            |\n",
      "|    time_elapsed       | 929           |\n",
      "|    total_timesteps    | 1851392       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.079142615   |\n",
      "|    entropy_loss       | -2.33         |\n",
      "|    explained_variance | 0.838         |\n",
      "|    learning_rate      | 0.00025       |\n",
      "|    loss               | -0.296        |\n",
      "|    mean_step_reward   | -0.0072827153 |\n",
      "|    n_updates          | 2250          |\n",
      "|    policyGradLoss     | -0.0451       |\n",
      "|    value_loss         | 0.0908        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 264          |\n",
      "|    iterations         | 31           |\n",
      "|    time_elapsed       | 960          |\n",
      "|    total_timesteps    | 1859584      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.102038555  |\n",
      "|    entropy_loss       | -2.3         |\n",
      "|    explained_variance | 0.759        |\n",
      "|    learning_rate      | 0.00025      |\n",
      "|    loss               | -0.253       |\n",
      "|    mean_step_reward   | -0.003962403 |\n",
      "|    n_updates          | 2260         |\n",
      "|    policyGradLoss     | -0.0555      |\n",
      "|    value_loss         | 0.168        |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 264        |\n",
      "|    iterations         | 32         |\n",
      "|    time_elapsed       | 991        |\n",
      "|    total_timesteps    | 1867776    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.0955063  |\n",
      "|    entropy_loss       | -2.3       |\n",
      "|    explained_variance | 0.756      |\n",
      "|    learning_rate      | 0.00025    |\n",
      "|    loss               | -0.327     |\n",
      "|    mean_step_reward   | 0.00071289 |\n",
      "|    n_updates          | 2270       |\n",
      "|    policyGradLoss     | -0.0493    |\n",
      "|    value_loss         | 0.138      |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 264          |\n",
      "|    iterations         | 33           |\n",
      "|    time_elapsed       | 1023         |\n",
      "|    total_timesteps    | 1875968      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.1214922    |\n",
      "|    entropy_loss       | -2.29        |\n",
      "|    explained_variance | 0.747        |\n",
      "|    learning_rate      | 0.00025      |\n",
      "|    loss               | -0.279       |\n",
      "|    mean_step_reward   | 0.0048510735 |\n",
      "|    n_updates          | 2280         |\n",
      "|    policyGradLoss     | -0.0703      |\n",
      "|    value_loss         | 0.158        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 264         |\n",
      "|    iterations         | 34          |\n",
      "|    time_elapsed       | 1054        |\n",
      "|    total_timesteps    | 1884160     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.12695254  |\n",
      "|    entropy_loss       | -2.31       |\n",
      "|    explained_variance | 0.636       |\n",
      "|    learning_rate      | 0.00025     |\n",
      "|    loss               | -0.332      |\n",
      "|    mean_step_reward   | 0.004281006 |\n",
      "|    n_updates          | 2290        |\n",
      "|    policyGradLoss     | -0.0789     |\n",
      "|    value_loss         | 0.185       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 264         |\n",
      "|    iterations         | 35          |\n",
      "|    time_elapsed       | 1085        |\n",
      "|    total_timesteps    | 1892352     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.18668377  |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.816       |\n",
      "|    learning_rate      | 0.00025     |\n",
      "|    loss               | -0.39       |\n",
      "|    mean_step_reward   | -0.00314209 |\n",
      "|    n_updates          | 2300        |\n",
      "|    policyGradLoss     | -0.123      |\n",
      "|    value_loss         | 0.112       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 263         |\n",
      "|    iterations         | 36          |\n",
      "|    time_elapsed       | 1117        |\n",
      "|    total_timesteps    | 1900544     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.1416226   |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.721       |\n",
      "|    learning_rate      | 0.00025     |\n",
      "|    loss               | -0.265      |\n",
      "|    mean_step_reward   | 0.006517333 |\n",
      "|    n_updates          | 2310        |\n",
      "|    policyGradLoss     | -0.0796     |\n",
      "|    value_loss         | 0.243       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 263          |\n",
      "|    iterations         | 37           |\n",
      "|    time_elapsed       | 1148         |\n",
      "|    total_timesteps    | 1908736      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.1569309    |\n",
      "|    entropy_loss       | -2.28        |\n",
      "|    explained_variance | 0.817        |\n",
      "|    learning_rate      | 0.00025      |\n",
      "|    loss               | -0.331       |\n",
      "|    mean_step_reward   | -0.006940918 |\n",
      "|    n_updates          | 2320         |\n",
      "|    policyGradLoss     | -0.0832      |\n",
      "|    value_loss         | 0.111        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 263          |\n",
      "|    iterations         | 38           |\n",
      "|    time_elapsed       | 1180         |\n",
      "|    total_timesteps    | 1916928      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.123998836  |\n",
      "|    entropy_loss       | -2.29        |\n",
      "|    explained_variance | 0.805        |\n",
      "|    learning_rate      | 0.00025      |\n",
      "|    loss               | -0.292       |\n",
      "|    mean_step_reward   | -0.008233642 |\n",
      "|    n_updates          | 2330         |\n",
      "|    policyGradLoss     | -0.0632      |\n",
      "|    value_loss         | 0.158        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 263         |\n",
      "|    iterations         | 39          |\n",
      "|    time_elapsed       | 1212        |\n",
      "|    total_timesteps    | 1925120     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.12728204  |\n",
      "|    entropy_loss       | -2.3        |\n",
      "|    explained_variance | 0.752       |\n",
      "|    learning_rate      | 0.00025     |\n",
      "|    loss               | -0.261      |\n",
      "|    mean_step_reward   | 0.005727539 |\n",
      "|    n_updates          | 2340        |\n",
      "|    policyGradLoss     | -0.0718     |\n",
      "|    value_loss         | 0.25        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 263          |\n",
      "|    iterations         | 40           |\n",
      "|    time_elapsed       | 1243         |\n",
      "|    total_timesteps    | 1933312      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.124657184  |\n",
      "|    entropy_loss       | -2.28        |\n",
      "|    explained_variance | 0.78         |\n",
      "|    learning_rate      | 0.00025      |\n",
      "|    loss               | -0.333       |\n",
      "|    mean_step_reward   | 0.0074853506 |\n",
      "|    n_updates          | 2350         |\n",
      "|    policyGradLoss     | -0.0941      |\n",
      "|    value_loss         | 0.28         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 263         |\n",
      "|    iterations         | 41          |\n",
      "|    time_elapsed       | 1275        |\n",
      "|    total_timesteps    | 1941504     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.16159472  |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.738       |\n",
      "|    learning_rate      | 0.00025     |\n",
      "|    loss               | -0.296      |\n",
      "|    mean_step_reward   | 0.010725096 |\n",
      "|    n_updates          | 2360        |\n",
      "|    policyGradLoss     | -0.0928     |\n",
      "|    value_loss         | 0.343       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 263          |\n",
      "|    iterations         | 42           |\n",
      "|    time_elapsed       | 1306         |\n",
      "|    total_timesteps    | 1949696      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.12888578   |\n",
      "|    entropy_loss       | -2.28        |\n",
      "|    explained_variance | 0.633        |\n",
      "|    learning_rate      | 0.00025      |\n",
      "|    loss               | -0.318       |\n",
      "|    mean_step_reward   | 0.0022583012 |\n",
      "|    n_updates          | 2370         |\n",
      "|    policyGradLoss     | -0.0754      |\n",
      "|    value_loss         | 0.359        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 262          |\n",
      "|    iterations         | 43           |\n",
      "|    time_elapsed       | 1341         |\n",
      "|    total_timesteps    | 1957888      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.11952192   |\n",
      "|    entropy_loss       | -2.31        |\n",
      "|    explained_variance | 0.703        |\n",
      "|    learning_rate      | 0.00025      |\n",
      "|    loss               | -0.288       |\n",
      "|    mean_step_reward   | 0.0071398923 |\n",
      "|    n_updates          | 2380         |\n",
      "|    policyGradLoss     | -0.0856      |\n",
      "|    value_loss         | 0.319        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 262          |\n",
      "|    iterations         | 44           |\n",
      "|    time_elapsed       | 1372         |\n",
      "|    total_timesteps    | 1966080      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.1426667    |\n",
      "|    entropy_loss       | -2.3         |\n",
      "|    explained_variance | 0.696        |\n",
      "|    learning_rate      | 0.00025      |\n",
      "|    loss               | -0.286       |\n",
      "|    mean_step_reward   | -7.32427e-05 |\n",
      "|    n_updates          | 2390         |\n",
      "|    policyGradLoss     | -0.0874      |\n",
      "|    value_loss         | 0.255        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 262           |\n",
      "|    iterations         | 45            |\n",
      "|    time_elapsed       | 1404          |\n",
      "|    total_timesteps    | 1974272       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.13941537    |\n",
      "|    entropy_loss       | -2.29         |\n",
      "|    explained_variance | 0.642         |\n",
      "|    learning_rate      | 0.00025       |\n",
      "|    loss               | -0.348        |\n",
      "|    mean_step_reward   | 0.00084350596 |\n",
      "|    n_updates          | 2400          |\n",
      "|    policyGradLoss     | -0.0837       |\n",
      "|    value_loss         | 0.254         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 262          |\n",
      "|    iterations         | 46           |\n",
      "|    time_elapsed       | 1435         |\n",
      "|    total_timesteps    | 1982464      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.13818194   |\n",
      "|    entropy_loss       | -2.29        |\n",
      "|    explained_variance | 0.764        |\n",
      "|    learning_rate      | 0.00025      |\n",
      "|    loss               | -0.349       |\n",
      "|    mean_step_reward   | 0.0055249017 |\n",
      "|    n_updates          | 2410         |\n",
      "|    policyGradLoss     | -0.102       |\n",
      "|    value_loss         | 0.228        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 262          |\n",
      "|    iterations         | 47           |\n",
      "|    time_elapsed       | 1467         |\n",
      "|    total_timesteps    | 1990656      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.11935789   |\n",
      "|    entropy_loss       | -2.32        |\n",
      "|    explained_variance | 0.78         |\n",
      "|    learning_rate      | 0.00025      |\n",
      "|    loss               | -0.273       |\n",
      "|    mean_step_reward   | 0.0034814444 |\n",
      "|    n_updates          | 2420         |\n",
      "|    policyGradLoss     | -0.0801      |\n",
      "|    value_loss         | 0.236        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 262          |\n",
      "|    iterations         | 48           |\n",
      "|    time_elapsed       | 1498         |\n",
      "|    total_timesteps    | 1998848      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.13173059   |\n",
      "|    entropy_loss       | -2.31        |\n",
      "|    explained_variance | 0.74         |\n",
      "|    learning_rate      | 0.00025      |\n",
      "|    loss               | -0.341       |\n",
      "|    mean_step_reward   | 0.0022875972 |\n",
      "|    n_updates          | 2430         |\n",
      "|    policyGradLoss     | -0.0889      |\n",
      "|    value_loss         | 0.233        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 262           |\n",
      "|    iterations         | 49            |\n",
      "|    time_elapsed       | 1529          |\n",
      "|    total_timesteps    | 2007040       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.12862332    |\n",
      "|    entropy_loss       | -2.33         |\n",
      "|    explained_variance | 0.789         |\n",
      "|    learning_rate      | 0.00025       |\n",
      "|    loss               | -0.299        |\n",
      "|    mean_step_reward   | 0.00025634724 |\n",
      "|    n_updates          | 2440          |\n",
      "|    policyGradLoss     | -0.0798       |\n",
      "|    value_loss         | 0.145         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 262          |\n",
      "|    iterations         | 50           |\n",
      "|    time_elapsed       | 1560         |\n",
      "|    total_timesteps    | 2015232      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.14177111   |\n",
      "|    entropy_loss       | -2.32        |\n",
      "|    explained_variance | 0.706        |\n",
      "|    learning_rate      | 0.00025      |\n",
      "|    loss               | -0.388       |\n",
      "|    mean_step_reward   | -0.006728516 |\n",
      "|    n_updates          | 2450         |\n",
      "|    policyGradLoss     | -0.0949      |\n",
      "|    value_loss         | 0.133        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 262          |\n",
      "|    iterations         | 51           |\n",
      "|    time_elapsed       | 1591         |\n",
      "|    total_timesteps    | 2023424      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.18571573   |\n",
      "|    entropy_loss       | -2.29        |\n",
      "|    explained_variance | 0.782        |\n",
      "|    learning_rate      | 0.00025      |\n",
      "|    loss               | -0.352       |\n",
      "|    mean_step_reward   | -0.008876953 |\n",
      "|    n_updates          | 2460         |\n",
      "|    policyGradLoss     | -0.106       |\n",
      "|    value_loss         | 0.0724       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 262          |\n",
      "|    iterations         | 52           |\n",
      "|    time_elapsed       | 1622         |\n",
      "|    total_timesteps    | 2031616      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.15196285   |\n",
      "|    entropy_loss       | -2.26        |\n",
      "|    explained_variance | 0.723        |\n",
      "|    learning_rate      | 0.00025      |\n",
      "|    loss               | -0.363       |\n",
      "|    mean_step_reward   | -0.010092773 |\n",
      "|    n_updates          | 2470         |\n",
      "|    policyGradLoss     | -0.111       |\n",
      "|    value_loss         | 0.0668       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 262           |\n",
      "|    iterations         | 53            |\n",
      "|    time_elapsed       | 1653          |\n",
      "|    total_timesteps    | 2039808       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.27222598    |\n",
      "|    entropy_loss       | -2.22         |\n",
      "|    explained_variance | 0.929         |\n",
      "|    learning_rate      | 0.00025       |\n",
      "|    loss               | -0.445        |\n",
      "|    mean_step_reward   | -0.0066137696 |\n",
      "|    n_updates          | 2480          |\n",
      "|    policyGradLoss     | -0.16         |\n",
      "|    value_loss         | 0.0194        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 262          |\n",
      "|    iterations         | 54           |\n",
      "|    time_elapsed       | 1685         |\n",
      "|    total_timesteps    | 2048000      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.2125457    |\n",
      "|    entropy_loss       | -2.21        |\n",
      "|    explained_variance | 0.939        |\n",
      "|    learning_rate      | 0.00025      |\n",
      "|    loss               | -0.399       |\n",
      "|    mean_step_reward   | -0.006103516 |\n",
      "|    n_updates          | 2490         |\n",
      "|    policyGradLoss     | -0.108       |\n",
      "|    value_loss         | 0.0231       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 262           |\n",
      "|    iterations         | 55            |\n",
      "|    time_elapsed       | 1713          |\n",
      "|    total_timesteps    | 2056192       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.21572492    |\n",
      "|    entropy_loss       | -2.21         |\n",
      "|    explained_variance | 0.899         |\n",
      "|    learning_rate      | 0.00025       |\n",
      "|    loss               | -0.358        |\n",
      "|    mean_step_reward   | -0.0033215336 |\n",
      "|    n_updates          | 2500          |\n",
      "|    policyGradLoss     | -0.0977       |\n",
      "|    value_loss         | 0.0487        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 262          |\n",
      "|    iterations         | 56           |\n",
      "|    time_elapsed       | 1746         |\n",
      "|    total_timesteps    | 2064384      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.15406      |\n",
      "|    entropy_loss       | -2.3         |\n",
      "|    explained_variance | 0.845        |\n",
      "|    learning_rate      | 0.00025      |\n",
      "|    loss               | -0.36        |\n",
      "|    mean_step_reward   | 0.0042932117 |\n",
      "|    n_updates          | 2510         |\n",
      "|    policyGradLoss     | -0.0755      |\n",
      "|    value_loss         | 0.0803       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 262          |\n",
      "|    iterations         | 57           |\n",
      "|    time_elapsed       | 1778         |\n",
      "|    total_timesteps    | 2072576      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.15650575   |\n",
      "|    entropy_loss       | -2.27        |\n",
      "|    explained_variance | 0.805        |\n",
      "|    learning_rate      | 0.00025      |\n",
      "|    loss               | -0.351       |\n",
      "|    mean_step_reward   | 0.0029016105 |\n",
      "|    n_updates          | 2520         |\n",
      "|    policyGradLoss     | -0.111       |\n",
      "|    value_loss         | 0.144        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 262           |\n",
      "|    iterations         | 58            |\n",
      "|    time_elapsed       | 1810          |\n",
      "|    total_timesteps    | 2080768       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.22513047    |\n",
      "|    entropy_loss       | -2.22         |\n",
      "|    explained_variance | 0.751         |\n",
      "|    learning_rate      | 0.00025       |\n",
      "|    loss               | -0.418        |\n",
      "|    mean_step_reward   | 4.8826914e-06 |\n",
      "|    n_updates          | 2530          |\n",
      "|    policyGradLoss     | -0.15         |\n",
      "|    value_loss         | 0.137         |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 262        |\n",
      "|    iterations         | 59         |\n",
      "|    time_elapsed       | 1841       |\n",
      "|    total_timesteps    | 2088960    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.20573688 |\n",
      "|    entropy_loss       | -2.23      |\n",
      "|    explained_variance | 0.79       |\n",
      "|    learning_rate      | 0.00025    |\n",
      "|    loss               | -0.401     |\n",
      "|    mean_step_reward   | -0.00125   |\n",
      "|    n_updates          | 2540       |\n",
      "|    policyGradLoss     | -0.138     |\n",
      "|    value_loss         | 0.124      |\n",
      "--------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 262            |\n",
      "|    iterations         | 60             |\n",
      "|    time_elapsed       | 1873           |\n",
      "|    total_timesteps    | 2097152        |\n",
      "| train/                |                |\n",
      "|    approx_kl          | 0.19011939     |\n",
      "|    entropy_loss       | -2.26          |\n",
      "|    explained_variance | 0.835          |\n",
      "|    learning_rate      | 0.00025        |\n",
      "|    loss               | -0.365         |\n",
      "|    mean_step_reward   | -0.00035522494 |\n",
      "|    n_updates          | 2550           |\n",
      "|    policyGradLoss     | -0.114         |\n",
      "|    value_loss         | 0.132          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 262          |\n",
      "|    iterations         | 61           |\n",
      "|    time_elapsed       | 1904         |\n",
      "|    total_timesteps    | 2105344      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.18036723   |\n",
      "|    entropy_loss       | -2.28        |\n",
      "|    explained_variance | 0.689        |\n",
      "|    learning_rate      | 0.00025      |\n",
      "|    loss               | -0.325       |\n",
      "|    mean_step_reward   | 0.0023864738 |\n",
      "|    n_updates          | 2560         |\n",
      "|    policyGradLoss     | -0.0988      |\n",
      "|    value_loss         | 0.202        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 262         |\n",
      "|    iterations         | 62          |\n",
      "|    time_elapsed       | 1936        |\n",
      "|    total_timesteps    | 2113536     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.21202315  |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.792       |\n",
      "|    learning_rate      | 0.00025     |\n",
      "|    loss               | -0.393      |\n",
      "|    mean_step_reward   | 0.006890869 |\n",
      "|    n_updates          | 2570        |\n",
      "|    policyGradLoss     | -0.14       |\n",
      "|    value_loss         | 0.174       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 262         |\n",
      "|    iterations         | 63          |\n",
      "|    time_elapsed       | 1967        |\n",
      "|    total_timesteps    | 2121728     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.1664578   |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.709       |\n",
      "|    learning_rate      | 0.00025     |\n",
      "|    loss               | -0.356      |\n",
      "|    mean_step_reward   | 0.008496093 |\n",
      "|    n_updates          | 2580        |\n",
      "|    policyGradLoss     | -0.122      |\n",
      "|    value_loss         | 0.279       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 262         |\n",
      "|    iterations         | 64          |\n",
      "|    time_elapsed       | 1999        |\n",
      "|    total_timesteps    | 2129920     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.16911381  |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.785       |\n",
      "|    learning_rate      | 0.00025     |\n",
      "|    loss               | -0.364      |\n",
      "|    mean_step_reward   | 0.008686522 |\n",
      "|    n_updates          | 2590        |\n",
      "|    policyGradLoss     | -0.129      |\n",
      "|    value_loss         | 0.19        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 262          |\n",
      "|    iterations         | 65           |\n",
      "|    time_elapsed       | 2031         |\n",
      "|    total_timesteps    | 2138112      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.13581821   |\n",
      "|    entropy_loss       | -2.32        |\n",
      "|    explained_variance | 0.739        |\n",
      "|    learning_rate      | 0.00025      |\n",
      "|    loss               | -0.294       |\n",
      "|    mean_step_reward   | 0.0038171383 |\n",
      "|    n_updates          | 2600         |\n",
      "|    policyGradLoss     | -0.0843      |\n",
      "|    value_loss         | 0.256        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 262           |\n",
      "|    iterations         | 66            |\n",
      "|    time_elapsed       | 2062          |\n",
      "|    total_timesteps    | 2146304       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.13544323    |\n",
      "|    entropy_loss       | -2.33         |\n",
      "|    explained_variance | 0.723         |\n",
      "|    learning_rate      | 0.00025       |\n",
      "|    loss               | -0.299        |\n",
      "|    mean_step_reward   | -0.0028173835 |\n",
      "|    n_updates          | 2610          |\n",
      "|    policyGradLoss     | -0.0899       |\n",
      "|    value_loss         | 0.183         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 262          |\n",
      "|    iterations         | 67           |\n",
      "|    time_elapsed       | 2094         |\n",
      "|    total_timesteps    | 2154496      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.15756848   |\n",
      "|    entropy_loss       | -2.3         |\n",
      "|    explained_variance | 0.856        |\n",
      "|    learning_rate      | 0.00025      |\n",
      "|    loss               | -0.352       |\n",
      "|    mean_step_reward   | -0.004239502 |\n",
      "|    n_updates          | 2620         |\n",
      "|    policyGradLoss     | -0.104       |\n",
      "|    value_loss         | 0.0971       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 262           |\n",
      "|    iterations         | 68            |\n",
      "|    time_elapsed       | 2122          |\n",
      "|    total_timesteps    | 2162688       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.19639961    |\n",
      "|    entropy_loss       | -2.29         |\n",
      "|    explained_variance | 0.833         |\n",
      "|    learning_rate      | 0.00025       |\n",
      "|    loss               | -0.411        |\n",
      "|    mean_step_reward   | -0.0049487306 |\n",
      "|    n_updates          | 2630          |\n",
      "|    policyGradLoss     | -0.121        |\n",
      "|    value_loss         | 0.0779        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 262          |\n",
      "|    iterations         | 69           |\n",
      "|    time_elapsed       | 2155         |\n",
      "|    total_timesteps    | 2170880      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.19339073   |\n",
      "|    entropy_loss       | -2.3         |\n",
      "|    explained_variance | 0.819        |\n",
      "|    learning_rate      | 0.00025      |\n",
      "|    loss               | -0.342       |\n",
      "|    mean_step_reward   | -0.005123291 |\n",
      "|    n_updates          | 2640         |\n",
      "|    policyGradLoss     | -0.0998      |\n",
      "|    value_loss         | 0.0626       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 261         |\n",
      "|    iterations         | 70          |\n",
      "|    time_elapsed       | 2189        |\n",
      "|    total_timesteps    | 2179072     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.192188    |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.72        |\n",
      "|    learning_rate      | 0.00025     |\n",
      "|    loss               | -0.339      |\n",
      "|    mean_step_reward   | 0.007178955 |\n",
      "|    n_updates          | 2650        |\n",
      "|    policyGradLoss     | -0.116      |\n",
      "|    value_loss         | 0.222       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 261         |\n",
      "|    iterations         | 71          |\n",
      "|    time_elapsed       | 2221        |\n",
      "|    total_timesteps    | 2187264     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.19225764  |\n",
      "|    entropy_loss       | -2.27       |\n",
      "|    explained_variance | 0.737       |\n",
      "|    learning_rate      | 0.00025     |\n",
      "|    loss               | -0.381      |\n",
      "|    mean_step_reward   | 0.007094727 |\n",
      "|    n_updates          | 2660        |\n",
      "|    policyGradLoss     | -0.121      |\n",
      "|    value_loss         | 0.187       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 261         |\n",
      "|    iterations         | 72          |\n",
      "|    time_elapsed       | 2252        |\n",
      "|    total_timesteps    | 2195456     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.22025338  |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.752       |\n",
      "|    learning_rate      | 0.00025     |\n",
      "|    loss               | -0.371      |\n",
      "|    mean_step_reward   | 0.011225585 |\n",
      "|    n_updates          | 2670        |\n",
      "|    policyGradLoss     | -0.132      |\n",
      "|    value_loss         | 0.258       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 261          |\n",
      "|    iterations         | 73           |\n",
      "|    time_elapsed       | 2284         |\n",
      "|    total_timesteps    | 2203648      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.22917473   |\n",
      "|    entropy_loss       | -2.25        |\n",
      "|    explained_variance | 0.761        |\n",
      "|    learning_rate      | 0.00025      |\n",
      "|    loss               | -0.375       |\n",
      "|    mean_step_reward   | 0.0045117186 |\n",
      "|    n_updates          | 2680         |\n",
      "|    policyGradLoss     | -0.142       |\n",
      "|    value_loss         | 0.165        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 261         |\n",
      "|    iterations         | 74          |\n",
      "|    time_elapsed       | 2315        |\n",
      "|    total_timesteps    | 2211840     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.23302087  |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.776       |\n",
      "|    learning_rate      | 0.00025     |\n",
      "|    loss               | -0.395      |\n",
      "|    mean_step_reward   | 0.005927734 |\n",
      "|    n_updates          | 2690        |\n",
      "|    policyGradLoss     | -0.147      |\n",
      "|    value_loss         | 0.161       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 261         |\n",
      "|    iterations         | 75          |\n",
      "|    time_elapsed       | 2347        |\n",
      "|    total_timesteps    | 2220032     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.2197188   |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.738       |\n",
      "|    learning_rate      | 0.00025     |\n",
      "|    loss               | -0.403      |\n",
      "|    mean_step_reward   | 0.004943847 |\n",
      "|    n_updates          | 2700        |\n",
      "|    policyGradLoss     | -0.135      |\n",
      "|    value_loss         | 0.231       |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 261           |\n",
      "|    iterations         | 76            |\n",
      "|    time_elapsed       | 2378          |\n",
      "|    total_timesteps    | 2228224       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.24153051    |\n",
      "|    entropy_loss       | -2.27         |\n",
      "|    explained_variance | 0.66          |\n",
      "|    learning_rate      | 0.00025       |\n",
      "|    loss               | -0.412        |\n",
      "|    mean_step_reward   | -0.0039672847 |\n",
      "|    n_updates          | 2710          |\n",
      "|    policyGradLoss     | -0.149        |\n",
      "|    value_loss         | 0.129         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 261          |\n",
      "|    iterations         | 77           |\n",
      "|    time_elapsed       | 2410         |\n",
      "|    total_timesteps    | 2236416      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.24137104   |\n",
      "|    entropy_loss       | -2.28        |\n",
      "|    explained_variance | 0.686        |\n",
      "|    learning_rate      | 0.00025      |\n",
      "|    loss               | -0.382       |\n",
      "|    mean_step_reward   | 0.0019201657 |\n",
      "|    n_updates          | 2720         |\n",
      "|    policyGradLoss     | -0.115       |\n",
      "|    value_loss         | 0.16         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 261          |\n",
      "|    iterations         | 78           |\n",
      "|    time_elapsed       | 2441         |\n",
      "|    total_timesteps    | 2244608      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.21894038   |\n",
      "|    entropy_loss       | -2.26        |\n",
      "|    explained_variance | 0.732        |\n",
      "|    learning_rate      | 0.00025      |\n",
      "|    loss               | -0.365       |\n",
      "|    mean_step_reward   | 0.0017736815 |\n",
      "|    n_updates          | 2730         |\n",
      "|    policyGradLoss     | -0.142       |\n",
      "|    value_loss         | 0.133        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 261          |\n",
      "|    iterations         | 79           |\n",
      "|    time_elapsed       | 2472         |\n",
      "|    total_timesteps    | 2252800      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.19204752   |\n",
      "|    entropy_loss       | -2.27        |\n",
      "|    explained_variance | 0.676        |\n",
      "|    learning_rate      | 0.00025      |\n",
      "|    loss               | -0.354       |\n",
      "|    mean_step_reward   | 0.0022314452 |\n",
      "|    n_updates          | 2740         |\n",
      "|    policyGradLoss     | -0.129       |\n",
      "|    value_loss         | 0.233        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 261          |\n",
      "|    iterations         | 80           |\n",
      "|    time_elapsed       | 2504         |\n",
      "|    total_timesteps    | 2260992      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.21904254   |\n",
      "|    entropy_loss       | -2.27        |\n",
      "|    explained_variance | 0.704        |\n",
      "|    learning_rate      | 0.00025      |\n",
      "|    loss               | -0.406       |\n",
      "|    mean_step_reward   | 0.0008508301 |\n",
      "|    n_updates          | 2750         |\n",
      "|    policyGradLoss     | -0.13        |\n",
      "|    value_loss         | 0.18         |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/SF84PT_2255360.zip\n",
      "[EVAL] Mean Return: -1.910, Best Return: -1.910\n",
      "New best record. Saved to ./runs_smw/best_model.zip\n",
      "Saved video to ./runs_smw/videos/step_2255360_mean_-1.91.mp4\n",
      "\n",
      "=== Round 2 | Learn 655360 steps (Total trained: 2255360) ===\n",
      "Logging to ./runs_smw/tb/SF84_lRWD_PT_0\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 761     |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 10      |\n",
      "|    total_timesteps | 2269184 |\n",
      "--------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 376          |\n",
      "|    iterations         | 2            |\n",
      "|    time_elapsed       | 43           |\n",
      "|    total_timesteps    | 2277376      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.25835454   |\n",
      "|    entropy_loss       | -2.26        |\n",
      "|    explained_variance | 0.771        |\n",
      "|    learning_rate      | 0.00025      |\n",
      "|    loss               | -0.435       |\n",
      "|    mean_step_reward   | -0.006518555 |\n",
      "|    n_updates          | 2770         |\n",
      "|    policyGradLoss     | -0.154       |\n",
      "|    value_loss         | 0.0744       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 345           |\n",
      "|    iterations         | 3             |\n",
      "|    time_elapsed       | 71            |\n",
      "|    total_timesteps    | 2285568       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.23666993    |\n",
      "|    entropy_loss       | -2.28         |\n",
      "|    explained_variance | 0.69          |\n",
      "|    learning_rate      | 0.00025       |\n",
      "|    loss               | -0.389        |\n",
      "|    mean_step_reward   | -0.0020703129 |\n",
      "|    n_updates          | 2780          |\n",
      "|    policyGradLoss     | -0.12         |\n",
      "|    value_loss         | 0.0932        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 317          |\n",
      "|    iterations         | 4            |\n",
      "|    time_elapsed       | 103          |\n",
      "|    total_timesteps    | 2293760      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.19085181   |\n",
      "|    entropy_loss       | -2.29        |\n",
      "|    explained_variance | 0.727        |\n",
      "|    learning_rate      | 0.00025      |\n",
      "|    loss               | -0.361       |\n",
      "|    mean_step_reward   | 0.0064953603 |\n",
      "|    n_updates          | 2790         |\n",
      "|    policyGradLoss     | -0.113       |\n",
      "|    value_loss         | 0.189        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 304          |\n",
      "|    iterations         | 5            |\n",
      "|    time_elapsed       | 134          |\n",
      "|    total_timesteps    | 2301952      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.21691284   |\n",
      "|    entropy_loss       | -2.26        |\n",
      "|    explained_variance | 0.775        |\n",
      "|    learning_rate      | 0.00025      |\n",
      "|    loss               | -0.395       |\n",
      "|    mean_step_reward   | 0.0030651852 |\n",
      "|    n_updates          | 2800         |\n",
      "|    policyGradLoss     | -0.145       |\n",
      "|    value_loss         | 0.179        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 295          |\n",
      "|    iterations         | 6            |\n",
      "|    time_elapsed       | 166          |\n",
      "|    total_timesteps    | 2310144      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.21883619   |\n",
      "|    entropy_loss       | -2.27        |\n",
      "|    explained_variance | 0.73         |\n",
      "|    learning_rate      | 0.00025      |\n",
      "|    loss               | -0.382       |\n",
      "|    mean_step_reward   | 0.0062756334 |\n",
      "|    n_updates          | 2810         |\n",
      "|    policyGradLoss     | -0.136       |\n",
      "|    value_loss         | 0.208        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 289           |\n",
      "|    iterations         | 7             |\n",
      "|    time_elapsed       | 197           |\n",
      "|    total_timesteps    | 2318336       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.21417072    |\n",
      "|    entropy_loss       | -2.27         |\n",
      "|    explained_variance | 0.72          |\n",
      "|    learning_rate      | 0.00025       |\n",
      "|    loss               | -0.394        |\n",
      "|    mean_step_reward   | 0.00047729467 |\n",
      "|    n_updates          | 2820          |\n",
      "|    policyGradLoss     | -0.144        |\n",
      "|    value_loss         | 0.165         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 285          |\n",
      "|    iterations         | 8            |\n",
      "|    time_elapsed       | 229          |\n",
      "|    total_timesteps    | 2326528      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.20162949   |\n",
      "|    entropy_loss       | -2.26        |\n",
      "|    explained_variance | 0.796        |\n",
      "|    learning_rate      | 0.00025      |\n",
      "|    loss               | -0.405       |\n",
      "|    mean_step_reward   | 0.0039440906 |\n",
      "|    n_updates          | 2830         |\n",
      "|    policyGradLoss     | -0.138       |\n",
      "|    value_loss         | 0.127        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 281         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 261         |\n",
      "|    total_timesteps    | 2334720     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.2063699   |\n",
      "|    entropy_loss       | -2.28       |\n",
      "|    explained_variance | 0.735       |\n",
      "|    learning_rate      | 0.00025     |\n",
      "|    loss               | -0.363      |\n",
      "|    mean_step_reward   | 0.003862305 |\n",
      "|    n_updates          | 2840        |\n",
      "|    policyGradLoss     | -0.138      |\n",
      "|    value_loss         | 0.157       |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 279           |\n",
      "|    iterations         | 10            |\n",
      "|    time_elapsed       | 293           |\n",
      "|    total_timesteps    | 2342912       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.19704527    |\n",
      "|    entropy_loss       | -2.3          |\n",
      "|    explained_variance | 0.794         |\n",
      "|    learning_rate      | 0.00025       |\n",
      "|    loss               | -0.39         |\n",
      "|    mean_step_reward   | -0.0012463375 |\n",
      "|    n_updates          | 2850          |\n",
      "|    policyGradLoss     | -0.129        |\n",
      "|    value_loss         | 0.125         |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 277         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 325         |\n",
      "|    total_timesteps    | 2351104     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.20810965  |\n",
      "|    entropy_loss       | -2.3        |\n",
      "|    explained_variance | 0.789       |\n",
      "|    learning_rate      | 0.00025     |\n",
      "|    loss               | -0.379      |\n",
      "|    mean_step_reward   | 0.005666503 |\n",
      "|    n_updates          | 2860        |\n",
      "|    policyGradLoss     | -0.124      |\n",
      "|    value_loss         | 0.184       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 275          |\n",
      "|    iterations         | 12           |\n",
      "|    time_elapsed       | 356          |\n",
      "|    total_timesteps    | 2359296      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.2989669    |\n",
      "|    entropy_loss       | -2.27        |\n",
      "|    explained_variance | 0.669        |\n",
      "|    learning_rate      | 0.00025      |\n",
      "|    loss               | -0.456       |\n",
      "|    mean_step_reward   | -0.010654297 |\n",
      "|    n_updates          | 2870         |\n",
      "|    policyGradLoss     | -0.138       |\n",
      "|    value_loss         | 0.0854       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 274           |\n",
      "|    iterations         | 13            |\n",
      "|    time_elapsed       | 387           |\n",
      "|    total_timesteps    | 2367488       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.215594      |\n",
      "|    entropy_loss       | -2.29         |\n",
      "|    explained_variance | 0.625         |\n",
      "|    learning_rate      | 0.00025       |\n",
      "|    loss               | -0.388        |\n",
      "|    mean_step_reward   | -0.0011694338 |\n",
      "|    n_updates          | 2880          |\n",
      "|    policyGradLoss     | -0.107        |\n",
      "|    value_loss         | 0.119         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 273          |\n",
      "|    iterations         | 14           |\n",
      "|    time_elapsed       | 419          |\n",
      "|    total_timesteps    | 2375680      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.2249649    |\n",
      "|    entropy_loss       | -2.26        |\n",
      "|    explained_variance | 0.752        |\n",
      "|    learning_rate      | 0.00025      |\n",
      "|    loss               | -0.389       |\n",
      "|    mean_step_reward   | 0.0034228512 |\n",
      "|    n_updates          | 2890         |\n",
      "|    policyGradLoss     | -0.136       |\n",
      "|    value_loss         | 0.179        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 274          |\n",
      "|    iterations         | 15           |\n",
      "|    time_elapsed       | 447          |\n",
      "|    total_timesteps    | 2383872      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.25739846   |\n",
      "|    entropy_loss       | -2.27        |\n",
      "|    explained_variance | 0.775        |\n",
      "|    learning_rate      | 0.00025      |\n",
      "|    loss               | -0.417       |\n",
      "|    mean_step_reward   | 0.0040039057 |\n",
      "|    n_updates          | 2900         |\n",
      "|    policyGradLoss     | -0.158       |\n",
      "|    value_loss         | 0.151        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 272          |\n",
      "|    iterations         | 16           |\n",
      "|    time_elapsed       | 480          |\n",
      "|    total_timesteps    | 2392064      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.2674598    |\n",
      "|    entropy_loss       | -2.26        |\n",
      "|    explained_variance | 0.749        |\n",
      "|    learning_rate      | 0.00025      |\n",
      "|    loss               | -0.423       |\n",
      "|    mean_step_reward   | 0.0012499996 |\n",
      "|    n_updates          | 2910         |\n",
      "|    policyGradLoss     | -0.158       |\n",
      "|    value_loss         | 0.111        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 270          |\n",
      "|    iterations         | 17           |\n",
      "|    time_elapsed       | 515          |\n",
      "|    total_timesteps    | 2400256      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.24444571   |\n",
      "|    entropy_loss       | -2.28        |\n",
      "|    explained_variance | 0.753        |\n",
      "|    learning_rate      | 0.00025      |\n",
      "|    loss               | -0.399       |\n",
      "|    mean_step_reward   | 0.0013659665 |\n",
      "|    n_updates          | 2920         |\n",
      "|    policyGradLoss     | -0.142       |\n",
      "|    value_loss         | 0.168        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 269         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 547         |\n",
      "|    total_timesteps    | 2408448     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.24234508  |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.761       |\n",
      "|    learning_rate      | 0.00025     |\n",
      "|    loss               | -0.388      |\n",
      "|    mean_step_reward   | 0.007547607 |\n",
      "|    n_updates          | 2930        |\n",
      "|    policyGradLoss     | -0.152      |\n",
      "|    value_loss         | 0.202       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 268          |\n",
      "|    iterations         | 19           |\n",
      "|    time_elapsed       | 578          |\n",
      "|    total_timesteps    | 2416640      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.24421385   |\n",
      "|    entropy_loss       | -2.28        |\n",
      "|    explained_variance | 0.764        |\n",
      "|    learning_rate      | 0.00025      |\n",
      "|    loss               | -0.387       |\n",
      "|    mean_step_reward   | 0.0071020504 |\n",
      "|    n_updates          | 2940         |\n",
      "|    policyGradLoss     | -0.142       |\n",
      "|    value_loss         | 0.173        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 268         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 610         |\n",
      "|    total_timesteps    | 2424832     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.21998999  |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.808       |\n",
      "|    learning_rate      | 0.00025     |\n",
      "|    loss               | -0.387      |\n",
      "|    mean_step_reward   | 0.012614746 |\n",
      "|    n_updates          | 2950        |\n",
      "|    policyGradLoss     | -0.153      |\n",
      "|    value_loss         | 0.267       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 267         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 642         |\n",
      "|    total_timesteps    | 2433024     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.22667205  |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.781       |\n",
      "|    learning_rate      | 0.00025     |\n",
      "|    loss               | -0.389      |\n",
      "|    mean_step_reward   | 0.010415038 |\n",
      "|    n_updates          | 2960        |\n",
      "|    policyGradLoss     | -0.154      |\n",
      "|    value_loss         | 0.317       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 267        |\n",
      "|    iterations         | 22         |\n",
      "|    time_elapsed       | 673        |\n",
      "|    total_timesteps    | 2441216    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.26207757 |\n",
      "|    entropy_loss       | -2.28      |\n",
      "|    explained_variance | 0.77       |\n",
      "|    learning_rate      | 0.00025    |\n",
      "|    loss               | -0.411     |\n",
      "|    mean_step_reward   | 0.00369873 |\n",
      "|    n_updates          | 2970       |\n",
      "|    policyGradLoss     | -0.157     |\n",
      "|    value_loss         | 0.171      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 267         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 705         |\n",
      "|    total_timesteps    | 2449408     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.27539304  |\n",
      "|    entropy_loss       | -2.27       |\n",
      "|    explained_variance | 0.723       |\n",
      "|    learning_rate      | 0.00025     |\n",
      "|    loss               | -0.458      |\n",
      "|    mean_step_reward   | -0.00194458 |\n",
      "|    n_updates          | 2980        |\n",
      "|    policyGradLoss     | -0.162      |\n",
      "|    value_loss         | 0.152       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 266          |\n",
      "|    iterations         | 24           |\n",
      "|    time_elapsed       | 736          |\n",
      "|    total_timesteps    | 2457600      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.3156969    |\n",
      "|    entropy_loss       | -2.26        |\n",
      "|    explained_variance | 0.737        |\n",
      "|    learning_rate      | 0.00025      |\n",
      "|    loss               | -0.439       |\n",
      "|    mean_step_reward   | -0.003765869 |\n",
      "|    n_updates          | 2990         |\n",
      "|    policyGradLoss     | -0.159       |\n",
      "|    value_loss         | 0.11         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 266          |\n",
      "|    iterations         | 25           |\n",
      "|    time_elapsed       | 768          |\n",
      "|    total_timesteps    | 2465792      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.2620343    |\n",
      "|    entropy_loss       | -2.27        |\n",
      "|    explained_variance | 0.51         |\n",
      "|    learning_rate      | 0.00025      |\n",
      "|    loss               | -0.382       |\n",
      "|    mean_step_reward   | -0.004321289 |\n",
      "|    n_updates          | 3000         |\n",
      "|    policyGradLoss     | -0.129       |\n",
      "|    value_loss         | 0.116        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 266          |\n",
      "|    iterations         | 26           |\n",
      "|    time_elapsed       | 799          |\n",
      "|    total_timesteps    | 2473984      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.24838692   |\n",
      "|    entropy_loss       | -2.29        |\n",
      "|    explained_variance | 0.758        |\n",
      "|    learning_rate      | 0.00025      |\n",
      "|    loss               | -0.401       |\n",
      "|    mean_step_reward   | 0.0005029291 |\n",
      "|    n_updates          | 3010         |\n",
      "|    policyGradLoss     | -0.133       |\n",
      "|    value_loss         | 0.129        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 266           |\n",
      "|    iterations         | 27            |\n",
      "|    time_elapsed       | 830           |\n",
      "|    total_timesteps    | 2482176       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.24268422    |\n",
      "|    entropy_loss       | -2.28         |\n",
      "|    explained_variance | 0.705         |\n",
      "|    learning_rate      | 0.00025       |\n",
      "|    loss               | -0.454        |\n",
      "|    mean_step_reward   | -0.0037451168 |\n",
      "|    n_updates          | 3020          |\n",
      "|    policyGradLoss     | -0.152        |\n",
      "|    value_loss         | 0.121         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 266            |\n",
      "|    iterations         | 28             |\n",
      "|    time_elapsed       | 860            |\n",
      "|    total_timesteps    | 2490368        |\n",
      "| train/                |                |\n",
      "|    approx_kl          | 0.21864572     |\n",
      "|    entropy_loss       | -2.31          |\n",
      "|    explained_variance | 0.768          |\n",
      "|    learning_rate      | 0.00025        |\n",
      "|    loss               | -0.381         |\n",
      "|    mean_step_reward   | -0.00035888678 |\n",
      "|    n_updates          | 3030           |\n",
      "|    policyGradLoss     | -0.131         |\n",
      "|    value_loss         | 0.122          |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 265         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 893         |\n",
      "|    total_timesteps    | 2498560     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.2172684   |\n",
      "|    entropy_loss       | -2.29       |\n",
      "|    explained_variance | 0.787       |\n",
      "|    learning_rate      | 0.00025     |\n",
      "|    loss               | -0.399      |\n",
      "|    mean_step_reward   | 0.011188963 |\n",
      "|    n_updates          | 3040        |\n",
      "|    policyGradLoss     | -0.135      |\n",
      "|    value_loss         | 0.236       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 264          |\n",
      "|    iterations         | 30           |\n",
      "|    time_elapsed       | 930          |\n",
      "|    total_timesteps    | 2506752      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.2266153    |\n",
      "|    entropy_loss       | -2.29        |\n",
      "|    explained_variance | 0.629        |\n",
      "|    learning_rate      | 0.00025      |\n",
      "|    loss               | -0.388       |\n",
      "|    mean_step_reward   | -0.003994141 |\n",
      "|    n_updates          | 3050         |\n",
      "|    policyGradLoss     | -0.139       |\n",
      "|    value_loss         | 0.201        |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 264            |\n",
      "|    iterations         | 31             |\n",
      "|    time_elapsed       | 961            |\n",
      "|    total_timesteps    | 2514944        |\n",
      "| train/                |                |\n",
      "|    approx_kl          | 0.26628998     |\n",
      "|    entropy_loss       | -2.26          |\n",
      "|    explained_variance | 0.791          |\n",
      "|    learning_rate      | 0.00025        |\n",
      "|    loss               | -0.45          |\n",
      "|    mean_step_reward   | -0.00017334044 |\n",
      "|    n_updates          | 3060           |\n",
      "|    policyGradLoss     | -0.169         |\n",
      "|    value_loss         | 0.107          |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 264         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 992         |\n",
      "|    total_timesteps    | 2523136     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.20839341  |\n",
      "|    entropy_loss       | -2.27       |\n",
      "|    explained_variance | 0.772       |\n",
      "|    learning_rate      | 0.00025     |\n",
      "|    loss               | -0.361      |\n",
      "|    mean_step_reward   | 0.001522216 |\n",
      "|    n_updates          | 3070        |\n",
      "|    policyGradLoss     | -0.141      |\n",
      "|    value_loss         | 0.191       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 264          |\n",
      "|    iterations         | 33           |\n",
      "|    time_elapsed       | 1023         |\n",
      "|    total_timesteps    | 2531328      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.21996811   |\n",
      "|    entropy_loss       | -2.29        |\n",
      "|    explained_variance | 0.762        |\n",
      "|    learning_rate      | 0.00025      |\n",
      "|    loss               | -0.39        |\n",
      "|    mean_step_reward   | 0.0064001465 |\n",
      "|    n_updates          | 3080         |\n",
      "|    policyGradLoss     | -0.146       |\n",
      "|    value_loss         | 0.197        |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 263            |\n",
      "|    iterations         | 34             |\n",
      "|    time_elapsed       | 1055           |\n",
      "|    total_timesteps    | 2539520        |\n",
      "| train/                |                |\n",
      "|    approx_kl          | 0.24034116     |\n",
      "|    entropy_loss       | -2.3           |\n",
      "|    explained_variance | 0.764          |\n",
      "|    learning_rate      | 0.00025        |\n",
      "|    loss               | -0.394         |\n",
      "|    mean_step_reward   | -0.00055175746 |\n",
      "|    n_updates          | 3090           |\n",
      "|    policyGradLoss     | -0.15          |\n",
      "|    value_loss         | 0.127          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 263          |\n",
      "|    iterations         | 35           |\n",
      "|    time_elapsed       | 1087         |\n",
      "|    total_timesteps    | 2547712      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.2672071    |\n",
      "|    entropy_loss       | -2.26        |\n",
      "|    explained_variance | 0.66         |\n",
      "|    learning_rate      | 0.00025      |\n",
      "|    loss               | -0.42        |\n",
      "|    mean_step_reward   | 0.0108850105 |\n",
      "|    n_updates          | 3100         |\n",
      "|    policyGradLoss     | -0.164       |\n",
      "|    value_loss         | 0.267        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 263         |\n",
      "|    iterations         | 36          |\n",
      "|    time_elapsed       | 1119        |\n",
      "|    total_timesteps    | 2555904     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.26352024  |\n",
      "|    entropy_loss       | -2.28       |\n",
      "|    explained_variance | 0.716       |\n",
      "|    learning_rate      | 0.00025     |\n",
      "|    loss               | -0.408      |\n",
      "|    mean_step_reward   | 0.011671143 |\n",
      "|    n_updates          | 3110        |\n",
      "|    policyGradLoss     | -0.161      |\n",
      "|    value_loss         | 0.23        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 263         |\n",
      "|    iterations         | 37          |\n",
      "|    time_elapsed       | 1150        |\n",
      "|    total_timesteps    | 2564096     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.25940478  |\n",
      "|    entropy_loss       | -2.28       |\n",
      "|    explained_variance | 0.696       |\n",
      "|    learning_rate      | 0.00025     |\n",
      "|    loss               | -0.422      |\n",
      "|    mean_step_reward   | 0.004360351 |\n",
      "|    n_updates          | 3120        |\n",
      "|    policyGradLoss     | -0.16       |\n",
      "|    value_loss         | 0.188       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 263          |\n",
      "|    iterations         | 38           |\n",
      "|    time_elapsed       | 1182         |\n",
      "|    total_timesteps    | 2572288      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.2588092    |\n",
      "|    entropy_loss       | -2.3         |\n",
      "|    explained_variance | 0.755        |\n",
      "|    learning_rate      | 0.00025      |\n",
      "|    loss               | -0.395       |\n",
      "|    mean_step_reward   | 0.0040319823 |\n",
      "|    n_updates          | 3130         |\n",
      "|    policyGradLoss     | -0.151       |\n",
      "|    value_loss         | 0.152        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 263           |\n",
      "|    iterations         | 39            |\n",
      "|    time_elapsed       | 1213          |\n",
      "|    total_timesteps    | 2580480       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.2341012     |\n",
      "|    entropy_loss       | -2.3          |\n",
      "|    explained_variance | 0.771         |\n",
      "|    learning_rate      | 0.00025       |\n",
      "|    loss               | -0.372        |\n",
      "|    mean_step_reward   | 0.00031005836 |\n",
      "|    n_updates          | 3140          |\n",
      "|    policyGradLoss     | -0.151        |\n",
      "|    value_loss         | 0.185         |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 263         |\n",
      "|    iterations         | 40          |\n",
      "|    time_elapsed       | 1245        |\n",
      "|    total_timesteps    | 2588672     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.24093616  |\n",
      "|    entropy_loss       | -2.27       |\n",
      "|    explained_variance | 0.761       |\n",
      "|    learning_rate      | 0.00025     |\n",
      "|    loss               | -0.387      |\n",
      "|    mean_step_reward   | 0.010413818 |\n",
      "|    n_updates          | 3150        |\n",
      "|    policyGradLoss     | -0.157      |\n",
      "|    value_loss         | 0.265       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 263          |\n",
      "|    iterations         | 41           |\n",
      "|    time_elapsed       | 1276         |\n",
      "|    total_timesteps    | 2596864      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.24927354   |\n",
      "|    entropy_loss       | -2.27        |\n",
      "|    explained_variance | 0.787        |\n",
      "|    learning_rate      | 0.00025      |\n",
      "|    loss               | -0.38        |\n",
      "|    mean_step_reward   | 0.0023999014 |\n",
      "|    n_updates          | 3160         |\n",
      "|    policyGradLoss     | -0.153       |\n",
      "|    value_loss         | 0.208        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 263          |\n",
      "|    iterations         | 42           |\n",
      "|    time_elapsed       | 1307         |\n",
      "|    total_timesteps    | 2605056      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.28265387   |\n",
      "|    entropy_loss       | -2.26        |\n",
      "|    explained_variance | 0.753        |\n",
      "|    learning_rate      | 0.00025      |\n",
      "|    loss               | -0.434       |\n",
      "|    mean_step_reward   | 0.0074682618 |\n",
      "|    n_updates          | 3170         |\n",
      "|    policyGradLoss     | -0.179       |\n",
      "|    value_loss         | 0.184        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 262          |\n",
      "|    iterations         | 43           |\n",
      "|    time_elapsed       | 1342         |\n",
      "|    total_timesteps    | 2613248      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.27397147   |\n",
      "|    entropy_loss       | -2.27        |\n",
      "|    explained_variance | 0.751        |\n",
      "|    learning_rate      | 0.00025      |\n",
      "|    loss               | -0.423       |\n",
      "|    mean_step_reward   | 0.0071813953 |\n",
      "|    n_updates          | 3180         |\n",
      "|    policyGradLoss     | -0.159       |\n",
      "|    value_loss         | 0.194        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 262         |\n",
      "|    iterations         | 44          |\n",
      "|    time_elapsed       | 1374        |\n",
      "|    total_timesteps    | 2621440     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.24466918  |\n",
      "|    entropy_loss       | -2.27       |\n",
      "|    explained_variance | 0.751       |\n",
      "|    learning_rate      | 0.00025     |\n",
      "|    loss               | -0.431      |\n",
      "|    mean_step_reward   | 0.007451172 |\n",
      "|    n_updates          | 3190        |\n",
      "|    policyGradLoss     | -0.161      |\n",
      "|    value_loss         | 0.235       |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 262       |\n",
      "|    iterations         | 45        |\n",
      "|    time_elapsed       | 1405      |\n",
      "|    total_timesteps    | 2629632   |\n",
      "| train/                |           |\n",
      "|    approx_kl          | 0.2501357 |\n",
      "|    entropy_loss       | -2.27     |\n",
      "|    explained_variance | 0.686     |\n",
      "|    learning_rate      | 0.00025   |\n",
      "|    loss               | -0.43     |\n",
      "|    mean_step_reward   | 0.0110083 |\n",
      "|    n_updates          | 3200      |\n",
      "|    policyGradLoss     | -0.168    |\n",
      "|    value_loss         | 0.251     |\n",
      "-------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 262          |\n",
      "|    iterations         | 46           |\n",
      "|    time_elapsed       | 1437         |\n",
      "|    total_timesteps    | 2637824      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.25421304   |\n",
      "|    entropy_loss       | -2.28        |\n",
      "|    explained_variance | 0.763        |\n",
      "|    learning_rate      | 0.00025      |\n",
      "|    loss               | -0.416       |\n",
      "|    mean_step_reward   | 0.0016186526 |\n",
      "|    n_updates          | 3210         |\n",
      "|    policyGradLoss     | -0.165       |\n",
      "|    value_loss         | 0.16         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 262         |\n",
      "|    iterations         | 47          |\n",
      "|    time_elapsed       | 1468        |\n",
      "|    total_timesteps    | 2646016     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.28144738  |\n",
      "|    entropy_loss       | -2.29       |\n",
      "|    explained_variance | 0.72        |\n",
      "|    learning_rate      | 0.00025     |\n",
      "|    loss               | -0.452      |\n",
      "|    mean_step_reward   | 0.003040771 |\n",
      "|    n_updates          | 3220        |\n",
      "|    policyGradLoss     | -0.183      |\n",
      "|    value_loss         | 0.154       |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 262           |\n",
      "|    iterations         | 48            |\n",
      "|    time_elapsed       | 1500          |\n",
      "|    total_timesteps    | 2654208       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.25882748    |\n",
      "|    entropy_loss       | -2.29         |\n",
      "|    explained_variance | 0.758         |\n",
      "|    learning_rate      | 0.00025       |\n",
      "|    loss               | -0.445        |\n",
      "|    mean_step_reward   | -0.0019262688 |\n",
      "|    n_updates          | 3230          |\n",
      "|    policyGradLoss     | -0.169        |\n",
      "|    value_loss         | 0.096         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 262          |\n",
      "|    iterations         | 49           |\n",
      "|    time_elapsed       | 1531         |\n",
      "|    total_timesteps    | 2662400      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.26492923   |\n",
      "|    entropy_loss       | -2.28        |\n",
      "|    explained_variance | 0.696        |\n",
      "|    learning_rate      | 0.00025      |\n",
      "|    loss               | -0.418       |\n",
      "|    mean_step_reward   | 0.0038415527 |\n",
      "|    n_updates          | 3240         |\n",
      "|    policyGradLoss     | -0.161       |\n",
      "|    value_loss         | 0.236        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 262         |\n",
      "|    iterations         | 50          |\n",
      "|    time_elapsed       | 1563        |\n",
      "|    total_timesteps    | 2670592     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.27733076  |\n",
      "|    entropy_loss       | -2.27       |\n",
      "|    explained_variance | 0.703       |\n",
      "|    learning_rate      | 0.00025     |\n",
      "|    loss               | -0.408      |\n",
      "|    mean_step_reward   | 0.008115234 |\n",
      "|    n_updates          | 3250        |\n",
      "|    policyGradLoss     | -0.171      |\n",
      "|    value_loss         | 0.211       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 261         |\n",
      "|    iterations         | 51          |\n",
      "|    time_elapsed       | 1594        |\n",
      "|    total_timesteps    | 2678784     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.2960861   |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.714       |\n",
      "|    learning_rate      | 0.00025     |\n",
      "|    loss               | -0.403      |\n",
      "|    mean_step_reward   | 0.004659423 |\n",
      "|    n_updates          | 3260        |\n",
      "|    policyGradLoss     | -0.174      |\n",
      "|    value_loss         | 0.2         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 261         |\n",
      "|    iterations         | 52          |\n",
      "|    time_elapsed       | 1626        |\n",
      "|    total_timesteps    | 2686976     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.24398038  |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.756       |\n",
      "|    learning_rate      | 0.00025     |\n",
      "|    loss               | -0.406      |\n",
      "|    mean_step_reward   | 0.002862548 |\n",
      "|    n_updates          | 3270        |\n",
      "|    policyGradLoss     | -0.165      |\n",
      "|    value_loss         | 0.212       |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 261           |\n",
      "|    iterations         | 53            |\n",
      "|    time_elapsed       | 1657          |\n",
      "|    total_timesteps    | 2695168       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.3188206     |\n",
      "|    entropy_loss       | -2.26         |\n",
      "|    explained_variance | 0.712         |\n",
      "|    learning_rate      | 0.00025       |\n",
      "|    loss               | -0.425        |\n",
      "|    mean_step_reward   | -0.0037927246 |\n",
      "|    n_updates          | 3280          |\n",
      "|    policyGradLoss     | -0.17         |\n",
      "|    value_loss         | 0.126         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 261          |\n",
      "|    iterations         | 54           |\n",
      "|    time_elapsed       | 1689         |\n",
      "|    total_timesteps    | 2703360      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.25632662   |\n",
      "|    entropy_loss       | -2.29        |\n",
      "|    explained_variance | 0.712        |\n",
      "|    learning_rate      | 0.00025      |\n",
      "|    loss               | -0.399       |\n",
      "|    mean_step_reward   | 0.0022375486 |\n",
      "|    n_updates          | 3290         |\n",
      "|    policyGradLoss     | -0.153       |\n",
      "|    value_loss         | 0.148        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 262         |\n",
      "|    iterations         | 55          |\n",
      "|    time_elapsed       | 1718        |\n",
      "|    total_timesteps    | 2711552     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.27360815  |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.748       |\n",
      "|    learning_rate      | 0.00025     |\n",
      "|    loss               | -0.397      |\n",
      "|    mean_step_reward   | 0.009697265 |\n",
      "|    n_updates          | 3300        |\n",
      "|    policyGradLoss     | -0.163      |\n",
      "|    value_loss         | 0.236       |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 261            |\n",
      "|    iterations         | 56             |\n",
      "|    time_elapsed       | 1751           |\n",
      "|    total_timesteps    | 2719744        |\n",
      "| train/                |                |\n",
      "|    approx_kl          | 0.21945779     |\n",
      "|    entropy_loss       | -2.28          |\n",
      "|    explained_variance | 0.672          |\n",
      "|    learning_rate      | 0.00025        |\n",
      "|    loss               | -0.371         |\n",
      "|    mean_step_reward   | -0.00024292013 |\n",
      "|    n_updates          | 3310           |\n",
      "|    policyGradLoss     | -0.148         |\n",
      "|    value_loss         | 0.207          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 261           |\n",
      "|    iterations         | 57            |\n",
      "|    time_elapsed       | 1782          |\n",
      "|    total_timesteps    | 2727936       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.2695001     |\n",
      "|    entropy_loss       | -2.29         |\n",
      "|    explained_variance | 0.642         |\n",
      "|    learning_rate      | 0.00025       |\n",
      "|    loss               | -0.412        |\n",
      "|    mean_step_reward   | -0.0018603518 |\n",
      "|    n_updates          | 3320          |\n",
      "|    policyGradLoss     | -0.158        |\n",
      "|    value_loss         | 0.135         |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 261        |\n",
      "|    iterations         | 58         |\n",
      "|    time_elapsed       | 1814       |\n",
      "|    total_timesteps    | 2736128    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.27601492 |\n",
      "|    entropy_loss       | -2.28      |\n",
      "|    explained_variance | 0.733      |\n",
      "|    learning_rate      | 0.00025    |\n",
      "|    loss               | -0.409     |\n",
      "|    mean_step_reward   | 0.00915161 |\n",
      "|    n_updates          | 3330       |\n",
      "|    policyGradLoss     | -0.163     |\n",
      "|    value_loss         | 0.189      |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 261          |\n",
      "|    iterations         | 59           |\n",
      "|    time_elapsed       | 1845         |\n",
      "|    total_timesteps    | 2744320      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.29167348   |\n",
      "|    entropy_loss       | -2.26        |\n",
      "|    explained_variance | 0.744        |\n",
      "|    learning_rate      | 0.00025      |\n",
      "|    loss               | -0.432       |\n",
      "|    mean_step_reward   | 0.0035473625 |\n",
      "|    n_updates          | 3340         |\n",
      "|    policyGradLoss     | -0.162       |\n",
      "|    value_loss         | 0.158        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 261          |\n",
      "|    iterations         | 60           |\n",
      "|    time_elapsed       | 1877         |\n",
      "|    total_timesteps    | 2752512      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.23962456   |\n",
      "|    entropy_loss       | -2.31        |\n",
      "|    explained_variance | 0.789        |\n",
      "|    learning_rate      | 0.00025      |\n",
      "|    loss               | -0.404       |\n",
      "|    mean_step_reward   | 0.0061059566 |\n",
      "|    n_updates          | 3350         |\n",
      "|    policyGradLoss     | -0.144       |\n",
      "|    value_loss         | 0.181        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 261         |\n",
      "|    iterations         | 61          |\n",
      "|    time_elapsed       | 1908        |\n",
      "|    total_timesteps    | 2760704     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.26129743  |\n",
      "|    entropy_loss       | -2.3        |\n",
      "|    explained_variance | 0.808       |\n",
      "|    learning_rate      | 0.00025     |\n",
      "|    loss               | -0.404      |\n",
      "|    mean_step_reward   | 0.006833496 |\n",
      "|    n_updates          | 3360        |\n",
      "|    policyGradLoss     | -0.151      |\n",
      "|    value_loss         | 0.192       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 261          |\n",
      "|    iterations         | 62           |\n",
      "|    time_elapsed       | 1940         |\n",
      "|    total_timesteps    | 2768896      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.25829887   |\n",
      "|    entropy_loss       | -2.3         |\n",
      "|    explained_variance | 0.767        |\n",
      "|    learning_rate      | 0.00025      |\n",
      "|    loss               | -0.415       |\n",
      "|    mean_step_reward   | 0.0059509273 |\n",
      "|    n_updates          | 3370         |\n",
      "|    policyGradLoss     | -0.153       |\n",
      "|    value_loss         | 0.162        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 261         |\n",
      "|    iterations         | 63          |\n",
      "|    time_elapsed       | 1971        |\n",
      "|    total_timesteps    | 2777088     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.25815845  |\n",
      "|    entropy_loss       | -2.29       |\n",
      "|    explained_variance | 0.679       |\n",
      "|    learning_rate      | 0.00025     |\n",
      "|    loss               | -0.382      |\n",
      "|    mean_step_reward   | 0.000854492 |\n",
      "|    n_updates          | 3380        |\n",
      "|    policyGradLoss     | -0.153      |\n",
      "|    value_loss         | 0.147       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 261          |\n",
      "|    iterations         | 64           |\n",
      "|    time_elapsed       | 2003         |\n",
      "|    total_timesteps    | 2785280      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.2592557    |\n",
      "|    entropy_loss       | -2.3         |\n",
      "|    explained_variance | 0.761        |\n",
      "|    learning_rate      | 0.00025      |\n",
      "|    loss               | -0.408       |\n",
      "|    mean_step_reward   | -0.000637207 |\n",
      "|    n_updates          | 3390         |\n",
      "|    policyGradLoss     | -0.161       |\n",
      "|    value_loss         | 0.13         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 261         |\n",
      "|    iterations         | 65          |\n",
      "|    time_elapsed       | 2034        |\n",
      "|    total_timesteps    | 2793472     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.26597065  |\n",
      "|    entropy_loss       | -2.29       |\n",
      "|    explained_variance | 0.723       |\n",
      "|    learning_rate      | 0.00025     |\n",
      "|    loss               | -0.402      |\n",
      "|    mean_step_reward   | 0.004494629 |\n",
      "|    n_updates          | 3400        |\n",
      "|    policyGradLoss     | -0.156      |\n",
      "|    value_loss         | 0.2         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 261         |\n",
      "|    iterations         | 66          |\n",
      "|    time_elapsed       | 2066        |\n",
      "|    total_timesteps    | 2801664     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.2856452   |\n",
      "|    entropy_loss       | -2.28       |\n",
      "|    explained_variance | 0.743       |\n",
      "|    learning_rate      | 0.00025     |\n",
      "|    loss               | -0.434      |\n",
      "|    mean_step_reward   | 0.003326416 |\n",
      "|    n_updates          | 3410        |\n",
      "|    policyGradLoss     | -0.17       |\n",
      "|    value_loss         | 0.163       |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 261           |\n",
      "|    iterations         | 67            |\n",
      "|    time_elapsed       | 2097          |\n",
      "|    total_timesteps    | 2809856       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.26648194    |\n",
      "|    entropy_loss       | -2.3          |\n",
      "|    explained_variance | 0.725         |\n",
      "|    learning_rate      | 0.00025       |\n",
      "|    loss               | -0.421        |\n",
      "|    mean_step_reward   | 0.00015014596 |\n",
      "|    n_updates          | 3420          |\n",
      "|    policyGradLoss     | -0.146        |\n",
      "|    value_loss         | 0.164         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 262           |\n",
      "|    iterations         | 68            |\n",
      "|    time_elapsed       | 2125          |\n",
      "|    total_timesteps    | 2818048       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.3010471     |\n",
      "|    entropy_loss       | -2.28         |\n",
      "|    explained_variance | 0.785         |\n",
      "|    learning_rate      | 0.00025       |\n",
      "|    loss               | -0.439        |\n",
      "|    mean_step_reward   | -0.0034289549 |\n",
      "|    n_updates          | 3430          |\n",
      "|    policyGradLoss     | -0.176        |\n",
      "|    value_loss         | 0.0691        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 261          |\n",
      "|    iterations         | 69           |\n",
      "|    time_elapsed       | 2158         |\n",
      "|    total_timesteps    | 2826240      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.28705832   |\n",
      "|    entropy_loss       | -2.29        |\n",
      "|    explained_variance | 0.745        |\n",
      "|    learning_rate      | 0.00025      |\n",
      "|    loss               | -0.438       |\n",
      "|    mean_step_reward   | 0.0013916016 |\n",
      "|    n_updates          | 3440         |\n",
      "|    policyGradLoss     | -0.156       |\n",
      "|    value_loss         | 0.107        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 261           |\n",
      "|    iterations         | 70            |\n",
      "|    time_elapsed       | 2193          |\n",
      "|    total_timesteps    | 2834432       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.29143766    |\n",
      "|    entropy_loss       | -2.28         |\n",
      "|    explained_variance | 0.808         |\n",
      "|    learning_rate      | 0.00025       |\n",
      "|    loss               | -0.394        |\n",
      "|    mean_step_reward   | -0.0034179692 |\n",
      "|    n_updates          | 3450          |\n",
      "|    policyGradLoss     | -0.17         |\n",
      "|    value_loss         | 0.0621        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 261          |\n",
      "|    iterations         | 71           |\n",
      "|    time_elapsed       | 2224         |\n",
      "|    total_timesteps    | 2842624      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.24073154   |\n",
      "|    entropy_loss       | -2.3         |\n",
      "|    explained_variance | 0.722        |\n",
      "|    learning_rate      | 0.00025      |\n",
      "|    loss               | -0.384       |\n",
      "|    mean_step_reward   | 0.0029882807 |\n",
      "|    n_updates          | 3460         |\n",
      "|    policyGradLoss     | -0.136       |\n",
      "|    value_loss         | 0.131        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 261          |\n",
      "|    iterations         | 72           |\n",
      "|    time_elapsed       | 2255         |\n",
      "|    total_timesteps    | 2850816      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.27303094   |\n",
      "|    entropy_loss       | -2.29        |\n",
      "|    explained_variance | 0.835        |\n",
      "|    learning_rate      | 0.00025      |\n",
      "|    loss               | -0.429       |\n",
      "|    mean_step_reward   | -0.000385742 |\n",
      "|    n_updates          | 3470         |\n",
      "|    policyGradLoss     | -0.152       |\n",
      "|    value_loss         | 0.0687       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 261           |\n",
      "|    iterations         | 73            |\n",
      "|    time_elapsed       | 2287          |\n",
      "|    total_timesteps    | 2859008       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.22141266    |\n",
      "|    entropy_loss       | -2.3          |\n",
      "|    explained_variance | 0.815         |\n",
      "|    learning_rate      | 0.00025       |\n",
      "|    loss               | -0.404        |\n",
      "|    mean_step_reward   | 0.00050048786 |\n",
      "|    n_updates          | 3480          |\n",
      "|    policyGradLoss     | -0.134        |\n",
      "|    value_loss         | 0.104         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 261           |\n",
      "|    iterations         | 74            |\n",
      "|    time_elapsed       | 2319          |\n",
      "|    total_timesteps    | 2867200       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.26102316    |\n",
      "|    entropy_loss       | -2.3          |\n",
      "|    explained_variance | 0.764         |\n",
      "|    learning_rate      | 0.00025       |\n",
      "|    loss               | -0.404        |\n",
      "|    mean_step_reward   | -0.0035803223 |\n",
      "|    n_updates          | 3490          |\n",
      "|    policyGradLoss     | -0.148        |\n",
      "|    value_loss         | 0.0773        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 261           |\n",
      "|    iterations         | 75            |\n",
      "|    time_elapsed       | 2351          |\n",
      "|    total_timesteps    | 2875392       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.24853322    |\n",
      "|    entropy_loss       | -2.3          |\n",
      "|    explained_variance | 0.771         |\n",
      "|    learning_rate      | 0.00025       |\n",
      "|    loss               | -0.41         |\n",
      "|    mean_step_reward   | -0.0022985842 |\n",
      "|    n_updates          | 3500          |\n",
      "|    policyGradLoss     | -0.143        |\n",
      "|    value_loss         | 0.0726        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 261           |\n",
      "|    iterations         | 76            |\n",
      "|    time_elapsed       | 2383          |\n",
      "|    total_timesteps    | 2883584       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.27001548    |\n",
      "|    entropy_loss       | -2.31         |\n",
      "|    explained_variance | 0.816         |\n",
      "|    learning_rate      | 0.00025       |\n",
      "|    loss               | -0.42         |\n",
      "|    mean_step_reward   | -0.0035058595 |\n",
      "|    n_updates          | 3510          |\n",
      "|    policyGradLoss     | -0.139        |\n",
      "|    value_loss         | 0.058         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 261           |\n",
      "|    iterations         | 77            |\n",
      "|    time_elapsed       | 2415          |\n",
      "|    total_timesteps    | 2891776       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.26538393    |\n",
      "|    entropy_loss       | -2.31         |\n",
      "|    explained_variance | 0.8           |\n",
      "|    learning_rate      | 0.00025       |\n",
      "|    loss               | -0.427        |\n",
      "|    mean_step_reward   | -0.0017895505 |\n",
      "|    n_updates          | 3520          |\n",
      "|    policyGradLoss     | -0.146        |\n",
      "|    value_loss         | 0.0789        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 261           |\n",
      "|    iterations         | 78            |\n",
      "|    time_elapsed       | 2446          |\n",
      "|    total_timesteps    | 2899968       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.24857095    |\n",
      "|    entropy_loss       | -2.31         |\n",
      "|    explained_variance | 0.791         |\n",
      "|    learning_rate      | 0.00025       |\n",
      "|    loss               | -0.408        |\n",
      "|    mean_step_reward   | -0.0023022466 |\n",
      "|    n_updates          | 3530          |\n",
      "|    policyGradLoss     | -0.144        |\n",
      "|    value_loss         | 0.0724        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 261          |\n",
      "|    iterations         | 79           |\n",
      "|    time_elapsed       | 2478         |\n",
      "|    total_timesteps    | 2908160      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.2450127    |\n",
      "|    entropy_loss       | -2.31        |\n",
      "|    explained_variance | 0.76         |\n",
      "|    learning_rate      | 0.00025      |\n",
      "|    loss               | -0.386       |\n",
      "|    mean_step_reward   | 0.0024975585 |\n",
      "|    n_updates          | 3540         |\n",
      "|    policyGradLoss     | -0.139       |\n",
      "|    value_loss         | 0.122        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 261          |\n",
      "|    iterations         | 80           |\n",
      "|    time_elapsed       | 2509         |\n",
      "|    total_timesteps    | 2916352      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.25334775   |\n",
      "|    entropy_loss       | -2.3         |\n",
      "|    explained_variance | 0.726        |\n",
      "|    learning_rate      | 0.00025      |\n",
      "|    loss               | -0.397       |\n",
      "|    mean_step_reward   | 0.0013354487 |\n",
      "|    n_updates          | 3550         |\n",
      "|    policyGradLoss     | -0.155       |\n",
      "|    value_loss         | 0.145        |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/SF84PT_2910720.zip\n",
      "[EVAL] Mean Return: 0.570, Best Return: 0.570\n",
      "New best record. Saved to ./runs_smw/best_model.zip\n",
      "Saved video to ./runs_smw/videos/step_2910720_mean_0.57.mp4\n",
      "\n",
      "=== Round 3 | Learn 655360 steps (Total trained: 2910720) ===\n",
      "Logging to ./runs_smw/tb/SF84_lRWD_PT_0\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 760     |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 10      |\n",
      "|    total_timesteps | 2924544 |\n",
      "--------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 375          |\n",
      "|    iterations         | 2            |\n",
      "|    time_elapsed       | 43           |\n",
      "|    total_timesteps    | 2932736      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.24571665   |\n",
      "|    entropy_loss       | -2.3         |\n",
      "|    explained_variance | 0.719        |\n",
      "|    learning_rate      | 0.00025      |\n",
      "|    loss               | -0.401       |\n",
      "|    mean_step_reward   | 0.0031347654 |\n",
      "|    n_updates          | 3570         |\n",
      "|    policyGradLoss     | -0.14        |\n",
      "|    value_loss         | 0.159        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 325           |\n",
      "|    iterations         | 3             |\n",
      "|    time_elapsed       | 75            |\n",
      "|    total_timesteps    | 2940928       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.2743747     |\n",
      "|    entropy_loss       | -2.29         |\n",
      "|    explained_variance | 0.849         |\n",
      "|    learning_rate      | 0.00025       |\n",
      "|    loss               | -0.399        |\n",
      "|    mean_step_reward   | -0.0013073734 |\n",
      "|    n_updates          | 3580          |\n",
      "|    policyGradLoss     | -0.156        |\n",
      "|    value_loss         | 0.0745        |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 306        |\n",
      "|    iterations         | 4          |\n",
      "|    time_elapsed       | 106        |\n",
      "|    total_timesteps    | 2949120    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.27471352 |\n",
      "|    entropy_loss       | -2.31      |\n",
      "|    explained_variance | 0.691      |\n",
      "|    learning_rate      | 0.00025    |\n",
      "|    loss               | -0.401     |\n",
      "|    mean_step_reward   | 0.00491333 |\n",
      "|    n_updates          | 3590       |\n",
      "|    policyGradLoss     | -0.137     |\n",
      "|    value_loss         | 0.154      |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 296          |\n",
      "|    iterations         | 5            |\n",
      "|    time_elapsed       | 138          |\n",
      "|    total_timesteps    | 2957312      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.22110541   |\n",
      "|    entropy_loss       | -2.32        |\n",
      "|    explained_variance | 0.726        |\n",
      "|    learning_rate      | 0.00025      |\n",
      "|    loss               | -0.387       |\n",
      "|    mean_step_reward   | 0.0011572263 |\n",
      "|    n_updates          | 3600         |\n",
      "|    policyGradLoss     | -0.135       |\n",
      "|    value_loss         | 0.171        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 290          |\n",
      "|    iterations         | 6            |\n",
      "|    time_elapsed       | 169          |\n",
      "|    total_timesteps    | 2965504      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.24387716   |\n",
      "|    entropy_loss       | -2.31        |\n",
      "|    explained_variance | 0.712        |\n",
      "|    learning_rate      | 0.00025      |\n",
      "|    loss               | -0.338       |\n",
      "|    mean_step_reward   | 0.0027087396 |\n",
      "|    n_updates          | 3610         |\n",
      "|    policyGradLoss     | -0.152       |\n",
      "|    value_loss         | 0.199        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 286          |\n",
      "|    iterations         | 7            |\n",
      "|    time_elapsed       | 200          |\n",
      "|    total_timesteps    | 2973696      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.24704248   |\n",
      "|    entropy_loss       | -2.31        |\n",
      "|    explained_variance | 0.742        |\n",
      "|    learning_rate      | 0.00025      |\n",
      "|    loss               | -0.396       |\n",
      "|    mean_step_reward   | 0.0022534183 |\n",
      "|    n_updates          | 3620         |\n",
      "|    policyGradLoss     | -0.158       |\n",
      "|    value_loss         | 0.207        |\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "best_mean = -1e18\n",
    "trained = 1_600_000\n",
    "round_idx = 0\n",
    "\n",
    "try:\n",
    "    while trained < TOTAL_STEPS:\n",
    "        round_idx += 1\n",
    "        chunk = min(TRAIN_CHUNK, TOTAL_STEPS - trained)\n",
    "        # chunk = 2000\n",
    "\n",
    "        print(f\"\\n=== Round {round_idx} | Learn {chunk} steps (Total trained: {trained}) ===\")\n",
    "        \n",
    "        # --- Train ---\n",
    "        model.learn(total_timesteps=chunk, reset_num_timesteps=False, tb_log_name='SF84_lRWD_PT')\n",
    "        trained += chunk\n",
    "\n",
    "        # --- Save Checkpoint ---\n",
    "        ckpt_path = os.path.join(CKPT_DIR, f\"SF84PT_{trained}.zip\")\n",
    "        model.save(ckpt_path)\n",
    "        print(f\"Saved checkpoint: {ckpt_path}\")\n",
    "\n",
    "        # --- Evaluate ---\n",
    "        mean_ret, best_ret = evaluate_policy(\n",
    "            model,\n",
    "            GAME,\n",
    "            STATE,\n",
    "            n_episodes=EVAL_EPISODES,\n",
    "            max_steps=EVAL_MAX_STEPS,\n",
    "        )\n",
    "        print(f\"[EVAL] Mean Return: {mean_ret:.3f}, Best Return: {best_ret:.3f}\")\n",
    "\n",
    "        # --- Save Best Model ---\n",
    "        if mean_ret > best_mean:\n",
    "            best_mean = mean_ret\n",
    "            best_path = os.path.join(LOG_DIR, \"best_model.zip\")\n",
    "            model.save(best_path)\n",
    "            print(f\"New best record. Saved to {best_path}\")\n",
    "\n",
    "        # --- Record Video ---\n",
    "        record_video(\n",
    "            model,\n",
    "            GAME,\n",
    "            STATE,\n",
    "            VIDEO_DIR,\n",
    "            video_len=RECORD_STEPS,\n",
    "            prefix=f\"step_{trained}_mean_{mean_ret:.2f}\",\n",
    "        )\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nTraining interrupted manually.\")\n",
    "\n",
    "finally:\n",
    "    train_env.close()\n",
    "    print(\"Training finished. Environment closed.\")\n",
    "    \n",
    "\"\"\"\n",
    "tensorboard --logdir=./runs_smw/tb\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f088b0b3-2418-4866-b332-0312c9f6467f",
   "metadata": {},
   "source": [
    "## Display Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73191bb-e875-4939-b04c-a4670abd9612",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Video\n",
    "import glob\n",
    "\n",
    "list_of_files = glob.glob(os.path.join(VIDEO_DIR, '*.mp4')) \n",
    "if list_of_files:\n",
    "    latest_file = max(list_of_files, key=os.path.getctime)\n",
    "    print(f\"Playing: {latest_file}\")\n",
    "    display(Video(latest_file, embed=True, width=600))\n",
    "else:\n",
    "    print(\"No videos found yet.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Lab8 (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
